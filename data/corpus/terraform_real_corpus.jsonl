{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"null\" {}\n\nresource \"aws_dms_certificate\" \"test\" {\n  certificate_id  = var.rName\n\n  tags = {\n    (var.unknownTagKey) = null_resource.test.id\n    (var.knownTagKey)   = var.knownTagValue\n  }\n}\n\nresource \"null_resource\" \"test\" {}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"unknownTagKey\" {\n  type     = string\n  nullable = false\n}\n\nvariable \"knownTagKey\" {\n  type     = string\n  nullable = false\n}\n\nvariable \"knownTagValue\" {\n  type     = string\n  nullable = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/Certificate/tagsComputed2/main_gen.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"null\" {}\n\nresource \"aws_dms_certificate\" \"test\" {\n  certificate_id  = var.rName\n\n  tags = {\n    (var.unknownTagKey) = null_resource.test.id\n  }\n}\n\nresource \"null_resource\" \"test\" {}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"unknownTagKey\" {\n  type     = string\n  nullable = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/Certificate/tagsComputed1/main_gen.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\n# tflint-ignore: terraform_unused_declarations\ndata \"aws_dms_replication_task\" \"test\" {\n  replication_task_id = aws_dms_replication_task.test.replication_task_id\n}\n\nresource \"aws_dms_replication_task\" \"test\" {\n  replication_task_id      = var.rName\n  migration_type           = \"full-load\"\n  replication_instance_arn = aws_dms_replication_instance.test.replication_instance_arn\n  source_endpoint_arn      = aws_dms_endpoint.source.endpoint_arn\n  target_endpoint_arn      = aws_dms_endpoint.target.endpoint_arn\n  table_mappings = jsonencode(\n    {\n      \"rules\" = [\n        {\n          \"rule-type\" = \"selection\",\n          \"rule-id\"   = \"1\",\n          \"rule-name\" = \"1\",\n          \"object-locator\" = {\n            \"schema-name\" = \"%\",\n            \"table-name\"  = \"%\"\n          },\n          \"rule-action\" = \"include\"\n        }\n      ]\n    }\n  )\n\n  tags = var.resource_tags\n}\n\n# testAccReplicationTaskConfig_base\n\nresource \"aws_dms_replication_subnet_group\" \"test\" {\n  replication_subnet_group_id          = var.rName\n  replication_subnet_group_description = \"terraform test for replication subnet group\"\n  subnet_ids                           = aws_subnet.test[*].id\n}\n\nresource \"aws_dms_replication_instance\" \"test\" {\n  allocated_storage            = 5\n  auto_minor_version_upgrade   = true\n  replication_instance_class   = \"dms.t3.medium\"\n  replication_instance_id      = var.rName\n  preferred_maintenance_window = \"sun:00:30-sun:02:30\"\n  publicly_accessible          = false\n  replication_subnet_group_id  = aws_dms_replication_subnet_group.test.replication_subnet_group_id\n}\n\n# testAccReplicationEndpointConfig_dummyDatabase\n\ndata \"aws_partition\" \"current\" {}\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_dms_endpoint\" \"source\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-source\"\n  endpoint_type = \"source\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\nresource \"aws_dms_endpoint\" \"target\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-target\"\n  endpoint_type = \"target\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\n# acctest.ConfigVPCWithSubnets(rName, 2)\n\nresource \"aws_vpc\" \"test\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"test\" {\n  count = 2\n\n  vpc_id            = aws_vpc.test.id\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n  cidr_block        = cidrsubnet(aws_vpc.test.cidr_block, 8, count.index)\n}\n\n# acctest.ConfigAvailableAZsNoOptInDefaultExclude\n\ndata \"aws_availability_zones\" \"available\" {\n  exclude_zone_ids = local.default_exclude_zone_ids\n  state            = \"available\"\n\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\nlocals {\n  default_exclude_zone_ids = [\"usw2-az4\", \"usgw1-az2\"]\n}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"resource_tags\" {\n  description = \"Tags to set on resource. To specify no tags, set to `null`\"\n  # Not setting a default, so that this must explicitly be set to `null` to specify no tags\n  type     = map(string)\n  nullable = true\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/ReplicationTask/data.tags/main_gen.tf", "category": "networking", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"null\" {}\n\nresource \"aws_dms_replication_task\" \"test\" {\n  replication_task_id      = var.rName\n  migration_type           = \"full-load\"\n  replication_instance_arn = aws_dms_replication_instance.test.replication_instance_arn\n  source_endpoint_arn      = aws_dms_endpoint.source.endpoint_arn\n  target_endpoint_arn      = aws_dms_endpoint.target.endpoint_arn\n  table_mappings = jsonencode(\n    {\n      \"rules\" = [\n        {\n          \"rule-type\" = \"selection\",\n          \"rule-id\"   = \"1\",\n          \"rule-name\" = \"1\",\n          \"object-locator\" = {\n            \"schema-name\" = \"%\",\n            \"table-name\"  = \"%\"\n          },\n          \"rule-action\" = \"include\"\n        }\n      ]\n    }\n  )\n\n  tags = {\n    (var.unknownTagKey) = null_resource.test.id\n    (var.knownTagKey)   = var.knownTagValue\n  }\n}\n\n# testAccReplicationTaskConfig_base\n\nresource \"aws_dms_replication_subnet_group\" \"test\" {\n  replication_subnet_group_id          = var.rName\n  replication_subnet_group_description = \"terraform test for replication subnet group\"\n  subnet_ids                           = aws_subnet.test[*].id\n}\n\nresource \"aws_dms_replication_instance\" \"test\" {\n  allocated_storage            = 5\n  auto_minor_version_upgrade   = true\n  replication_instance_class   = \"dms.t3.medium\"\n  replication_instance_id      = var.rName\n  preferred_maintenance_window = \"sun:00:30-sun:02:30\"\n  publicly_accessible          = false\n  replication_subnet_group_id  = aws_dms_replication_subnet_group.test.replication_subnet_group_id\n}\n\n# testAccReplicationEndpointConfig_dummyDatabase\n\ndata \"aws_partition\" \"current\" {}\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_dms_endpoint\" \"source\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-source\"\n  endpoint_type = \"source\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\nresource \"aws_dms_endpoint\" \"target\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-target\"\n  endpoint_type = \"target\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\n# acctest.ConfigVPCWithSubnets(rName, 2)\n\nresource \"aws_vpc\" \"test\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"test\" {\n  count = 2\n\n  vpc_id            = aws_vpc.test.id\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n  cidr_block        = cidrsubnet(aws_vpc.test.cidr_block, 8, count.index)\n}\n\n# acctest.ConfigAvailableAZsNoOptInDefaultExclude\n\ndata \"aws_availability_zones\" \"available\" {\n  exclude_zone_ids = local.default_exclude_zone_ids\n  state            = \"available\"\n\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\nlocals {\n  default_exclude_zone_ids = [\"usw2-az4\", \"usgw1-az2\"]\n}\n\nresource \"null_resource\" \"test\" {}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"unknownTagKey\" {\n  type     = string\n  nullable = false\n}\n\nvariable \"knownTagKey\" {\n  type     = string\n  nullable = false\n}\n\nvariable \"knownTagValue\" {\n  type     = string\n  nullable = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/ReplicationTask/tagsComputed2/main_gen.tf", "category": "networking", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"aws\" {\n  default_tags {\n    tags = var.provider_tags\n  }\n  ignore_tags {\n    keys = var.ignore_tag_keys\n  }\n}\n\nresource \"aws_dms_replication_task\" \"test\" {\n  replication_task_id      = var.rName\n  migration_type           = \"full-load\"\n  replication_instance_arn = aws_dms_replication_instance.test.replication_instance_arn\n  source_endpoint_arn      = aws_dms_endpoint.source.endpoint_arn\n  target_endpoint_arn      = aws_dms_endpoint.target.endpoint_arn\n  table_mappings = jsonencode(\n    {\n      \"rules\" = [\n        {\n          \"rule-type\" = \"selection\",\n          \"rule-id\"   = \"1\",\n          \"rule-name\" = \"1\",\n          \"object-locator\" = {\n            \"schema-name\" = \"%\",\n            \"table-name\"  = \"%\"\n          },\n          \"rule-action\" = \"include\"\n        }\n      ]\n    }\n  )\n\n  tags = var.resource_tags\n}\n\n# testAccReplicationTaskConfig_base\n\nresource \"aws_dms_replication_subnet_group\" \"test\" {\n  replication_subnet_group_id          = var.rName\n  replication_subnet_group_description = \"terraform test for replication subnet group\"\n  subnet_ids                           = aws_subnet.test[*].id\n}\n\nresource \"aws_dms_replication_instance\" \"test\" {\n  allocated_storage            = 5\n  auto_minor_version_upgrade   = true\n  replication_instance_class   = \"dms.t3.medium\"\n  replication_instance_id      = var.rName\n  preferred_maintenance_window = \"sun:00:30-sun:02:30\"\n  publicly_accessible          = false\n  replication_subnet_group_id  = aws_dms_replication_subnet_group.test.replication_subnet_group_id\n}\n\n# testAccReplicationEndpointConfig_dummyDatabase\n\ndata \"aws_partition\" \"current\" {}\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_dms_endpoint\" \"source\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-source\"\n  endpoint_type = \"source\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\nresource \"aws_dms_endpoint\" \"target\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-target\"\n  endpoint_type = \"target\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\n# acctest.ConfigVPCWithSubnets(rName, 2)\n\nresource \"aws_vpc\" \"test\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"test\" {\n  count = 2\n\n  vpc_id            = aws_vpc.test.id\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n  cidr_block        = cidrsubnet(aws_vpc.test.cidr_block, 8, count.index)\n}\n\n# acctest.ConfigAvailableAZsNoOptInDefaultExclude\n\ndata \"aws_availability_zones\" \"available\" {\n  exclude_zone_ids = local.default_exclude_zone_ids\n  state            = \"available\"\n\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\nlocals {\n  default_exclude_zone_ids = [\"usw2-az4\", \"usgw1-az2\"]\n}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"resource_tags\" {\n  description = \"Tags to set on resource. To specify no tags, set to `null`\"\n  # Not setting a default, so that this must explicitly be set to `null` to specify no tags\n  type     = map(string)\n  nullable = true\n}\n\nvariable \"provider_tags\" {\n  type     = map(string)\n  nullable = true\n  default  = null\n}\n\nvariable \"ignore_tag_keys\" {\n  type     = set(string)\n  nullable = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/ReplicationTask/tags_ignore/main_gen.tf", "category": "networking", "authentic": true}}
{"prompt": "Create a Terraform configuration for Azure security groups", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"${var.prefix}-resources\"\n  location = var.location\n}\n\nresource \"azurerm_virtual_network\" \"example\" {\n  name                = \"${var.prefix}-VN\"\n  address_space       = [\"10.0.0.0/16\"]\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n}\n\nresource \"azurerm_subnet\" \"example\" {\n  name                 = \"${var.prefix}-SN\"\n  resource_group_name  = azurerm_resource_group.example.name\n  virtual_network_name = azurerm_virtual_network.example.name\n  address_prefixes     = [\"10.0.0.0/24\"]\n}\n\nresource \"azurerm_subnet_network_security_group_association\" \"example\" {\n  subnet_id                 = azurerm_subnet.example.id\n  network_security_group_id = azurerm_network_security_group.example.id\n}\n\nresource \"azurerm_public_ip\" \"vm\" {\n  name                = \"${var.prefix}-PIP\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  allocation_method   = \"Dynamic\"\n}\n\nresource \"azurerm_network_security_group\" \"example\" {\n  name                = \"${var.prefix}-NSG\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n}\n\nresource \"azurerm_network_security_rule\" \"RDPRule\" {\n  name                        = \"RDPRule\"\n  resource_group_name         = azurerm_resource_group.example.name\n  priority                    = 1000\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = 3389\n  source_address_prefix       = \"167.220.255.0/25\"\n  destination_address_prefix  = \"*\"\n  network_security_group_name = azurerm_network_security_group.example.name\n}\n\nresource \"azurerm_network_security_rule\" \"MSSQLRule\" {\n  name                        = \"MSSQLRule\"\n  resource_group_name         = azurerm_resource_group.example.name\n  priority                    = 1001\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = 1433\n  source_address_prefix       = \"167.220.255.0/25\"\n  destination_address_prefix  = \"*\"\n  network_security_group_name = azurerm_network_security_group.example.name\n}\n\nresource \"azurerm_network_interface\" \"example\" {\n  name                = \"${var.prefix}-NIC\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n\n  ip_configuration {\n    name                          = \"exampleconfiguration1\"\n    subnet_id                     = azurerm_subnet.example.id\n    private_ip_address_allocation = \"Dynamic\"\n    public_ip_address_id          = azurerm_public_ip.vm.id\n  }\n}\n\nresource \"azurerm_network_interface_security_group_association\" \"example\" {\n  network_interface_id      = azurerm_network_interface.example.id\n  network_security_group_id = azurerm_network_security_group.example.id\n}\n\nresource \"azurerm_virtual_machine\" \"example\" {\n  name                  = \"${var.prefix}-VM\"\n  location              = azurerm_resource_group.example.location\n  resource_group_name   = azurerm_resource_group.example.name\n  network_interface_ids = [azurerm_network_interface.example.id]\n  vm_size               = \"Standard_DS14_v2\"\n\n  storage_image_reference {\n    publisher = \"MicrosoftSQLServer\"\n    offer     = \"SQL2017-WS2016\"\n    sku       = \"SQLDEV\"\n    version   = \"laexample\"\n  }\n\n  storage_os_disk {\n    name              = \"${var.prefix}-OSDisk\"\n    caching           = \"ReadOnly\"\n    create_option     = \"FromImage\"\n    managed_disk_type = \"Premium_LRS\"\n  }\n\n  os_profile {\n    computer_name  = \"winhost01\"\n    admin_username = \"exampleadmin\"\n    admin_password = \"<REDACTED>\"\n  }\n\n  os_profile_windows_config {\n    timezone                  = \"Pacific Standard Time\"\n    provision_vm_agent        = true\n    enable_automatic_upgrades = true\n  }\n}\n\nresource \"azurerm_mssql_virtual_machine\" \"example\" {\n  virtual_machine_id = azurerm_virtual_machine.example.id\n  sql_license_type   = \"PAYG\"\n}\n\nresource \"azurerm_virtual_network\" \"test\" {\n  name                = \"${var.prefix}-VN\"\n  address_space       = [\"10.0.0.0/16\"]\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n}\n\nresource \"azurerm_subnet\" \"test\" {\n  name                 = \"internal\"\n  resource_group_name  = azurerm_resource_group.example.name\n  virtual_network_name = azurerm_virtual_network.test.name\n  address_prefixes     = [\"10.0.2.0/24\"]\n}\n\nresource \"azurerm_public_ip\" \"test\" {\n  name                = \"${var.prefix}-PIP\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  allocation_method   = \"Dynamic\"\n}\n\nresource \"azurerm_network_interface\" \"test\" {\n  name                = \"${var.prefix}-INT\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n\n  ip_configuration {\n    name                          = \"internal\"\n    subnet_id                     = azurerm_subnet.test.id\n    private_ip_address_allocation = \"Dynamic\"\n    public_ip_address_id          = azurerm_public_ip.test.id\n  }\n}\n\nresource \"azurerm_virtual_machine\" \"test\" {\n  name                  = \"${var.prefix}-VM\"\n  location              = azurerm_resource_group.example.location\n  resource_group_name   = azurerm_resource_group.example.name\n  network_interface_ids = [azurerm_network_interface.test.id]\n  vm_size               = \"Standard_F4\"\n\n  storage_image_reference {\n    publisher = \"MicrosoftWindowsServer\"\n    offer     = \"WindowsServer\"\n    sku       = \"2016-Datacenter\"\n    version   = \"latest\"\n  }\n\n  storage_os_disk {\n    name              = \"myosdisk1\"\n    caching           = \"ReadWrite\"\n    create_option     = \"FromImage\"\n    managed_disk_type = \"Standard_LRS\"\n  }\n\n  os_profile {\n    computer_name  = \"${var.prefix}-VM\"\n    admin_username = \"testadmin\"\n    admin_password = \"<REDACTED>\"\n  }\n\n  os_profile_windows_config {\n    timezone           = \"Pacific Standard Time\"\n    provision_vm_agent = true\n  }\n}\n\nresource \"azurerm_virtual_machine_extension\" \"test\" {\n  name                 = \"${var.prefix}-EXT\"\n  virtual_machine_id   = azurerm_virtual_machine.test.id\n  publisher            = \"Microsoft.Compute\"\n  type                 = \"CustomScriptExtension\"\n  type_handler_version = \"1.10\"\n  settings = jsonencode({\n    \"fileUris\"         = [\"https://raw.githubusercontent.com/Azure/azure-quickstart-templates/<TOKEN>/101-vms-with-selfhost-integration-runtime/gatewayInstall.ps1\"],\n    \"commandToExecute\" = \"powershell -ExecutionPolicy Unrestricted -File gatewayInstall.ps1 ${azurerm_data_factory_integration_runtime_self_hosted.host.primary_authorization_key} && timeout /t 120\"\n  })\n}\n\nresource \"azurerm_resource_group\" \"host\" {\n  name     = \"${var.prefix}-resources\"\n  location = var.location\n}\n\nresource \"azurerm_data_factory\" \"host\" {\n  name                = \"${var.prefix}DFHOST\"\n  location            = azurerm_resource_group.host.location\n  resource_group_name = azurerm_resource_group.host.name\n}\n\nresource \"azurerm_data_factory_integration_runtime_self_hosted\" \"host\" {\n  name            = \"${var.prefix}IRHOST\"\n  data_factory_id = azurerm_data_factory.host.id\n}\n\nresource \"azurerm_resource_group\" \"target\" {\n  name     = \"${var.prefix}-resources\"\n  location = var.location\n}\n\nresource \"azurerm_role_assignment\" \"target\" {\n  scope                = azurerm_data_factory.host.id\n  role_definition_name = \"Contributor\"\n  principal_id         = azurerm_data_factory.target.identity[0].principal_id\n}\n\nresource \"azurerm_data_factory\" \"target\" {\n  name                = \"${var.prefix}DFTGT\"\n  location            = azurerm_resource_group.target.location\n  resource_group_name = azurerm_resource_group.target.name\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n}\n\nresource \"azurerm_data_factory_integration_runtime_self_hosted\" \"target\" {\n  name            = \"${var.prefix}IRTGT\"\n  data_factory_id = azurerm_data_factory.target.id\n\n  rbac_authorization {\n    resource_id = azurerm_data_factory_integration_runtime_self_hosted.host.id\n  }\n\n  depends_on = [azurerm_role_assignment.target, azurerm_virtual_machine_extension.test]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-azurerm/examples/data-factory/shared-self-hosted/main.tf", "category": "security", "authentic": true}}
{"prompt": "Create a Terraform configuration for Azure Kubernetes cluster", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\noutput \"id\" {\n  value = azurerm_kubernetes_cluster.example.id\n}\n\noutput \"kube_config\" {\n  value = azurerm_kubernetes_cluster.example.kube_config_raw\n}\n\noutput \"client_key\" {\n  value = azurerm_kubernetes_cluster.example.kube_config.0.client_key\n}\n\noutput \"client_certificate\" {\n  value = azurerm_kubernetes_cluster.example.kube_config.0.client_certificate\n}\n\noutput \"cluster_ca_certificate\" {\n  value = azurerm_kubernetes_cluster.example.kube_config.0.cluster_ca_certificate\n}\n\noutput \"host\" {\n  value = azurerm_kubernetes_cluster.example.kube_config.0.host\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-azurerm/examples/kubernetes/spot-node-pool/outputs.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Create a Terraform configuration for Azure Kubernetes cluster", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"${var.prefix}-k8s-resources\"\n  location = var.location\n}\n\nresource \"azurerm_kubernetes_cluster\" \"example\" {\n  name                = \"${var.prefix}-k8s\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  dns_prefix          = \"${var.prefix}-k8s\"\n\n  default_node_pool {\n    name       = \"default\"\n    node_count = 1\n    vm_size    = \"Standard_DS2_v2\"\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n}\n\nresource \"azurerm_kubernetes_cluster_node_pool\" \"example\" {\n  name                  = \"spot\"\n  kubernetes_cluster_id = azurerm_kubernetes_cluster.example.id\n  vm_size               = \"Standard_DS2_v2\"\n  node_count            = 1\n  priority              = \"Spot\"\n  eviction_policy       = \"Delete\"\n  spot_max_price        = 0.5 # note: this is the \"maximum\" price\n  node_labels = {\n    \"kubernetes.azure.com/scalesetpriority\" = \"spot\"\n  }\n  node_taints = [\n    \"kubernetes.azure.com/scalesetpriority=spot:NoSchedule\"\n  ]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-azurerm/examples/kubernetes/spot-node-pool/main.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Create a Terraform configuration for Azure Kubernetes cluster", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"${var.prefix}-k8s-resources\"\n  location = var.location\n}\n\nresource \"azurerm_virtual_network\" \"example\" {\n  name                = \"${var.prefix}-network\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  address_space       = [\"10.1.0.0/16\"]\n}\n\nresource \"azurerm_subnet\" \"internal\" {\n  name                 = \"internal\"\n  virtual_network_name = azurerm_virtual_network.example.name\n  resource_group_name  = azurerm_resource_group.example.name\n  address_prefixes     = [\"10.1.0.0/22\"]\n}\n\nresource \"azurerm_kubernetes_cluster\" \"example\" {\n  name                = \"${var.prefix}-k8s\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  dns_prefix          = \"${var.prefix}-k8s\"\n\n  default_node_pool {\n    name           = \"system\"\n    node_count     = 1\n    vm_size        = \"Standard_DS2_v2\"\n    vnet_subnet_id = azurerm_subnet.internal.id\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n}\n\nresource \"azurerm_kubernetes_cluster_node_pool\" \"user\" {\n  name                  = \"user\"\n  kubernetes_cluster_id = azurerm_kubernetes_cluster.example.id\n  vm_size               = \"Standard_DS2_v2\"\n  node_count            = 1\n  vnet_subnet_id        = azurerm_subnet.internal.id\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-azurerm/examples/kubernetes/nodes-on-internal-network/main.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\n# https://cloud.google.com/vpc/docs/shared-vpc\n\nprovider \"google\" {\n  region      = var.region\n  credentials = file(var.credentials_file_path)\n}\n\nprovider \"random\" {\n}\n\nresource \"random_id\" \"host_project_name\" {\n  byte_length = 8\n}\n\nresource \"random_id\" \"service_project_1_name\" {\n  byte_length = 8\n}\n\nresource \"random_id\" \"service_project_2_name\" {\n  byte_length = 8\n}\n\nresource \"random_id\" \"standalone_project_name\" {\n  byte_length = 8\n}\n\n# The project which owns the VPC.\nresource \"google_project\" \"host_project\" {\n  name            = \"Host Project\"\n  project_id      = \"tf-vpc-${random_id.host_project_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\n# One project which will use the VPC.\nresource \"google_project\" \"service_project_1\" {\n  name            = \"Service Project 1\"\n  project_id      = \"tf-vpc-${random_id.service_project_1_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\n# The other project which will use the VPC.\nresource \"google_project\" \"service_project_2\" {\n  name            = \"Service Project 2\"\n  project_id      = \"tf-vpc-${random_id.service_project_2_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\n# A project which will not use the VPC, for the sake of demonstration.\nresource \"google_project\" \"standalone_project\" {\n  name            = \"Standalone Project\"\n  project_id      = \"tf-vpc-${random_id.standalone_project_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\n# Compute service needs to be enabled for all four new projects.\nresource \"google_project_service\" \"host_project\" {\n  project = google_project.host_project.project_id\n  service = \"compute.googleapis.com\"\n}\n\nresource \"google_project_service\" \"service_project_1\" {\n  project = google_project.service_project_1.project_id\n  service = \"compute.googleapis.com\"\n}\n\nresource \"google_project_service\" \"service_project_2\" {\n  project = google_project.service_project_2.project_id\n  service = \"compute.googleapis.com\"\n}\n\nresource \"google_project_service\" \"standalone_project\" {\n  project = google_project.standalone_project.project_id\n  service = \"compute.googleapis.com\"\n}\n\n# Enable shared VPC hosting in the host project.\nresource \"google_compute_shared_vpc_host_project\" \"host_project\" {\n  project    = google_project.host_project.project_id\n  depends_on = [google_project_service.host_project]\n}\n\n# Enable shared VPC in the two service projects - explicitly depend on the host\n# project enabling it, because enabling shared VPC will fail if the host project\n# is not yet hosting.\nresource \"google_compute_shared_vpc_service_project\" \"service_project_1\" {\n  host_project    = google_project.host_project.project_id\n  service_project = google_project.service_project_1.project_id\n\n  depends_on = [\n    google_compute_shared_vpc_host_project.host_project,\n    google_project_service.service_project_1,\n  ]\n}\n\nresource \"google_compute_shared_vpc_service_project\" \"service_project_2\" {\n  host_project    = google_project.host_project.project_id\n  service_project = google_project.service_project_2.project_id\n\n  depends_on = [\n    google_compute_shared_vpc_host_project.host_project,\n    google_project_service.service_project_2,\n  ]\n}\n\n# Create the hosted network.\nresource \"google_compute_network\" \"shared_network\" {\n  name                    = \"shared-network\"\n  auto_create_subnetworks = \"true\"\n  project                 = google_compute_shared_vpc_host_project.host_project.project\n\n  depends_on = [\n    google_compute_shared_vpc_service_project.service_project_1,\n    google_compute_shared_vpc_service_project.service_project_2,\n  ]\n}\n\n# Allow the hosted network to be hit over ICMP, SSH, and HTTP.\nresource \"google_compute_firewall\" \"shared_network\" {\n  name    = \"allow-ssh-and-icmp\"\n  network = google_compute_network.shared_network.self_link\n  project = google_compute_network.shared_network.project\n\n  allow {\n    protocol = \"icmp\"\n  }\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\", \"80\"]\n  }\n}\n\n# Create a standalone network with the same firewall rules.\nresource \"google_compute_network\" \"standalone_network\" {\n  name                    = \"standalone-network\"\n  auto_create_subnetworks = \"true\"\n  project                 = google_project.standalone_project.project_id\n  depends_on              = [google_project_service.standalone_project]\n}\n\nresource \"google_compute_firewall\" \"standalone_network\" {\n  name    = \"allow-ssh-and-icmp\"\n  network = google_compute_network.standalone_network.self_link\n\n  allow {\n    protocol = \"icmp\"\n  }\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\", \"80\"]\n  }\n\n  project = google_project.standalone_project.project_id\n}\n\n# Create a VM which hosts a web page stating its identity (\"VM1\")\nresource \"google_compute_instance\" \"project_1_vm\" {\n  name         = \"tf-project-1-vm\"\n  project      = google_project.service_project_1.project_id\n  machine_type = \"f1-micro\"\n  zone         = var.region_zone\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  metadata_startup_script = \"VM_NAME=VM1\\n${file(\"scripts/install-vm.sh\")}\"\n\n  network_interface {\n    network = google_compute_network.shared_network.self_link\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n\n  depends_on = [google_project_service.service_project_1]\n}\n\n# Create a VM which hosts a web page demonstrating the example networking.\nresource \"google_compute_instance\" \"project_2_vm\" {\n  name         = \"tf-project-2-vm\"\n  machine_type = \"f1-micro\"\n  project      = google_project.service_project_2.project_id\n  zone         = var.region_zone\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  metadata_startup_script = <<EOF\nVM1_EXT_IP=${google_compute_instance.project_1_vm.network_interface[0].access_config[0].nat_ip}\nST_VM_EXT_IP=${google_compute_instance.standalone_project_vm.network_interface[0].access_config[0].nat_ip}\nVM1_INT_IP=${google_compute_instance.project_1_vm.network_interface[0].address}\nST_VM_INT_IP=${google_compute_instance.standalone_project_vm.network_interface[0].address}\n${file(\"scripts/install-network-page.sh\")}\nEOF\n\n\n  network_interface {\n    network = google_compute_network.shared_network.self_link\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n\n  depends_on = [google_project_service.service_project_2]\n}\n\n# Create a VM which hosts a web page stating its identity (\"standalone\").\nresource \"google_compute_instance\" \"standalone_project_vm\" {\n  name         = \"tf-standalone-vm\"\n  machine_type = \"f1-micro\"\n  project      = google_project.standalone_project.project_id\n  zone         = var.region_zone\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  metadata_startup_script = \"VM_NAME=standalone\\n${file(\"scripts/install-vm.sh\")}\"\n\n  network_interface {\n    network = google_compute_network.standalone_network.self_link\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n\n  depends_on = [google_project_service.standalone_project]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/shared-vpc/main.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\n# Example for using Cloud Armor https://cloud.google.com/armor/\n#\n\nresource \"random_id\" \"instance_id\" {\n  byte_length = 4\n}\n\n# Configure the Google Cloud provider\nprovider \"google\" {\n  credentials = file(var.credentials_file_path)\n  project     = var.project_name\n  region      = var.region\n  zone        = var.region_zone\n}\n\n# Set up a backend to be proxied to:\n# A single instance in a pool running nginx with port 80 open will allow end to end network testing\nresource \"google_compute_instance\" \"cluster1\" {\n  name         = \"armor-gce-${random_id.instance_id.hex}\"\n  machine_type = \"f1-micro\"\n\n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-9\"\n    }\n  }\n\n  network_interface {\n    network = \"default\"\n    access_config {\n      # Ephemeral IP\n    }\n  }\n\n  metadata_startup_script = \"sudo apt-get update; sudo apt-get install -yq nginx; sudo service nginx restart\"\n}\n\nresource \"google_compute_firewall\" \"cluster1\" {\n  name    = \"armor-firewall\"\n  network = \"default\"\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"80\", \"43\"]\n  }\n}\n\nresource \"google_compute_instance_group\" \"webservers\" {\n  name        = \"instance-group-all\"\n  description = \"An instance group for the single GCE instance\"\n\n  instances = [\n    google_compute_instance.cluster1.self_link,\n  ]\n\n  named_port {\n    name = \"http\"\n    port = \"80\"\n  }\n}\n\nresource \"google_compute_target_pool\" \"example\" {\n  name = \"armor-pool\"\n\n  instances = [\n    google_compute_instance.cluster1.self_link,\n  ]\n\n  health_checks = [\n    google_compute_http_health_check.health.name,\n  ]\n}\n\nresource \"google_compute_http_health_check\" \"health\" {\n  name               = \"armor-healthcheck\"\n  request_path       = \"/\"\n  check_interval_sec = 1\n  timeout_sec        = 1\n}\n\nresource \"google_compute_backend_service\" \"website\" {\n  name        = \"armor-backend\"\n  description = \"Our company website\"\n  port_name   = \"http\"\n  protocol    = \"HTTP\"\n  timeout_sec = 10\n  enable_cdn  = false\n\n  backend {\n    group = google_compute_instance_group.webservers.self_link\n  }\n\n  security_policy = google_compute_security_policy.security-policy-1.self_link\n\n  health_checks = [google_compute_http_health_check.health.self_link]\n}\n\n# Cloud Armor Security policies\nresource \"google_compute_security_policy\" \"security-policy-1\" {\n  name        = \"armor-security-policy\"\n  description = \"example security policy\"\n\n  # Reject all traffic that hasn't been whitelisted.\n  rule {\n    action   = \"deny(403)\"\n    priority = \"2147483647\"\n\n    match {\n      versioned_expr = \"SRC_IPS_V1\"\n\n      config {\n        src_ip_ranges = [\"*\"]\n      }\n    }\n\n    description = \"Default rule, higher priority overrides it\"\n  }\n\n  # Whitelist traffic from certain ip address\n  rule {\n    action   = \"allow\"\n    priority = \"1000\"\n\n    match {\n      versioned_expr = \"SRC_IPS_V1\"\n\n      config {\n        src_ip_ranges = var.ip_white_list\n      }\n    }\n\n    description = \"allow traffic from 192.0.2.0/24\"\n  }\n}\n\n# Front end of the load balancer\nresource \"google_compute_global_forwarding_rule\" \"default\" {\n  name       = \"armor-rule\"\n  target     = google_compute_target_http_proxy.default.self_link\n  port_range = \"80\"\n}\n\nresource \"google_compute_target_http_proxy\" \"default\" {\n  name    = \"armor-proxy\"\n  url_map = google_compute_url_map.default.self_link\n}\n\nresource \"google_compute_url_map\" \"default\" {\n  name            = \"armor-url-map\"\n  default_service = google_compute_backend_service.website.self_link\n\n  host_rule {\n    hosts        = [\"mysite.com\"]\n    path_matcher = \"allpaths\"\n  }\n\n  path_matcher {\n    name            = \"allpaths\"\n    default_service = google_compute_backend_service.website.self_link\n\n    path_rule {\n      paths   = [\"/*\"]\n      service = google_compute_backend_service.website.self_link\n    }\n  }\n}\n\noutput \"ip\" {\n  value = google_compute_global_forwarding_rule.default.ip_address\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/cloud-armor/main.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\n# https://cloud.google.com/compute/docs/load-balancing/http/content-based-example\n\nprovider \"google\" {\n  region      = var.region\n  project     = var.project_name\n  credentials = file(var.credentials_file_path)\n  zone        = var.region_zone\n}\n\nresource \"google_compute_instance\" \"www\" {\n  name         = \"tf-www-compute\"\n  machine_type = \"f1-micro\"\n  tags         = [\"http-tag\"]\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  network_interface {\n    network = \"default\"\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  metadata_startup_script = file(\"scripts/install-www.sh\")\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n}\n\nresource \"google_compute_instance\" \"www-video\" {\n  name         = \"tf-www-video-compute\"\n  machine_type = \"f1-micro\"\n  tags         = [\"http-tag\"]\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  network_interface {\n    network = \"default\"\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  metadata_startup_script = file(\"scripts/install-video.sh\")\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n}\n\nresource \"google_compute_global_address\" \"external-address\" {\n  name = \"tf-external-address\"\n}\n\nresource \"google_compute_instance_group\" \"www-resources\" {\n  name = \"tf-www-resources\"\n\n  instances = [google_compute_instance.www.self_link]\n\n  named_port {\n    name = \"http\"\n    port = \"80\"\n  }\n}\n\nresource \"google_compute_instance_group\" \"video-resources\" {\n  name = \"tf-video-resources\"\n\n  instances = [google_compute_instance.www-video.self_link]\n\n  named_port {\n    name = \"http\"\n    port = \"80\"\n  }\n}\n\nresource \"google_compute_health_check\" \"health-check\" {\n  name = \"tf-health-check\"\n\n  http_health_check {\n  }\n}\n\nresource \"google_compute_backend_service\" \"www-service\" {\n  name     = \"tf-www-service\"\n  protocol = \"HTTP\"\n\n  backend {\n    group = google_compute_instance_group.www-resources.self_link\n  }\n\n  health_checks = [google_compute_health_check.health-check.self_link]\n}\n\nresource \"google_compute_backend_service\" \"video-service\" {\n  name     = \"tf-video-service\"\n  protocol = \"HTTP\"\n\n  backend {\n    group = google_compute_instance_group.video-resources.self_link\n  }\n\n  health_checks = [google_compute_health_check.health-check.self_link]\n}\n\nresource \"google_compute_url_map\" \"web-map\" {\n  name            = \"tf-web-map\"\n  default_service = google_compute_backend_service.www-service.self_link\n\n  host_rule {\n    hosts        = [\"*\"]\n    path_matcher = \"tf-allpaths\"\n  }\n\n  path_matcher {\n    name            = \"tf-allpaths\"\n    default_service = google_compute_backend_service.www-service.self_link\n\n    path_rule {\n      paths   = [\"/video\", \"/video/*\"]\n      service = google_compute_backend_service.video-service.self_link\n    }\n  }\n}\n\nresource \"google_compute_target_http_proxy\" \"http-lb-proxy\" {\n  name    = \"tf-http-lb-proxy\"\n  url_map = google_compute_url_map.web-map.self_link\n}\n\nresource \"google_compute_global_forwarding_rule\" \"default\" {\n  name       = \"tf-http-content-gfr\"\n  target     = google_compute_target_http_proxy.http-lb-proxy.self_link\n  ip_address = google_compute_global_address.external-address.address\n  port_range = \"80\"\n}\n\nresource \"google_compute_firewall\" \"default\" {\n  name    = \"tf-www-firewall-allow-internal-only\"\n  network = \"default\"\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"80\"]\n  }\n\n  source_ranges = [\"130.211.0.0/22\", \"35.191.0.0/16\"]\n  target_tags   = [\"http-tag\"]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/content-based-load-balancing/main.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\nprovider \"google\" {\n  region      = var.region\n  credentials = file(var.credentials_file_path)\n}\n\nprovider \"random\" {\n}\n\nresource \"random_id\" \"project_name\" {\n  byte_length = 8\n}\n\nresource \"google_project\" \"endpoints_project\" {\n  name            = \"Endpoints Project\"\n  project_id      = \"tf-ep-${random_id.project_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\nresource \"google_project_service\" \"endpoints_project\" {\n  project = google_project.endpoints_project.project_id\n  service = \"compute.googleapis.com\"\n}\n\nresource \"google_project_service\" \"endpoints_project_sm\" {\n  project = google_project.endpoints_project.project_id\n  service = \"servicemanagement.googleapis.com\"\n}\n\nresource \"google_endpoints_service\" \"endpoints_service\" {\n  service_name = \"echo-api.endpoints.${google_project.endpoints_project.project_id}.cloud.goog\"\n  project      = google_project.endpoints_project.project_id\n\n  openapi_config = <<EOF\nswagger: \"2.0\"\ninfo:\n  description: \"A simple Google Cloud Endpoints API example.\"\n  title: \"Endpoints Example\"\n  version: \"1.0.0\"\nhost: \"echo-api.endpoints.${google_project.endpoints_project.project_id}.cloud.goog\"\nbasePath: \"/\"\nconsumes:\n- \"application/json\"\nproduces:\n- \"application/json\"\nschemes:\n- \"https\"\npaths:\n  \"/echo\":\n    post:\n      description: \"Echo back a given message.\"\n      operationId: \"echo\"\n      produces:\n      - \"application/json\"\n      responses:\n        200:\n          description: \"Echo\"\n          schema:\n            $ref: \"#/definitions/echoMessage\"\n      parameters:\n      - description: \"Message to echo\"\n        in: body\n        name: message\n        required: true\n        schema:\n          $ref: \"#/definitions/echoMessage\"\n      security:\n      - api_key: []\ndefinitions:\n  echoMessage:\n    properties:\n      message:\n        type: \"string\"\nEOF\n\n\n  depends_on = [google_project_service.endpoints_project_sm]\n}\n\nresource \"google_compute_network\" \"network\" {\n  name                    = \"ep-network\"\n  auto_create_subnetworks = \"true\"\n  project                 = google_project.endpoints_project.project_id\n  depends_on              = [google_project_service.endpoints_project]\n}\n\n# Allow the hosted network to be hit over ICMP, SSH, and HTTP.\nresource \"google_compute_firewall\" \"network\" {\n  name    = \"allow-ssh-and-icmp\"\n  network = google_compute_network.network.self_link\n  project = google_compute_network.network.project\n\n  allow {\n    protocol = \"icmp\"\n  }\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\", \"80\"]\n  }\n}\n\nresource \"google_compute_instance\" \"project_1_vm\" {\n  name         = \"tf-ep-vm\"\n  project      = google_project.endpoints_project.project_id\n  machine_type = \"f1-micro\"\n  zone         = var.region_zone\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  metadata = {\n    endpoints-service-name      = google_endpoints_service.endpoints_service.service_name\n    endpoints-service-config-id = google_endpoints_service.endpoints_service.config_id\n    startup-script              = file(\"scripts/install-vm.sh\")\n  }\n\n  network_interface {\n    network = google_compute_firewall.network.network\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/cloud-platform\"]\n  }\n\n  depends_on = [\n    google_project_service.endpoints_project_sm,\n    google_project_service.endpoints_project,\n  ]\n}\n\noutput \"ip\" {\n  value = google_compute_instance.project_1_vm.network_interface[0].access_config[0].nat_ip\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/endpoints-on-compute-engine/main.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\n# An example of how to connect two GCE networks with a VPN\nprovider \"google\" {\n  credentials = file(\"~/gce/account.json\")\n  project     = var.project\n  region      = var.region1\n}\n\n# Create the two networks we want to join. They must have separate, internal\n# ranges.\nresource \"google_compute_network\" \"network1\" {\n  name       = \"network1\"\n  ipv4_range = \"10.120.0.0/16\"\n}\n\nresource \"google_compute_network\" \"network2\" {\n  name       = \"network2\"\n  ipv4_range = \"10.121.0.0/16\"\n}\n\n# Attach a VPN gateway to each network.\nresource \"google_compute_vpn_gateway\" \"target_gateway1\" {\n  name    = \"vpn1\"\n  network = google_compute_network.network1.self_link\n  region  = var.region1\n}\n\nresource \"google_compute_vpn_gateway\" \"target_gateway2\" {\n  name    = \"vpn2\"\n  network = google_compute_network.network2.self_link\n  region  = var.region2\n}\n\n# Create an outward facing static IP for each VPN that will be used by the\n# other VPN to connect.\nresource \"google_compute_address\" \"vpn_static_ip1\" {\n  name   = \"vpn-static-ip1\"\n  region = var.region1\n}\n\nresource \"google_compute_address\" \"vpn_static_ip2\" {\n  name   = \"vpn-static-ip2\"\n  region = var.region2\n}\n\n# Forward IPSec traffic coming into our static IP to our VPN gateway.\nresource \"google_compute_forwarding_rule\" \"fr1_esp\" {\n  name        = \"fr1-esp\"\n  region      = var.region1\n  ip_protocol = \"ESP\"\n  ip_address  = google_compute_address.vpn_static_ip1.address\n  target      = google_compute_vpn_gateway.target_gateway1.self_link\n}\n\nresource \"google_compute_forwarding_rule\" \"fr2_esp\" {\n  name        = \"fr2-esp\"\n  region      = var.region2\n  ip_protocol = \"ESP\"\n  ip_address  = google_compute_address.vpn_static_ip2.address\n  target      = google_compute_vpn_gateway.target_gateway2.self_link\n}\n\n# The following two sets of forwarding rules are used as a part of the IPSec\n# protocol\nresource \"google_compute_forwarding_rule\" \"fr1_udp500\" {\n  name        = \"fr1-udp500\"\n  region      = var.region1\n  ip_protocol = \"UDP\"\n  port_range  = \"500\"\n  ip_address  = google_compute_address.vpn_static_ip1.address\n  target      = google_compute_vpn_gateway.target_gateway1.self_link\n}\n\nresource \"google_compute_forwarding_rule\" \"fr2_udp500\" {\n  name        = \"fr2-udp500\"\n  region      = var.region2\n  ip_protocol = \"UDP\"\n  port_range  = \"500\"\n  ip_address  = google_compute_address.vpn_static_ip2.address\n  target      = google_compute_vpn_gateway.target_gateway2.self_link\n}\n\nresource \"google_compute_forwarding_rule\" \"fr1_udp4500\" {\n  name        = \"fr1-udp4500\"\n  region      = var.region1\n  ip_protocol = \"UDP\"\n  port_range  = \"4500\"\n  ip_address  = google_compute_address.vpn_static_ip1.address\n  target      = google_compute_vpn_gateway.target_gateway1.self_link\n}\n\nresource \"google_compute_forwarding_rule\" \"fr2_udp4500\" {\n  name        = \"fr2-udp4500\"\n  region      = var.region2\n  ip_protocol = \"UDP\"\n  port_range  = \"4500\"\n  ip_address  = google_compute_address.vpn_static_ip2.address\n  target      = google_compute_vpn_gateway.target_gateway2.self_link\n}\n\n# Each tunnel is responsible for encrypting and decrypting traffic exiting\n# and leaving its associated gateway\nresource \"google_compute_vpn_tunnel\" \"tunnel1\" {\n  name               = \"tunnel1\"\n  region             = var.region1\n  peer_ip            = google_compute_address.vpn_static_ip2.address\n  shared_secret = \"<REDACTED>\"\n  target_vpn_gateway = google_compute_vpn_gateway.target_gateway1.self_link\n\n  depends_on = [\n    google_compute_forwarding_rule.fr1_udp500,\n    google_compute_forwarding_rule.fr1_udp4500,\n    google_compute_forwarding_rule.fr1_esp,\n  ]\n}\n\nresource \"google_compute_vpn_tunnel\" \"tunnel2\" {\n  name               = \"tunnel2\"\n  region             = var.region2\n  peer_ip            = google_compute_address.vpn_static_ip1.address\n  shared_secret = \"<REDACTED>\"\n  target_vpn_gateway = google_compute_vpn_gateway.target_gateway2.self_link\n\n  depends_on = [\n    google_compute_forwarding_rule.fr2_udp500,\n    google_compute_forwarding_rule.fr2_udp4500,\n    google_compute_forwarding_rule.fr2_esp,\n  ]\n}\n\n# Each route tells the associated network to send all traffic in the dest_range\n# through the VPN tunnel\nresource \"google_compute_route\" \"route1\" {\n  name                = \"route1\"\n  network             = google_compute_network.network1.name\n  next_hop_vpn_tunnel = google_compute_vpn_tunnel.tunnel1.self_link\n  dest_range          = google_compute_network.network2.ipv4_range\n  priority            = 1000\n}\n\nresource \"google_compute_route\" \"route2\" {\n  name                = \"route2\"\n  network             = google_compute_network.network2.name\n  next_hop_vpn_tunnel = google_compute_vpn_tunnel.tunnel2.self_link\n  dest_range          = google_compute_network.network1.ipv4_range\n  priority            = 1000\n}\n\n# We want to allow the two networks to communicate, so we need to unblock\n# them in the firewall\nresource \"google_compute_firewall\" \"network1-allow-network1\" {\n  name          = \"network1-allow-network1\"\n  network       = google_compute_network.network1.name\n  source_ranges = [google_compute_network.network1.ipv4_range]\n\n  allow {\n    protocol = \"tcp\"\n  }\n\n  allow {\n    protocol = \"udp\"\n  }\n\n  allow {\n    protocol = \"icmp\"\n  }\n}\n\nresource \"google_compute_firewall\" \"network1-allow-network2\" {\n  name          = \"network1-allow-network2\"\n  network       = google_compute_network.network1.name\n  source_ranges = [google_compute_network.network2.ipv4_range]\n\n  allow {\n    protocol = \"tcp\"\n  }\n\n  allow {\n    protocol = \"udp\"\n  }\n\n  allow {\n    protocol = \"icmp\"\n  }\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/vpn/vpn.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Kubernetes compute instances", "completion": "```hcl\nterraform {\n  required_version = \">= 0.11.7\"\n}\n\ndata \"terraform_remote_state\" \"k8s_cluster\" {\n  backend = \"atlas\"\n  config {\n    name = \"${var.tfe_organization}/${var.k8s_cluster_workspace}\"\n  }\n}\n\nprovider \"kubernetes\" {\n  load_config_file = false\n  host = \"${data.terraform_remote_state.k8s_cluster.k8s_endpoint}\"\n  client_certificate = \"${base64decode(data.terraform_remote_state.k8s_cluster.k8s_master_auth_client_certificate)}\"\n  client_key = \"<REDACTED>\"\n  cluster_ca_certificate = \"${base64decode(data.terraform_remote_state.k8s_cluster.k8s_master_auth_cluster_ca_certificate)}\"\n}\n\nresource \"null_resource\" \"service_account\" {\n\n  provisioner \"file\" {\n    source = \"cats-and-dogs.yaml\"\n    destination = \"~/cats-and-dogs.yaml\"\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"oc new-project cats-and-dogs --description=\\\"cats and dogs project\\\" --display-name=\\\"cats-and-dogs\\\"\",\n      \"kubectl create -f cats-and-dogs.yaml\",\n      \"kubectl get serviceaccount cats-and-dogs -o yaml > cats-and-dogs-service.yaml\",\n      \"grep \\\"cats-and-dogs-token\\\" cats-and-dogs-service.yaml | cut -d ':' -f 2 | sed 's/ //' > cats-and-dogs-secret-name\"\n    ]\n  }\n\n  connection {\n    host = \"${data.terraform_remote_state.k8s_cluster.master_public_dns}\"\n    type = \"ssh\"\n    agent = false\n    user = \"ec2-user\"\n    private_key = \"<REDACTED>\"\n    bastion_host = \"${data.terraform_remote_state.k8s_cluster.bastion_public_dns}\"\n  }\n}\n\nresource \"null_resource\" \"get_secret_name\" {\n  provisioner \"remote-exec\" {\n    inline = [\n      \"scp -o StrictHostKeyChecking=no -i ~/.ssh/private-key.pem ec2-user@${data.terraform_remote_state.k8s_cluster.master_public_dns}:~/cats-and-dogs-secret-name cats-and-dogs-secret-name\"\n    ]\n\n    connection {\n      host = \"${data.terraform_remote_state.k8s_cluster.bastion_public_dns}\"\n      type = \"ssh\"\n      agent = false\n      user = \"ec2-user\"\n      private_key = \"<REDACTED>\"\n    }\n  }\n\n  provisioner \"local-exec\" {\n    command = \"echo \\\"${var.private_key_data}\\\" > private-key.pem\"\n  }\n\n  provisioner \"local-exec\" {\n    command = \"chmod 400 private-key.pem\"\n  }\n\n  provisioner \"local-exec\" {\n    command = \"scp -o StrictHostKeyChecking=no -i private-key.pem  ec2-user@${data.terraform_remote_state.k8s_cluster.bastion_public_dns}:~/cats-and-dogs-secret-name cats-and-dogs-secret-name\"\n  }\n\n  depends_on = [\"null_resource.service_account\"]\n}\n\ndata \"null_data_source\" \"retrieve_secret_name_from_file\" {\n  inputs = {\n    secret_name = \"${chomp(file(\"cats-and-dogs-secret-name\"))}\"\n  }\n  depends_on = [\"null_resource.get_secret_name\"]\n}\n\nresource \"kubernetes_pod\" \"cats-and-dogs-backend\" {\n  metadata {\n    name = \"cats-and-dogs-backend\"\n    namespace = \"cats-and-dogs\"\n    labels {\n      App = \"cats-and-dogs-backend\"\n    }\n  }\n  spec {\n    service_account_name = \"cats-and-dogs\"\n    container {\n      image = \"rberlind/cats-and-dogs-backend:k8s-auth\"\n      image_pull_policy = \"Always\"\n      name  = \"cats-and-dogs-backend\"\n      command = [\"/app/start_redis.sh\"]\n      env = {\n        name = \"VAULT_ADDR\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_addr}\"\n      }\n      env = {\n        name = \"VAULT_K8S_BACKEND\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_k8s_auth_backend}\"\n      }\n      env = {\n        name = \"VAULT_USER\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_user}\"\n      }\n      env = {\n        name = \"K8S_TOKEN\"\n        value_from {\n          secret_key_ref {\n            name = \"${data.null_data_source.retrieve_secret_name_from_file.outputs[\"secret_name\"]}\"\n            key = \"<REDACTED>\"\n          }\n        }\n      }\n      port {\n        container_port = 6379\n      }\n    }\n  }\n}\n\nresource \"kubernetes_service\" \"cats-and-dogs-backend\" {\n  metadata {\n    name = \"cats-and-dogs-backend\"\n    namespace = \"cats-and-dogs\"\n  }\n  spec {\n    selector {\n      App = \"${kubernetes_pod.cats-and-dogs-backend.metadata.0.labels.App}\"\n    }\n    port {\n      port = 6379\n      target_port = 6379\n    }\n  }\n}\n\nresource \"kubernetes_pod\" \"cats-and-dogs-frontend\" {\n  metadata {\n    name = \"cats-and-dogs-frontend\"\n    namespace = \"cats-and-dogs\"\n    labels {\n      App = \"cats-and-dogs-frontend\"\n    }\n  }\n  spec {\n    service_account_name = \"cats-and-dogs\"\n    container {\n      image = \"rberlind/cats-and-dogs-frontend:k8s-auth\"\n      image_pull_policy = \"Always\"\n      name  = \"cats-and-dogs-frontend\"\n      env = {\n        name = \"REDIS\"\n        value = \"cats-and-dogs-backend\"\n      }\n      env = {\n        name = \"VAULT_ADDR\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_addr}\"\n      }\n      env = {\n        name = \"VAULT_K8S_BACKEND\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_k8s_auth_backend}\"\n      }\n      env = {\n        name = \"VAULT_USER\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_user}\"\n      }\n      env = {\n        name = \"K8S_TOKEN\"\n        value_from {\n          secret_key_ref {\n            name = \"${data.null_data_source.retrieve_secret_name_from_file.outputs[\"secret_name\"]}\"\n            key = \"<REDACTED>\"\n          }\n        }\n      }\n      port {\n        container_port = 80\n      }\n    }\n  }\n\n  depends_on = [\"kubernetes_service.cats-and-dogs-backend\"]\n}\n\nresource \"kubernetes_service\" \"cats-and-dogs-frontend\" {\n  metadata {\n    name = \"cats-and-dogs-frontend\"\n    namespace = \"cats-and-dogs\"\n  }\n  spec {\n    selector {\n      App = \"${kubernetes_pod.cats-and-dogs-frontend.metadata.0.labels.App}\"\n    }\n    port {\n      port = 80\n      target_port = 80\n    }\n    type = \"LoadBalancer\"\n  }\n}\n\nresource \"null_resource\" \"expose_route\" {\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"oc expose service cats-and-dogs-frontend --hostname=cats-and-dogs-frontend.${data.terraform_remote_state.k8s_cluster.master_public_ip}.xip.io\"\n    ]\n  }\n\n  connection {\n    host = \"${data.terraform_remote_state.k8s_cluster.master_public_dns}\"\n    type = \"ssh\"\n    agent = false\n    user = \"ec2-user\"\n    private_key = \"<REDACTED>\"\n    bastion_host = \"${data.terraform_remote_state.k8s_cluster.bastion_public_dns}\"\n  }\n\n  depends_on = [\"kubernetes_service.cats-and-dogs-frontend\"]\n\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/k8s-services-openshift/main.tf", "category": "compute", "authentic": true}}
{"prompt": "Create a Terraform configuration for Kubernetes Kubernetes cluster", "completion": "```hcl\nterraform {\n  required_version = \">= 0.11.11\"\n}\n\ndata \"terraform_remote_state\" \"k8s_cluster\" {\n  backend = \"atlas\"\n  config {\n    name = \"${var.tfe_organization}/${var.k8s_cluster_workspace}\"\n  }\n}\n\ndata \"terraform_remote_state\" \"k8s_vault_config\" {\n  backend = \"atlas\"\n  config {\n    name = \"${var.tfe_organization}/${var.k8s_vault_config_workspace}\"\n  }\n}\n\nprovider \"kubernetes\" {\n  host = \"${data.terraform_remote_state.k8s_cluster.k8s_endpoint}\"\n  client_certificate = \"${base64decode(data.terraform_remote_state.k8s_cluster.k8s_master_auth_client_certificate)}\"\n  client_key = \"<REDACTED>\"\n  cluster_ca_certificate = \"${base64decode(data.terraform_remote_state.k8s_cluster.k8s_master_auth_cluster_ca_certificate)}\"\n}\n\nresource \"kubernetes_namespace\" \"cats-and-dogs\" {\n  metadata {\n    name = \"cats-and-dogs\"\n  }\n}\n\nresource \"kubernetes_service_account\" \"cats-and-dogs\" {\n  metadata {\n    name = \"cats-and-dogs\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n  }\n}\n\nresource \"kubernetes_pod\" \"cats-and-dogs-backend\" {\n  metadata {\n    name = \"cats-and-dogs-backend\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n    labels {\n      App = \"cats-and-dogs-backend\"\n    }\n  }\n  spec {\n    service_account_name = \"${kubernetes_service_account.cats-and-dogs.metadata.0.name}\"\n    container {\n      image = \"${var.backend_image}\"\n      image_pull_policy = \"Always\"\n      name  = \"cats-and-dogs-backend\"\n      command = [\"/app/start_redis.sh\"]\n      env = {\n        name = \"VAULT_ADDR\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_addr}\"\n      }\n      env = {\n        name = \"VAULT_K8S_BACKEND\"\n        value = \"${data.terraform_remote_state.k8s_vault_config.vault_k8s_auth_backend}\"\n      }\n      env = {\n        name = \"VAULT_USER\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_user}\"\n      }\n      env = {\n        name = \"K8S_TOKEN\"\n        value_from {\n          secret_key_ref {\n            name = \"${kubernetes_service_account.cats-and-dogs.default_secret_name}\"\n            key = \"<REDACTED>\"\n          }\n        }\n      }\n      port {\n        container_port = 6379\n      }\n    }\n  }\n}\n\nresource \"kubernetes_service\" \"cats-and-dogs-backend\" {\n  metadata {\n    name = \"cats-and-dogs-backend\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n  }\n  spec {\n    selector {\n      App = \"${kubernetes_pod.cats-and-dogs-backend.metadata.0.labels.App}\"\n    }\n    port {\n      port = 6379\n      target_port = 6379\n    }\n  }\n}\n\nresource \"kubernetes_pod\" \"cats-and-dogs-frontend\" {\n  metadata {\n    name = \"cats-and-dogs-frontend\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n    labels {\n      App = \"cats-and-dogs-frontend\"\n    }\n  }\n  spec {\n    service_account_name = \"${kubernetes_service_account.cats-and-dogs.metadata.0.name}\"\n    container {\n      image = \"${var.frontend_image}\"\n      image_pull_policy = \"Always\"\n      name  = \"cats-and-dogs-frontend\"\n      env = {\n        name = \"REDIS\"\n        value = \"cats-and-dogs-backend\"\n      }\n      env = {\n        name = \"VAULT_ADDR\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_addr}\"\n      }\n      env = {\n        name = \"VAULT_K8S_BACKEND\"\n        value = \"${data.terraform_remote_state.k8s_vault_config.vault_k8s_auth_backend}\"\n      }\n      env = {\n        name = \"VAULT_USER\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_user}\"\n      }\n      env = {\n        name = \"K8S_TOKEN\"\n        value_from {\n          secret_key_ref {\n            name = \"${kubernetes_service_account.cats-and-dogs.default_secret_name}\"\n            key = \"<REDACTED>\"\n          }\n        }\n      }\n      port {\n        container_port = 80\n      }\n    }\n  }\n\n  depends_on = [\"kubernetes_service.cats-and-dogs-backend\"]\n}\n\nresource \"kubernetes_service\" \"cats-and-dogs-frontend\" {\n  metadata {\n    name = \"cats-and-dogs-frontend\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n  }\n  spec {\n    selector {\n      App = \"${kubernetes_pod.cats-and-dogs-frontend.metadata.0.labels.App}\"\n    }\n    port {\n      port = 80\n      target_port = 80\n    }\n    type = \"LoadBalancer\"\n  }\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/k8s-services/main.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure infrastructure deployment", "completion": "```hcl\nvariable \"tfe_organization\" {\n  description = \"TFE organization\"\n  default = \"RogerBerlind\"\n}\n\nvariable \"k8s_cluster_workspace\" {\n  description = \"workspace to use for the k8s cluster\"\n}\n\nvariable \"k8s_vault_config_workspace\" {\n  description = \"workspace to use for the vault configuration\"\n}\n\nvariable \"frontend_image\" {\n  default = \"rberlind/cats-and-dogs-frontend:k8s-auth\"\n  description = \"Docker image location of the frontend app\"\n}\n\n variable \"backend_image\" {\n  default = \"rberlind/cats-and-dogs-backend:k8s-auth\"\n  description = \"Docker image location of the frontend app\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/k8s-services/variables.tf", "category": "variables", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\noutput \"compute_network_consumable\" {\n  value       = \"${google_compute_network.demo_network.name}\"\n  description = \"The Network Name\"\n}\n\noutput \"subnetwork_consumable_name\" {\n  value       = \"${google_compute_subnetwork.demo_subnetwork.name}\"\n  description = \"The Subnet Name\"\n}\n\noutput \"subnetwork_consumable_ip_cidr_range\" {\n  value       = \"${google_compute_subnetwork.demo_subnetwork.ip_cidr_range}\"\n  description = \"The default Cidr Range\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/getting-started/terraform-gcp/outputs.tf", "category": "outputs", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure infrastructure deployment", "completion": "```hcl\nvariable \"gn_name\" {\n  default     = \"\"\n  description = \"The default name for the Compute Network\"\n}\n\nvariable \"sn_name\" {\n  default     = \"\"\n  description = \"The default name for the subnet\"\n}\n\nvariable \"sn_region\" {\n  default     = \"\"\n  description = \"The default region for the subnet\"\n}\n\nvariable \"sn_cidr_range\" {\n  default     = \"\"\n  description = \"The default Subnet Cidr Range\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/getting-started/terraform-gcp/_interface.tf", "category": "infrastructure", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\ndata \"aws_region\" \"current\" {\n  # Call this API only if create_vpc and enable_flow_log are true\n  count = var.create_vpc && var.enable_flow_log ? 1 : 0\n}\n\ndata \"aws_caller_identity\" \"current\" {\n  # Call this API only if create_vpc and enable_flow_log are true\n  count = var.create_vpc && var.enable_flow_log ? 1 : 0\n}\n\ndata \"aws_partition\" \"current\" {\n  # Call this API only if create_vpc and enable_flow_log are true\n  count = var.create_vpc && var.enable_flow_log ? 1 : 0\n}\n\nlocals {\n  # Only create flow log if user selected to create a VPC as well\n  enable_flow_log = var.create_vpc && var.enable_flow_log\n\n  create_flow_log_cloudwatch_iam_role  = local.enable_flow_log && var.flow_log_destination_type != \"s3\" && var.create_flow_log_cloudwatch_iam_role\n  create_flow_log_cloudwatch_log_group = local.enable_flow_log && var.flow_log_destination_type != \"s3\" && var.create_flow_log_cloudwatch_log_group\n\n  flow_log_destination_arn                  = local.create_flow_log_cloudwatch_log_group ? try(aws_cloudwatch_log_group.flow_log[0].arn, null) : var.flow_log_destination_arn\n  flow_log_iam_role_arn                     = var.flow_log_destination_type != \"s3\" && local.create_flow_log_cloudwatch_iam_role ? try(aws_iam_role.vpc_flow_log_cloudwatch[0].arn, null) : var.flow_log_cloudwatch_iam_role_arn\n  flow_log_cloudwatch_log_group_name_suffix = var.flow_log_cloudwatch_log_group_name_suffix == \"\" ? local.vpc_id : var.flow_log_cloudwatch_log_group_name_suffix\n  flow_log_group_arns = [\n    for log_group in aws_cloudwatch_log_group.flow_log :\n    \"arn:${data.aws_partition.current[0].partition}:logs:${data.aws_region.current[0].region}:${data.aws_caller_identity.current[0].account_id}:log-group:${log_group.name}:*\"\n  ]\n}\n\n################################################################################\n# Flow Log\n################################################################################\n\nresource \"aws_flow_log\" \"this\" {\n  count = local.enable_flow_log ? 1 : 0\n\n  log_destination_type       = var.flow_log_destination_type\n  log_destination            = local.flow_log_destination_arn\n  log_format                 = var.flow_log_log_format\n  iam_role_arn               = local.flow_log_iam_role_arn\n  deliver_cross_account_role = var.flow_log_deliver_cross_account_role\n  traffic_type               = var.flow_log_traffic_type\n  vpc_id                     = local.vpc_id\n  max_aggregation_interval   = var.flow_log_max_aggregation_interval\n\n  dynamic \"destination_options\" {\n    for_each = var.flow_log_destination_type == \"s3\" ? [true] : []\n\n    content {\n      file_format                = var.flow_log_file_format\n      hive_compatible_partitions = var.flow_log_hive_compatible_partitions\n      per_hour_partition         = var.flow_log_per_hour_partition\n    }\n  }\n\n  tags = merge(var.tags, var.vpc_flow_log_tags)\n}\n\n################################################################################\n# Flow Log CloudWatch\n################################################################################\n\nresource \"aws_cloudwatch_log_group\" \"flow_log\" {\n  count = local.create_flow_log_cloudwatch_log_group ? 1 : 0\n\n  name              = \"${var.flow_log_cloudwatch_log_group_name_prefix}${local.flow_log_cloudwatch_log_group_name_suffix}\"\n  retention_in_days = var.flow_log_cloudwatch_log_group_retention_in_days\n  kms_key_id        = var.flow_log_cloudwatch_log_group_kms_key_id\n  skip_destroy      = var.flow_log_cloudwatch_log_group_skip_destroy\n  log_group_class   = var.flow_log_cloudwatch_log_group_class\n\n  tags = merge(var.tags, var.vpc_flow_log_tags)\n}\n\nresource \"aws_iam_role\" \"vpc_flow_log_cloudwatch\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  name        = var.vpc_flow_log_iam_role_use_name_prefix ? null : var.vpc_flow_log_iam_role_name\n  name_prefix = var.vpc_flow_log_iam_role_use_name_prefix ? \"${var.vpc_flow_log_iam_role_name}-\" : null\n\n  assume_role_policy   = data.aws_iam_policy_document.flow_log_cloudwatch_assume_role[0].json\n  permissions_boundary = var.vpc_flow_log_permissions_boundary\n\n  tags = merge(var.tags, var.vpc_flow_log_tags)\n}\n\ndata \"aws_iam_policy_document\" \"flow_log_cloudwatch_assume_role\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  statement {\n    sid = \"AWSVPCFlowLogsAssumeRole\"\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"vpc-flow-logs.amazonaws.com\"]\n    }\n\n    effect = \"Allow\"\n\n    actions = [\"sts:AssumeRole\"]\n\n    dynamic \"condition\" {\n      for_each = var.flow_log_cloudwatch_iam_role_conditions\n      content {\n        test     = condition.value.test\n        variable = condition.value.variable\n        values   = condition.value.values\n      }\n    }\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"vpc_flow_log_cloudwatch\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  role       = aws_iam_role.vpc_flow_log_cloudwatch[0].name\n  policy_arn = aws_iam_policy.vpc_flow_log_cloudwatch[0].arn\n}\n\nresource \"aws_iam_policy\" \"vpc_flow_log_cloudwatch\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  name        = var.vpc_flow_log_iam_policy_use_name_prefix ? null : var.vpc_flow_log_iam_policy_name\n  name_prefix = var.vpc_flow_log_iam_policy_use_name_prefix ? \"${var.vpc_flow_log_iam_policy_name}-\" : null\n  policy      = data.aws_iam_policy_document.vpc_flow_log_cloudwatch[0].json\n  tags        = merge(var.tags, var.vpc_flow_log_tags)\n}\n\ndata \"aws_iam_policy_document\" \"vpc_flow_log_cloudwatch\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  statement {\n    sid = \"AWSVPCFlowLogsPushToCloudWatch\"\n\n    effect = \"Allow\"\n\n    actions = [\n      \"logs:CreateLogStream\",\n      \"logs:PutLogEvents\",\n      \"logs:DescribeLogGroups\",\n      \"logs:DescribeLogStreams\",\n    ]\n\n    resources = local.flow_log_group_arns\n  }\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/vpc-flow-logs.tf", "category": "networking", "authentic": true}}
{"prompt": "Write a Terraform module for AWS infrastructure", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n\n  assume_role {\n    role_arn = \"arn:aws:iam::<ACCOUNT_ID>:role/outpost-shared-anton\"\n  }\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  name   = \"ex-${basename(path.cwd)}\"\n  region = \"eu-west-1\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Example    = local.name\n    GithubRepo = \"terraform-aws-vpc\"\n    GithubOrg  = \"terraform-aws-modules\"\n  }\n\n  network_acls = {\n    outpost_inbound = [\n      {\n        rule_number = 100\n        rule_action = \"allow\"\n        from_port   = 80\n        to_port     = 80\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 110\n        rule_action = \"allow\"\n        from_port   = 443\n        to_port     = 443\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 120\n        rule_action = \"allow\"\n        from_port   = 22\n        to_port     = 22\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 130\n        rule_action = \"allow\"\n        from_port   = 3389\n        to_port     = 3389\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number     = 140\n        rule_action     = \"allow\"\n        from_port       = 80\n        to_port         = 80\n        protocol        = \"tcp\"\n        ipv6_cidr_block = \"::/0\"\n      },\n    ]\n    outpost_outbound = [\n      {\n        rule_number = 100\n        rule_action = \"allow\"\n        from_port   = 80\n        to_port     = 80\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 110\n        rule_action = \"allow\"\n        from_port   = 443\n        to_port     = 443\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 120\n        rule_action = \"allow\"\n        from_port   = 1433\n        to_port     = 1433\n        protocol    = \"tcp\"\n        cidr_block  = \"10.0.100.0/22\"\n      },\n      {\n        rule_number = 130\n        rule_action = \"allow\"\n        from_port   = 22\n        to_port     = 22\n        protocol    = \"tcp\"\n        cidr_block  = \"10.0.100.0/22\"\n      },\n      {\n        rule_number = 140\n        rule_action = \"allow\"\n        icmp_code   = -1\n        icmp_type   = 8\n        protocol    = \"icmp\"\n        cidr_block  = \"10.0.0.0/22\"\n      },\n      {\n        rule_number     = 150\n        rule_action     = \"allow\"\n        from_port       = 90\n        to_port         = 90\n        protocol        = \"tcp\"\n        ipv6_cidr_block = \"::/0\"\n      },\n    ]\n  }\n}\n\n################################################################################\n# VPC Module\n################################################################################\n\nmodule \"vpc\" {\n  source = \"../../\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k)]\n  public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 4)]\n\n  # Outpost is using single AZ specified in `outpost_az`\n  outpost_subnets = [\"10.0.50.0/24\", \"10.0.51.0/24\"]\n  outpost_arn     = data.aws_outposts_outpost.shared.arn\n  outpost_az      = data.aws_outposts_outpost.shared.availability_zone\n\n  # IPv6\n  enable_ipv6                                    = true\n  outpost_subnet_assign_ipv6_address_on_creation = true\n  outpost_subnet_ipv6_prefixes                   = [2, 3, 4]\n\n  # NAT Gateway\n  enable_nat_gateway = true\n  single_nat_gateway = true\n\n  # Network ACLs\n  outpost_dedicated_network_acl = true\n  outpost_inbound_acl_rules     = local.network_acls[\"outpost_inbound\"]\n  outpost_outbound_acl_rules    = local.network_acls[\"outpost_outbound\"]\n\n  tags = local.tags\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\ndata \"aws_outposts_outpost\" \"shared\" {\n  name = \"SEA19.07\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/examples/outpost/main.tf", "category": "module", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  name   = \"ex-${basename(path.cwd)}\"\n  region = \"eu-west-1\"\n\n  azs               = slice(data.aws_availability_zones.available.names, 0, 3)\n  preview_partition = cidrsubnets(aws_vpc_ipam_preview_next_cidr.this.cidr, 2, 2, 2)\n\n  tags = {\n    Example    = local.name\n    GithubRepo = \"terraform-aws-vpc\"\n    GithubOrg  = \"terraform-aws-modules\"\n  }\n}\n\n################################################################################\n# VPC Module\n################################################################################\n\n# IPv4\nmodule \"vpc_ipam_set_netmask\" {\n  source = \"../..\"\n\n  name = \"${local.name}-set-netmask\"\n\n  use_ipam_pool       = true\n  ipv4_ipam_pool_id   = aws_vpc_ipam_pool.this.id\n  ipv4_netmask_length = 16\n  azs                 = local.azs\n\n  private_subnets = cidrsubnets(local.preview_partition[0], 2, 2, 2)\n  public_subnets  = cidrsubnets(local.preview_partition[1], 2, 2, 2)\n\n  tags = local.tags\n\n  depends_on = [\n    aws_vpc_ipam_pool_cidr.this\n  ]\n}\n\nmodule \"vpc_ipam_set_cidr\" {\n  source = \"../..\"\n\n  name = \"${local.name}-set-cidr\"\n\n  use_ipam_pool     = true\n  ipv4_ipam_pool_id = aws_vpc_ipam_pool.this.id\n  cidr              = \"10.1.0.0/16\"\n  azs               = local.azs\n\n  private_subnets = [\"10.1.1.0/24\", \"10.1.2.0/24\", \"10.1.3.0/24\"]\n  public_subnets  = [\"10.1.11.0/24\", \"10.1.12.0/24\", \"10.1.13.0/24\"]\n\n  tags = local.tags\n}\n\n# # IPv6 - Requires having a CIDR plus its message and signature (see below)\n# module \"vpc_ipv6_ipam_set_netmask\" {\n#   source = \"../..\"\n\n#   name = \"${local.name}-ipv6-set-netmask\"\n\n#   use_ipam_pool       = true\n#   ipv4_ipam_pool_id   = aws_vpc_ipam_pool.this.id\n#   ipv6_ipam_pool_id   = aws_vpc_ipam_pool.ipv6.id\n#   ipv6_netmask_length = 56\n#   azs                 = local.azs\n\n#   tags = local.tags\n# }\n\n################################################################################\n# Supporting Resources\n################################################################################\n\n/*\nNOTES ON IPAM USAGE:\n\nIn order to build subnets with your VPC Terraform must know subnet CIDRs to properly plan # of resources to build.\nSince CIDR is derived by IPAM by calling CreateVpc this is not possible within a module unless cidr is known ahead of time.\nWe can get around this by \"previewing\" the CIDR and then using that as the subnet values.\n\nIn the example above we use `cidrsubnets()` to calculate a public and private \"partitions\" (group of cidrs) then calculate the specific\nCIDRs for each subnet type.\n\nFor an explanation on prolonged delete times on IPAM pools see 2nd\n*note* in terraform docs: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_ipam_pool_cidr\n*/\n\nresource \"aws_vpc_ipam\" \"this\" {\n  operating_regions {\n    region_name = local.region\n  }\n\n  tags = local.tags\n}\n\n# IPv4\nresource \"aws_vpc_ipam_pool\" \"this\" {\n  description                       = \"IPv4 pool\"\n  address_family                    = \"ipv4\"\n  ipam_scope_id                     = aws_vpc_ipam.this.private_default_scope_id\n  locale                            = local.region\n  allocation_default_netmask_length = 16\n\n  tags = local.tags\n}\n\nresource \"aws_vpc_ipam_pool_cidr\" \"this\" {\n  ipam_pool_id = aws_vpc_ipam_pool.this.id\n  cidr         = \"10.0.0.0/8\"\n}\n\nresource \"aws_vpc_ipam_preview_next_cidr\" \"this\" {\n  ipam_pool_id = aws_vpc_ipam_pool.this.id\n\n  depends_on = [\n    aws_vpc_ipam_pool_cidr.this\n  ]\n}\n\n# IPv6\nresource \"aws_vpc_ipam_pool\" \"ipv6\" {\n  description                       = \"IPv6 pool\"\n  address_family                    = \"ipv6\"\n  ipam_scope_id                     = aws_vpc_ipam.this.public_default_scope_id\n  locale                            = local.region\n  allocation_default_netmask_length = 56\n  publicly_advertisable             = false\n  aws_service                       = \"ec2\"\n\n  tags = local.tags\n}\n\n# # Requires having a CIDR plus its message and signature\n# resource \"aws_vpc_ipam_pool_cidr\" \"ipv6\" {\n#   ipam_pool_id = aws_vpc_ipam_pool.ipv6.id\n#   cidr         = var.ipv6_cidr\n\n#   cidr_authorization_context {\n#     message   = var.message\n#     signature = var.signature\n#   }\n# }\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/examples/ipam/main.tf", "category": "networking", "authentic": true}}
{"prompt": "Write a Terraform module for AWS infrastructure", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  name   = \"ex-${basename(path.cwd)}\"\n  region = \"eu-west-1\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Example    = local.name\n    GithubRepo = \"terraform-aws-vpc\"\n    GithubOrg  = \"terraform-aws-modules\"\n  }\n}\n\n################################################################################\n# VPC Module\n################################################################################\n\nmodule \"vpc\" {\n  source = \"../../\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n\n  vpc_block_public_access_options = {\n    internet_gateway_block_mode = \"block-bidirectional\"\n  }\n\n  vpc_block_public_access_exclusions = {\n    exclude_vpc = {\n      exclude_vpc                     = true\n      internet_gateway_exclusion_mode = \"allow-bidirectional\"\n    }\n  }\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/examples/block-public-access/main.tf", "category": "module", "authentic": true}}
{"prompt": "Create a Terraform configuration for infrastructure storage bucket", "completion": "```hcl\n# VPC flow log - Cloudwatch logs (default)\noutput \"vpc_with_flow_logs_cloudwatch_logs_default_vpc_flow_log_id\" {\n  description = \"The ID of the Flow Log resource\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs_default.vpc_flow_log_id\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_default_vpc_flow_log_destination_arn\" {\n  description = \"The ARN of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs_default.vpc_flow_log_destination_arn\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_default_vpc_flow_log_destination_type\" {\n  description = \"The type of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs_default.vpc_flow_log_destination_type\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_default_vpc_flow_log_cloudwatch_iam_role_arn\" {\n  description = \"The ARN of the IAM role used when pushing logs to Cloudwatch log group\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs_default.vpc_flow_log_cloudwatch_iam_role_arn\n}\n\n# VPC flow log - Cloudwatch logs (created separately)\noutput \"vpc_with_flow_logs_cloudwatch_logs_vpc_flow_log_id\" {\n  description = \"The ID of the Flow Log resource\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs.vpc_flow_log_id\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_vpc_flow_log_destination_arn\" {\n  description = \"The ARN of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs.vpc_flow_log_destination_arn\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_vpc_flow_log_destination_type\" {\n  description = \"The type of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs.vpc_flow_log_destination_type\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_vpc_flow_log_cloudwatch_iam_role_arn\" {\n  description = \"The ARN of the IAM role used when pushing logs to Cloudwatch log group\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs.vpc_flow_log_cloudwatch_iam_role_arn\n}\n\n# VPC flow log - S3 bucket\noutput \"vpc_flow_logs_s3_bucket_vpc_flow_log_id\" {\n  description = \"The ID of the Flow Log resource\"\n  value       = module.vpc_with_flow_logs_s3_bucket.vpc_flow_log_id\n}\n\noutput \"vpc_flow_logs_s3_bucket_vpc_flow_log_destination_arn\" {\n  description = \"The ARN of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_s3_bucket.vpc_flow_log_destination_arn\n}\n\noutput \"vpc_flow_logs_s3_bucket_vpc_flow_log_destination_type\" {\n  description = \"The type of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_s3_bucket.vpc_flow_log_destination_type\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/examples/vpc-flow-logs/outputs.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS Kubernetes cluster", "completion": "```hcl\nlocals {\n  dualstack_oidc_issuer_url = try(replace(replace(aws_eks_cluster.this[0].identity[0].oidc[0].issuer, \"https://oidc.eks.\", \"https://oidc-eks.\"), \".amazonaws.com/\", \".api.aws/\"), null)\n}\n\n################################################################################\n# Cluster\n################################################################################\n\noutput \"cluster_arn\" {\n  description = \"The Amazon Resource Name (ARN) of the cluster\"\n  value       = try(aws_eks_cluster.this[0].arn, null)\n\n  depends_on = [\n    aws_eks_access_entry.this,\n    aws_eks_access_policy_association.this,\n  ]\n}\n\noutput \"cluster_certificate_authority_data\" {\n  description = \"Base64 encoded certificate data required to communicate with the cluster\"\n  value       = try(aws_eks_cluster.this[0].certificate_authority[0].data, null)\n\n  depends_on = [\n    aws_eks_access_entry.this,\n    aws_eks_access_policy_association.this,\n  ]\n}\n\noutput \"cluster_endpoint\" {\n  description = \"Endpoint for your Kubernetes API server\"\n  value       = try(aws_eks_cluster.this[0].endpoint, null)\n\n  depends_on = [\n    aws_eks_access_entry.this,\n    aws_eks_access_policy_association.this,\n  ]\n}\n\noutput \"cluster_id\" {\n  description = \"The ID of the EKS cluster. Note: currently a value is returned only for local EKS clusters created on Outposts\"\n  value       = try(aws_eks_cluster.this[0].cluster_id, \"\")\n}\n\noutput \"cluster_name\" {\n  description = \"The name of the EKS cluster\"\n  value       = try(aws_eks_cluster.this[0].name, \"\")\n\n  depends_on = [\n    aws_eks_access_entry.this,\n    aws_eks_access_policy_association.this,\n  ]\n}\n\noutput \"cluster_oidc_issuer_url\" {\n  description = \"The URL on the EKS cluster for the OpenID Connect identity provider\"\n  value       = try(aws_eks_cluster.this[0].identity[0].oidc[0].issuer, null)\n}\n\noutput \"cluster_dualstack_oidc_issuer_url\" {\n  description = \"Dual-stack compatible URL on the EKS cluster for the OpenID Connect identity provider\"\n  value       = local.dualstack_oidc_issuer_url\n}\n\noutput \"cluster_version\" {\n  description = \"The Kubernetes version for the cluster\"\n  value       = try(aws_eks_cluster.this[0].version, null)\n}\n\noutput \"cluster_platform_version\" {\n  description = \"Platform version for the cluster\"\n  value       = try(aws_eks_cluster.this[0].platform_version, null)\n}\n\noutput \"cluster_status\" {\n  description = \"Status of the EKS cluster. One of `CREATING`, `ACTIVE`, `DELETING`, `FAILED`\"\n  value       = try(aws_eks_cluster.this[0].status, null)\n}\n\noutput \"cluster_primary_security_group_id\" {\n  description = \"Cluster security group that was created by Amazon EKS for the cluster. Managed node groups use this security group for control-plane-to-data-plane communication. Referred to as 'Cluster security group' in the EKS console\"\n  value       = try(aws_eks_cluster.this[0].vpc_config[0].cluster_security_group_id, null)\n}\n\noutput \"cluster_service_cidr\" {\n  description = \"The CIDR block where Kubernetes pod and service IP addresses are assigned from\"\n  value       = var.cluster_ip_family == \"ipv6\" ? try(aws_eks_cluster.this[0].kubernetes_network_config[0].service_ipv6_cidr, null) : try(aws_eks_cluster.this[0].kubernetes_network_config[0].service_ipv4_cidr, null)\n}\n\noutput \"cluster_ip_family\" {\n  description = \"The IP family used by the cluster (e.g. `ipv4` or `ipv6`)\"\n  value       = try(aws_eks_cluster.this[0].kubernetes_network_config[0].ip_family, null)\n}\n\n################################################################################\n# Access Entry\n################################################################################\n\noutput \"access_entries\" {\n  description = \"Map of access entries created and their attributes\"\n  value       = aws_eks_access_entry.this\n}\n\noutput \"access_policy_associations\" {\n  description = \"Map of eks cluster access policy associations created and their attributes\"\n  value       = aws_eks_access_policy_association.this\n}\n\n################################################################################\n# KMS Key\n################################################################################\n\noutput \"kms_key_arn\" {\n  description = \"The Amazon Resource Name (ARN) of the key\"\n  value       = module.kms.key_arn\n}\n\noutput \"kms_key_id\" {\n  description = \"The globally unique identifier for the key\"\n  value       = module.kms.key_id\n}\n\noutput \"kms_key_policy\" {\n  description = \"The IAM resource policy set on the key\"\n  value       = module.kms.key_policy\n}\n\n################################################################################\n# Cluster Security Group\n################################################################################\n\noutput \"cluster_security_group_arn\" {\n  description = \"Amazon Resource Name (ARN) of the cluster security group\"\n  value       = try(aws_security_group.cluster[0].arn, null)\n}\n\noutput \"cluster_security_group_id\" {\n  description = \"ID of the cluster security group\"\n  value       = try(aws_security_group.cluster[0].id, null)\n}\n\n################################################################################\n# Node Security Group\n################################################################################\n\noutput \"node_security_group_arn\" {\n  description = \"Amazon Resource Name (ARN) of the node shared security group\"\n  value       = try(aws_security_group.node[0].arn, null)\n}\n\noutput \"node_security_group_id\" {\n  description = \"ID of the node shared security group\"\n  value       = try(aws_security_group.node[0].id, null)\n}\n\n################################################################################\n# IRSA\n################################################################################\n\noutput \"oidc_provider\" {\n  description = \"The OpenID Connect identity provider (issuer URL without leading `https://`)\"\n  value       = try(replace(aws_eks_cluster.this[0].identity[0].oidc[0].issuer, \"https://\", \"\"), null)\n}\n\noutput \"oidc_provider_arn\" {\n  description = \"The ARN of the OIDC Provider if `enable_irsa = true`\"\n  value       = try(aws_iam_openid_connect_provider.oidc_provider[0].arn, null)\n}\n\noutput \"cluster_tls_certificate_sha1_fingerprint\" {\n  description = \"The SHA1 fingerprint of the public key of the cluster's certificate\"\n  value       = try(data.tls_certificate.this[0].certificates[0].sha1_fingerprint, null)\n}\n\n################################################################################\n# IAM Role\n################################################################################\n\noutput \"cluster_iam_role_name\" {\n  description = \"Cluster IAM role name\"\n  value       = try(aws_iam_role.this[0].name, null)\n}\n\noutput \"cluster_iam_role_arn\" {\n  description = \"Cluster IAM role ARN\"\n  value       = try(aws_iam_role.this[0].arn, null)\n}\n\noutput \"cluster_iam_role_unique_id\" {\n  description = \"Stable and unique string identifying the IAM role\"\n  value       = try(aws_iam_role.this[0].unique_id, null)\n}\n\n################################################################################\n# EKS Auto Node IAM Role\n################################################################################\n\noutput \"node_iam_role_name\" {\n  description = \"EKS Auto node IAM role name\"\n  value       = try(aws_iam_role.eks_auto[0].name, null)\n}\n\noutput \"node_iam_role_arn\" {\n  description = \"EKS Auto node IAM role ARN\"\n  value       = try(aws_iam_role.eks_auto[0].arn, null)\n}\n\noutput \"node_iam_role_unique_id\" {\n  description = \"Stable and unique string identifying the IAM role\"\n  value       = try(aws_iam_role.eks_auto[0].unique_id, null)\n}\n\n################################################################################\n# EKS Addons\n################################################################################\n\noutput \"cluster_addons\" {\n  description = \"Map of attribute maps for all EKS cluster addons enabled\"\n  value       = merge(aws_eks_addon.this, aws_eks_addon.before_compute)\n}\n\n################################################################################\n# EKS Identity Provider\n################################################################################\n\noutput \"cluster_identity_providers\" {\n  description = \"Map of attribute maps for all EKS identity providers enabled\"\n  value       = aws_eks_identity_provider_config.this\n}\n\n################################################################################\n# CloudWatch Log Group\n################################################################################\n\noutput \"cloudwatch_log_group_name\" {\n  description = \"Name of cloudwatch log group created\"\n  value       = try(aws_cloudwatch_log_group.this[0].name, null)\n}\n\noutput \"cloudwatch_log_group_arn\" {\n  description = \"Arn of cloudwatch log group created\"\n  value       = try(aws_cloudwatch_log_group.this[0].arn, null)\n}\n\n################################################################################\n# Fargate Profile\n################################################################################\n\noutput \"fargate_profiles\" {\n  description = \"Map of attribute maps for all EKS Fargate Profiles created\"\n  value       = module.fargate_profile\n}\n\n################################################################################\n# EKS Managed Node Group\n################################################################################\n\noutput \"eks_managed_node_groups\" {\n  description = \"Map of attribute maps for all EKS managed node groups created\"\n  value       = module.eks_managed_node_group\n}\n\noutput \"eks_managed_node_groups_autoscaling_group_names\" {\n  description = \"List of the autoscaling group names created by EKS managed node groups\"\n  value       = compact(flatten([for group in module.eks_managed_node_group : group.node_group_autoscaling_group_names]))\n}\n\n################################################################################\n# Self Managed Node Group\n################################################################################\n\noutput \"self_managed_node_groups\" {\n  description = \"Map of attribute maps for all self managed node groups created\"\n  value       = module.self_managed_node_group\n}\n\noutput \"self_managed_node_groups_autoscaling_group_names\" {\n  description = \"List of the autoscaling group names created by self-managed node groups\"\n  value       = compact([for group in module.self_managed_node_group : group.autoscaling_group_name])\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/outputs.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Create a Terraform configuration for infrastructure Kubernetes cluster", "completion": "```hcl\n################################################################################\n# Cluster\n################################################################################\n\noutput \"cluster_arn\" {\n  description = \"The Amazon Resource Name (ARN) of the cluster\"\n  value       = module.eks.cluster_arn\n}\n\noutput \"cluster_certificate_authority_data\" {\n  description = \"Base64 encoded certificate data required to communicate with the cluster\"\n  value       = module.eks.cluster_certificate_authority_data\n}\n\noutput \"cluster_endpoint\" {\n  description = \"Endpoint for your Kubernetes API server\"\n  value       = module.eks.cluster_endpoint\n}\n\noutput \"cluster_id\" {\n  description = \"The ID of the EKS cluster. Note: currently a value is returned only for local EKS clusters created on Outposts\"\n  value       = module.eks.cluster_id\n}\n\noutput \"cluster_name\" {\n  description = \"The name of the EKS cluster\"\n  value       = module.eks.cluster_name\n}\n\noutput \"cluster_oidc_issuer_url\" {\n  description = \"The URL on the EKS cluster for the OpenID Connect identity provider\"\n  value       = module.eks.cluster_oidc_issuer_url\n}\n\noutput \"cluster_dualstack_oidc_issuer_url\" {\n  description = \"Dual-stack compatible URL on the EKS cluster for the OpenID Connect identity provider\"\n  value       = module.eks.cluster_dualstack_oidc_issuer_url\n}\n\noutput \"cluster_platform_version\" {\n  description = \"Platform version for the cluster\"\n  value       = module.eks.cluster_platform_version\n}\n\noutput \"cluster_status\" {\n  description = \"Status of the EKS cluster. One of `CREATING`, `ACTIVE`, `DELETING`, `FAILED`\"\n  value       = module.eks.cluster_status\n}\n\noutput \"cluster_primary_security_group_id\" {\n  description = \"Cluster security group that was created by Amazon EKS for the cluster. Managed node groups use this security group for control-plane-to-data-plane communication. Referred to as 'Cluster security group' in the EKS console\"\n  value       = module.eks.cluster_primary_security_group_id\n}\n\noutput \"cluster_service_cidr\" {\n  description = \"The CIDR block where Kubernetes pod and service IP addresses are assigned from\"\n  value       = module.eks.cluster_service_cidr\n}\n\noutput \"cluster_ip_family\" {\n  description = \"The IP family used by the cluster (e.g. `ipv4` or `ipv6`)\"\n  value       = module.eks.cluster_ip_family\n}\n\n################################################################################\n# Access Entry\n################################################################################\n\noutput \"access_entries\" {\n  description = \"Map of access entries created and their attributes\"\n  value       = module.eks.access_entries\n}\n\n################################################################################\n# KMS Key\n################################################################################\n\noutput \"kms_key_arn\" {\n  description = \"The Amazon Resource Name (ARN) of the key\"\n  value       = module.eks.kms_key_arn\n}\n\noutput \"kms_key_id\" {\n  description = \"The globally unique identifier for the key\"\n  value       = module.eks.kms_key_id\n}\n\noutput \"kms_key_policy\" {\n  description = \"The IAM resource policy set on the key\"\n  value       = module.eks.kms_key_policy\n}\n\n################################################################################\n# Security Group\n################################################################################\n\noutput \"cluster_security_group_arn\" {\n  description = \"Amazon Resource Name (ARN) of the cluster security group\"\n  value       = module.eks.cluster_security_group_arn\n}\n\noutput \"cluster_security_group_id\" {\n  description = \"ID of the cluster security group\"\n  value       = module.eks.cluster_security_group_id\n}\n\n################################################################################\n# Node Security Group\n################################################################################\n\noutput \"node_security_group_arn\" {\n  description = \"Amazon Resource Name (ARN) of the node shared security group\"\n  value       = module.eks.node_security_group_arn\n}\n\noutput \"node_security_group_id\" {\n  description = \"ID of the node shared security group\"\n  value       = module.eks.node_security_group_id\n}\n\n################################################################################\n# IRSA\n################################################################################\n\noutput \"oidc_provider\" {\n  description = \"The OpenID Connect identity provider (issuer URL without leading `https://`)\"\n  value       = module.eks.oidc_provider\n}\n\noutput \"oidc_provider_arn\" {\n  description = \"The ARN of the OIDC Provider if `enable_irsa = true`\"\n  value       = module.eks.oidc_provider_arn\n}\n\noutput \"cluster_tls_certificate_sha1_fingerprint\" {\n  description = \"The SHA1 fingerprint of the public key of the cluster's certificate\"\n  value       = module.eks.cluster_tls_certificate_sha1_fingerprint\n}\n\n################################################################################\n# IAM Role\n################################################################################\n\noutput \"cluster_iam_role_name\" {\n  description = \"Cluster IAM role name\"\n  value       = module.eks.cluster_iam_role_name\n}\n\noutput \"cluster_iam_role_arn\" {\n  description = \"Cluster IAM role ARN\"\n  value       = module.eks.cluster_iam_role_arn\n}\n\noutput \"cluster_iam_role_unique_id\" {\n  description = \"Stable and unique string identifying the IAM role\"\n  value       = module.eks.cluster_iam_role_unique_id\n}\n\n################################################################################\n# EKS Auto Node IAM Role\n################################################################################\n\noutput \"node_iam_role_name\" {\n  description = \"EKS Auto node IAM role name\"\n  value       = module.eks.node_iam_role_name\n}\n\noutput \"node_iam_role_arn\" {\n  description = \"EKS Auto node IAM role ARN\"\n  value       = module.eks.node_iam_role_arn\n}\n\noutput \"node_iam_role_unique_id\" {\n  description = \"Stable and unique string identifying the IAM role\"\n  value       = module.eks.node_iam_role_unique_id\n}\n\n################################################################################\n# EKS Addons\n################################################################################\n\noutput \"cluster_addons\" {\n  description = \"Map of attribute maps for all EKS cluster addons enabled\"\n  value       = module.eks.cluster_addons\n}\n\n################################################################################\n# EKS Identity Provider\n################################################################################\n\noutput \"cluster_identity_providers\" {\n  description = \"Map of attribute maps for all EKS identity providers enabled\"\n  value       = module.eks.cluster_identity_providers\n}\n\n################################################################################\n# CloudWatch Log Group\n################################################################################\n\noutput \"cloudwatch_log_group_name\" {\n  description = \"Name of cloudwatch log group created\"\n  value       = module.eks.cloudwatch_log_group_name\n}\n\noutput \"cloudwatch_log_group_arn\" {\n  description = \"Arn of cloudwatch log group created\"\n  value       = module.eks.cloudwatch_log_group_arn\n}\n\n################################################################################\n# Fargate Profile\n################################################################################\n\noutput \"fargate_profiles\" {\n  description = \"Map of attribute maps for all EKS Fargate Profiles created\"\n  value       = module.eks.fargate_profiles\n}\n\n################################################################################\n# EKS Managed Node Group\n################################################################################\n\noutput \"eks_managed_node_groups\" {\n  description = \"Map of attribute maps for all EKS managed node groups created\"\n  value       = module.eks.eks_managed_node_groups\n}\n\noutput \"eks_managed_node_groups_autoscaling_group_names\" {\n  description = \"List of the autoscaling group names created by EKS managed node groups\"\n  value       = module.eks.eks_managed_node_groups_autoscaling_group_names\n}\n\n################################################################################\n# Self Managed Node Group\n################################################################################\n\noutput \"self_managed_node_groups\" {\n  description = \"Map of attribute maps for all self managed node groups created\"\n  value       = module.eks.self_managed_node_groups\n}\n\noutput \"self_managed_node_groups_autoscaling_group_names\" {\n  description = \"List of the autoscaling group names created by self-managed node groups\"\n  value       = module.eks.self_managed_node_groups_autoscaling_group_names\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/examples/eks-auto-mode/outputs.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS Kubernetes cluster", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {\n  # Exclude local zones\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\nlocals {\n  name            = \"ex-${basename(path.cwd)}\"\n  cluster_version = \"1.33\"\n  region          = \"us-west-2\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Test       = local.name\n    GithubRepo = \"terraform-aws-eks\"\n    GithubOrg  = \"terraform-aws-modules\"\n  }\n}\n\n################################################################################\n# EKS Module\n################################################################################\n\nmodule \"eks\" {\n  source = \"../..\"\n\n  cluster_name                   = local.name\n  cluster_version                = local.cluster_version\n  cluster_endpoint_public_access = true\n\n  enable_cluster_creator_admin_permissions = true\n\n  cluster_compute_config = {\n    enabled    = true\n    node_pools = [\"general-purpose\"]\n  }\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  tags = local.tags\n}\n\nmodule \"disabled_eks\" {\n  source = \"../..\"\n\n  create = false\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n  public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 48)]\n  intra_subnets   = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 52)]\n\n  enable_nat_gateway = true\n  single_nat_gateway = true\n\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = 1\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\" = 1\n  }\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/examples/eks-auto-mode/main.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Write a Terraform module for infrastructure infrastructure", "completion": "```hcl\nmodule \"eks_al2023\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"~> 20.0\"\n\n  cluster_name    = \"${local.name}-al2023\"\n  cluster_version = \"1.33\"\n\n  # EKS Addons\n  cluster_addons = {\n    coredns                = {}\n    eks-pod-identity-agent = {}\n    kube-proxy             = {}\n    vpc-cni                = {}\n  }\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  self_managed_node_groups = {\n    example = {\n      ami_type      = \"AL2023_x86_64_STANDARD\"\n      instance_type = \"m6i.large\"\n\n      min_size = 2\n      max_size = 5\n      # This value is ignored after the initial creation\n      # https://github.com/bryantbiggs/eks-desired-size-hack\n      desired_size = 2\n\n      # This is not required - demonstrates how to pass additional configuration to nodeadm\n      # Ref https://awslabs.github.io/amazon-eks-ami/nodeadm/doc/api/\n      cloudinit_pre_nodeadm = [\n        {\n          content_type = \"application/node.eks.aws\"\n          content      = <<-EOT\n            ---\n            apiVersion: node.eks.aws/v1alpha1\n            kind: NodeConfig\n            spec:\n              kubelet:\n                config:\n                  shutdownGracePeriod: 30s\n                  featureGates:\n                    DisableKubeletCloudCredentialProviders: true\n          EOT\n        }\n      ]\n    }\n  }\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/examples/self-managed-node-group/eks-al2023.tf", "category": "module", "authentic": true}}
{"prompt": "Write a Terraform module for infrastructure infrastructure", "completion": "```hcl\nmodule \"eks_bottlerocket\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"~> 20.0\"\n\n  cluster_name    = \"${local.name}-bottlerocket\"\n  cluster_version = \"1.33\"\n\n  # EKS Addons\n  cluster_addons = {\n    coredns                = {}\n    eks-pod-identity-agent = {}\n    kube-proxy             = {}\n    vpc-cni                = {}\n  }\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  self_managed_node_groups = {\n    example = {\n      ami_type      = \"BOTTLEROCKET_x86_64\"\n      instance_type = \"m6i.large\"\n\n      min_size = 2\n      max_size = 5\n      # This value is ignored after the initial creation\n      # https://github.com/bryantbiggs/eks-desired-size-hack\n      desired_size = 2\n\n      # This is not required - demonstrates how to pass additional configuration\n      # Ref https://bottlerocket.dev/en/os/1.19.x/api/settings/\n      bootstrap_extra_args = <<-EOT\n        # The admin host container provides SSH access and runs with \"superpowers\".\n        # It is disabled by default, but can be disabled explicitly.\n        [settings.host-containers.admin]\n        enabled = false\n\n        # The control host container provides out-of-band access via SSM.\n        # It is enabled by default, and can be disabled if you do not expect to use SSM.\n        # This could leave you with no way to access the API and change settings on an existing node!\n        [settings.host-containers.control]\n        enabled = true\n\n        # extra args added\n        [settings.kernel]\n        lockdown = \"integrity\"\n      EOT\n    }\n  }\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/examples/self-managed-node-group/eks-bottlerocket.tf", "category": "module", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure database", "completion": "```hcl\noutput \"enhanced_monitoring_iam_role_name\" {\n  description = \"The name of the monitoring role\"\n  value       = module.db_instance.enhanced_monitoring_iam_role_name\n}\n\noutput \"enhanced_monitoring_iam_role_arn\" {\n  description = \"The Amazon Resource Name (ARN) specifying the monitoring role\"\n  value       = module.db_instance.enhanced_monitoring_iam_role_arn\n}\n\noutput \"db_instance_address\" {\n  description = \"The address of the RDS instance\"\n  value       = module.db_instance.db_instance_address\n}\n\noutput \"db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = module.db_instance.db_instance_arn\n}\n\noutput \"db_instance_availability_zone\" {\n  description = \"The availability zone of the RDS instance\"\n  value       = module.db_instance.db_instance_availability_zone\n}\n\noutput \"db_instance_endpoint\" {\n  description = \"The connection endpoint\"\n  value       = module.db_instance.db_instance_endpoint\n}\n\noutput \"db_listener_endpoint\" {\n  description = \"Specifies the listener connection endpoint for SQL Server Always On\"\n  value       = module.db_instance.db_listener_endpoint\n}\n\noutput \"db_instance_engine\" {\n  description = \"The database engine\"\n  value       = module.db_instance.db_instance_engine\n}\n\noutput \"db_instance_engine_version_actual\" {\n  description = \"The running version of the database\"\n  value       = module.db_instance.db_instance_engine_version_actual\n}\n\noutput \"db_instance_hosted_zone_id\" {\n  description = \"The canonical hosted zone ID of the DB instance (to be used in a Route 53 Alias record)\"\n  value       = module.db_instance.db_instance_hosted_zone_id\n}\n\noutput \"db_instance_identifier\" {\n  description = \"The RDS instance identifier\"\n  value       = module.db_instance.db_instance_identifier\n}\n\noutput \"db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = module.db_instance.db_instance_resource_id\n}\n\noutput \"db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = module.db_instance.db_instance_status\n}\n\noutput \"db_instance_name\" {\n  description = \"The database name\"\n  value       = module.db_instance.db_instance_name\n}\n\noutput \"db_instance_username\" {\n  description = \"The master username for the database\"\n  value       = module.db_instance.db_instance_username\n  sensitive   = true\n}\n\noutput \"db_instance_domain\" {\n  description = \"The ID of the Directory Service Active Directory domain the instance is joined to\"\n  value       = module.db_instance.db_instance_domain\n}\n\noutput \"db_instance_domain_auth_secret_arn\" {\n  description = \"The ARN for the Secrets Manager secret with the self managed Active Directory credentials for the user joining the domain\"\n  value       = module.db_instance.db_instance_domain_auth_secret_arn\n}\n\noutput \"db_instance_domain_dns_ips\" {\n  description = \"The IPv4 DNS IP addresses of your primary and secondary self managed Active Directory domain controllers\"\n  value       = module.db_instance.db_instance_domain_dns_ips\n}\n\noutput \"db_instance_domain_fqdn\" {\n  description = \"The fully qualified domain name (FQDN) of an self managed Active Directory domain\"\n  value       = module.db_instance.db_instance_domain_fqdn\n}\n\noutput \"db_instance_domain_iam_role_name\" {\n  description = \"The name of the IAM role to be used when making API calls to the Directory Service\"\n  value       = module.db_instance.db_instance_domain_iam_role_name\n}\n\noutput \"db_instance_domain_ou\" {\n  description = \"The self managed Active Directory organizational unit for your DB instance to join\"\n  value       = module.db_instance.db_instance_domain_ou\n}\n\noutput \"db_instance_port\" {\n  description = \"The database port\"\n  value       = module.db_instance.db_instance_port\n}\n\noutput \"db_instance_ca_cert_identifier\" {\n  description = \"Specifies the identifier of the CA certificate for the DB instance\"\n  value       = module.db_instance.db_instance_ca_cert_identifier\n}\n\noutput \"db_instance_master_user_secret_arn\" {\n  description = \"The ARN of the master user secret (Only available when manage_master_user_password is set to true)\"\n  value       = module.db_instance.db_instance_master_user_secret_arn\n}\n\noutput \"db_subnet_group_id\" {\n  description = \"The db subnet group name\"\n  value       = module.db_subnet_group.db_subnet_group_id\n}\n\noutput \"db_subnet_group_arn\" {\n  description = \"The ARN of the db subnet group\"\n  value       = module.db_subnet_group.db_subnet_group_arn\n}\n\noutput \"db_parameter_group_id\" {\n  description = \"The db parameter group id\"\n  value       = module.db_parameter_group.db_parameter_group_id\n}\n\noutput \"db_parameter_group_arn\" {\n  description = \"The ARN of the db parameter group\"\n  value       = module.db_parameter_group.db_parameter_group_arn\n}\n\n# DB option group\noutput \"db_option_group_id\" {\n  description = \"The db option group id\"\n  value       = module.db_option_group.db_option_group_id\n}\n\noutput \"db_option_group_arn\" {\n  description = \"The ARN of the db option group\"\n  value       = module.db_option_group.db_option_group_arn\n}\n\n################################################################################\n# CloudWatch Log Group\n################################################################################\n\noutput \"db_instance_cloudwatch_log_groups\" {\n  description = \"Map of CloudWatch log groups created and their attributes\"\n  value       = module.db_instance.db_instance_cloudwatch_log_groups\n}\n\n################################################################################\n# DB Instance Role Association\n################################################################################\n\noutput \"db_instance_role_associations\" {\n  description = \"A map of DB Instance Identifiers and IAM Role ARNs separated by a comma\"\n  value       = module.db_instance_role_association\n}\n\n################################################################################\n# Managed Secret Rotation\n################################################################################\n\noutput \"db_instance_secretsmanager_secret_rotation_enabled\" {\n  description = \"Specifies whether automatic rotation is enabled for the secret\"\n  value       = module.db_instance.db_instance_secretsmanager_secret_rotation_enabled\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/outputs.tf", "category": "database", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure database", "completion": "```hcl\n# Master\noutput \"master_db_instance_address\" {\n  description = \"The address of the RDS instance\"\n  value       = module.master.db_instance_address\n}\n\noutput \"master_db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = module.master.db_instance_arn\n}\n\noutput \"master_db_instance_availability_zone\" {\n  description = \"The availability zone of the RDS instance\"\n  value       = module.master.db_instance_availability_zone\n}\n\noutput \"master_db_instance_endpoint\" {\n  description = \"The connection endpoint\"\n  value       = module.master.db_instance_endpoint\n}\n\noutput \"master_db_instance_engine\" {\n  description = \"The database engine\"\n  value       = module.master.db_instance_engine\n}\n\noutput \"master_db_instance_engine_version_actual\" {\n  description = \"The running version of the database\"\n  value       = module.master.db_instance_engine_version_actual\n}\n\noutput \"master_db_instance_hosted_zone_id\" {\n  description = \"The canonical hosted zone ID of the DB instance (to be used in a Route 53 Alias record)\"\n  value       = module.master.db_instance_hosted_zone_id\n}\n\noutput \"master_db_instance_identifier\" {\n  description = \"The RDS instance identifier\"\n  value       = module.master.db_instance_identifier\n}\n\noutput \"master_db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = module.master.db_instance_resource_id\n}\n\noutput \"master_db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = module.master.db_instance_status\n}\n\noutput \"master_db_instance_name\" {\n  description = \"The database name\"\n  value       = module.master.db_instance_name\n}\n\noutput \"master_db_instance_username\" {\n  description = \"The master username for the database\"\n  value       = module.master.db_instance_username\n  sensitive   = true\n}\n\noutput \"master_db_instance_port\" {\n  description = \"The database port\"\n  value       = module.master.db_instance_port\n}\n\noutput \"master_db_subnet_group_id\" {\n  description = \"The db subnet group name\"\n  value       = module.master.db_subnet_group_id\n}\n\noutput \"master_db_subnet_group_arn\" {\n  description = \"The ARN of the db subnet group\"\n  value       = module.master.db_subnet_group_arn\n}\n\noutput \"master_db_instance_cloudwatch_log_groups\" {\n  description = \"Map of CloudWatch log groups created and their attributes\"\n  value       = module.master.db_instance_cloudwatch_log_groups\n}\n\n# Replica\noutput \"replica_db_instance_address\" {\n  description = \"The address of the RDS instance\"\n  value       = module.replica.db_instance_address\n}\n\noutput \"replica_db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = module.replica.db_instance_arn\n}\n\noutput \"replica_db_instance_availability_zone\" {\n  description = \"The availability zone of the RDS instance\"\n  value       = module.replica.db_instance_availability_zone\n}\n\noutput \"replica_db_instance_endpoint\" {\n  description = \"The connection endpoint\"\n  value       = module.replica.db_instance_endpoint\n}\n\noutput \"replica_db_instance_engine\" {\n  description = \"The database engine\"\n  value       = module.replica.db_instance_engine\n}\n\noutput \"replica_db_instance_engine_version_actual\" {\n  description = \"The running version of the database\"\n  value       = module.replica.db_instance_engine_version_actual\n}\n\noutput \"replica_db_instance_hosted_zone_id\" {\n  description = \"The canonical hosted zone ID of the DB instance (to be used in a Route 53 Alias record)\"\n  value       = module.replica.db_instance_hosted_zone_id\n}\n\noutput \"replica_db_instance_identifier\" {\n  description = \"The RDS instance identifier\"\n  value       = module.replica.db_instance_identifier\n}\n\noutput \"replica_db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = module.replica.db_instance_resource_id\n}\n\noutput \"replica_db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = module.replica.db_instance_status\n}\n\noutput \"replica_db_instance_name\" {\n  description = \"The database name\"\n  value       = module.replica.db_instance_name\n}\n\noutput \"replica_db_instance_username\" {\n  description = \"The replica username for the database\"\n  value       = module.replica.db_instance_username\n  sensitive   = true\n}\n\noutput \"replica_db_instance_port\" {\n  description = \"The database port\"\n  value       = module.replica.db_instance_port\n}\n\noutput \"replica_db_instance_cloudwatch_log_groups\" {\n  description = \"Map of CloudWatch log groups created and their attributes\"\n  value       = module.replica.db_instance_cloudwatch_log_groups\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/examples/cross-region-replica-postgres/outputs.tf", "category": "database", "authentic": true}}
{"prompt": "Write a Terraform configuration for AWS database", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region1\n}\n\nprovider \"aws\" {\n  alias  = \"region2\"\n  region = local.region2\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\nlocals {\n  name    = \"replica-postgresql\"\n  region1 = \"eu-west-1\"\n  region2 = \"eu-central-1\"\n\n  tags = {\n    Name       = local.name\n    Example    = local.name\n    Repository = \"https://github.com/terraform-aws-modules/terraform-aws-rds\"\n  }\n\n  engine                = \"postgres\"\n  engine_version        = \"14\"\n  family                = \"postgres14\" # DB parameter group\n  major_engine_version  = \"14\"         # DB option group\n  instance_class        = \"db.t4g.large\"\n  allocated_storage     = 20\n  max_allocated_storage = 100\n  port                  = 5432\n}\n\n################################################################################\n# Master DB\n################################################################################\n\nmodule \"master\" {\n  source = \"../../\"\n\n  identifier = \"${local.name}-master\"\n\n  engine               = local.engine\n  engine_version       = local.engine_version\n  family               = local.family\n  major_engine_version = local.major_engine_version\n  instance_class       = local.instance_class\n\n  allocated_storage     = local.allocated_storage\n  max_allocated_storage = local.max_allocated_storage\n\n  db_name  = \"replicaPostgresql\"\n  username = \"replica_postgresql\"\n  port     = local.port\n\n  multi_az               = true\n  db_subnet_group_name   = module.vpc_region1.database_subnet_group_name\n  vpc_security_group_ids = [module.security_group_region1.security_group_id]\n\n  maintenance_window              = \"Mon:00:00-Mon:03:00\"\n  backup_window                   = \"03:00-06:00\"\n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n\n  # Backups are required in order to create a replica\n  backup_retention_period = 1\n  skip_final_snapshot     = true\n  deletion_protection     = false\n\n  tags = local.tags\n}\n\n################################################################################\n# Replica DB\n################################################################################\n\nmodule \"kms\" {\n  source      = \"terraform-aws-modules/kms/aws\"\n  version     = \"~> 1.0\"\n  description = \"KMS key for cross region replica DB\"\n\n  # Aliases\n  aliases                 = [local.name]\n  aliases_use_name_prefix = true\n\n  key_owners = [data.aws_caller_identity.current.id]\n\n  tags = local.tags\n\n  providers = {\n    aws = aws.region2\n  }\n}\n\nmodule \"replica\" {\n  source = \"../../\"\n\n  providers = {\n    aws = aws.region2\n  }\n\n  identifier = \"${local.name}-replica\"\n\n  # Source database. For cross-region use db_instance_arn\n  replicate_source_db = module.master.db_instance_arn\n\n  engine               = local.engine\n  engine_version       = local.engine_version\n  family               = local.family\n  major_engine_version = local.major_engine_version\n  instance_class       = local.instance_class\n  kms_key_id           = module.kms.key_arn\n\n  allocated_storage     = local.allocated_storage\n  max_allocated_storage = local.max_allocated_storage\n\n  # Not supported with replicas\n  manage_master_user_password = false\n\n  # Username and password should not be set for replicas\n  port = local.port\n\n  # parameter group for replica is inherited from the source database\n  create_db_parameter_group = false\n\n  multi_az               = false\n  vpc_security_group_ids = [module.security_group_region2.security_group_id]\n\n  maintenance_window              = \"Tue:00:00-Tue:03:00\"\n  backup_window                   = \"03:00-06:00\"\n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n\n  backup_retention_period = 0\n  skip_final_snapshot     = true\n  deletion_protection     = false\n\n  # Specify a subnet group created in the replica region\n  db_subnet_group_name = module.vpc_region2.database_subnet_group_name\n\n  tags = local.tags\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\nmodule \"vpc_region1\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = \"10.100.0.0/18\"\n\n  azs              = [\"${local.region1}a\", \"${local.region1}b\", \"${local.region1}c\"]\n  public_subnets   = [\"10.100.0.0/24\", \"10.100.1.0/24\", \"10.100.2.0/24\"]\n  private_subnets  = [\"10.100.3.0/24\", \"10.100.4.0/24\", \"10.100.5.0/24\"]\n  database_subnets = [\"10.100.7.0/24\", \"10.100.8.0/24\", \"10.100.9.0/24\"]\n\n  create_database_subnet_group = true\n\n  tags = local.tags\n}\n\nmodule \"security_group_region1\" {\n  source  = \"terraform-aws-modules/security-group/aws\"\n  version = \"~> 5.0\"\n\n  name        = local.name\n  description = \"Replica PostgreSQL example security group\"\n  vpc_id      = module.vpc_region1.vpc_id\n\n  # ingress\n  ingress_with_cidr_blocks = [\n    {\n      from_port   = 5432\n      to_port     = 5432\n      protocol    = \"tcp\"\n      description = \"PostgreSQL access from within VPC\"\n      cidr_blocks = module.vpc_region1.vpc_cidr_block\n    },\n  ]\n\n  tags = local.tags\n}\n\nmodule \"vpc_region2\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  providers = {\n    aws = aws.region2\n  }\n\n  name = local.name\n  cidr = \"10.100.0.0/18\"\n\n  azs              = [\"${local.region2}a\", \"${local.region2}b\", \"${local.region2}c\"]\n  public_subnets   = [\"10.100.0.0/24\", \"10.100.1.0/24\", \"10.100.2.0/24\"]\n  private_subnets  = [\"10.100.3.0/24\", \"10.100.4.0/24\", \"10.100.5.0/24\"]\n  database_subnets = [\"10.100.7.0/24\", \"10.100.8.0/24\", \"10.100.9.0/24\"]\n\n  create_database_subnet_group = true\n\n  tags = local.tags\n}\n\nmodule \"security_group_region2\" {\n  source  = \"terraform-aws-modules/security-group/aws\"\n  version = \"~> 5.0\"\n\n  providers = {\n    aws = aws.region2\n  }\n\n  name        = local.name\n  description = \"Replica PostgreSQL example security group\"\n  vpc_id      = module.vpc_region2.vpc_id\n\n  # ingress\n  ingress_with_cidr_blocks = [\n    {\n      from_port   = 5432\n      to_port     = 5432\n      protocol    = \"tcp\"\n      description = \"PostgreSQL access from within VPC\"\n      cidr_blocks = module.vpc_region2.vpc_cidr_block\n    },\n  ]\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/examples/cross-region-replica-postgres/main.tf", "category": "database", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure database", "completion": "```hcl\noutput \"db_instance_address\" {\n  description = \"The address of the RDS instance\"\n  value       = module.db.db_instance_address\n}\n\noutput \"db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = module.db.db_instance_arn\n}\n\noutput \"db_instance_availability_zone\" {\n  description = \"The availability zone of the RDS instance\"\n  value       = module.db.db_instance_availability_zone\n}\n\noutput \"db_instance_endpoint\" {\n  description = \"The connection endpoint\"\n  value       = module.db.db_instance_endpoint\n}\n\noutput \"db_instance_engine\" {\n  description = \"The database engine\"\n  value       = module.db.db_instance_engine\n}\n\noutput \"db_instance_engine_version_actual\" {\n  description = \"The running version of the database\"\n  value       = module.db.db_instance_engine_version_actual\n}\n\noutput \"db_instance_hosted_zone_id\" {\n  description = \"The canonical hosted zone ID of the DB instance (to be used in a Route 53 Alias record)\"\n  value       = module.db.db_instance_hosted_zone_id\n}\n\noutput \"db_instance_identifier\" {\n  description = \"The RDS instance identifier\"\n  value       = module.db.db_instance_identifier\n}\n\noutput \"db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = module.db.db_instance_resource_id\n}\n\noutput \"db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = module.db.db_instance_status\n}\n\noutput \"db_instance_name\" {\n  description = \"The database name\"\n  value       = module.db.db_instance_name\n}\n\noutput \"db_instance_username\" {\n  description = \"The master username for the database\"\n  value       = module.db.db_instance_username\n  sensitive   = true\n}\n\noutput \"db_instance_port\" {\n  description = \"The database port\"\n  value       = module.db.db_instance_port\n}\n\noutput \"db_subnet_group_id\" {\n  description = \"The db subnet group name\"\n  value       = module.db.db_subnet_group_id\n}\n\noutput \"db_subnet_group_arn\" {\n  description = \"The ARN of the db subnet group\"\n  value       = module.db.db_subnet_group_arn\n}\n\noutput \"db_parameter_group_id\" {\n  description = \"The db parameter group id\"\n  value       = module.db.db_parameter_group_id\n}\n\noutput \"db_parameter_group_arn\" {\n  description = \"The ARN of the db parameter group\"\n  value       = module.db.db_parameter_group_arn\n}\n\noutput \"db_enhanced_monitoring_iam_role_arn\" {\n  description = \"The Amazon Resource Name (ARN) specifying the monitoring role\"\n  value       = module.db.enhanced_monitoring_iam_role_arn\n}\n\noutput \"db_instance_cloudwatch_log_groups\" {\n  description = \"Map of CloudWatch log groups created and their attributes\"\n  value       = module.db.db_instance_cloudwatch_log_groups\n}\n\noutput \"db_instance_master_user_secret_arn\" {\n  description = \"The ARN of the master user secret (Only available when manage_master_user_password is set to true)\"\n  value       = module.db.db_instance_master_user_secret_arn\n}\n\noutput \"db_instance_role_associations\" {\n  description = \"The outputs for the role associations\"\n  value       = module.db.db_instance_role_associations\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/examples/role-association-postgres/outputs.tf", "category": "database", "authentic": true}}
{"prompt": "Write a Terraform configuration for AWS database", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_caller_identity\" \"current\" {}\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  name   = \"role-association-invoke-lambda\"\n  region = \"eu-west-1\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Name       = local.name\n    Example    = local.name\n    Repository = \"https://github.com/terraform-aws-modules/terraform-aws-rds\"\n  }\n}\n\n################################################################################\n# RDS Module\n################################################################################\n\nmodule \"db\" {\n  source = \"../../\"\n\n  identifier = local.name\n\n  # All available versions: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html#PostgreSQL.Concepts\n  engine               = \"postgres\"\n  engine_version       = \"14\"\n  family               = \"postgres14\" # DB parameter group\n  major_engine_version = \"14\"         # DB option group\n  instance_class       = \"db.t4g.large\"\n\n  allocated_storage = 20\n\n  # NOTE: Do NOT use 'user' as the value for 'username' as it throws:\n  # \"Error creating DB Instance: InvalidParameterValue: MasterUsername\n  # user cannot be used as it is a reserved word used by the engine\"\n  db_name  = \"RoleAssociationInvokeLambda\"\n  username = \"role_association_invoke_lambda\"\n  port     = 5432\n\n  multi_az               = true\n  db_subnet_group_name   = module.vpc.database_subnet_group\n  vpc_security_group_ids = [module.security_group.security_group_id]\n\n  maintenance_window      = \"Mon:00:00-Mon:03:00\"\n  backup_window           = \"03:00-06:00\"\n  backup_retention_period = 0\n\n  deletion_protection = false\n\n  # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/PostgreSQL-Lambda.html\n  db_instance_role_associations = {\n    Lambda = module.rds_invoke_lambda_role.iam_role_arn\n  }\n\n  parameters = [\n    {\n      name         = \"rds.custom_dns_resolution\"\n      value        = 1\n      apply_method = \"pending-reboot\"\n    },\n  ]\n\n  tags = local.tags\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs              = local.azs\n  public_subnets   = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k)]\n  private_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 3)]\n  database_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 6)]\n\n  create_database_subnet_group = true\n  enable_nat_gateway           = true\n\n  tags = local.tags\n}\n\nmodule \"security_group\" {\n  source  = \"terraform-aws-modules/security-group/aws\"\n  version = \"~> 4.0\"\n\n  name        = local.name\n  description = \"Complete PostgreSQL example security group\"\n  vpc_id      = module.vpc.vpc_id\n\n  # ingress\n  ingress_with_cidr_blocks = [\n    {\n      from_port   = 5432\n      to_port     = 5432\n      protocol    = \"tcp\"\n      description = \"PostgreSQL access from within VPC\"\n      cidr_blocks = module.vpc.vpc_cidr_block\n    },\n  ]\n\n  # egress\n  egress_with_cidr_blocks = [\n    {\n      from_port   = 443\n      to_port     = 443\n      protocol    = \"tcp\"\n      description = \"Egress to AWS Lambda VPC\"\n      cidr_blocks = \"0.0.0.0/0\"\n    }\n  ]\n\n  tags = local.tags\n}\n\nmodule \"rds_invoke_lambda_role\" {\n  source  = \"terraform-aws-modules/iam/aws//modules/iam-assumable-role\"\n  version = \"~> 5.28.0\"\n\n  create_role       = true\n  role_requires_mfa = false\n\n  role_name_prefix = local.name\n\n  custom_role_policy_arns = [\n    module.rds_invoke_lambda_policy.arn\n  ]\n  custom_role_trust_policy = data.aws_iam_policy_document.rds_invoke_lambda_assume_role.json\n}\n\nmodule \"rds_invoke_lambda_policy\" {\n  source  = \"terraform-aws-modules/iam/aws//modules/iam-policy\"\n  version = \"~> 5.28.0\"\n\n  name        = \"${local.name}-policy\"\n  path        = \"/\"\n  description = \"Invoke Lambda from RDS Postgresql policy\"\n\n  policy = data.aws_iam_policy_document.rds_invoke_lambda.json\n}\n\ndata \"aws_iam_policy_document\" \"rds_invoke_lambda\" {\n  statement {\n    sid = \"InvokeLambda\"\n    actions = [\n      \"lambda:InvokeFunction\"\n    ]\n    resources = [\n      module.lambda.lambda_function_arn\n    ]\n  }\n}\n\ndata \"aws_iam_policy_document\" \"rds_invoke_lambda_assume_role\" {\n  statement {\n    sid = \"AssumeRole\"\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"rds.amazonaws.com\"]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      values   = [data.aws_caller_identity.current.id]\n      variable = \"aws:SourceAccount\"\n    }\n\n    effect = \"Allow\"\n\n    actions = [\"sts:AssumeRole\"]\n  }\n}\n\nmodule \"lambda\" {\n  source  = \"terraform-aws-modules/lambda/aws\"\n  version = \"~> 6.0\"\n\n  function_name = local.name\n  handler       = \"lambda_function.lambda_handler\"\n  runtime       = \"python3.10\"\n  source_path   = \"${path.module}/fixtures/lambda_function.py\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/examples/role-association-postgres/main.tf", "category": "database", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\noutput \"s3_bucket_id\" {\n  description = \"The name of the bucket.\"\n  value       = try(aws_s3_bucket.this[0].id, aws_s3_directory_bucket.this[0].bucket, \"\")\n}\n\noutput \"s3_bucket_arn\" {\n  description = \"The ARN of the bucket. Will be of format arn:aws:s3:::bucketname.\"\n  value       = try(aws_s3_bucket.this[0].arn, \"\")\n}\n\noutput \"s3_bucket_bucket_domain_name\" {\n  description = \"The bucket domain name. Will be of format bucketname.s3.amazonaws.com.\"\n  value       = try(aws_s3_bucket.this[0].bucket_domain_name, \"\")\n}\n\noutput \"s3_bucket_bucket_regional_domain_name\" {\n  description = \"The bucket region-specific domain name. The bucket domain name including the region name, please refer here for format. Note: The AWS CloudFront allows specifying S3 region-specific endpoint when creating S3 origin, it will prevent redirect issues from CloudFront to S3 Origin URL.\"\n  value       = try(aws_s3_bucket.this[0].bucket_regional_domain_name, \"\")\n}\n\noutput \"s3_bucket_hosted_zone_id\" {\n  description = \"The Route 53 Hosted Zone ID for this bucket's region.\"\n  value       = try(aws_s3_bucket.this[0].hosted_zone_id, \"\")\n}\n\noutput \"s3_bucket_lifecycle_configuration_rules\" {\n  description = \"The lifecycle rules of the bucket, if the bucket is configured with lifecycle rules. If not, this will be an empty string.\"\n  value       = try(aws_s3_bucket_lifecycle_configuration.this[0].rule, \"\")\n}\n\noutput \"s3_bucket_policy\" {\n  description = \"The policy of the bucket, if the bucket is configured with a policy. If not, this will be an empty string.\"\n  value       = try(aws_s3_bucket_policy.this[0].policy, \"\")\n}\n\noutput \"s3_bucket_region\" {\n  description = \"The AWS region this bucket resides in.\"\n  value       = try(aws_s3_bucket.this[0].bucket_region, \"\")\n}\n\noutput \"s3_bucket_website_endpoint\" {\n  description = \"The website endpoint, if the bucket is configured with a website. If not, this will be an empty string.\"\n  value       = try(aws_s3_bucket_website_configuration.this[0].website_endpoint, \"\")\n}\n\noutput \"s3_bucket_website_domain\" {\n  description = \"The domain of the website endpoint, if the bucket is configured with a website. If not, this will be an empty string. This is used to create Route 53 alias records.\"\n  value       = try(aws_s3_bucket_website_configuration.this[0].website_domain, \"\")\n}\n\noutput \"s3_directory_bucket_name\" {\n  description = \"Name of the directory bucket.\"\n  value       = try(aws_s3_directory_bucket.this[0].bucket, null)\n}\n\noutput \"s3_directory_bucket_arn\" {\n  description = \"ARN of the directory bucket.\"\n  value       = try(aws_s3_directory_bucket.this[0].arn, null)\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/outputs.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\nprovider \"aws\" {\n  region = \"eu-west-1\"\n\n  # Make it faster by skipping something\n  skip_metadata_api_check     = true\n  skip_region_validation      = true\n  skip_credentials_validation = true\n}\n\nlocals {\n  bucket_name = \"s3-table-bucket-${random_pet.this.id}\"\n}\n\ndata \"aws_caller_identity\" \"this\" {}\n\ndata \"aws_region\" \"this\" {}\n\nmodule \"table_bucket\" {\n  source = \"../../modules/table-bucket\"\n\n  table_bucket_name = local.bucket_name\n\n  encryption_configuration = {\n    kms_key_arn   = module.kms.key_arn\n    sse_algorithm = \"aws:kms\"\n  }\n\n  maintenance_configuration = {\n    iceberg_unreferenced_file_removal = {\n      status = \"enabled\"\n\n      settings = {\n        non_current_days  = 7\n        unreferenced_days = 3\n      }\n    }\n  }\n\n  create_table_bucket_policy = true\n  table_bucket_policy_statements = [\n    {\n      effect = \"Allow\"\n      principals = [{\n        type        = \"AWS\"\n        identifiers = [data.aws_caller_identity.this.account_id]\n      }]\n      actions = [\n        \"s3tables:GetTableData\",\n        \"s3tables:GetTableMetadataLocation\"\n      ]\n    }\n  ]\n\n  tables = {\n    table1 = {\n      format    = \"ICEBERG\"\n      namespace = aws_s3tables_namespace.namespace.namespace\n\n      encryption_configuration = {\n        kms_key_arn   = module.kms.key_arn\n        sse_algorithm = \"aws:kms\"\n      }\n\n      maintenance_configuration = {\n        iceberg_compaction = {\n          status = \"enabled\"\n          settings = {\n            target_file_size_mb = 64\n          }\n        }\n        iceberg_snapshot_management = {\n          status = \"enabled\"\n          settings = {\n            max_snapshot_age_hours = 40\n            min_snapshots_to_keep  = 3\n          }\n        }\n      }\n\n      create_table_policy = true\n      policy_statements = [\n        {\n          sid    = \"DeleteTable\"\n          effect = \"Allow\"\n          principals = [{\n            type        = \"AWS\"\n            identifiers = [data.aws_caller_identity.this.account_id]\n          }]\n          actions = [\n            \"s3tables:DeleteTable\",\n            \"s3tables:UpdateTableMetadataLocation\",\n            \"s3tables:PutTableData\",\n            \"s3tables:GetTableMetadataLocation\"\n          ]\n        }\n      ]\n    }\n    table2 = {\n      format    = \"ICEBERG\"\n      name      = \"table2\"\n      namespace = aws_s3tables_namespace.namespace.namespace\n    }\n    table3 = {\n      format    = \"ICEBERG\"\n      namespace = aws_s3tables_namespace.namespace.namespace\n\n      metadata = {\n        iceberg = {\n          schema = {\n            field = {\n              created_at = {\n                name     = \"created_at\"\n                type     = \"timestamp\"\n                required = false\n              }\n              price = {\n                type     = \"decimal(10,2)\"\n                required = false\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\nresource \"random_pet\" \"this\" {\n  length = 2\n}\n\nresource \"aws_s3tables_namespace\" \"namespace\" {\n  namespace        = \"example_namespace\"\n  table_bucket_arn = module.table_bucket.s3_table_bucket_arn\n}\n\nmodule \"kms\" {\n  source  = \"terraform-aws-modules/kms/aws\"\n  version = \"~> 3.0\"\n\n  description             = \"Key example for s3 table buckets\"\n  deletion_window_in_days = 7\n\n  # https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-kms-permissions.html\n  key_statements = [\n    {\n      sid = \"s3TablesMaintenancePolicy\"\n      actions = [\n        \"kms:GenerateDataKey\",\n        \"kms:Decrypt\"\n      ]\n      resources = [\"*\"]\n\n      principals = [\n        {\n          type        = \"Service\"\n          identifiers = [\"maintenance.s3tables.amazonaws.com\"]\n        }\n      ]\n\n      conditions = [\n        {\n          test     = \"StringEquals\"\n          variable = \"aws:SourceAccount\"\n          values = [\n            data.aws_caller_identity.this.id,\n          ]\n        },\n        {\n          test     = \"StringLike\"\n          variable = \"kms:EncryptionContext:aws:s3:arn\"\n          values = [\n            \"arn:aws:s3tables:${data.aws_region.this.region}:${data.aws_caller_identity.this.account_id}:bucket/${local.bucket_name}/table/*\"\n          ]\n        }\n      ]\n    }\n  ]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/examples/table-bucket/main.tf", "category": "storage", "authentic": true}}
{"prompt": "Write a Terraform configuration for AWS compute instances", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n\n  # Make it faster by skipping something\n  skip_metadata_api_check     = true\n  skip_region_validation      = true\n  skip_credentials_validation = true\n}\n\nlocals {\n  bucket_name = \"s3-bucket-${random_pet.this.id}\"\n  region      = \"eu-west-1\"\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_canonical_user_id\" \"current\" {}\n\ndata \"aws_cloudfront_log_delivery_canonical_user_id\" \"cloudfront\" {}\n\nresource \"random_pet\" \"this\" {\n  length = 2\n}\n\nresource \"aws_kms_key\" \"objects\" {\n  description             = \"KMS key is used to encrypt bucket objects\"\n  deletion_window_in_days = 7\n}\n\nresource \"aws_iam_role\" \"this\" {\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\ndata \"aws_iam_policy_document\" \"bucket_policy\" {\n  statement {\n    principals {\n      type        = \"AWS\"\n      identifiers = [aws_iam_role.this.arn]\n    }\n\n    actions = [\n      \"s3:ListBucket\",\n    ]\n\n    resources = [\n      \"arn:aws:s3:::${local.bucket_name}\",\n    ]\n  }\n}\n\nmodule \"log_bucket\" {\n  source = \"../../\"\n\n  bucket        = \"logs-${random_pet.this.id}\"\n  force_destroy = true\n\n  control_object_ownership = true\n\n  attach_elb_log_delivery_policy        = true\n  attach_lb_log_delivery_policy         = true\n  attach_access_log_delivery_policy     = true\n  attach_cloudtrail_log_delivery_policy = true\n  attach_deny_insecure_transport_policy = true\n  attach_require_latest_tls_policy      = true\n  attach_waf_log_delivery_policy        = true\n\n  access_log_delivery_policy_source_accounts      = [data.aws_caller_identity.current.account_id]\n  access_log_delivery_policy_source_buckets       = [\"arn:aws:s3:::${local.bucket_name}\"]\n  access_log_delivery_policy_source_organizations = [\"o-123456\"]\n  lb_log_delivery_policy_source_organizations     = [\"o-123456\"]\n}\n\nmodule \"cloudfront_log_bucket\" {\n  source = \"../../\"\n\n  bucket                   = \"cloudfront-logs-${random_pet.this.id}\"\n  control_object_ownership = true\n  object_ownership         = \"ObjectWriter\"\n\n  grant = [{\n    type       = \"CanonicalUser\"\n    permission = \"FULL_CONTROL\"\n    id         = data.aws_canonical_user_id.current.id\n    }, {\n    type       = \"CanonicalUser\"\n    permission = \"FULL_CONTROL\"\n    id         = data.aws_cloudfront_log_delivery_canonical_user_id.cloudfront.id # Ref. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html\n    }\n  ]\n\n  owner = {\n    id = data.aws_canonical_user_id.current.id\n  }\n\n  force_destroy = true\n}\n\nmodule \"simple_bucket\" {\n  source = \"../../\"\n\n  bucket = \"simple-${random_pet.this.id}\"\n\n  force_destroy = true\n}\n\nmodule \"s3_bucket\" {\n  source = \"../../\"\n\n  bucket = local.bucket_name\n\n  force_destroy       = true\n  acceleration_status = \"Suspended\"\n  request_payer       = \"BucketOwner\"\n\n  tags = {\n    Owner = \"Anton\"\n  }\n\n  # Note: Object Lock configuration can be enabled only on new buckets\n  # https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_object_lock_configuration\n  object_lock_enabled = true\n  object_lock_configuration = {\n    rule = {\n      default_retention = {\n        mode = \"GOVERNANCE\"\n        days = 1\n      }\n    }\n  }\n\n  # Bucket policies\n  attach_policy                             = true\n  policy                                    = data.aws_iam_policy_document.bucket_policy.json\n  attach_deny_insecure_transport_policy     = true\n  attach_require_latest_tls_policy          = true\n  attach_deny_incorrect_encryption_headers  = true\n  attach_deny_incorrect_kms_key_sse         = true\n  allowed_kms_key_arn                       = aws_kms_key.objects.arn\n  attach_deny_unencrypted_object_uploads    = true\n  attach_deny_ssec_encrypted_object_uploads = true\n\n  # S3 bucket-level Public Access Block configuration (by default now AWS has made this default as true for S3 bucket-level block public access)\n  # block_public_acls       = true\n  # block_public_policy     = true\n  # ignore_public_acls      = true\n  # restrict_public_buckets = true\n\n  # S3 Bucket Ownership Controls\n  # https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_ownership_controls\n  control_object_ownership = true\n  object_ownership         = \"BucketOwnerPreferred\"\n\n  expected_bucket_owner                  = data.aws_caller_identity.current.account_id\n  transition_default_minimum_object_size = \"varies_by_storage_class\"\n\n  acl = \"private\" # \"acl\" conflicts with \"grant\" and \"owner\"\n\n  logging = {\n    target_bucket = module.log_bucket.s3_bucket_id\n    target_prefix = \"log/\"\n    target_object_key_format = {\n      partitioned_prefix = {\n        partition_date_source = \"DeliveryTime\" # \"EventTime\"\n      }\n      # simple_prefix = {}\n    }\n  }\n\n  versioning = {\n    status     = true\n    mfa_delete = false\n  }\n\n  website = {\n    # conflicts with \"error_document\"\n    #        redirect_all_requests_to = {\n    #          host_name = \"https://modules.tf\"\n    #        }\n\n    index_document = \"index.html\"\n    error_document = \"error.html\"\n    routing_rules = [{\n      condition = {\n        key_prefix_equals = \"docs/\"\n      },\n      redirect = {\n        replace_key_prefix_with = \"documents/\"\n      }\n      }, {\n      condition = {\n        http_error_code_returned_equals = 404\n        key_prefix_equals               = \"archive/\"\n      },\n      redirect = {\n        host_name          = \"archive.myhost.com\"\n        http_redirect_code = 301\n        protocol           = \"https\"\n        replace_key_with   = \"not_found.html\"\n      }\n    }]\n  }\n\n  server_side_encryption_configuration = {\n    rule = {\n      apply_server_side_encryption_by_default = {\n        kms_master_key_id = aws_kms_key.objects.arn\n        sse_algorithm     = \"aws:kms\"\n      }\n    }\n  }\n\n  cors_rule = [\n    {\n      allowed_methods = [\"PUT\", \"POST\"]\n      allowed_origins = [\"https://modules.tf\", \"https://terraform-aws-modules.modules.tf\"]\n      allowed_headers = [\"*\"]\n      expose_headers  = [\"ETag\"]\n      max_age_seconds = 3000\n      }, {\n      allowed_methods = [\"PUT\"]\n      allowed_origins = [\"https://example.com\"]\n      allowed_headers = [\"*\"]\n      expose_headers  = [\"ETag\"]\n      max_age_seconds = 3000\n    }\n  ]\n\n  lifecycle_rule = [\n    {\n      id      = \"log\"\n      enabled = true\n\n      filter = {\n        tags = {\n          some    = \"value\"\n          another = \"value2\"\n        }\n      }\n\n      transition = [\n        {\n          days          = 30\n          storage_class = \"ONEZONE_IA\"\n          }, {\n          days          = 60\n          storage_class = \"GLACIER\"\n        }\n      ]\n\n      #        expiration = {\n      #          days = 90\n      #          expired_object_delete_marker = true\n      #        }\n\n      #        noncurrent_version_expiration = {\n      #          newer_noncurrent_versions = 5\n      #          days = 30\n      #        }\n    },\n    {\n      id                                     = \"log1\"\n      enabled                                = true\n      abort_incomplete_multipart_upload_days = 7\n\n      noncurrent_version_transition = [\n        {\n          days          = 30\n          storage_class = \"STANDARD_IA\"\n        },\n        {\n          days          = 60\n          storage_class = \"ONEZONE_IA\"\n        },\n        {\n          days          = 90\n          storage_class = \"GLACIER\"\n        },\n      ]\n\n      noncurrent_version_expiration = {\n        days = 300\n      }\n    },\n    {\n      id      = \"log2\"\n      enabled = true\n\n      filter = {\n        prefix                   = \"log1/\"\n        object_size_greater_than = 200000\n        object_size_less_than    = 500000\n        tags = {\n          some    = \"value\"\n          another = \"value2\"\n        }\n      }\n\n      noncurrent_version_transition = [\n        {\n          days          = 30\n          storage_class = \"STANDARD_IA\"\n        },\n      ]\n\n      noncurrent_version_expiration = {\n        days = 300\n      }\n    },\n  ]\n\n  intelligent_tiering = {\n    general = {\n      status = \"Enabled\"\n      filter = {\n        prefix = \"/\"\n        tags = {\n          Environment = \"dev\"\n        }\n      }\n      tiering = {\n        ARCHIVE_ACCESS = {\n          days = 180\n        }\n      }\n    },\n    documents = {\n      status = false\n      filter = {\n        prefix = \"documents/\"\n      }\n      tiering = {\n        ARCHIVE_ACCESS = {\n          days = 125\n        }\n        DEEP_ARCHIVE_ACCESS = {\n          days = 200\n        }\n      }\n    }\n  }\n\n  metric_configuration = [\n    {\n      name = \"documents\"\n      filter = {\n        prefix = \"documents/\"\n        tags = {\n          priority = \"high\"\n        }\n      }\n    },\n    {\n      name = \"other\"\n      filter = {\n        tags = {\n          production = \"true\"\n        }\n      }\n    },\n    {\n      name = \"all\"\n    }\n  ]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/examples/complete/main.tf", "category": "compute", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n\n  # Make it faster by skipping something\n  skip_metadata_api_check     = true\n  skip_region_validation      = true\n  skip_credentials_validation = true\n}\n\nlocals {\n  bucket_name = \"s3-bucket-${random_pet.this.id}\"\n  region      = \"eu-west-1\"\n}\n\nresource \"random_pet\" \"this\" {\n  length = 2\n}\n\nmodule \"s3_bucket\" {\n  source = \"../../\"\n\n  bucket        = local.bucket_name\n  force_destroy = true\n}\n\n#############################################\n# Using packaged function from Lambda module\n#############################################\n\nlocals {\n  package_url = \"https://raw.githubusercontent.com/terraform-aws-modules/terraform-aws-lambda/master/examples/fixtures/python3.8-zip/existing_package.zip\"\n  downloaded  = \"downloaded_package_${md5(local.package_url)}.zip\"\n}\n\nresource \"null_resource\" \"download_package\" {\n  triggers = {\n    downloaded = local.downloaded\n  }\n\n  provisioner \"local-exec\" {\n    command = \"curl -L -o ${local.downloaded} ${local.package_url}\"\n  }\n}\n\nmodule \"lambda_function1\" {\n  source  = \"terraform-aws-modules/lambda/aws\"\n  version = \"~> 3.0\"\n\n  function_name = \"${random_pet.this.id}-lambda1\"\n  handler       = \"index.lambda_handler\"\n  runtime       = \"python3.8\"\n\n  create_package         = false\n  local_existing_package = local.downloaded\n}\n\nmodule \"lambda_function2\" {\n  source  = \"terraform-aws-modules/lambda/aws\"\n  version = \"~> 3.0\"\n\n  function_name = \"${random_pet.this.id}-lambda2\"\n  handler       = \"index.lambda_handler\"\n  runtime       = \"python3.8\"\n\n  create_package         = false\n  local_existing_package = local.downloaded\n}\n\nmodule \"sns_topic1\" {\n  source  = \"terraform-aws-modules/sns/aws\"\n  version = \"~> 3.0\"\n\n  name_prefix = \"${random_pet.this.id}-2\"\n}\n\nmodule \"sns_topic2\" {\n  source  = \"terraform-aws-modules/sns/aws\"\n  version = \"~> 3.0\"\n\n  name_prefix = \"${random_pet.this.id}-2\"\n}\n\nresource \"aws_sqs_queue\" \"this\" {\n  count = 2\n  name  = \"${random_pet.this.id}-${count.index}\"\n}\n\n# SQS policy created outside of the module\ndata \"aws_iam_policy_document\" \"sqs_external\" {\n  statement {\n    effect  = \"Allow\"\n    actions = [\"sqs:SendMessage\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"s3.amazonaws.com\"]\n    }\n\n    resources = [aws_sqs_queue.this[0].arn]\n  }\n}\n\nresource \"aws_sqs_queue_policy\" \"allow_external\" {\n  queue_url = aws_sqs_queue.this[0].id\n  policy    = data.aws_iam_policy_document.sqs_external.json\n}\n\nmodule \"all_notifications\" {\n  source = \"../../modules/notification\"\n\n  bucket = module.s3_bucket.s3_bucket_id\n\n  eventbridge = true\n\n  # Common error - Error putting S3 notification configuration: InvalidArgument: Configuration is ambiguously defined. Cannot have overlapping suffixes in two rules if the prefixes are overlapping for the same event type.\n\n  lambda_notifications = {\n    lambda1 = {\n      function_arn  = module.lambda_function1.lambda_function_arn\n      function_name = module.lambda_function1.lambda_function_name\n      events        = [\"s3:ObjectCreated:Put\"]\n      filter_prefix = \"prefix/\"\n      filter_suffix = \".json\"\n    }\n\n    lambda2 = {\n      function_arn  = module.lambda_function2.lambda_function_arn\n      function_name = module.lambda_function2.lambda_function_name\n      events        = [\"s3:ObjectCreated:Post\"]\n    }\n  }\n\n  sqs_notifications = {\n    sqs1 = {\n      queue_arn     = aws_sqs_queue.this[0].arn\n      events        = [\"s3:ObjectCreated:Put\"]\n      filter_prefix = \"prefix2/\"\n      filter_suffix = \".txt\"\n\n      #      queue_id =  aws_sqs_queue.this[0].id // optional\n    }\n  }\n\n  sns_notifications = {\n    sns1 = {\n      topic_arn     = module.sns_topic1.sns_topic_arn\n      events        = [\"s3:ObjectRemoved:Delete\"]\n      filter_prefix = \"prefix3/\"\n      filter_suffix = \".csv\"\n    }\n\n    sns2 = {\n      topic_arn = module.sns_topic2.sns_topic_arn\n      events    = [\"s3:ObjectRemoved:DeleteMarkerCreated\"]\n    }\n  }\n\n  # Creation of policy is handled outside of the module\n  create_sqs_policy = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/examples/notification/main.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\nlocals {\n  region = \"eu-west-1\"\n}\n\nprovider \"aws\" {\n  region = local.region\n\n  # Make it faster by skipping something\n  skip_metadata_api_check     = true\n  skip_region_validation      = true\n  skip_credentials_validation = true\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nmodule \"simple\" {\n  source = \"../../\"\n\n  is_directory_bucket = true\n  bucket              = random_pet.this.id\n  # https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-express-Endpoints.html\n  availability_zone_id = data.aws_availability_zones.available.zone_ids[1]\n}\n\nmodule \"complete\" {\n  source = \"../../\"\n\n  is_directory_bucket = true\n  bucket              = \"${random_pet.this.id}-complete\"\n  # https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-express-Endpoints.html\n  availability_zone_id = data.aws_availability_zones.available.zone_ids[1]\n  server_side_encryption_configuration = {\n    rule = {\n      bucket_key_enabled = true # required for directory buckets\n      apply_server_side_encryption_by_default = {\n        kms_master_key_id = aws_kms_key.objects.arn\n        sse_algorithm     = \"aws:kms\"\n      }\n    }\n  }\n  lifecycle_rule = [\n    {\n      id     = \"test\"\n      status = \"Enabled\"\n      expiration = {\n        days = 7\n      }\n    },\n    {\n      id     = \"logs\"\n      status = \"Enabled\"\n      expiration = {\n        days = 5\n      }\n      filter = {\n        prefix                = \"logs/\"\n        object_size_less_than = 10\n      }\n    },\n    {\n      id     = \"other\"\n      status = \"Enabled\"\n      expiration = {\n        days = 2\n      }\n      filter = {\n        prefix = \"other/\"\n      }\n    }\n  ]\n  attach_policy = true\n  policy        = data.aws_iam_policy_document.bucket_policy.json\n\n  tags = {\n    directory-bucket = true\n  }\n}\n\nresource \"random_pet\" \"this\" {\n  length = 2\n}\n\nresource \"aws_kms_key\" \"objects\" {\n  description             = \"KMS key is used to encrypt bucket objects\"\n  deletion_window_in_days = 7\n}\n\ndata \"aws_iam_policy_document\" \"bucket_policy\" {\n\n  statement {\n    sid    = \"ReadWriteAccess\"\n    effect = \"Allow\"\n\n    actions = [\n      \"s3express:CreateSession\",\n    ]\n\n    resources = [module.complete.s3_directory_bucket_arn]\n\n    principals {\n      identifiers = [data.aws_caller_identity.current.account_id]\n      type        = \"AWS\"\n    }\n  }\n\n  statement {\n    sid    = \"ReadOnlyAccess\"\n    effect = \"Allow\"\n\n    actions = [\n      \"s3express:CreateSession\",\n    ]\n\n    resources = [module.complete.s3_directory_bucket_arn]\n\n    principals {\n      identifiers = [data.aws_caller_identity.current.account_id]\n      type        = \"AWS\"\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      values   = [\"ReadOnly\"]\n      variable = \"s3express:SessionMode\"\n    }\n  }\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/examples/directory-bucket/main.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for VPC networking", "completion": "```hcl\nresource \"aws_codebuild_project\" \"frontend\" {\n  name          = \"frontend\"\n  build_timeout = \"5\"\n  service_role  = \"${aws_iam_role.frontend_build.arn}\"\n\n  artifacts {\n    type = \"S3\"\n    location = \"frontend.myapp.com\"\n    namespace_type = \"NONE\"\n    packaging = \"NONE\"\n    path = \"public\"\n  }\n\n  environment {\n    compute_type                = \"BUILD_GENERAL1_SMALL\"\n    image                       = \"aws/codebuild/standard:1.0\"\n    type                        = \"LINUX_CONTAINER\"\n    image_pull_credentials_type = \"CODEBUILD\"\n\n    environment_variable {\n      name  = \"SOME_KEY1\"\n      value = \"SOME_VALUE1\"\n    }\n  }\n\n  logs_config {\n    cloudwatch_logs {\n      group_name = \"build\"\n      stream_name = \"frontend-build\"\n    }\n  }\n\n  source {\n    type            = \"GITHUB\"\n    location        = \"https://github.com/MyOrg/my-repo.git\"\n    git_clone_depth = 1\n    report_build_status = true\n    auth {\n      type = \"OAUTH\"\n    }\n  }\n\n  vpc_config {\n    vpc_id = module.vpc.vpc_id\n    subnets = module.vpc.private_subnets\n    security_group_ids = [aws_security_group.build.id]\n  }\n}\n```", "metadata": {"source": "stackoverflow", "question_id": 58321632, "title": "AWS CodeBuild VPC_CLIENT_ERROR: Unexpected EC2 error: UnauthorizedOperation", "score": 22, "category": "storage", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure deployment", "completion": "```hcl\nmodule \"nat\" {\n  source     = \"GoogleCloudPlatform/nat-gateway/google\"\n  region     = \"europe-west1\"\n  network    = \"default\"\n  subnetwork = \"default\"\n}\n\nresource \"google_container_node_pool\" \"cluster_1_np\" {\n  name               = \"cluster-1-np\"\n  region             = \"europe-west1\"\n  cluster            = \"${google_container_cluster.cluster_1.name}\"\n  initial_node_count = 1\n\n  lifecycle {\n    ignore_changes = [\"node_count\"]\n  }\n\n  autoscaling {\n    min_node_count = 1\n    max_node_count = 50\n  }\n\n  management {\n    auto_repair  = true\n    auto_upgrade = true\n  }\n\n  node_config {\n    oauth_scopes = [\n      \"https://www.googleapis.com/auth/compute\",\n      \"https://www.googleapis.com/auth/devstorage.read_only\",\n      \"https://www.googleapis.com/auth/logging.write\",\n      \"https://www.googleapis.com/auth/monitoring\",\n      \"https://www.googleapis.com/auth/pubsub\",\n    ]\n\n    tags = [\"${module.nat.routing_tag_regional}\"]\n  }\n}\n\nresource \"google_container_cluster\" \"cluster_1\" {\n  provider                 = \"google-beta\"\n  name                     = \"cluster-1\"\n  region                   = \"europe-west1\"\n  remove_default_node_pool = true\n\n  private_cluster_config {\n    enable_private_endpoint = false\n    enable_private_nodes    = true\n    master_ipv4_cidr_block  = \"172.16.0.0/28\"\n  }\n\n  ip_allocation_policy {\n    create_subnetwork = true\n  }\n\n  lifecycle {\n    ignore_changes = [\"initial_node_count\", \"network_policy\", \"node_config\", \"node_pool\"]\n  }\n\n  node_pool {\n    name = \"default-pool\"\n  }\n\n  addons_config {\n    http_load_balancing {\n      disabled = false\n    }\n\n    horizontal_pod_autoscaling {\n      disabled = false\n    }\n  }\n\n  master_authorized_networks_config {\n    cidr_blocks = [\n      {\n        cidr_block   = \"<MY_OFFICE_CIDR>\"\n        display_name = \"Office\"\n      },\n    ]\n  }\n}\n```", "metadata": {"source": "stackoverflow", "question_id": 53106222, "title": "Terraformed private GKE cluster automation access", "score": 8, "category": "module", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure deployment", "completion": "```hcl\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n-/+ destroy and then create replacement\n\nTerraform will perform the following actions:\n\n  # module.dev_environment.google_compute_instance.dev_machine must be replaced\n-/+ resource \"google_compute_instance\" \"dev_machine\" {\n      ~ cpu_platform         = \"Intel Broadwell\" -> (known after apply)\n      ~ current_status       = \"RUNNING\" -> (known after apply)\n      ~ deletion_protection  = false -> true\n      - enable_display       = false -> null\n      ~ guest_accelerator    = [] -> (known after apply)\n      ~ id                   = \"<id with project>\" -> (known after apply)\n      ~ instance_id          = \"<instance id>\" -> (known after apply)\n      ~ label_fingerprint    = \"<label fingerprint>\" -> (known after apply)\n      - labels               = {} -> null\n      - metadata             = {} -> null\n      ~ metadata_fingerprint = \"<metadata fingerprint>=\" -> (known after apply)\n      + min_cpu_platform     = (known after apply)\n        name                 = \"dev-machine-pweather\"\n      ~ project              = \"<project id>\" -> (known after apply)\n      - resource_policies    = [] -> null\n      ~ self_link            = \"<project id url>/instances/dev-machine-pweather\" -> (known after apply)\n        tags                 = [\n            \"dev-vm-pweather\",\n        ]\n      ~ tags_fingerprint     = \"<tag fingerprint>\" -> (known after apply)\n      ~ zone                 = \"us-east4-a\" -> (known after apply)\n        # (2 unchanged attributes hidden)\n\n      ~ boot_disk {\n          ~ device_name                = \"persistent-disk-0\" -> (known after apply)\n          + disk_encryption_key_sha256 = (known after apply)\n          + kms_key_self_link          = (known after apply)\n          ~ source                     = \"<project id url>/us-east4-a/disks/dev-machine-pweather\" -> (known after apply)\n            # (2 unchanged attributes hidden)\n\n          ~ initialize_params {\n              ~ image  = \"https://www.googleapis.com/compute/v1/projects/ubuntu-os-pro-cloud/global/images/ubuntu-pro-2004-focal-v20210720\" -> \"ubuntu-os-pro-cloud/ubuntu-pro-2004-lts\" # forces replacement\n              ~ labels = {} -> (known after apply)\n              ~ type   = \"pd-standard\" -> (known after apply)\n                # (1 unchanged attribute hidden)\n            }\n        }\n\n      + confidential_instance_config {\n          + enable_confidential_compute = (known after apply)\n        }\n\n      ~ network_interface {\n          ~ name               = \"nic0\" -> (known after apply)\n          ~ network            = \"<project id url>/global/networks/pweather-vpc\" -> \"pweather-vpc\"\n          ~ network_ip         = \"10.0.0.17\" -> (known after apply)\n          ~ subnetwork         = \"<project id url>/subnetworks/pweather-subnet\" -> \"pweather-subnet\"\n          ~ subnetwork_project = \"<project>\" -> (known after apply)\n\n          ~ access_config {\n              ~ nat_ip       = \"<NAT IP> -> (known after apply)\n              ~ network_tier = \"PREMIUM\" -> (known after apply)\n            }\n        }\n\n      + reservation_affinity {\n          + type = (known after apply)\n\n          + specific_reservation {\n              + key    = (known after apply)\n              + values = (known after apply)\n            }\n        }\n\n      ~ scheduling {\n          ~ automatic_restart   = true -> (known after apply)\n          ~ min_node_cpus       = 0 -> (known after apply)\n          ~ on_host_maintenance = \"MIGRATE\" -> (known after apply)\n          ~ preemptible         = false -> (known after apply)\n\n          + node_affinities {\n              + key      = (known after apply)\n              + operator = (known after apply)\n              + values   = (known after apply)\n            }\n        }\n\n      - shielded_instance_config {\n          - enable_integrity_monitoring = true -> null\n          - enable_secure_boot          = false -> null\n          - enable_vtpm                 = true -> null\n        }\n    }\n\n  # module.dev_environment.google_compute_instance.dev_machine-minor must be replaced\n-/+ resource \"google_compute_instance\" \"dev_machine-minor\" {\n      ~ cpu_platform         = \"Intel Broadwell\" -> (known after apply)\n      ~ current_status       = \"RUNNING\" -> (known after apply)\n      ~ deletion_protection  = false -> true\n      - enable_display       = false -> null\n      ~ guest_accelerator    = [] -> (known after apply)\n      ~ id                   = \"<project id url>/instances/dev-machine-minor-pweather\" -> (known after apply)\n      ~ instance_id          = \"<instance id>\" -> (known after apply)\n      ~ label_fingerprint    = \"<label fingerprint>\" -> (known after apply)\n      - labels               = {} -> null\n      - metadata             = {} -> null\n      ~ metadata_fingerprint = \"udK04sf2kcQ=\" -> (known after apply)\n      + min_cpu_platform     = (known after apply)\n        name                 = \"dev-machine-minor-pweather\"\n      ~ project              = \"<project name>\" -> (known after apply)\n      - resource_policies    = [] -> null\n      ~ self_link            = \"<project id url>/us-east4-a/instances/dev-machine-minor-pweather\" -> (known after apply)\n        tags                 = [\n            \"dev-vm-pweather\",\n        ]\n      ~ tags_fingerprint     = \"<tag fingerprint>\" -> (known after apply)\n      ~ zone                 = \"us-east4-a\" -> (known after apply)\n        # (2 unchanged attributes hidden)\n\n      ~ boot_disk {\n          ~ device_name                = \"persistent-disk-0\" -> (known after apply)\n          + disk_encryption_key_sha256 = (known after apply)\n          + kms_key_self_link          = (known after apply)\n          ~ source                     = \"<project id url>/us-east4-a/disks/dev-machine-minor-pweather\" -> (known after apply)\n            # (2 unchanged attributes hidden)\n\n          ~ initialize_params {\n              ~ image  = \"https://www.googleapis.com/compute/v1/projects/ubuntu-os-pro-cloud/global/images/ubuntu-pro-2004-focal-v20210720\" -> \"ubuntu-os-pro-cloud/ubuntu-pro-2004-lts\" # forces replacement\n              ~ labels = {} -> (known after apply)\n              ~ type   = \"pd-standard\" -> (known after apply)\n                # (1 unchanged attribute hidden)\n            }\n        }\n\n      + confidential_instance_config {\n          + enable_confidential_compute = (known after apply)\n        }\n\n      ~ network_interface {\n          ~ name               = \"nic0\" -> (known after apply)\n          ~ network            = \"<project id url>>/global/networks/pweather-vpc\" -> \"pweather-vpc\"\n          ~ network_ip         = \"10.0.0.16\" -> (known after apply)\n          ~ subnetwork         = \"<project id url>/us-east4/subnetworks/pweather-subnet\" -> \"pweather-subnet\"\n          ~ subnetwork_project = \"<project>\" -> (known after apply)\n\n          ~ access_config {\n              ~ nat_ip       = \"<NAT IP>\" -> (known after apply)\n              ~ network_tier = \"PREMIUM\" -> (known after apply)\n            }\n        }\n\n      + reservation_affinity {\n          + type = (known after apply)\n\n          + specific_reservation {\n              + key    = (known after apply)\n              + values = (known after apply)\n            }\n        }\n\n      ~ scheduling {\n          ~ automatic_restart   = true -> (known after apply)\n          ~ min_node_cpus       = 0 -> (known after apply)\n          ~ on_host_maintenance = \"MIGRATE\" -> (known after apply)\n          ~ preemptible         = false -> (known after apply)\n\n          + node_affinities {\n              + key      = (known after apply)\n              + operator = (known after apply)\n              + values   = (known after apply)\n            }\n        }\n\n      - shielded_instance_config {\n          - enable_integrity_monitoring = true -> null\n          - enable_secure_boot          = false -> null\n          - enable_vtpm                 = true -> null\n        }\n    }\n\nPlan: 2 to add, 0 to change, 2 to destroy.\n\nChanges to Outputs:\n  ~ vm_ip = \"<VM IP>\" -> (known after apply)\n\n------------------------------------------------------------------------\n\nNote: You didn't specify an \"-out\" parameter to save this plan, so Terraform\ncan't guarantee that exactly these actions will be performed if\n\"terraform apply\" is subsequently run.\n```", "metadata": {"source": "stackoverflow", "question_id": 68574608, "title": "Terraform always tries to replace gcp compute instance without changes", "score": 4, "category": "infrastructure", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure deployment", "completion": "```hcl\nprovider \"kubernetes\" {\n  config_path = \"~/.kube/config\"\n}\n\nresource \"kubernetes_namespace\" \"tfs\" {\n  metadata {\n    name = \"tfs\" # terraform-sandbox\n  }\n}\n\nresource \"kubernetes_deployment\" \"golang_webapp\" {\n  metadata {\n    name      = \"golang-webapp\"\n    namespace = \"tfs\"\n    labels = {\n      app = \"webapp\"\n    }\n  }\n  spec {\n    replicas = 3\n    selector {\n      match_labels = {\n        app = \"webapp\"\n      }\n    }\n    template {\n      metadata {\n        labels = {\n          app = \"webapp\"\n        }\n      }\n      spec {\n        container {\n          image             = \"golang-docker-example\"\n          name              = \"golang-webapp\"\n          image_pull_policy = \"Never\" # this is set so that kuberenetes wont try to download the image but use the localy built one\n          liveness_probe {\n            http_get {\n              path = \"/\"\n              port = 8080\n            }\n            initial_delay_seconds = 15\n            period_seconds        = 15\n          }\n\n          readiness_probe {\n            http_get {\n              path = \"/\"\n              port = 8080\n            }\n            initial_delay_seconds = 3\n            period_seconds        = 3\n          }\n        }\n      }\n    }\n  }\n}\n\n\nresource \"kubernetes_service\" \"golang_webapp\" {\n  metadata {\n    name      = \"golang-webapp\"\n    namespace = \"tfs\"\n    labels = {\n      app = \"webapp_ingress\"\n    }\n  }\n  spec {\n    selector = {\n      app = kubernetes_deployment.golang_webapp.metadata.0.labels.app\n    }\n    port {\n      port        = 8080\n      target_port = 8080\n      protocol    = \"TCP\"\n    }\n    # type = \"ClusterIP\"\n    type = \"NodePort\"\n  }\n}\n\nresource \"kubernetes_ingress\" \"main_ingress\" {\n  metadata {\n    name      = \"main-ingress\"\n    namespace = \"tfs\"\n  }\n\n  spec {\n    rule {\n      http {\n        path {\n          backend {\n            service_name = \"golang-webapp\"\n            service_port = 8080\n          }\n          path = \"/golang-webapp\"\n        }\n      }\n    }\n  }\n}\n```", "metadata": {"source": "stackoverflow", "question_id": 70497809, "title": "Terraform fails to create ingress (could not find the requested resource ingresses.extensions)", "score": 15, "category": "orchestration", "authentic": true}}
