{"prompt": "Create a shell script for application deployment", "completion": "```bash\n# Step 1: Create a directory for packaging and copy your Python script\nmkdir -p package_daily\ncp historical_weather_fetch.py package_daily/\n\n# Step 2: Install the 'requests' dependency along with a compatible version of urllib3 into the package directory.\n# This forces urllib3 to remain in the 1.x series (e.g., 1.26.x) which works with Python 3.8.\npip install requests \"urllib3<2\" -t package_daily/ --quiet\n\n# Step 3: Create the deployment package as a zip file\ncd package_daily\nzip -r ../historical_weather_fetch.zip .\ncd ..\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/core/weather/fix2.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# Deploy script for the Visual Crossing weather data fetching Lambda functions\n# Sets up S3 bucket and Lambda functions to fetch and store weather data for various cities\n# Deployment region: af-south-1 (Cape Town)\n\n# Exit on error\nset -e\n\n# Check if .env file exists and load it\nif [ -f .env ]; then\n    export $(grep -v '^#' .env | xargs)\n    echo \"Loaded environment variables from .env file\"\nelse\n    echo \"No .env file found. Make sure you have set the VISUALCROSSING_API_KEY environment variable.\"\nfi\n\n# Check if API key is set\nif [ -z \"$VISUALCROSSING_API_KEY\" ]; then\n    echo \"VISUALCROSSING_API_KEY environment variable is not set.\"\n    echo \"Please set it using 'export VISUALCROSSING_API_KEY=your_api_key_here'\"\n    exit 1\nfi\n\n# Configuration\nREGION=\"us-east-1\"\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nLAMBDA_ROLE_NAME=\"lambda-weather-execution-role\"\nS3_BUCKET=\"visualcrossing-city-database\"\nLAMBDA_RUNTIME=\"python3.9\"\nLAMBDA_MEMORY=256\nLAMBDA_TIMEOUT=120\nLAMBDA_DAILY_WEATHER_NAME=\"daily_weather_fetch\"\n\n# Check if virtual environment exists, if not create one\nif [ ! -d \"venv\" ]; then\n    echo \"Creating virtual environment...\"\n    python3 -m venv venv\nfi\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Install dependencies\necho \"Installing dependencies...\"\npip install boto3 requests\n\n# Create output directory for packages\nmkdir -p build\n\necho \"Creating S3 bucket if it doesn't exist...\"\nif ! aws s3api head-bucket --bucket $S3_BUCKET --region $REGION 2>/dev/null; then\n    echo \"Creating S3 bucket: $S3_BUCKET\"\n    aws s3api create-bucket \\\n        --bucket $S3_BUCKET \\\n        --region $REGION \\\n        --create-bucket-configuration LocationConstraint=$REGION\n\n    # Wait for bucket to be available\n    echo \"Waiting for bucket to become available...\"\n    sleep 5\nelse\n    echo \"S3 bucket already exists: $S3_BUCKET\"\nfi\n\n# Create IAM role for Lambda if it doesn't exist\necho \"Setting up IAM role for Lambda...\"\nif ! aws iam get-role --role-name $LAMBDA_ROLE_NAME 2>/dev/null; then\n    echo \"Creating IAM role: $LAMBDA_ROLE_NAME\"\n\n    # Create a trust policy document for Lambda\n    cat > /tmp/trust-policy.json << EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n    # Create the role\n    aws iam create-role \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --assume-role-policy-document file:///tmp/trust-policy.json\n\n    # Attach policies\n    echo \"Attaching policies to IAM role...\"\n\n    # Basic execution role for CloudWatch Logs\n    aws iam attach-role-policy \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n\n    # S3 access for storing weather data\n    aws iam attach-role-policy \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess\n\n    # Wait for role to be ready\n    echo \"Waiting for IAM role to be ready...\"\n    sleep 10\nelse\n    echo \"IAM role already exists: $LAMBDA_ROLE_NAME\"\nfi\n\n# Get the IAM role ARN\nLAMBDA_ROLE_ARN=\"arn:aws:iam::$ACCOUNT_ID:role/$LAMBDA_ROLE_NAME\"\necho \"Using IAM role ARN: $LAMBDA_ROLE_ARN\"\n\n# Deploy daily weather fetch Lambda\necho \"Deploying daily weather fetch Lambda...\"\n\n# Package the code\necho \"Packaging daily_weather_fetch.py...\"\nmkdir -p build/daily_weather\ncp daily_weather_fetch.py build/daily_weather/\ncd build/daily_weather\nzip -r ../daily_weather_function.zip .\ncd ../..\n\n# Check if the Lambda function exists\nif aws lambda get-function --function-name $LAMBDA_DAILY_WEATHER_NAME --region $REGION 2>/dev/null; then\n    echo \"Updating existing Lambda function: $LAMBDA_DAILY_WEATHER_NAME\"\n\n    # FIRST: Update the Lambda function configuration\n    echo \"Updating Lambda configuration...\"\n    aws lambda update-function-configuration \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --timeout $LAMBDA_TIMEOUT \\\n        --memory-size $LAMBDA_MEMORY \\\n        --environment \"Variables={VISUALCROSSING_API_KEY=$VISUALCROSSING_API_KEY,S3_BUCKET=$S3_BUCKET}\" \\\n        --region $REGION\n\n    # Wait for configuration update to complete\n    echo \"Waiting for configuration update to complete...\"\n    sleep 10\n\n    # Verify environment variables\n    CURRENT_ENV=$(aws lambda get-function --function-name $LAMBDA_DAILY_WEATHER_NAME --region $REGION --query 'Configuration.Environment.Variables' --output json)\n    echo \"Updated environment variables: $CURRENT_ENV\"\n\n    # SECOND: Update the Lambda function code\n    echo \"Updating Lambda code...\"\n    aws lambda update-function-code \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --zip-file fileb://build/daily_weather_function.zip \\\n        --region $REGION\nelse\n    echo \"Creating new Lambda function: $LAMBDA_DAILY_WEATHER_NAME\"\n\n    # Create the Lambda function\n    aws lambda create-function \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --runtime $LAMBDA_RUNTIME \\\n        --role $LAMBDA_ROLE_ARN \\\n        --handler daily_weather_fetch.lambda_handler \\\n        --zip-file fileb://build/daily_weather_function.zip \\\n        --timeout $LAMBDA_TIMEOUT \\\n        --memory-size $LAMBDA_MEMORY \\\n        --environment \"Variables={VISUALCROSSING_API_KEY=$VISUALCROSSING_API_KEY,S3_BUCKET=$S3_BUCKET}\" \\\n        --region $REGION\nfi\n\n# Create or update EventBridge rule to trigger the Lambda daily at midnight UTC\nRULE_NAME=\"daily-weather-fetch-trigger\"\necho \"Setting up EventBridge rule: $RULE_NAME\"\n\naws events put-rule \\\n    --name $RULE_NAME \\\n    --schedule-expression \"cron(0 0 * * ? *)\" \\\n    --state ENABLED \\\n    --region $REGION\n\n# Add the daily weather Lambda as target\naws events put-targets \\\n    --rule $RULE_NAME \\\n    --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:$REGION:$ACCOUNT_ID:function:$LAMBDA_DAILY_WEATHER_NAME\" \\\n    --region $REGION\n\n# Add permission for EventBridge to invoke the Lambda\necho \"Adding permission for EventBridge to invoke Lambda...\"\naws lambda add-permission \\\n    --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n    --statement-id \"AllowExecutionFromEventBridge\" \\\n    --action \"lambda:InvokeFunction\" \\\n    --principal \"events.amazonaws.com\" \\\n    --source-arn \"arn:aws:events:$REGION:$ACCOUNT_ID:rule/$RULE_NAME\" \\\n    --region $REGION || true  # Ignore error if permission already exists\n\necho \"Deployment completed successfully!\"\necho \"The daily weather fetch Lambda will run every day at midnight UTC.\"\necho \"Weather data will be stored in s3://$S3_BUCKET/<city_name>/daily/ directories.\"\necho \"Historical data: s3://$S3_BUCKET/<city_name>/daily/YYYY-MM-DD.json\"\necho \"Forecast data: s3://$S3_BUCKET/<city_name>/daily/forecast_YYYY-MM-DD.json\"\n\n# Deactivate virtual environment\ndeactivate\n\necho \"You can test the Lambda function by running:\"\necho \"aws lambda invoke --function-name $LAMBDA_DAILY_WEATHER_NAME --payload '{}' --region $REGION output.json\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/core/weather/deploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#!/bin/bash\n# setup-monitoring.sh\n# Sets up CloudWatch alarms for monitoring core API components\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region> [environment]\"\n    echo \"Example: $0 eu-south-1 production\"\n    exit 1\nfi\n\n# Set variables\nTARGET_REGION=\"$1\"\nENVIRONMENT=\"${2:-production}\"  # Default to production if not specified\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\nALARM_EMAIL=\"<EMAIL>\"  # Replace with actual alert email\n\n# Load region-specific configuration\nCONFIG_FILE=\"$SCRIPT_DIR/../config/$TARGET_REGION.env\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n    echo \"Error: Configuration file not found: $CONFIG_FILE\"\n    echo \"Please create a configuration file for this region first.\"\n    exit 1\nfi\n\nsource \"$CONFIG_FILE\"\n\n# Function to check if SNS topic exists\nget_sns_topic_arn() {\n    local topic_name=\"${REGION_PREFIX}-api-alarms\"\n    local topic_arn\n\n    topic_arn=$(aws sns list-topics --region \"$TARGET_REGION\" \\\n        --query \"Topics[?contains(TopicArn, '$topic_name')].TopicArn\" \\\n        --output text)\n\n    if [ -n \"$topic_arn\" ]; then\n        echo \"$topic_arn\"\n        return 0\n    else\n        return 1\n    fi\n}\n\n# Function to check if email is subscribed to SNS topic\nis_email_subscribed() {\n    local topic_arn=$1\n    local email=$2\n\n    aws sns list-subscriptions-by-topic --region \"$TARGET_REGION\" \\\n        --topic-arn \"$topic_arn\" \\\n        --query \"Subscriptions[?Protocol=='email' && Endpoint=='$email'].SubscriptionArn\" \\\n        --output text | grep -q .\n}\n\n# Create or get SNS topic for alarms\necho \"Setting up SNS topic for alarms...\"\nSNS_TOPIC_ARN=$(get_sns_topic_arn) || {\n    echo \"Creating new SNS topic...\"\n    SNS_TOPIC_ARN=$(aws sns create-topic \\\n        --region \"$TARGET_REGION\" \\\n        --name \"${REGION_PREFIX}-api-alarms\" \\\n        --query 'TopicArn' \\\n        --output text)\n}\n\n# Subscribe email to SNS topic if not already subscribed\nif ! is_email_subscribed \"$SNS_TOPIC_ARN\" \"$ALARM_EMAIL\"; then\n    echo \"Subscribing email to SNS topic...\"\n    aws sns subscribe \\\n        --region \"$TARGET_REGION\" \\\n        --topic-arn \"$SNS_TOPIC_ARN\" \\\n        --protocol email \\\n        --notification-endpoint \"$ALARM_EMAIL\"\nelse\n    echo \"Email already subscribed to SNS topic\"\nfi\n\n# Function to check if alarm exists\nalarm_exists() {\n    local alarm_name=$1\n    aws cloudwatch describe-alarms --region \"$TARGET_REGION\" \\\n        --alarm-names \"$alarm_name\" \\\n        --query 'MetricAlarms[0].AlarmName' \\\n        --output text | grep -q .\n}\n\n# Function to create or update Lambda alarms\ncreate_lambda_alarms() {\n    local function_name=$1\n    local threshold=$2\n\n    echo \"Setting up alarms for Lambda function: $function_name\"\n\n    # Error rate alarm\n    local error_alarm_name=\"${REGION_PREFIX}-${function_name}-errors\"\n    if ! alarm_exists \"$error_alarm_name\"; then\n        echo \"Creating error rate alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name has errors\" \\\n            --metric-name Errors \\\n            --namespace AWS/Lambda \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Error rate alarm already exists\"\n    fi\n\n    # Duration alarm\n    local duration_alarm_name=\"${REGION_PREFIX}-${function_name}-duration\"\n    if ! alarm_exists \"$duration_alarm_name\"; then\n        echo \"Creating duration alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$duration_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name duration exceeds threshold\" \\\n            --metric-name Duration \\\n            --namespace AWS/Lambda \\\n            --statistic Average \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold \"$threshold\" \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Duration alarm already exists\"\n    fi\n\n    # Throttles alarm\n    local throttle_alarm_name=\"${REGION_PREFIX}-${function_name}-throttles\"\n    if ! alarm_exists \"$throttle_alarm_name\"; then\n        echo \"Creating throttles alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$throttle_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name is throttled\" \\\n            --metric-name Throttles \\\n            --namespace AWS/Lambda \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Throttles alarm already exists\"\n    fi\n}\n\n# Function to create or update API Gateway alarms\ncreate_api_alarms() {\n    local api_id=$1\n    local api_name=$2\n\n    echo \"Setting up alarms for API Gateway: $api_name\"\n\n    # 4XX errors alarm\n    local error_4xx_alarm_name=\"${REGION_PREFIX}-${api_name}-4xx-errors\"\n    if ! alarm_exists \"$error_4xx_alarm_name\"; then\n        echo \"Creating 4XX errors alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_4xx_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name has 4XX errors\" \\\n            --metric-name 4XXError \\\n            --namespace AWS/ApiGateway \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 10 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"4XX errors alarm already exists\"\n    fi\n\n    # 5XX errors alarm\n    local error_5xx_alarm_name=\"${REGION_PREFIX}-${api_name}-5xx-errors\"\n    if ! alarm_exists \"$error_5xx_alarm_name\"; then\n        echo \"Creating 5XX errors alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_5xx_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name has 5XX errors\" \\\n            --metric-name 5XXError \\\n            --namespace AWS/ApiGateway \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"5XX errors alarm already exists\"\n    fi\n\n    # Latency alarm\n    local latency_alarm_name=\"${REGION_PREFIX}-${api_name}-latency\"\n    if ! alarm_exists \"$latency_alarm_name\"; then\n        echo \"Creating latency alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$latency_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name latency is high\" \\\n            --metric-name Latency \\\n            --namespace AWS/ApiGateway \\\n            --statistic Average \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1000 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Latency alarm already exists\"\n    fi\n}\n\n# Function to create or update S3 bucket alarms\ncreate_s3_alarms() {\n    local bucket_name=$1\n\n    echo \"Setting up alarms for S3 bucket: $bucket_name\"\n\n    # Bucket size alarm\n    local size_alarm_name=\"${REGION_PREFIX}-${bucket_name}-size\"\n    if ! alarm_exists \"$size_alarm_name\"; then\n        echo \"Creating bucket size alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$size_alarm_name\" \\\n            --alarm-description \"Alarm when S3 bucket $bucket_name size is high\" \\\n            --metric-name BucketSizeBytes \\\n            --namespace AWS/S3 \\\n            --statistic Average \\\n            --period 86400 \\\n            --evaluation-periods 1 \\\n            --threshold 10737418240 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=BucketName,Value=\"$bucket_name\" Name=StorageType,Value=StandardStorage \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Bucket size alarm already exists\"\n    fi\n\n    # Number of objects alarm\n    local objects_alarm_name=\"${REGION_PREFIX}-${bucket_name}-objects\"\n    if ! alarm_exists \"$objects_alarm_name\"; then\n        echo \"Creating objects count alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$objects_alarm_name\" \\\n            --alarm-description \"Alarm when S3 bucket $bucket_name has too many objects\" \\\n            --metric-name NumberOfObjects \\\n            --namespace AWS/S3 \\\n            --statistic Average \\\n            --period 86400 \\\n            --evaluation-periods 1 \\\n            --threshold 1000000 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=BucketName,Value=\"$bucket_name\" Name=StorageType,Value=AllStorageTypes \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Objects count alarm already exists\"\n    fi\n}\n\n# Create alarms for all Lambda functions\necho \"Setting up Lambda function alarms...\"\ncreate_lambda_alarms \"ingestHistoricalData\" 300000  # 5 minutes\ncreate_lambda_alarms \"ingestNowcastData\" 300000\ncreate_lambda_alarms \"trainForecaster\" 900000  # 15 minutes\ncreate_lambda_alarms \"generatePresignedUrl\" 30000  # 30 seconds\ncreate_lambda_alarms \"interpolateData\" 300000\ncreate_lambda_alarms \"generateForecast\" 300000\ncreate_lambda_alarms \"returnForecastingResults\" 300000\ncreate_lambda_alarms \"marketPriceForecast\" 300000\ncreate_lambda_alarms \"electricityDispatch\" 300000\ncreate_lambda_alarms \"weather\" 300000\n\n# Create alarms for all API Gateways\necho \"Setting up API Gateway alarms...\"\nAPIS=$(aws apigateway get-rest-apis --region \"$TARGET_REGION\" --query \"items[?contains(name, '${REGION_PREFIX}')].[id,name]\" --output text)\nwhile read -r API_ID API_NAME; do\n    create_api_alarms \"$API_ID\" \"$API_NAME\"\ndone <<< \"$APIS\"\n\n# Create alarms for all S3 buckets\necho \"Setting up S3 bucket alarms...\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-input\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-output\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-facing\"\n\necho \"=============================================\"\necho \"CloudWatch alarms setup completed!\"\necho \"Alarm notifications will be sent to: $ALARM_EMAIL\"\necho \"=============================================\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/setup-monitoring.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Create a shell script for application deployment", "completion": "```bash\n#!/bin/bash\n\n# Automated Testing Framework Implementation\n# Location: /deploy/scripts/implement-testing.sh\n# Usage from repo root: deploy/scripts/implement-testing.sh [phase_number]\n# Usage from scripts dir: ./implement-testing.sh [phase_number]\n#\n# Examples:\n#   deploy/scripts/implement-testing.sh        # Run all phases\n#   deploy/scripts/implement-testing.sh 2      # Run only phase 2\n#   deploy/scripts/implement-testing.sh status # Check completion status\n\nset -e  # Exit on any error\n\n# Determine repo root from script location\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nREPO_ROOT=\"$(cd \"$SCRIPT_DIR/../..\" && pwd)\"\nLOG_FILE=\"$REPO_ROOT/testing-implementation.log\"\nVALIDATION_ERRORS=0\n\n# Change to repo root for all operations\ncd \"$REPO_ROOT\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\nlog() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nsuccess() {\n    echo -e \"${GREEN}✅ $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nwarning() {\n    echo -e \"${YELLOW}⚠️  $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nerror() {\n    echo -e \"${RED}❌ $1${NC}\" | tee -a \"$LOG_FILE\"\n    ((VALIDATION_ERRORS++))\n}\n\ninfo() {\n    echo -e \"${BLUE}ℹ️  $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nvalidate_environment() {\n    info \"Validating environment...\"\n    info \"Script location: $SCRIPT_DIR\"\n    info \"Repository root: $REPO_ROOT\"\n\n    # Check if we're in a git repo\n    if ! git rev-parse --git-dir > /dev/null 2>&1; then\n        error \"Not in a git repository\"\n        exit 1\n    fi\n\n    # Check for Python\n    if ! command -v python3 &> /dev/null; then\n        error \"Python3 not found\"\n        exit 1\n    fi\n\n    # Check for core directory\n    if [ ! -d \"$REPO_ROOT/core\" ]; then\n        error \"core/ directory not found in repository root: $REPO_ROOT\"\n        info \"Expected structure: $REPO_ROOT/core/\"\n        exit 1\n    fi\n\n    success \"Environment validation passed\"\n}\n\nphase1_foundation() {\n    info \"Phase 1: Setting up foundation...\"\n    info \"Working in repository root: $REPO_ROOT\"\n\n    # Check if already completed\n    if [ -f \".testing-framework-phase1\" ]; then\n        success \"Phase 1 already completed - skipping\"\n        return 0\n    fi\n\n    # Create test directory structure\n    info \"Creating test directory structure...\"\n    mkdir -p tests/{test_functionality,test_data_processing,test_error_handling,test_integration,test_performance,test_business_logic}\n    mkdir -p tests/fixtures/{sample_data,test_models,mock_responses}\n    mkdir -p tests/utils\n\n    # Create conftest.py (backup existing if present)\n    if [ -f \"tests/conftest.py\" ]; then\n        warning \"tests/conftest.py exists - backing up to tests/conftest.py.bak\"\n        cp tests/conftest.py tests/conftest.py.bak\n    fi\n\n    info \"Creating pytest configuration...\"\n    cat > tests/conftest.py << 'EOF'\nimport pytest\nimport sys\nimport os\nfrom unittest.mock import Mock, patch\nimport pandas as pd\nimport numpy as np\n\n# Add core package to path\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\n\n@pytest.fixture\ndef sample_weather_data():\n    return {\n        \"temperature\": [20, 22, 24, 26, 25, 23, 21],\n        \"solar_irradiance\": [0, 200, 400, 600, 400, 200, 0],\n        \"wind_speed\": [5, 7, 6, 8, 9, 6, 4]\n    }\n\n@pytest.fixture\ndef sample_load_data():\n    return pd.DataFrame({\n        \"timestamp\": pd.date_range(\"2024-01-01\", periods=24, freq=\"H\"),\n        \"load\": np.random.normal(100, 20, 24).clip(50, 200)\n    })\n\n@pytest.fixture\ndef mock_dispatch_config():\n    return {\n        \"battery_capacity\": 100.0,\n        \"battery_min_soc\": 0.2,\n        \"battery_max_soc\": 0.8,\n        \"solar_capacity\": 50.0,\n        \"grid_connection\": True\n    }\nEOF\n\n    # Create pytest.ini (backup existing if present)\n    if [ -f \"pytest.ini\" ]; then\n        warning \"pytest.ini exists - backing up to pytest.ini.bak\"\n        cp pytest.ini pytest.ini.bak\n    fi\n\n    info \"Creating pytest configuration...\"\n    cat > pytest.ini << 'EOF'\n[tool:pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts =\n    --verbose\n    --tb=short\n    --cov=core\n    --cov-report=term-missing\n    --cov-report=html\n    --timeout=300\nmarkers =\n    slow: marks tests as slow (deselect with '-m \"not slow\"')\n    integration: marks tests as integration tests\n    performance: marks tests as performance tests\nEOF\n\n    # Create GitHub Actions workflow (backup existing if present)\n    mkdir -p .github/workflows\n    if [ -f \".github/workflows/test.yml\" ]; then\n        warning \"GitHub Actions workflow exists - backing up to .github/workflows/test.yml.bak\"\n        cp .github/workflows/test.yml .github/workflows/test.yml.bak\n    fi\n\n    info \"Creating GitHub Actions workflow...\"\n    cat > .github/workflows/test.yml << 'EOF'\nname: Automated Testing Pipeline\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.8, 3.9, '3.10']\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v4\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install pytest pytest-cov pytest-timeout pytest-mock\n\n    - name: Install package\n      run: pip install -e .\n\n    - name: Run tests\n      run: pytest tests/ --cov=core --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\nEOF\n\n    # Validate Phase 1\n    if [ -d \"tests/test_functionality\" ] && [ -f \"tests/conftest.py\" ] && [ -f \".github/workflows/test.yml\" ]; then\n        # Mark phase as completed\n        echo \"$(date)\" > .testing-framework-phase1\n        success \"Phase 1 completed - Foundation setup complete\"\n        return 0\n    else\n        error \"Phase 1 validation failed\"\n        return 1\n    fi\n}\n\nphase2_core_testing() {\n    info \"Phase 2: Generating core tests...\"\n\n    # Check if already completed\n    if [ -f \".testing-framework-phase2\" ]; then\n        success \"Phase 2 already completed - skipping\"\n        return 0\n    fi\n\n    # Check if Phase 1 was completed\n    if [ ! -f \".testing-framework-phase1\" ]; then\n        error \"Phase 1 not completed - run Phase 1 first\"\n        return 1\n    fi\n\n    # Auto-generate basic functionality tests\n    info \"Auto-discovering modules and generating tests...\"\n    python3 << 'EOF'\nimport os\nimport sys\n\n# Ensure we're working from repo root\nrepo_root = os.getcwd()\ncore_path = os.path.join(repo_root, \"core\")\n\ndef discover_modules():\n    modules = []\n    if not os.path.exists(core_path):\n        print(f\"Error: core directory not found at {core_path}\")\n        return modules\n\n    for root, dirs, files in os.walk(core_path):\n        for file in files:\n            if file.endswith('.py') and not file.startswith('__'):\n                module_path = os.path.join(root, file)\n                # Convert to module name relative to repo root\n                rel_path = os.path.relpath(module_path, repo_root)\n                module_name = rel_path.replace('/', '.').replace('.py', '')\n                modules.append((module_name, module_path))\n    return modules\n\ndef generate_basic_test(module_name, module_path):\n    test_name = module_name.replace('.', '_')\n    return f'''\nimport pytest\nimport sys\nimport os\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))\n\ndef test_{test_name}_imports():\n    \"\"\"Test that {module_name} can be imported without errors.\"\"\"\n    try:\n        import {module_name}\n        assert True\n    except ImportError as e:\n        pytest.fail(f\"Failed to import {module_name}: {{e}}\")\n\ndef test_{test_name}_basic_functionality():\n    \"\"\"Test basic functionality of {module_name}.\"\"\"\n    try:\n        import {module_name}\n        # Add module-specific tests here\n        assert hasattr({module_name}, '__file__')\n    except Exception as e:\n        pytest.fail(f\"Basic functionality test failed for {module_name}: {{e}}\")\n'''\n\n# Generate tests for discovered modules\nmodules = discover_modules()\nfor module_name, module_path in modules:\n    if 'core.' in module_name:\n        test_content = generate_basic_test(module_name, module_path)\n        test_file = f\"tests/test_functionality/test_{module_name.replace('.', '_')}.py\"\n        os.makedirs(os.path.dirname(test_file), exist_ok=True)\n        with open(test_file, 'w') as f:\n            f.write(test_content)\n\nprint(f\"Generated {len(modules)} test files\")\nEOF\n\n    # Create data processing tests\n    cat > tests/test_data_processing/test_data_validation.py << 'EOF'\nimport pytest\nimport pandas as pd\nimport numpy as np\n\ndef test_data_frame_validation():\n    \"\"\"Test basic DataFrame validation.\"\"\"\n    df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n    assert len(df) == 3\n    assert list(df.columns) == ['a', 'b']\n\ndef test_time_series_validation():\n    \"\"\"Test time series data validation.\"\"\"\n    dates = pd.date_range('2024-01-01', periods=24, freq='H')\n    ts = pd.Series(range(24), index=dates)\n    assert len(ts) == 24\n    assert ts.index.freq == 'H'\n\ndef test_missing_data_handling():\n    \"\"\"Test handling of missing data.\"\"\"\n    data = [1, 2, None, 4, 5]\n    series = pd.Series(data)\n    assert series.isnull().sum() == 1\n    filled = series.fillna(series.mean())\n    assert filled.isnull().sum() == 0\nEOF\n\n    # Run tests to validate\n    if python3 -m pytest tests/test_functionality/ -v --tb=short; then\n        # Mark phase as completed\n        echo \"$(date)\" > .testing-framework-phase2\n        success \"Phase 2 completed - Core tests generated and passing\"\n        return 0\n    else\n        warning \"Phase 2 completed but some tests are failing\"\n        echo \"$(date)\" > .testing-framework-phase2\n        return 0  # Don't fail the phase for test failures\n    fi\n}\n\ncheck_status() {\n    info \"Checking implementation status...\"\n\n    for phase in 1 2 3 4; do\n        if [ -f \".testing-framework-phase${phase}\" ]; then\n            local date=$(cat .testing-framework-phase${phase})\n            success \"Phase ${phase}: Completed on ${date}\"\n        else\n            warning \"Phase ${phase}: Not completed\"\n        fi\n    done\n\n    echo \"\"\n    info \"To run missing phases:\"\n    echo \"  ./implement-testing.sh 1   # Run Phase 1 only\"\n    echo \"  ./implement-testing.sh 2   # Run Phase 2 only\"\n    echo \"  ./implement-testing.sh     # Run all incomplete phases\"\n}\n\nphase3_integration() {\n    info \"Phase 3: Creating integration tests...\"\n\n    # Check if already completed\n    if [ -f \".testing-framework-phase3\" ]; then\n        success \"Phase 3 already completed - skipping\"\n        return 0\n    fi\n\n    # Check if Phase 2 was completed\n    if [ ! -f \".testing-framework-phase2\" ]; then\n        error \"Phase 2 not completed - run Phase 2 first\"\n        return 1\n    fi\n\n    # Create integration test\n    cat > tests/test_integration/test_end_to_end.py << 'EOF'\nimport pytest\nimport sys\nimport os\n\ndef test_module_imports():\n    \"\"\"Test that core modules can be imported together.\"\"\"\n    try:\n        # Test importing main modules\n        modules_to_test = [\n            'core.electricityDispatch',\n            'core.marketPriceForecast',\n            'core.generateForecast',\n            'core.weather',\n            'core.interpolateData'\n        ]\n\n        imported = []\n        for module in modules_to_test:\n            try:\n                __import__(module)\n                imported.append(module)\n            except ImportError:\n                pass  # Module might not exist\n\n        assert len(imported) > 0, \"No core modules could be imported\"\n\n    except Exception as e:\n        pytest.fail(f\"Integration import test failed: {e}\")\n\ndef test_basic_workflow():\n    \"\"\"Test a basic workflow if modules are available.\"\"\"\n    try:\n        # This is a placeholder for actual workflow testing\n        # Would need to be customized based on available modules\n        assert True, \"Basic workflow placeholder test\"\n    except Exception as e:\n        pytest.fail(f\"Basic workflow test failed: {e}\")\nEOF\n\n    # Create business logic tests\n    cat > tests/test_business_logic/test_energy_constraints.py << 'EOF'\nimport pytest\nimport numpy as np\n\ndef test_energy_balance_logic():\n    \"\"\"Test energy balance constraint logic.\"\"\"\n    # Mock energy balance calculation\n    generation = np.array([10, 20, 30, 25, 15])\n    load = np.array([12, 18, 28, 22, 17])\n\n    # Simple energy balance check\n    net_energy = generation - load\n\n    # Test that we can calculate net energy\n    assert len(net_energy) == 5\n    assert isinstance(net_energy[0], (int, float, np.number))\n\ndef test_capacity_constraints():\n    \"\"\"Test capacity constraint validation.\"\"\"\n    battery_capacity = 100.0\n    current_soc = 0.5\n    charge_rate = 20.0\n\n    # Test charge limits\n    max_charge = min(charge_rate, (1.0 - current_soc) * battery_capacity)\n    assert max_charge >= 0\n    assert max_charge <= battery_capacity\n\n    # Test discharge limits\n    max_discharge = min(charge_rate, current_soc * battery_capacity)\n    assert max_discharge >= 0\n    assert max_discharge <= battery_capacity\nEOF\n\n    echo \"$(date)\" > .testing-framework-phase3\n    success \"Phase 3 completed - Integration and business logic tests created\"\n    return 0\n}\n\nphase4_monitoring() {\n    info \"Phase 4: Setting up monitoring and maintenance...\"\n\n    # Check if already completed\n    if [ -f \".testing-framework-phase4\" ]; then\n        success \"Phase 4 already completed - skipping\"\n        return 0\n    fi\n\n    # Check if Phase 3 was completed\n    if [ ! -f \".testing-framework-phase3\" ]; then\n        error \"Phase 3 not completed - run Phase 3 first\"\n        return 1\n    fi\n\n    # Create test monitoring script\n    cat > tests/utils/test_monitor.py << 'EOF'\n#!/usr/bin/env python3\nimport subprocess\nimport json\nimport sys\n\ndef run_tests_with_metrics():\n    \"\"\"Run tests and collect metrics.\"\"\"\n    try:\n        result = subprocess.run([\n            'python', '-m', 'pytest',\n            'tests/',\n            '--cov=core',\n            '--cov-report=json',\n            '--tb=short'\n        ], capture_output=True, text=True, timeout=900)\n\n        metrics = {\n            'exit_code': result.returncode,\n            'tests_passed': result.returncode == 0,\n            'stdout_lines': len(result.stdout.split('\\n')),\n            'stderr_lines': len(result.stderr.split('\\n'))\n        }\n\n        # Try to parse coverage\n        try:\n            with open('coverage.json', 'r') as f:\n                coverage_data = json.load(f)\n                metrics['coverage_percent'] = coverage_data['totals']['percent_covered']\n        except:\n            metrics['coverage_percent'] = 0\n\n        return metrics\n\n    except subprocess.TimeoutExpired:\n        return {'error': 'Tests timed out after 15 minutes'}\n\nif __name__ == '__main__':\n    metrics = run_tests_with_metrics()\n    print(json.dumps(metrics, indent=2))\nEOF\n\n    chmod +x tests/utils/test_monitor.py\n\n    # Create maintenance checklist\n    cat > TESTING_MAINTENANCE.md << 'EOF'\n# Testing Framework Maintenance\n\n## Daily Checks\n- [ ] All GitHub Actions workflows passing\n- [ ] Test coverage above 80%\n- [ ] No flaky tests (>2% failure rate)\n\n## Weekly Checks\n- [ ] Review test execution time (<15 minutes)\n- [ ] Update test data if needed\n- [ ] Review and fix any skipped tests\n\n## Monthly Checks\n- [ ] Update test dependencies\n- [ ] Review and refactor slow tests\n- [ ] Add tests for new features\n- [ ] Archive obsolete tests\n\n## Monitoring Commands\n```bash\n# Run all tests with coverage\npython -m pytest tests/ --cov=core --cov-report=html\n\n# Run only fast tests\npython -m pytest tests/ -m \"not slow\"\n\n# Run performance tests\npython -m pytest tests/test_performance/ --benchmark-only\n\n# Get test metrics\npython tests/utils/test_monitor.py\n```\nEOF\n\n    echo \"$(date)\" > .testing-framework-phase4\n    success \"Phase 4 completed - Monitoring and maintenance setup complete\"\n    return 0\n}\n\nrun_final_validation() {\n    info \"Running final validation...\"\n\n    local errors=0\n\n    # Check directory structure\n    if [ ! -d \"$REPO_ROOT/tests\" ]; then\n        error \"tests/ directory missing in $REPO_ROOT\"\n        ((errors++))\n    fi\n\n    # Check key files\n    for file in \"tests/conftest.py\" \"pytest.ini\" \".github/workflows/test.yml\"; do\n        if [ ! -f \"$REPO_ROOT/$file\" ]; then\n            error \"Required file missing: $REPO_ROOT/$file\"\n            ((errors++))\n        fi\n    done\n\n    # Try to run a basic test\n    if ! python3 -c \"import pytest; pytest.main(['--version'])\" > /dev/null 2>&1; then\n        warning \"pytest not available - install with: pip install pytest pytest-cov\"\n    else\n        info \"Running basic import tests...\"\n        if python3 -m pytest tests/ --collect-only > /dev/null 2>&1; then\n            success \"Test collection successful\"\n        else\n            warning \"Some tests may have collection issues\"\n        fi\n    fi\n\n    if [ $errors -eq 0 ]; then\n        success \"Final validation passed - Testing framework ready!\"\n        success \"Working directory: $REPO_ROOT\"\n        success \"Script location: $SCRIPT_DIR\"\n        return 0\n    else\n        error \"Final validation failed with $errors errors\"\n        return 1\n    fi\n}\n\n# Main execution\nmain() {\n    # Handle status check\n    if [ \"$1\" = \"status\" ]; then\n        check_status\n        exit 0\n    fi\n\n    local start_phase=1\n    local end_phase=4\n\n    if [ $# -eq 1 ]; then\n        start_phase=$1\n        end_phase=$1\n        info \"Running only Phase $1\"\n    else\n        info \"Running phases 1-4 (skipping completed phases)\"\n        # Auto-detect which phases need to be run\n        for phase in 1 2 3 4; do\n            if [ -f \".testing-framework-phase${phase}\" ]; then\n                info \"Phase ${phase} already completed - will skip\"\n            fi\n        done\n    fi\n\n    log \"Starting testing framework implementation...\"\n    log \"Script executed from: $SCRIPT_DIR\"\n    log \"Operating on repository: $REPO_ROOT\"\n\n    validate_environment\n\n    for phase in $(seq $start_phase $end_phase); do\n        case $phase in\n            1) phase1_foundation || exit 1 ;;\n            2) phase2_core_testing || exit 1 ;;\n            3) phase3_integration || exit 1 ;;\n            4) phase4_monitoring || exit 1 ;;\n            *) error \"Invalid phase: $phase\" && exit 1 ;;\n        esac\n    done\n\n    if [ $start_phase -eq 1 ] && [ $end_phase -eq 4 ]; then\n        run_final_validation\n    fi\n\n    success \"Implementation complete! Check $LOG_FILE for details.\"\n\n    if [ $VALIDATION_ERRORS -gt 0 ]; then\n        warning \"$VALIDATION_ERRORS validation warnings encountered\"\n    fi\n\n    info \"Next steps:\"\n    echo \"  1. Install test dependencies: pip install pytest pytest-cov pytest-timeout\"\n    echo \"  2. Run tests: python -m pytest tests/\"\n    echo \"  3. Check coverage: open htmlcov/index.html\"\n    echo \"  4. Commit changes: git add . && git commit -m 'Add automated testing framework'\"\n    echo \"\"\n    info \"Useful commands (from $REPO_ROOT):\"\n    echo \"  deploy/scripts/implement-testing.sh status    # Check which phases are completed\"\n    echo \"  deploy/scripts/implement-testing.sh 2         # Run only Phase 2\"\n    echo \"  deploy/scripts/implement-testing.sh           # Run all incomplete phases\"\n}\n\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/implement_testing.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/bash\n# build-and-push-images.sh\n# Script to build and push Docker images for core API components\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region>\"\n    echo \"Example: $0 eu-south-1\"\n    exit 1\nfi\n\nTARGET_REGION=\"$1\"\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\nPROJECT_ROOT=\"$(cd \"$SCRIPT_DIR/../../\" &> /dev/null && pwd)\"\n\necho \"Building and pushing Docker images to region: $TARGET_REGION\"\necho \"Account ID: $ACCOUNT_ID\"\necho \"Project root: $PROJECT_ROOT\"\n\n# Login to ECR\necho \"Logging in to ECR...\"\naws ecr get-login-password --region \"$TARGET_REGION\" | docker login --username AWS --password-stdin \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com\"\n\n# Components to build\nCOMPONENTS=(\n    \"ingestHistoricalLoadData:ingesthistoricaldata\"\n    \"ingestNowcastLoadData:ingestnowcastdata\"\n    \"trainForecaster:trainforecaster\"\n)\n\n# Build and push GeneratePresignedUrlLambda\necho \"Building and pushing GeneratePresignedUrlLambda...\"\ncd \"$PROJECT_ROOT/core/ingestHistoricalLoadData\"\n\n# Create a temporary Dockerfile for GeneratePresignedUrlLambda\ncat > Dockerfile.presignedurl << 'EOF'\nFROM public.ecr.aws/lambda/python:3.9\n\n# Copy GeneratePresignedUrlLambda.py\nCOPY GeneratePresignedUrlLambda.py ${LAMBDA_TASK_ROOT}\n\n# Install requirements\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Set the CMD to your handler\nCMD [\"GeneratePresignedUrlLambda.lambda_handler\"]\nEOF\n\n# Build and push the image\ndocker build -f Dockerfile.presignedurl -t \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com/generatepresignedurl/lambda:latest\" .\ndocker push \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com/generatepresignedurl/lambda:latest\"\n\n# Clean up temporary Dockerfile\nrm Dockerfile.presignedurl\n\n# Build and push other components\nfor COMPONENT in \"${COMPONENTS[@]}\"; do\n    # Split component name and repo name\n    COMPONENT_NAME=$(echo \"$COMPONENT\" | cut -d':' -f1)\n    REPO_NAME=$(echo \"$COMPONENT\" | cut -d':' -f2)\n\n    echo \"Building and pushing $COMPONENT_NAME...\"\n\n    # Change to component directory\n    cd \"$PROJECT_ROOT/core/$COMPONENT_NAME\"\n\n    # Build Docker image\n    docker build -t \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com/$REPO_NAME/lambda:latest\" .\n\n    # Push Docker image to ECR\n    docker push \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com/$REPO_NAME/lambda:latest\"\n\n    echo \"$COMPONENT_NAME built and pushed successfully\"\ndone\n\necho \"All images built and pushed successfully\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/build-and-push-images.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n#!/bin/bash\n# create-api-keys.sh\n# Script to create the admin (superuser) API key for a new environment and store it securely\n\nset -e  # Exit on error\n\nif [ $# -lt 2 ]; then\n    echo \"Usage: $0 <region> <environment>\"\n    echo \"Example: $0 eu-south-1 production\"\n    exit 1\nfi\n\nTARGET_REGION=\"$1\"\nENVIRONMENT=\"$2\"\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\n\nCONFIG_FILE=\"$SCRIPT_DIR/../config/$TARGET_REGION.env\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n    echo \"Error: Configuration file not found: $CONFIG_FILE\"\n    exit 1\nfi\n\nsource \"$CONFIG_FILE\"\n\nDYNAMO_TABLE=\"clients\"\nADMIN_CLIENT_ID=1\nADMIN_NAME=\"Admin\"\nADMIN_ROLE=\"superuser\"\nADMIN_EMAIL=\"<EMAIL>\"\nSECRET_NAME=\"ona-admin-api-key-$TARGET_REGION-$ENVIRONMENT\"\n\n# Check if admin client exists\nADMIN_EXISTS=$(aws dynamodb get-item \\\n    --region us-east-1 \\\n    --table-name \"$DYNAMO_TABLE\" \\\n    --key \"{\\\"client_id\\\":{\\\"N\\\":\\\"$ADMIN_CLIENT_ID\\\"}}\" \\\n    --query 'Item.client_id.N' \\\n    --output text 2>/dev/null || echo \"DOES_NOT_EXIST\")\n\nif [ \"$ADMIN_EXISTS\" = \"DOES_NOT_EXIST\" ]; then\n    echo \"Creating admin (superuser) client...\"\n    aws dynamodb put-item \\\n        --region us-east-1 \\\n        --table-name \"$DYNAMO_TABLE\" \\\n        --item \"{\\\"client_id\\\":{\\\"N\\\":\\\"$ADMIN_CLIENT_ID\\\"},\\\"name\\\":{\\\"S\\\":\\\"$ADMIN_NAME\\\"},\\\"role\\\":{\\\"S\\\":\\\"$ADMIN_ROLE\\\"},\\\"contact_email\\\":{\\\"S\\\":\\\"$ADMIN_EMAIL\\\"}}\"\n    echo \"Admin client created.\"\nelse\n    echo \"Admin client already exists.\"\nfi\n\n# Create API key for admin client\nPYTHON_CODE=\"\"\"\nfrom core.manageUsers.create_api_key import create_api_key\nimport boto3\nimport sys\nregion = '$TARGET_REGION'\nenvironment = '$ENVIRONMENT'\nclient_id = $ADMIN_CLIENT_ID\nkey = create_api_key(region, environment, client_id)\nif not key:\n    print('Failed to create or retrieve admin API key', file=sys.stderr)\n    sys.exit(1)\n# Store in AWS Secrets Manager\ndescription = f'Ona admin API key for {region} {environment}'\nsecrets = boto3.client('secretsmanager', region_name=region)\ntry:\n    secrets.create_secret(Name='$SECRET_NAME', SecretString=key, Description=description)\n    print(f'Stored admin API key in Secrets Manager: $SECRET_NAME')\nexcept secrets.exceptions.ResourceExistsException:\n    secrets.put_secret_value(SecretId='$SECRET_NAME', SecretString=key)\n    print(f'Updated admin API key in Secrets Manager: $SECRET_NAME')\n\"\"\"\n\npython3 -c \"$PYTHON_CODE\"\n\necho \"Admin API key setup complete.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/create-api-keys.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n#!/bin/bash\n# create-ecr-repos.sh\n# Script to create ECR repositories for core API components\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region>\"\n    echo \"Example: $0 eu-south-1\"\n    exit 1\nfi\n\nTARGET_REGION=\"$1\"\n\necho \"Creating ECR repositories in region: $TARGET_REGION\"\n\n# List of repository names to create\nREPO_NAMES=(\n    \"ingesthistoricaldata/lambda\"\n    \"ingestnowcastdata/lambda\"\n    \"trainforecaster/lambda\"\n    \"generatepresignedurl/lambda\"\n)\n\n# Create each repository if it doesn't exist\nfor REPO_NAME in \"${REPO_NAMES[@]}\"; do\n    echo \"Checking repository: $REPO_NAME\"\n\n    # Check if repository exists\n    if aws ecr describe-repositories --region \"$TARGET_REGION\" --repository-names \"$REPO_NAME\" >/dev/null 2>&1; then\n        echo \"Repository $REPO_NAME already exists\"\n    else\n        echo \"Creating repository: $REPO_NAME\"\n        aws ecr create-repository \\\n            --region \"$TARGET_REGION\" \\\n            --repository-name \"$REPO_NAME\" \\\n            --image-scanning-configuration scanOnPush=true\n\n        # Set lifecycle policy to keep only the last 5 images\n        echo \"Setting lifecycle policy for $REPO_NAME\"\n        aws ecr put-lifecycle-policy \\\n            --region \"$TARGET_REGION\" \\\n            --repository-name \"$REPO_NAME\" \\\n            --lifecycle-policy-text '{\n                \"rules\": [\n                    {\n                        \"rulePriority\": 1,\n                        \"description\": \"Keep only the last 5 images\",\n                        \"selection\": {\n                            \"tagStatus\": \"any\",\n                            \"countType\": \"imageCountMoreThan\",\n                            \"countNumber\": 5\n                        },\n                        \"action\": {\n                            \"type\": \"expire\"\n                        }\n                    }\n                ]\n            }'\n\n        echo \"Repository $REPO_NAME created successfully\"\n    fi\ndone\n\necho \"ECR repository setup complete\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/create-ecr-repos.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# deploy-core-api.sh\n# Main script for deploying core API endpoints to specified AWS region\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region> [environment]\"\n    echo \"Example: $0 eu-south-1 production\"\n    exit 1\nfi\n\n# Set variables\nTARGET_REGION=\"$1\"\nENVIRONMENT=\"${2:-production}\"  # Default to production if not specified\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\n\n# Define common tags for all resources\nTAGS=\"Environment=$ENVIRONMENT \\\n      Service=OnaAPI \\\n      Component=Core \\\n      CostCenter=EnergyForecasting \\\n      Owner=PlatformTeam \\\n      UptimeSLA=99.9 \\\n      DataClassification=Internal \\\n      Compliance=ISO27001 \\\n      ManagedBy=CloudFormation \\\n      Version=1.0\"\n\n# Function to check if a CloudFormation stack exists\nstack_exists() {\n    local stack_name=$1\n    aws cloudformation describe-stacks --region \"$TARGET_REGION\" \\\n        --stack-name \"$stack_name\" \\\n        --query 'Stacks[0].StackStatus' \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\n# Function to check if a stack is in a stable state\nis_stack_stable() {\n    local stack_name=$1\n    local status\n    status=$(stack_exists \"$stack_name\")\n    [[ \"$status\" =~ ^(CREATE_COMPLETE|UPDATE_COMPLETE|UPDATE_ROLLBACK_COMPLETE)$ ]]\n}\n\n# Function to wait for a stack to be stable\nwait_for_stack() {\n    local stack_name=$1\n    local max_attempts=30\n    local attempt=1\n\n    echo \"Waiting for stack $stack_name to be stable...\"\n    while [ $attempt -le $max_attempts ]; do\n        if is_stack_stable \"$stack_name\"; then\n            echo \"Stack $stack_name is stable\"\n            return 0\n        fi\n        echo \"Attempt $attempt/$max_attempts: Stack $stack_name is not stable yet...\"\n        sleep 30\n        ((attempt++))\n    done\n    echo \"Stack $stack_name did not become stable in time\"\n    return 1\n}\n\n# Function to check if ECR repository exists\necr_repo_exists() {\n    local repo_name=$1\n    aws ecr describe-repositories --region \"$TARGET_REGION\" \\\n        --repository-names \"$repo_name\" \\\n        --query 'repositories[0].repositoryName' \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\n# Function to check if API Gateway exists\napi_exists() {\n    local api_name=$1\n    aws apigateway get-rest-apis --region \"$TARGET_REGION\" \\\n        --query \"items[?name=='$api_name'].id\" \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\necho \"=============================================\"\necho \"Deploying Core API to region: $TARGET_REGION\"\necho \"Environment: $ENVIRONMENT\"\necho \"Account ID: $ACCOUNT_ID\"\necho \"=============================================\"\n\n# Load region-specific configuration\nCONFIG_FILE=\"$SCRIPT_DIR/config/$TARGET_REGION.env\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n    echo \"Error: Configuration file not found: $CONFIG_FILE\"\n    echo \"Please create a configuration file for this region first.\"\n    exit 1\nfi\n\nsource \"$CONFIG_FILE\"\n\n# Load environment-specific configuration (if exists)\nENV_CONFIG_FILE=\"$SCRIPT_DIR/config/$TARGET_REGION-$ENVIRONMENT.env\"\nif [ -f \"$ENV_CONFIG_FILE\" ]; then\n    source \"$ENV_CONFIG_FILE\"\n    echo \"Loaded environment-specific configuration from $ENV_CONFIG_FILE\"\nfi\n\n# Step 1: Create ECR repositories (if they don't exist)\necho \"Creating ECR repositories if they don't exist...\"\nfor repo in ingesthistoricaldata ingestnowcastdata trainforecaster generatepresignedurl \\\n            interpolatedata generateforecast returnforecastingresults marketpriceforecast \\\n            electricitydispatch weather; do\n    if [ \"$(ecr_repo_exists \"$repo/lambda\")\" = \"DOES_NOT_EXIST\" ]; then\n        echo \"Creating ECR repository: $repo/lambda\"\n        aws ecr create-repository --region \"$TARGET_REGION\" \\\n            --repository-name \"$repo/lambda\" \\\n            --tags $TAGS\n    else\n        echo \"ECR repository $repo/lambda already exists\"\n    fi\ndone\n\n# Step 2: Build and push Docker images\necho \"Building and pushing Docker images...\"\n\"$SCRIPT_DIR/scripts/build-and-push-images.sh\" \"$TARGET_REGION\"\n\n# Step 3: Deploy CloudFormation stack for S3 buckets\necho \"Deploying S3 buckets...\"\nS3_STACK_NAME=\"${REGION_PREFIX}-s3-buckets\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/s3-buckets.yaml\" \\\n    --stack-name \"$S3_STACK_NAME\" \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n    --tags $TAGS\n\n# Wait for S3 stack to be stable before proceeding\nwait_for_stack \"$S3_STACK_NAME\"\n\n# Step 4: Deploy CloudFormation stack for IAM roles\necho \"Deploying IAM roles...\"\nIAM_STACK_NAME=\"${REGION_PREFIX}-iam-roles\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/iam-roles.yaml\" \\\n    --stack-name \"$IAM_STACK_NAME\" \\\n    --capabilities CAPABILITY_NAMED_IAM \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n    --tags $TAGS\n\n# Wait for IAM stack to be stable before proceeding\nwait_for_stack \"$IAM_STACK_NAME\"\n\n# Step 5: Deploy CloudFormation stack for Lambda functions\necho \"Deploying Lambda functions...\"\nLAMBDA_STACK_NAME=\"${REGION_PREFIX}-lambda-functions\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/lambda-functions.yaml\" \\\n    --stack-name \"$LAMBDA_STACK_NAME\" \\\n    --capabilities CAPABILITY_IAM \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n        AccountId=\"$ACCOUNT_ID\" \\\n        LambdaMemory=\"$LAMBDA_MEMORY\" \\\n        IngestHistoricalDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/ingesthistoricaldata/lambda:latest\" \\\n        IngestNowcastDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/ingestnowcastdata/lambda:latest\" \\\n        TrainForecasterImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/trainforecaster/lambda:latest\" \\\n        GeneratePresignedUrlImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/generatepresignedurl/lambda:latest\" \\\n        InterpolateDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/interpolatedata/lambda:latest\" \\\n        GenerateForecastImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/generateforecast/lambda:latest\" \\\n        ReturnForecastingResultsImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/returnforecastingresults/lambda:latest\" \\\n        MarketPriceForecastImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/marketpriceforecast/lambda:latest\" \\\n        ElectricityDispatchImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/electricitydispatch/lambda:latest\" \\\n        WeatherImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/weather/lambda:latest\" \\\n    --tags $TAGS\n\n# Wait for Lambda stack to be stable before proceeding\nwait_for_stack \"$LAMBDA_STACK_NAME\"\n\n# Step 6: Deploy CloudFormation stack for API Gateway\necho \"Deploying API Gateway...\"\nAPI_STACK_NAME=\"${REGION_PREFIX}-api-gateway\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/api-gateway.yaml\" \\\n    --stack-name \"$API_STACK_NAME\" \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n        EndpointType=\"$API_ENDPOINT_TYPE\" \\\n        IngestHistoricalDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='IngestHistoricalDataFunctionArn'].OutputValue\" --output text) \\\n        IngestNowcastDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='IngestNowcastDataFunctionArn'].OutputValue\" --output text) \\\n        TrainForecasterFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='TrainForecasterFunctionArn'].OutputValue\" --output text) \\\n        GeneratePresignedUrlFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='GeneratePresignedUrlFunctionArn'].OutputValue\" --output text) \\\n        InterpolateDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='InterpolateDataFunctionArn'].OutputValue\" --output text) \\\n        GenerateForecastFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='GenerateForecastFunctionArn'].OutputValue\" --output text) \\\n        ReturnForecastingResultsFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='ReturnForecastingResultsFunctionArn'].OutputValue\" --output text) \\\n        MarketPriceForecastFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='MarketPriceForecastFunctionArn'].OutputValue\" --output text) \\\n        ElectricityDispatchFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='ElectricityDispatchFunctionArn'].OutputValue\" --output text) \\\n        WeatherFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='WeatherFunctionArn'].OutputValue\" --output text) \\\n    --tags $TAGS\n\n# Wait for API Gateway stack to be stable before proceeding\nwait_for_stack \"$API_STACK_NAME\"\n\n# Step 7: Create and configure API keys\necho \"Creating API keys...\"\n\"$SCRIPT_DIR/scripts/create-api-keys.sh\" \"$TARGET_REGION\" \"$ENVIRONMENT\"\n\n# Step 8: Deploy the API\necho \"Deploying API Gateway endpoints...\"\nAPIS=$(aws apigateway get-rest-apis --region \"$TARGET_REGION\" --query \"items[?contains(name, '${REGION_PREFIX}')].id\" --output text)\nfor API_ID in $APIS; do\n    echo \"Deploying API: $API_ID\"\n    aws apigateway create-deployment \\\n        --region \"$TARGET_REGION\" \\\n        --rest-api-id \"$API_ID\" \\\n        --stage-name \"$ENVIRONMENT\" \\\n        --description \"Deployment from deploy-core-api.sh script\" \\\n        --tags $TAGS\ndone\n\n# Step 9: Set up CloudWatch Alarms for monitoring\necho \"Setting up CloudWatch Alarms...\"\n\"$SCRIPT_DIR/scripts/setup-monitoring.sh\" \"$TARGET_REGION\" \"$ENVIRONMENT\"\n\necho \"=============================================\"\necho \"Core API deployment to $TARGET_REGION completed!\"\necho \"=============================================\"\n\n# Output API endpoints\necho \"API Endpoints:\"\nfor API_ID in $APIS; do\n    API_NAME=$(aws apigateway get-rest-api --region \"$TARGET_REGION\" --rest-api-id \"$API_ID\" --query \"name\" --output text)\n    echo \"$API_NAME: https://$API_ID.execute-api.$TARGET_REGION.amazonaws.com/$ENVIRONMENT\"\ndone\n\necho \"See CloudFormation stacks for more details:\"\necho \"https://$TARGET_REGION.console.aws.amazon.com/cloudformation/home?region=$TARGET_REGION#/stacks\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/deploy-core-api.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\nset -euo pipefail\n\n###############################\n# CONFIGURATION & INITIALIZATION\n###############################\n\n# Region and account information\nREGION=${AWS_DEFAULT_REGION:-us-east-1}\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n\n# Lambda function configuration\nFUNCTION_NAME=\"LogsProxyFunction\"\nZIP_FILE=\"logsProxyLambda.zip\"            # The deployment package to be created if it doesn't exist.\nSOURCE_FILE=\"logsProxyLambda.js\"          # Your Lambda source code file.\nHANDLER=\"logsProxyLambda.handler\"         # Expects an exported function named 'handler' in the source file.\nRUNTIME=\"nodejs18.x\"\nROLE_NAME=\"lambda-execution-role\"\n\n# API Gateway configuration\nAPI_NAME=\"LogsProxyApi\"\nSTAGE_NAME=\"test\"\nRESOURCE_PATH=\"logs\"\nAPI_KEY_NAME=\"LogsProxyApiKey\"\nUSAGE_PLAN_NAME=\"LogsProxyUsagePlan\"\n\n###############################\n# PREPARE LAMBDA DEPLOYMENT PACKAGE\n###############################\n# If the ZIP file does not exist, create it from the SOURCE_FILE.\nif [ ! -f \"$ZIP_FILE\" ]; then\n  if [ ! -f \"$SOURCE_FILE\" ]; then\n    echo \"Error: Lambda source file '$SOURCE_FILE' not found. Aborting.\"\n    exit 1\n  fi\n  echo \"Lambda deployment package not found. Creating '$ZIP_FILE' from '$SOURCE_FILE'...\"\n  zip \"$ZIP_FILE\" \"$SOURCE_FILE\"\nfi\n\n###############################\n# CREATE OR VERIFY IAM ROLE\n###############################\necho \"Checking for IAM role '$ROLE_NAME'...\"\nif ! aws iam get-role --role-name \"$ROLE_NAME\" >/dev/null 2>&1; then\n  echo \"IAM role '$ROLE_NAME' not found. Creating it...\"\n  # Create a temporary trust policy file\n  cat > trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Principal\": { \"Service\": \"lambda.amazonaws.com\" },\n    \"Action\": \"sts:AssumeRole\"\n  }]\n}\nEOF\n  aws iam create-role --role-name \"$ROLE_NAME\" --assume-role-policy-document file://trust-policy.json\n  # Attach the basic Lambda execution policy\n  aws iam attach-role-policy --role-name \"$ROLE_NAME\" --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n  # Wait a few seconds for IAM propagation\n  sleep 10\n  rm trust-policy.json\nfi\nROLE_ARN=$(aws iam get-role --role-name \"$ROLE_NAME\" --query 'Role.Arn' --output text)\necho \"Using IAM Role ARN: $ROLE_ARN\"\n\n###############################\n# CREATE OR UPDATE THE LAMBDA FUNCTION\n###############################\nif aws lambda get-function --function-name \"$FUNCTION_NAME\" >/dev/null 2>&1; then\n  echo \"Lambda function '$FUNCTION_NAME' exists. Updating function code...\"\n  aws lambda update-function-code \\\n    --function-name \"$FUNCTION_NAME\" \\\n    --zip-file fileb://\"$ZIP_FILE\"\nelse\n  echo \"Creating Lambda function '$FUNCTION_NAME'...\"\n  aws lambda create-function \\\n    --function-name \"$FUNCTION_NAME\" \\\n    --runtime \"$RUNTIME\" \\\n    --role \"$ROLE_ARN\" \\\n    --handler \"$HANDLER\" \\\n    --zip-file fileb://\"$ZIP_FILE\" \\\n    --memory-size 128 \\\n    --timeout 30\nfi\n\n# Retrieve the Lambda function ARN for integration\nLAMBDA_ARN=$(aws lambda get-function --function-name \"$FUNCTION_NAME\" --query 'Configuration.FunctionArn' --output text)\necho \"Lambda function ARN: $LAMBDA_ARN\"\n\n###############################\n# CREATE THE API GATEWAY REST API\n###############################\necho \"Creating API Gateway REST API '$API_NAME'...\"\nAPI_ID=$(aws apigateway create-rest-api --name \"$API_NAME\" --query 'id' --output text)\necho \"API ID: $API_ID\"\n\n# Get the root resource ID (the \"/\" resource)\nROOT_ID=$(aws apigateway get-resources --rest-api-id \"$API_ID\" --query 'items[?path==`/`].id' --output text)\necho \"Root Resource ID: $ROOT_ID\"\n\n# Create a new resource for the path \"/logs\"\necho \"Creating resource for '/$RESOURCE_PATH'...\"\nLOGS_RESOURCE_ID=$(aws apigateway create-resource \\\n  --rest-api-id \"$API_ID\" \\\n  --parent-id \"$ROOT_ID\" \\\n  --path-part \"$RESOURCE_PATH\" \\\n  --query 'id' --output text)\necho \"Logs Resource ID: $LOGS_RESOURCE_ID\"\n\n# Create a GET method on the /logs resource with API key requirement\necho \"Creating GET method on '/$RESOURCE_PATH' with API Key required...\"\naws apigateway put-method \\\n  --rest-api-id \"$API_ID\" \\\n  --resource-id \"$LOGS_RESOURCE_ID\" \\\n  --http-method GET \\\n  --authorization-type \"NONE\" \\\n  --api-key-required\n\n# Set up Lambda proxy integration for the GET method\necho \"Setting up Lambda proxy integration for GET '/$RESOURCE_PATH'...\"\naws apigateway put-integration \\\n  --rest-api-id \"$API_ID\" \\\n  --resource-id \"$LOGS_RESOURCE_ID\" \\\n  --http-method GET \\\n  --type AWS_PROXY \\\n  --integration-http-method POST \\\n  --uri \"arn:aws:apigateway:${REGION}:lambda:path/2015-03-31/functions/${LAMBDA_ARN}/invocations\"\n\n# Grant API Gateway permission to invoke the Lambda function\necho \"Adding permission for API Gateway to invoke Lambda...\"\naws lambda add-permission \\\n  --function-name \"$FUNCTION_NAME\" \\\n  --statement-id \"apigateway-invoke-permissions\" \\\n  --action lambda:InvokeFunction \\\n  --principal apigateway.amazonaws.com \\\n  --source-arn \"arn:aws:execute-api:${REGION}:${ACCOUNT_ID}:${API_ID}/*/GET/$RESOURCE_PATH\"\n\n###############################\n# DEPLOY THE API\n###############################\necho \"Deploying API to stage '$STAGE_NAME'...\"\naws apigateway create-deployment --rest-api-id \"$API_ID\" --stage-name \"$STAGE_NAME\"\n\n###############################\n# CREATE API KEY, USAGE PLAN, AND ASSOCIATE THEM\n###############################\necho \"Creating API Key '$API_KEY_NAME'...\"\nAPI_KEY_ID=$(aws apigateway create-api-key --name \"$API_KEY_NAME\" --enabled --query 'id' --output text)\necho \"API Key ID: $API_KEY_ID\"\n\necho \"Creating Usage Plan '$USAGE_PLAN_NAME'...\"\nUSAGE_PLAN_ID=$(aws apigateway create-usage-plan \\\n  --name \"$USAGE_PLAN_NAME\" \\\n  --api-stages apiId=\"$API_ID\",stage=\"$STAGE_NAME\" \\\n  --throttle burstLimit=2,rateLimit=10 \\\n  --query 'id' --output text)\necho \"Usage Plan ID: $USAGE_PLAN_ID\"\n\necho \"Associating API Key with the Usage Plan...\"\naws apigateway create-usage-plan-key \\\n  --usage-plan-id \"$USAGE_PLAN_ID\" \\\n  --key-id \"$API_KEY_ID\" \\\n  --key-type API_KEY\n\n###############################\n# OUTPUT THE ENDPOINT AND API KEY VALUE\n###############################\nAPI_ENDPOINT=\"https://${API_ID}.execute-api.${REGION}.amazonaws.com/${STAGE_NAME}/logs\"\necho \"API Endpoint: $API_ENDPOINT\"\n\nAPI_KEY_VALUE=$(aws apigateway get-api-key --api-key \"$API_KEY_ID\" --include-value --query 'value' --output text)\necho \"API Key: $API_KEY_VALUE\"\n\n###############################################################################\n# Changelog:\n#\n# 1. **Deployment Package Creation:**\n#    - Added a check to see if the ZIP file (logsProxyLambda.zip) exists.\n#    - If it does not exist, the script checks for the source file (logsProxyLambda.js)\n#      and creates the ZIP file using the `zip` command.\n#\n# 2. **Lambda Function Creation/Update:**\n#    - The script checks if the Lambda function exists.\n#      - If it exists, it updates the function code.\n#      - If it does not exist, it creates the function using the newly created ZIP file.\n#\n# 3. **Remaining API Gateway Setup:**\n#    - Continues with creating the API Gateway REST API, resource, method, integration,\n#      deployment, API key, usage plan, and association.\n#\n# This script now does not assume the Lambda function already exists; it packages\n# the source code, creates the Lambda function if needed, and then proceeds with deployment.\n###############################################################################\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/deploy_proxy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n#!/bin/bash\nset -euo pipefail\n\n# This script releases all unused (unassociated) Elastic IP addresses in your AWS account.\n# When you hit the AWS EIP limit, running this script will free up EIPs that are not in use.\n#\n# Usage:\n#   1. Save this script as release_unused_eips.sh\n#   2. Make it executable: chmod +x release_unused_eips.sh\n#   3. Run the script: ./release_unused_eips.sh\n\necho \"Fetching all allocated Elastic IP addresses that are unused...\"\n# Retrieves the AllocationIds of EIPs that are not associated with any resource\nEIP_IDS=$(aws ec2 describe-addresses --query 'Addresses[?AssociationId==null].AllocationId' --output text)\n\nif [ -z \"$EIP_IDS\" ]; then\n    echo \"No unused Elastic IP addresses found. You have not exceeded your limit due to unused addresses.\"\n    exit 0\nfi\n\necho \"Found the following unused Elastic IP addresses:\"\necho \"$EIP_IDS\"\necho\n\nfor eip in $EIP_IDS; do\n    echo \"Releasing Elastic IP: $eip...\"\n    aws ec2 release-address --allocation-id \"$eip\"\n    echo \"Released Elastic IP: $eip\"\ndone\n\necho \"All unused Elastic IP addresses have been released.\"\n\n# Changelog:\n# -------------\n# 1. **Purpose:**\n#    - Added a new script to automatically release any unused (unassociated) Elastic IP addresses.\n#\n# 2. **Elastic IP Retrieval:**\n#    - Uses the command `aws ec2 describe-addresses` with a JMESPath query to filter for addresses\n#      where `AssociationId` is null. This ensures only unused EIPs are targeted.\n#\n# 3. **Loop & Release:**\n#    - Iterates over each unused Elastic IP and calls `aws ec2 release-address` to free it.\n#\n# 4. **Logging:**\n#    - Detailed echo statements are provided to inform the user of which EIPs are being released.\n#\n# 5. **Error Handling:**\n#    - Uses `set -euo pipefail` to ensure the script exits if any command fails or if a variable is undefined.\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/release.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# cleanup.sh\n# Consolidated cleanup script for AWS resources used by the data scraper system\n#=============================================================================\n\n# Source the common library\n# shellcheck disable=SC1091\nsource \"$(dirname \"${BASH_SOURCE[0]}\")/common-lib.sh\"\n\n# Function to display help specific to this script\nshow_help() {\n  display_help \"all       Clean up all AWS resources (Lambda, ECS, ECR, networking)\n  lambda    Clean up Lambda functions, roles, event sources, and SQS queues\n  ecs       Clean up ECS cluster, services, and task definitions\n  ecr       Clean up ECR repositories and container images\n  network   Clean up VPC, subnets, gateways, and security groups\"\n}\n\n#-----------------------------------------------------------------------------\n# ECR REPOSITORY CLEANUP\n#-----------------------------------------------------------------------------\n\n# Clean up ECR resources (repository and images)\ncleanup_ecr() {\n  log_section \"Cleaning up ECR resources\"\n\n  if resource_exists \"ecr\" \"$ECR_REPO\"; then\n    # List all images in the repository\n    local images=$(aws ecr list-images --repository-name \"$ECR_REPO\" --region \"$REGION\" --query 'imageIds[*]' --output json)\n\n    if [[ \"$images\" != \"[]\" && -n \"$images\" ]]; then\n      log_info \"Deleting all images from ECR repository: $ECR_REPO\"\n      aws ecr batch-delete-image \\\n        --repository-name \"$ECR_REPO\" \\\n        --image-ids \"$images\" \\\n        --region \"$REGION\"\n    fi\n\n    log_info \"Deleting ECR repository: $ECR_REPO\"\n    aws ecr delete-repository \\\n      --repository-name \"$ECR_REPO\" \\\n      --force \\\n      --region \"$REGION\"\n  else\n    log_info \"ECR repository '$ECR_REPO' does not exist\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# NETWORKING RESOURCE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Clean up networking resources (VPC, subnets, gateways, etc.)\ncleanup_networking() {\n  log_section \"Cleaning up networking resources\"\n\n  # Get the VPC ID based on the cluster name tag\n  VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=tag:Name,Values=$CLUSTER_NAME-vpc\" --query \"Vpcs[0].VpcId\" --output text --region \"$REGION\")\n\n  if [[ \"$VPC_ID\" != \"None\" && -n \"$VPC_ID\" ]]; then\n    # Get the NAT Gateway ID\n    NAT_GW_ID=$(aws ec2 describe-nat-gateways --filter \"Name=vpc-id,Values=$VPC_ID\" --query \"NatGateways[0].NatGatewayId\" --output text --region \"$REGION\")\n    if [[ \"$NAT_GW_ID\" != \"None\" && -n \"$NAT_GW_ID\" ]]; then\n      log_info \"Deleting NAT Gateway: $NAT_GW_ID\"\n      aws ec2 delete-nat-gateway --nat-gateway-id \"$NAT_GW_ID\" --region \"$REGION\"\n      # Wait for NAT Gateway to be deleted\n      aws ec2 wait nat-gateway-deleted --nat-gateway-ids \"$NAT_GW_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Elastic IP associated with the NAT Gateway\n    EIP_ALLOC_ID=$(aws ec2 describe-addresses --filter \"Name=domain,Values=vpc\" --query \"Addresses[0].AllocationId\" --output text --region \"$REGION\")\n    if [[ \"$EIP_ALLOC_ID\" != \"None\" && -n \"$EIP_ALLOC_ID\" ]]; then\n      log_info \"Releasing Elastic IP: $EIP_ALLOC_ID\"\n      aws ec2 release-address --allocation-id \"$EIP_ALLOC_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Security Group ID\n    SEC_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=group-name,Values=$SEC_GROUP_NAME\" --query \"SecurityGroups[0].GroupId\" --output text --region \"$REGION\")\n    if [[ \"$SEC_GROUP_ID\" != \"None\" && -n \"$SEC_GROUP_ID\" ]]; then\n      log_info \"Deleting Security Group: $SEC_GROUP_ID\"\n      aws ec2 delete-security-group --group-id \"$SEC_GROUP_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Subnet IDs\n    SUBNET_IDS=$(aws ec2 describe-subnets --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"Subnets[].SubnetId\" --output text --region \"$REGION\")\n    if [[ -n \"$SUBNET_IDS\" ]]; then\n      for SUBNET_ID in $SUBNET_IDS; do\n        log_info \"Deleting Subnet: $SUBNET_ID\"\n        aws ec2 delete-subnet --subnet-id \"$SUBNET_ID\" --region \"$REGION\"\n      done\n    fi\n\n    # Get the Route Table ID\n    RT_ID=$(aws ec2 describe-route-tables --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"RouteTables[0].RouteTableId\" --output text --region \"$REGION\")\n    if [[ \"$RT_ID\" != \"None\" && -n \"$RT_ID\" ]]; then\n      log_info \"Deleting Route Table: $RT_ID\"\n      aws ec2 delete-route-table --route-table-id \"$RT_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Internet Gateway ID\n    IGW_ID=$(aws ec2 describe-internet-gateways --filters \"Name=attachment.vpc-id,Values=$VPC_ID\" --query \"InternetGateways[0].InternetGatewayId\" --output text --region \"$REGION\")\n    if [[ \"$IGW_ID\" != \"None\" && -n \"$IGW_ID\" ]]; then\n      log_info \"Detaching Internet Gateway from VPC: $IGW_ID\"\n      aws ec2 detach-internet-gateway --internet-gateway-id \"$IGW_ID\" --vpc-id \"$VPC_ID\" --region \"$REGION\"\n      log_info \"Deleting Internet Gateway: $IGW_ID\"\n      aws ec2 delete-internet-gateway --internet-gateway-id \"$IGW_ID\" --region \"$REGION\"\n    fi\n\n    # Finally, delete the VPC\n    log_info \"Deleting VPC: $VPC_ID\"\n    aws ec2 delete-vpc --vpc-id \"$VPC_ID\" --region \"$REGION\"\n  else\n    log_info \"VPC for cluster '$CLUSTER_NAME' not found\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# ECS RESOURCE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Clean up ECS resources (services, cluster, and log groups)\ncleanup_ecs() {\n  log_section \"Cleaning up ECS resources\"\n\n  # Update service to 0 tasks if it exists\n  if resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    log_info \"Updating ECS Service to 0 tasks: $SERVICE_NAME\"\n    aws ecs update-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --desired-count 0 \\\n      --region \"$REGION\"\n\n    log_info \"Waiting for service to stabilize...\"\n    aws ecs wait services-stable \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --services \"$SERVICE_NAME\" \\\n      --region \"$REGION\"\n\n    log_info \"Deleting ECS Service: $SERVICE_NAME\"\n    aws ecs delete-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --force \\\n      --region \"$REGION\"\n  else\n    log_info \"ECS Service '$SERVICE_NAME' does not exist\"\n  fi\n\n  # Delete ECS Cluster if it exists\n  if resource_exists \"ecs-cluster\" \"$CLUSTER_NAME\"; then\n    log_info \"Deleting ECS Cluster: $CLUSTER_NAME\"\n    aws ecs delete-cluster \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --region \"$REGION\"\n  else\n    log_info \"ECS Cluster '$CLUSTER_NAME' does not exist\"\n  fi\n\n  # Delete CloudWatch Log Group\n  local log_group=\"$LOG_GROUP_PREFIX/$CLUSTER_NAME\"\n  if aws logs describe-log-groups --log-group-name-prefix \"$log_group\" --region \"$REGION\" | grep -q \"$log_group\"; then\n    log_info \"Deleting CloudWatch Log Group: $log_group\"\n    aws logs delete-log-group --log-group-name \"$log_group\" --region \"$REGION\"\n  else\n    log_info \"CloudWatch Log Group '$log_group' does not exist\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# LAMBDA FUNCTION CLEANUP\n#-----------------------------------------------------------------------------\n\n# Clean up Lambda resources (functions, roles, queues, etc.)\ncleanup_lambda() {\n  log_section \"Cleaning up Lambda resources\"\n\n  # Delete CloudWatch rule\n  if aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" &> /dev/null; then\n    log_info \"Removing CloudWatch rule targets...\"\n    aws events remove-targets --rule \"$CLOUDWATCH_RULE_NAME\" --ids 1 --region \"$REGION\" || true\n\n    log_info \"Deleting CloudWatch rule...\"\n    aws events delete-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" || true\n  fi\n\n  # Delete Lambda functions\n  if resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\"; then\n    log_info \"Deleting Master Lambda function...\"\n    aws lambda delete-function --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" || true\n  fi\n\n  if resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\"; then\n    # Delete Event Source Mappings\n    local MAPPINGS=$(aws lambda list-event-source-mappings --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'EventSourceMappings[].UUID' --output text 2>/dev/null || true)\n    if [[ -n \"$MAPPINGS\" ]]; then\n      for UUID in $MAPPINGS; do\n        log_info \"Deleting event source mapping $UUID...\"\n        aws lambda delete-event-source-mapping --uuid \"$UUID\" --region \"$REGION\" || true\n      done\n    fi\n\n    log_info \"Deleting PDF Processor Lambda function...\"\n    aws lambda delete-function --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" || true\n  fi\n\n  # Delete SQS queues\n  if resource_exists \"sqs\" \"$SQS_QUEUE_NAME\"; then\n    QUEUE_URL=$(aws sqs get-queue-url --queue-name \"$SQS_QUEUE_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    log_info \"Deleting SQS queue $SQS_QUEUE_NAME...\"\n    aws sqs delete-queue --queue-url \"$QUEUE_URL\" --region \"$REGION\" || true\n  fi\n\n  if resource_exists \"sqs\" \"$DLQ_NAME\"; then\n    DLQ_URL=$(aws sqs get-queue-url --queue-name \"$DLQ_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    log_info \"Deleting SQS DLQ $DLQ_NAME...\"\n    aws sqs delete-queue --queue-url \"$DLQ_URL\" --region \"$REGION\" || true\n  fi\n\n  # Delete IAM roles and policies\n  if resource_exists \"iam-role\" \"$MASTER_LAMBDA_ROLE_NAME\"; then\n    log_info \"Deleting inline policy from $MASTER_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role-policy --role-name \"$MASTER_LAMBDA_ROLE_NAME\" --policy-name \"MasterLambdaPolicy\" || true\n\n    log_info \"Deleting IAM role $MASTER_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role --role-name \"$MASTER_LAMBDA_ROLE_NAME\" || true\n  fi\n\n  if resource_exists \"iam-role\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\"; then\n    log_info \"Deleting inline policy from $PDF_PROCESSOR_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role-policy --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" --policy-name \"PDFProcessorLambdaPolicy\" || true\n\n    log_info \"Deleting IAM role $PDF_PROCESSOR_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" || true\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# COMPREHENSIVE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Cleanup all resources across all AWS services\ncleanup_all() {\n  # Order matters here to avoid dependency issues\n  cleanup_ecs\n  cleanup_ecr\n  cleanup_lambda\n  cleanup_networking\n}\n\n#-----------------------------------------------------------------------------\n# MAIN FUNCTION\n#-----------------------------------------------------------------------------\n\n# Main function\nmain() {\n  # Parse command line arguments\n  local COMMAND=\"\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -h|--help)\n        show_help\n        ;;\n      all|lambda|ecs|ecr|network)\n        COMMAND=\"$1\"\n        shift\n        ;;\n      *)\n        log_error \"Unknown option: $1\"\n        show_help\n        ;;\n    esac\n  done\n\n  # Initialize the deployment environment\n  init_deployment\n\n  # Execute the command\n  case \"$COMMAND\" in\n    all)\n      cleanup_all\n      ;;\n    lambda)\n      cleanup_lambda\n      ;;\n    ecs)\n      cleanup_ecs\n      ;;\n    ecr)\n      cleanup_ecr\n      ;;\n    network)\n      cleanup_networking\n      ;;\n    *)\n      log_error \"No command specified\"\n      show_help\n      ;;\n  esac\n\n  # Finish the deployment\n  finish_deployment\n}\n\n# Execute main function with all arguments\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/cleanup.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# manage-ecs.sh\n# Consolidated ECS management script for deploying, updating, and\n# managing ECS-based containers for the data scraper system\n#=============================================================================\n\n# Source the common library\n# shellcheck disable=SC1091\nsource \"$(dirname \"${BASH_SOURCE[0]}\")/common-lib.sh\"\n\n# Function to display help specific to this script\nshow_help() {\n  display_help \"deploy     Create and deploy the complete ECS infrastructure including VPC,\n            subnets, cluster, ECR repo, and container service\n  update     Update only the container image with the latest code changes\n  delete     Delete all ECS resources and related infrastructure\n  status     Show the current status of ECS resources and services\"\n}\n\n#-----------------------------------------------------------------------------\n# NETWORKING INFRASTRUCTURE\n#-----------------------------------------------------------------------------\n\n# Create VPC and networking resources\ncreate_networking() {\n  log_section \"Creating networking resources\"\n\n  # Create VPC\n  log_info \"Creating VPC with CIDR block $VPC_CIDR...\"\n  VPC_ID=$(aws ec2 create-vpc --cidr-block \"$VPC_CIDR\" --query \"Vpc.VpcId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$VPC_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-vpc\" --region \"$REGION\"\n  log_info \"Created VPC: $VPC_ID\"\n\n  # Create Internet Gateway\n  log_info \"Creating Internet Gateway...\"\n  IGW_ID=$(aws ec2 create-internet-gateway --query \"InternetGateway.InternetGatewayId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$IGW_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-igw\" --region \"$REGION\"\n  aws ec2 attach-internet-gateway --internet-gateway-id \"$IGW_ID\" --vpc-id \"$VPC_ID\" --region \"$REGION\"\n  log_info \"Created and attached Internet Gateway: $IGW_ID\"\n\n  # Create Route Table\n  log_info \"Creating Route Table...\"\n  RT_ID=$(aws ec2 create-route-table --vpc-id \"$VPC_ID\" --query \"RouteTable.RouteTableId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$RT_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-rt\" --region \"$REGION\"\n  aws ec2 create-route --route-table-id \"$RT_ID\" --destination-cidr-block \"0.0.0.0/0\" --gateway-id \"$IGW_ID\" --region \"$REGION\"\n  log_info \"Created Route Table: $RT_ID\"\n\n  # Create Public Subnet\n  log_info \"Creating Public Subnet...\"\n  PUB_SUBNET_ID=$(aws ec2 create-subnet --vpc-id \"$VPC_ID\" --cidr-block \"$PUBLIC_SUBNET_CIDR\" --query \"Subnet.SubnetId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$PUB_SUBNET_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-pub-subnet\" --region \"$REGION\"\n  aws ec2 associate-route-table --subnet-id \"$PUB_SUBNET_ID\" --route-table-id \"$RT_ID\" --region \"$REGION\"\n  log_info \"Created and associated Public Subnet: $PUB_SUBNET_ID\"\n\n  # Create Private Subnet\n  log_info \"Creating Private Subnet...\"\n  PRI_SUBNET_ID=$(aws ec2 create-subnet --vpc-id \"$VPC_ID\" --cidr-block \"$PRIVATE_SUBNET_CIDR\" --query \"Subnet.SubnetId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$PRI_SUBNET_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-pri-subnet\" --region \"$REGION\"\n  log_info \"Created Private Subnet: $PRI_SUBNET_ID\"\n\n  # Create NAT Gateway (in Public Subnet)\n  log_info \"Creating NAT Gateway (in Public Subnet)...\"\n  EIP_ALLOC_ID=$(aws ec2 allocate-address --query \"AllocationId\" --output text --region \"$REGION\")\n  NAT_GW_ID=$(aws ec2 create-nat-gateway --subnet-id \"$PUB_SUBNET_ID\" --allocation-id \"$EIP_ALLOC_ID\" --query \"NatGateway.NatGatewayId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$NAT_GW_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-nat\" --region \"$REGION\"\n  aws ec2 wait nat-gateway-available --nat-gateway-ids \"$NAT_GW_ID\" --region \"$REGION\"\n  log_info \"Created NAT Gateway: $NAT_GW_ID\"\n\n  # Create Security Group\n  log_info \"Creating Security Group...\"\n  SEC_GROUP_ID=$(aws ec2 create-security-group --group-name \"$SEC_GROUP_NAME\" --description \"Security group for ECS scraper tasks\" --vpc-id \"$VPC_ID\" --query \"GroupId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$SEC_GROUP_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-sg\" --region \"$REGION\"\n  aws ec2 authorize-security-group-ingress --group-id \"$SEC_GROUP_ID\" --protocol tcp --port 80 --cidr \"0.0.0.0/0\" --region \"$REGION\"\n  log_info \"Created Security Group: $SEC_GROUP_ID\"\n\n  # Save the IDs to variables for later use\n  export VPC_ID PUB_SUBNET_ID PRI_SUBNET_ID SEC_GROUP_ID\n}\n\n#-----------------------------------------------------------------------------\n# LOGGING CONFIGURATION\n#-----------------------------------------------------------------------------\n\n# Ensure CloudWatch Log Group exists\nensure_log_group() {\n  local log_group=\"$LOG_GROUP_PREFIX/$CLUSTER_NAME\"\n\n  log_section \"Ensuring CloudWatch Log Group exists\"\n\n  if ! aws logs describe-log-groups --log-group-name-prefix \"$log_group\" --region \"$REGION\" | grep -q \"$log_group\"; then\n    log_info \"Creating CloudWatch Log Group: $log_group\"\n    aws logs create-log-group --log-group-name \"$log_group\" --region \"$REGION\"\n    # Set a retention policy (14 days)\n    aws logs put-retention-policy --log-group-name \"$log_group\" --retention-in-days 14 --region \"$REGION\"\n    log_info \"Created CloudWatch Log Group: $log_group\"\n  else\n    log_info \"CloudWatch Log Group '$log_group' already exists\"\n  fi\n\n  export LOG_GROUP=\"$log_group\"\n}\n\n#-----------------------------------------------------------------------------\n# ECS CLUSTER AND CONTAINER MANAGEMENT\n#-----------------------------------------------------------------------------\n\n# Create ECS Cluster\ncreate_ecs_cluster() {\n  log_section \"Creating ECS Cluster\"\n\n  if ! resource_exists \"ecs-cluster\" \"$CLUSTER_NAME\"; then\n    log_info \"Creating ECS Cluster: $CLUSTER_NAME\"\n    aws ecs create-cluster --cluster-name \"$CLUSTER_NAME\" --region \"$REGION\" >/dev/null\n    log_info \"Created ECS Cluster: $CLUSTER_NAME\"\n  else\n    log_info \"ECS Cluster '$CLUSTER_NAME' already exists\"\n  fi\n}\n\n# Create or verify ECR Repository\ncreate_ecr_repository() {\n  log_section \"Creating ECR Repository\"\n\n  if ! resource_exists \"ecr\" \"$ECR_REPO\"; then\n    log_info \"Creating ECR Repository: $ECR_REPO\"\n    aws ecr create-repository --repository-name \"$ECR_REPO\" --region \"$REGION\"\n    log_info \"Created ECR Repository: $ECR_REPO\"\n  else\n    log_info \"ECR Repository '$ECR_REPO' already exists\"\n  fi\n\n  ECR_URI=$(aws ecr describe-repositories --repository-names \"$ECR_REPO\" --region \"$REGION\" --query 'repositories[0].repositoryUri' --output text)\n  log_info \"ECR Repository URI: $ECR_URI\"\n\n  export ECR_URI\n}\n\n# Build and push Docker image\nbuild_and_push_image() {\n  log_section \"Building and pushing Docker image\"\n\n  # Login to ECR\n  log_info \"Logging in to ECR...\"\n  aws ecr get-login-password --region \"$REGION\" | docker login --username AWS --password-stdin \"${ECR_URI%%/*}\"\n\n  # Build the Docker image\n  log_info \"Building Docker image from Dockerfile...\"\n  docker build -t \"$ECR_URI\" ../docker\n\n  # Tag the image\n  log_info \"Tagging Docker image as latest...\"\n  docker tag \"$ECR_URI\" \"$ECR_URI:latest\"\n\n  # Push the image to ECR\n  log_info \"Pushing Docker image to ECR repository...\"\n  docker push \"$ECR_URI:latest\"\n\n  log_info \"Docker image pushed to ECR: $ECR_URI:latest\"\n}\n\n# Register ECS Task Definition\nregister_task_definition() {\n  log_section \"Registering ECS Task Definition\"\n\n  # Get the caller identity for IAM role ARN\n  ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n\n  # Create the task definition with proper configuration\n  log_info \"Registering ECS Task Definition: $TASK_NAME\"\n  TASK_DEF_ARN=$(aws ecs register-task-definition --family \"$TASK_NAME\" \\\n    --network-mode awsvpc \\\n    --execution-role-arn \"arn:aws:iam::$ACCOUNT_ID:role/$IAM_ROLE\" \\\n    --requires-compatibilities FARGATE \\\n    --cpu \"$ECS_CPU\" --memory \"$ECS_MEMORY\" \\\n    --container-definitions \"[{\n        \\\"name\\\": \\\"$CONTAINER_NAME\\\",\n        \\\"image\\\": \\\"$ECR_URI:latest\\\",\n        \\\"cpu\\\": $CONTAINER_CPU,\n        \\\"memory\\\": $CONTAINER_MEMORY,\n        \\\"essential\\\": true,\n        \\\"portMappings\\\": [{\\\"containerPort\\\": $CONTAINER_PORT, \\\"hostPort\\\": $CONTAINER_PORT}],\n        \\\"logConfiguration\\\": {\n            \\\"logDriver\\\": \\\"awslogs\\\",\n            \\\"options\\\": {\n                \\\"awslogs-group\\\": \\\"$LOG_GROUP\\\",\n                \\\"awslogs-region\\\": \\\"$REGION\\\",\n                \\\"awslogs-stream-prefix\\\": \\\"ecs\\\"\n            }\n        }\n    }]\" \\\n    --region \"$REGION\" \\\n    --query 'taskDefinition.taskDefinitionArn' \\\n    --output text)\n\n  log_info \"Task Definition Registered: $TASK_DEF_ARN\"\n\n  export TASK_DEF_ARN\n}\n\n# Create ECS Service\ncreate_ecs_service() {\n  log_section \"Creating ECS Service\"\n\n  if ! resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    log_info \"Creating ECS Service: $SERVICE_NAME\"\n    aws ecs create-service --cluster \"$CLUSTER_NAME\" --service-name \"$SERVICE_NAME\" \\\n      --task-definition \"$TASK_NAME\" \\\n      --desired-count 1 --launch-type FARGATE \\\n      --network-configuration \"awsvpcConfiguration={\n          subnets=[\\\"$PUB_SUBNET_ID\\\"],\n          securityGroups=[\\\"$SEC_GROUP_ID\\\"],\n          assignPublicIp=\\\"ENABLED\\\"\n      }\" \\\n      --region \"$REGION\"\n\n    log_info \"ECS Service created: $SERVICE_NAME\"\n  else\n    log_info \"ECS Service '$SERVICE_NAME' already exists\"\n  fi\n}\n\n# Update ECS Service with new task definition\nupdate_ecs_service() {\n  log_section \"Updating ECS Service\"\n\n  if resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    log_info \"Updating ECS Service: $SERVICE_NAME\"\n    aws ecs update-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --task-definition \"$TASK_NAME\" \\\n      --force-new-deployment \\\n      --region \"$REGION\"\n\n    log_info \"ECS Service updated: $SERVICE_NAME\"\n  else\n    log_error \"ECS Service '$SERVICE_NAME' does not exist. Cannot update.\"\n    exit 1\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# RESOURCE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Delete ECS resources\ndelete_ecs_resources() {\n  log_section \"Deleting ECS Resources\"\n\n  # Delete ECS Service\n  if resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    log_info \"Updating ECS Service to 0 tasks: $SERVICE_NAME\"\n    aws ecs update-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --desired-count 0 \\\n      --region \"$REGION\"\n\n    log_info \"Waiting for service to stabilize...\"\n    aws ecs wait services-stable \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --services \"$SERVICE_NAME\" \\\n      --region \"$REGION\"\n\n    log_info \"Deleting ECS Service: $SERVICE_NAME\"\n    aws ecs delete-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --force \\\n      --region \"$REGION\"\n  else\n    log_info \"ECS Service '$SERVICE_NAME' does not exist\"\n  fi\n\n  # Delete ECS Cluster\n  if resource_exists \"ecs-cluster\" \"$CLUSTER_NAME\"; then\n    log_info \"Deleting ECS Cluster: $CLUSTER_NAME\"\n    aws ecs delete-cluster \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --region \"$REGION\"\n  else\n    log_info \"ECS Cluster '$CLUSTER_NAME' does not exist\"\n  fi\n\n  # Delete networking resources\n  log_info \"Deleting networking resources...\"\n  # Get the VPC ID based on the cluster name tag\n  VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=tag:Name,Values=$CLUSTER_NAME-vpc\" --query \"Vpcs[0].VpcId\" --output text --region \"$REGION\")\n\n  if [[ \"$VPC_ID\" != \"None\" && -n \"$VPC_ID\" ]]; then\n    # Get the NAT Gateway ID\n    NAT_GW_ID=$(aws ec2 describe-nat-gateways --filter \"Name=vpc-id,Values=$VPC_ID\" --query \"NatGateways[0].NatGatewayId\" --output text --region \"$REGION\")\n    if [[ \"$NAT_GW_ID\" != \"None\" && -n \"$NAT_GW_ID\" ]]; then\n      log_info \"Deleting NAT Gateway: $NAT_GW_ID\"\n      aws ec2 delete-nat-gateway --nat-gateway-id \"$NAT_GW_ID\" --region \"$REGION\"\n      # Wait for NAT Gateway to be deleted\n      aws ec2 wait nat-gateway-deleted --nat-gateway-ids \"$NAT_GW_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Elastic IP associated with the NAT Gateway\n    EIP_ALLOC_ID=$(aws ec2 describe-addresses --filter \"Name=domain,Values=vpc\" --query \"Addresses[0].AllocationId\" --output text --region \"$REGION\")\n    if [[ \"$EIP_ALLOC_ID\" != \"None\" && -n \"$EIP_ALLOC_ID\" ]]; then\n      log_info \"Releasing Elastic IP: $EIP_ALLOC_ID\"\n      aws ec2 release-address --allocation-id \"$EIP_ALLOC_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Security Group ID\n    SEC_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=group-name,Values=$SEC_GROUP_NAME\" --query \"SecurityGroups[0].GroupId\" --output text --region \"$REGION\")\n    if [[ \"$SEC_GROUP_ID\" != \"None\" && -n \"$SEC_GROUP_ID\" ]]; then\n      log_info \"Deleting Security Group: $SEC_GROUP_ID\"\n      aws ec2 delete-security-group --group-id \"$SEC_GROUP_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Subnet IDs\n    SUBNET_IDS=$(aws ec2 describe-subnets --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"Subnets[].SubnetId\" --output text --region \"$REGION\")\n    if [[ -n \"$SUBNET_IDS\" ]]; then\n      for SUBNET_ID in $SUBNET_IDS; do\n        log_info \"Deleting Subnet: $SUBNET_ID\"\n        aws ec2 delete-subnet --subnet-id \"$SUBNET_ID\" --region \"$REGION\"\n      done\n    fi\n\n    # Get the Route Table ID\n    RT_ID=$(aws ec2 describe-route-tables --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"RouteTables[0].RouteTableId\" --output text --region \"$REGION\")\n    if [[ \"$RT_ID\" != \"None\" && -n \"$RT_ID\" ]]; then\n      log_info \"Deleting Route Table: $RT_ID\"\n      aws ec2 delete-route-table --route-table-id \"$RT_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Internet Gateway ID\n    IGW_ID=$(aws ec2 describe-internet-gateways --filters \"Name=attachment.vpc-id,Values=$VPC_ID\" --query \"InternetGateways[0].InternetGatewayId\" --output text --region \"$REGION\")\n    if [[ \"$IGW_ID\" != \"None\" && -n \"$IGW_ID\" ]]; then\n      log_info \"Detaching Internet Gateway from VPC: $IGW_ID\"\n      aws ec2 detach-internet-gateway --internet-gateway-id \"$IGW_ID\" --vpc-id \"$VPC_ID\" --region \"$REGION\"\n      log_info \"Deleting Internet Gateway: $IGW_ID\"\n      aws ec2 delete-internet-gateway --internet-gateway-id \"$IGW_ID\" --region \"$REGION\"\n    fi\n\n    # Finally, delete the VPC\n    log_info \"Deleting VPC: $VPC_ID\"\n    aws ec2 delete-vpc --vpc-id \"$VPC_ID\" --region \"$REGION\"\n  else\n    log_info \"VPC for cluster '$CLUSTER_NAME' not found\"\n  fi\n\n  # Delete CloudWatch Log Group\n  local log_group=\"$LOG_GROUP_PREFIX/$CLUSTER_NAME\"\n  if aws logs describe-log-groups --log-group-name-prefix \"$log_group\" --region \"$REGION\" | grep -q \"$log_group\"; then\n    log_info \"Deleting CloudWatch Log Group: $log_group\"\n    aws logs delete-log-group --log-group-name \"$log_group\" --region \"$REGION\"\n  else\n    log_info \"CloudWatch Log Group '$log_group' does not exist\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# STATUS REPORTING\n#-----------------------------------------------------------------------------\n\n# Get status of ECS resources\nget_ecs_status() {\n  log_section \"ECS Resources Status\"\n\n  # Check ECS Cluster\n  printf \"%-20s %-10s %-20s %-10s\\n\" \"CLUSTER NAME\" \"EXISTS\" \"STATUS\" \"ACTIVE SERVICES\"\n  printf \"%-20s %-10s %-20s %-10s\\n\" \"------------\" \"------\" \"------\" \"--------------\"\n\n  if resource_exists \"ecs-cluster\" \"$CLUSTER_NAME\"; then\n    local cluster_info=$(aws ecs describe-clusters --clusters \"$CLUSTER_NAME\" --region \"$REGION\" --query 'clusters[0].[status,activeServicesCount]' --output text)\n    local status=$(echo \"$cluster_info\" | cut -f1)\n    local service_count=$(echo \"$cluster_info\" | cut -f2)\n    printf \"%-20s %-10s %-20s %-10s\\n\" \"$CLUSTER_NAME\" \"Yes\" \"$status\" \"$service_count\"\n  else\n    printf \"%-20s %-10s %-20s %-10s\\n\" \"$CLUSTER_NAME\" \"No\" \"N/A\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Check ECS Service\n  printf \"%-20s %-10s %-15s %-15s %-15s\\n\" \"SERVICE NAME\" \"EXISTS\" \"STATUS\" \"RUNNING TASKS\" \"DESIRED TASKS\"\n  printf \"%-20s %-10s %-15s %-15s %-15s\\n\" \"------------\" \"------\" \"------\" \"------------\" \"-------------\"\n\n  if resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    local service_info=$(aws ecs describe-services --cluster \"$CLUSTER_NAME\" --services \"$SERVICE_NAME\" --region \"$REGION\" --query 'services[0].[status,runningCount,desiredCount]' --output text)\n    local status=$(echo \"$service_info\" | cut -f1)\n    local running_count=$(echo \"$service_info\" | cut -f2)\n    local desired_count=$(echo \"$service_info\" | cut -f3)\n    printf \"%-20s %-10s %-15s %-15s %-15s\\n\" \"$SERVICE_NAME\" \"Yes\" \"$status\" \"$running_count\" \"$desired_count\"\n  else\n    printf \"%-20s %-10s %-15s %-15s %-15s\\n\" \"$SERVICE_NAME\" \"No\" \"N/A\" \"N/A\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Check ECR Repository\n  printf \"%-20s %-10s %-50s\\n\" \"ECR REPOSITORY\" \"EXISTS\" \"URI\"\n  printf \"%-20s %-10s %-50s\\n\" \"--------------\" \"------\" \"---\"\n\n  if resource_exists \"ecr\" \"$ECR_REPO\"; then\n    local uri=$(aws ecr describe-repositories --repository-names \"$ECR_REPO\" --region \"$REGION\" --query 'repositories[0].repositoryUri' --output text)\n    printf \"%-20s %-10s %-50s\\n\" \"$ECR_REPO\" \"Yes\" \"$uri\"\n  else\n    printf \"%-20s %-10s %-50s\\n\" \"$ECR_REPO\" \"No\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Get the VPC ID based on the cluster name tag\n  VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=tag:Name,Values=$CLUSTER_NAME-vpc\" --query \"Vpcs[0].VpcId\" --output text --region \"$REGION\")\n\n  if [[ \"$VPC_ID\" != \"None\" && -n \"$VPC_ID\" ]]; then\n    printf \"%-20s %-10s %-30s\\n\" \"NETWORKING\" \"EXISTS\" \"ID\"\n    printf \"%-20s %-10s %-30s\\n\" \"----------\" \"------\" \"--\"\n    printf \"%-20s %-10s %-30s\\n\" \"VPC\" \"Yes\" \"$VPC_ID\"\n\n    # Get other networking components\n    SEC_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=group-name,Values=$SEC_GROUP_NAME\" --query \"SecurityGroups[0].GroupId\" --output text --region \"$REGION\")\n    [[ \"$SEC_GROUP_ID\" != \"None\" && -n \"$SEC_GROUP_ID\" ]] && printf \"%-20s %-10s %-30s\\n\" \"Security Group\" \"Yes\" \"$SEC_GROUP_ID\" || printf \"%-20s %-10s %-30s\\n\" \"Security Group\" \"No\" \"N/A\"\n\n    SUBNET_IDS=$(aws ec2 describe-subnets --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"Subnets[].SubnetId\" --output text --region \"$REGION\")\n    for SUBNET_ID in $SUBNET_IDS; do\n      printf \"%-20s %-10s %-30s\\n\" \"Subnet\" \"Yes\" \"$SUBNET_ID\"\n    done\n  else\n    printf \"%-20s %-10s %-30s\\n\" \"NETWORKING\" \"EXISTS\" \"ID\"\n    printf \"%-20s %-10s %-30s\\n\" \"----------\" \"------\" \"--\"\n    printf \"%-20s %-10s %-30s\\n\" \"VPC\" \"No\" \"N/A\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# HIGH-LEVEL OPERATION FUNCTIONS\n#-----------------------------------------------------------------------------\n\n# Deploy all ECS resources\ndeploy_all() {\n  ensure_log_group\n  create_networking\n  create_ecs_cluster\n  create_ecr_repository\n  build_and_push_image\n  register_task_definition\n  create_ecs_service\n}\n\n# Update existing ECS deployment\nupdate_existing() {\n  ensure_log_group\n  create_ecr_repository\n  build_and_push_image\n  register_task_definition\n  update_ecs_service\n}\n\n#-----------------------------------------------------------------------------\n# MAIN FUNCTION\n#-----------------------------------------------------------------------------\n\n# Main function\nmain() {\n  # Parse command line arguments\n  local COMMAND=\"\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -h|--help)\n        show_help\n        ;;\n      deploy|update|delete|status)\n        COMMAND=\"$1\"\n        shift\n        ;;\n      *)\n        log_error \"Unknown option: $1\"\n        show_help\n        ;;\n    esac\n  done\n\n  # Initialize the deployment environment\n  init_deployment \"docker\"\n\n  # Execute the command\n  case \"$COMMAND\" in\n    deploy)\n      deploy_all\n      ;;\n    update)\n      update_existing\n      ;;\n    delete)\n      delete_ecs_resources\n      ;;\n    status)\n      get_ecs_status\n      ;;\n    *)\n      log_error \"No command specified\"\n      show_help\n      ;;\n  esac\n\n  # Finish the deployment\n  finish_deployment\n}\n\n# Execute main function with all arguments\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/manage-ecs.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# config.sh\n# Central configuration for the scraper and ETL pipeline infrastructure\n#=============================================================================\n\n#-----------------------------------------------------------------------------\n# CORE AWS CONFIGURATION\n#-----------------------------------------------------------------------------\n# AWS region and account details\nREGION=\"af-south-1\"\nACCOUNT_ID=\"<ACCOUNT_ID>\"\nS3_BUCKET=\"api-policy-repo\"\n\n#-----------------------------------------------------------------------------\n# LAMBDA CONFIGURATION\n#-----------------------------------------------------------------------------\n# Master Lambda (Scheduler)\n# This Lambda runs on a schedule and checks for new PDFs to process\nMASTER_LAMBDA_FUNCTION_NAME=\"MasterLambdaFunction\"\nMASTER_LAMBDA_ROLE_NAME=\"MasterLambdaRole\"\nMASTER_LAMBDA_SOURCE=\"../lambda/master/master_lambda.py\"\nMASTER_LAMBDA_ZIP=\"master_lambda.zip\"\nMASTER_LAMBDA_HANDLER=\"master_lambda.lambda_handler\"\nMASTER_LAMBDA_RUNTIME=\"python3.9\"\nMASTER_LAMBDA_TIMEOUT=60\nMASTER_LAMBDA_MEMORY=128\n\n# PDF Processor Lambda\n# This Lambda processes PDFs, extracts text, and generates embeddings\nPDF_PROCESSOR_LAMBDA_FUNCTION_NAME=\"PDFProcessorLambdaFunction\"\nPDF_PROCESSOR_LAMBDA_ROLE_NAME=\"PDFProcessorLambdaRole\"\nPDF_PROCESSOR_LAMBDA_SOURCE=\"../lambda/pdf_processor/pdf_processor_lambda.py\"\nPDF_PROCESSOR_LAMBDA_ZIP=\"pdf_processor_lambda.zip\"\nPDF_PROCESSOR_LAMBDA_HANDLER=\"pdf_processor_lambda.lambda_handler\"\nPDF_PROCESSOR_LAMBDA_RUNTIME=\"python3.9\"\nPDF_PROCESSOR_LAMBDA_TIMEOUT=300\nPDF_PROCESSOR_LAMBDA_MEMORY=512\n\n# Logs Proxy Lambda\n# This Lambda provides centralized logging for the system\nLOGS_PROXY_LAMBDA_FUNCTION_NAME=\"LogsProxyLambdaFunction\"\nLOGS_PROXY_LAMBDA_ROLE_NAME=\"LogsProxyLambdaRole\"\nLOGS_PROXY_LAMBDA_SOURCE=\"../lambda/logs_proxy/logsProxyLambda.js\"\nLOGS_PROXY_LAMBDA_ZIP=\"logsProxyLambda.zip\"\nLOGS_PROXY_LAMBDA_HANDLER=\"logsProxyLambda.handler\"\nLOGS_PROXY_LAMBDA_RUNTIME=\"nodejs14.x\"\nLOGS_PROXY_LAMBDA_TIMEOUT=60\nLOGS_PROXY_LAMBDA_MEMORY=128\n\n#-----------------------------------------------------------------------------\n# SQS CONFIGURATION\n#-----------------------------------------------------------------------------\n# Main queue for PDF processing messages\nSQS_QUEUE_NAME=\"PDFProcessingQueue\"\n# Dead Letter Queue for failed processing attempts\nDLQ_NAME=\"PDFProcessingDLQ\"\n# Number of messages to process in a batch\nSQS_BATCH_SIZE=10\n\n#-----------------------------------------------------------------------------\n# CLOUDWATCH CONFIGURATION\n#-----------------------------------------------------------------------------\n# CloudWatch rule to schedule the Master Lambda\nCLOUDWATCH_RULE_NAME=\"MasterLambdaScheduleRule\"\n# Daily at midnight UTC\nCLOUDWATCH_RULE_SCHEDULE=\"cron(0 0 * * ? *)\"\n# Prefix for CloudWatch log groups\nLOG_GROUP_PREFIX=\"/ecs\"\n\n#-----------------------------------------------------------------------------\n# ECS CONFIGURATION\n#-----------------------------------------------------------------------------\n# ECS cluster and service settings\nCLUSTER_NAME=\"scraper-cluster\"\nSERVICE_NAME=\"scraper-service\"\nTASK_NAME=\"scraper-task\"\nCONTAINER_NAME=\"scraper\"\nECR_REPO=\"scraper-code\"\n\n# Task and container resource settings\nECS_CPU=\"512\"\nECS_MEMORY=\"1024\"\nCONTAINER_CPU=\"256\"\nCONTAINER_MEMORY=\"512\"\nCONTAINER_PORT=80\n\n# IAM role for ECS task execution\nIAM_ROLE=\"APILambdaManagement\"\n\n#-----------------------------------------------------------------------------\n# NETWORKING CONFIGURATION\n#-----------------------------------------------------------------------------\n# VPC and subnet CIDR blocks\nVPC_CIDR=\"10.0.0.0/16\"\nPUBLIC_SUBNET_CIDR=\"10.0.1.0/24\"\nPRIVATE_SUBNET_CIDR=\"10.0.2.0/24\"\n# Security group name for ECS tasks\nSEC_GROUP_NAME=\"scraper-sg\"\n\n#-----------------------------------------------------------------------------\n# API KEYS AND CREDENTIALS\n#-----------------------------------------------------------------------------\n# WARNING: These should be moved to AWS Secrets Manager for production deployments\nGOVINFO_API_KEY=\"0yyvGVuCtmK28iOU1c6jYO6w0rzXVencKGQxU5o9\"\nLEGISCAN_API_KEY=\"6fac7c423da95e77575205a2b30f858f\"\nOPENEI_API_KEY=\"vpMPBsUopWqUmh33FL1ZFTIuD1LUcwiunfe5LiOq\"\nCOURTLISTENER_API_KEY=\"578d9ab5e03cafdc1ced7dfce158cd42ef60a2c7\"\nNEWSAPI_API_KEY=\"0f4bd0908be448a19534fd7c27db60dc\"\nNYT_API_KEY=\"lAVZGadEGMAvb18GkGqFvvyLn16iz9vW\"\nNEWSDATA_API_KEY=\"pub_72073d9a4c5ff9f932782d9a1f01780127c4d\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/config.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# manage-lambda.sh\n# Consolidated Lambda management script for deploying, updating, and\n# deleting Lambda functions for the ETL pipeline\n#=============================================================================\n\n# Source the common library\n# shellcheck disable=SC1091\nsource \"$(dirname \"${BASH_SOURCE[0]}\")/common-lib.sh\"\n\n# Function to display help specific to this script\nshow_help() {\n  display_help \"deploy     Deploy or update the complete Lambda infrastructure including roles,\n            queues, and functions\n  update     Update only the Lambda function code with latest changes\n  delete     Delete all Lambda functions and related resources (roles, queues, etc.)\n  status     Show the current status of Lambda functions and related resources\"\n}\n\n#-----------------------------------------------------------------------------\n# IAM ROLE FUNCTIONS\n#-----------------------------------------------------------------------------\n\n# Function to create IAM roles for Lambda functions\ncreate_iam_roles() {\n  log_section \"Creating IAM roles\"\n\n  # Master Lambda role\n  if ! resource_exists \"iam-role\" \"$MASTER_LAMBDA_ROLE_NAME\"; then\n    log_info \"Creating IAM role for Master Lambda...\"\n    MASTER_ROLE_TRUST_POLICY='{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},\n        \"Action\": \"sts:AssumeRole\"\n      }]\n    }'\n\n    MASTER_LAMBDA_ROLE_ARN=$(aws iam create-role \\\n      --role-name \"$MASTER_LAMBDA_ROLE_NAME\" \\\n      --assume-role-policy-document \"$MASTER_ROLE_TRUST_POLICY\" \\\n      --query 'Role.Arn' --output text) || { log_error \"Failed to create Master Lambda IAM role\"; exit 1; }\n\n    log_info \"Master Lambda Role ARN: $MASTER_LAMBDA_ROLE_ARN\"\n\n    MASTER_POLICY_DOCUMENT='{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"logs:CreateLogGroup\",\"logs:CreateLogStream\",\"logs:PutLogEvents\"],\n          \"Resource\": \"arn:aws:logs:'$REGION':*:*\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:ListBucket\"],\n          \"Resource\": \"arn:aws:s3:::'$S3_BUCKET'\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"sqs:SendMessage\"],\n          \"Resource\": \"*\"\n        }\n      ]\n    }'\n\n    aws iam put-role-policy \\\n      --role-name \"$MASTER_LAMBDA_ROLE_NAME\" \\\n      --policy-name \"MasterLambdaPolicy\" \\\n      --policy-document \"$MASTER_POLICY_DOCUMENT\"\n\n    log_info \"Attached policy to $MASTER_LAMBDA_ROLE_NAME\"\n  else\n    log_info \"Role $MASTER_LAMBDA_ROLE_NAME already exists\"\n    MASTER_LAMBDA_ROLE_ARN=$(aws iam get-role --role-name \"$MASTER_LAMBDA_ROLE_NAME\" --query 'Role.Arn' --output text)\n  fi\n\n  # PDF Processor Lambda role\n  if ! resource_exists \"iam-role\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\"; then\n    log_info \"Creating IAM role for PDF Processor Lambda...\"\n    PDF_PROCESSOR_ROLE_TRUST_POLICY='{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},\n        \"Action\": \"sts:AssumeRole\"\n      }]\n    }'\n\n    PDF_PROCESSOR_LAMBDA_ROLE_ARN=$(aws iam create-role \\\n      --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" \\\n      --assume-role-policy-document \"$PDF_PROCESSOR_ROLE_TRUST_POLICY\" \\\n      --query 'Role.Arn' --output text) || { log_error \"Failed to create PDF Processor Lambda IAM role\"; exit 1; }\n\n    log_info \"PDF Processor Lambda Role ARN: $PDF_PROCESSOR_LAMBDA_ROLE_ARN\"\n\n    PDF_PROCESSOR_POLICY_DOCUMENT='{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"logs:CreateLogGroup\",\"logs:CreateLogStream\",\"logs:PutLogEvents\"],\n          \"Resource\": \"arn:aws:logs:'$REGION':*:*\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:GetObject\"],\n          \"Resource\": \"arn:aws:s3:::'$S3_BUCKET'/usa/energy/content/*\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:PutObject\"],\n          \"Resource\": \"arn:aws:s3:::'$S3_BUCKET'/usa/extracted/*\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\n            \"sqs:ReceiveMessage\",\n            \"sqs:DeleteMessage\",\n            \"sqs:GetQueueAttributes\",\n            \"sqs:ChangeMessageVisibility\"\n          ],\n          \"Resource\": \"*\"\n        }\n      ]\n    }'\n\n    aws iam put-role-policy \\\n      --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" \\\n      --policy-name \"PDFProcessorLambdaPolicy\" \\\n      --policy-document \"$PDF_PROCESSOR_POLICY_DOCUMENT\"\n\n    log_info \"Attached policy to $PDF_PROCESSOR_LAMBDA_ROLE_NAME\"\n  else\n    log_info \"Role $PDF_PROCESSOR_LAMBDA_ROLE_NAME already exists\"\n    PDF_PROCESSOR_LAMBDA_ROLE_ARN=$(aws iam get-role --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" --query 'Role.Arn' --output text)\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# SQS QUEUE MANAGEMENT\n#-----------------------------------------------------------------------------\n\n# Function to create SQS queues\ncreate_sqs_queues() {\n  log_section \"Creating SQS queues\"\n\n  # Create DLQ (Dead Letter Queue)\n  if ! resource_exists \"sqs\" \"$DLQ_NAME\"; then\n    log_info \"Creating Dead Letter Queue (DLQ)...\"\n    DLQ_URL=$(aws sqs create-queue --queue-name \"$DLQ_NAME\" --region \"$REGION\" --output text)\n    log_info \"DLQ created: URL=$DLQ_URL\"\n  else\n    log_info \"DLQ $DLQ_NAME already exists\"\n    DLQ_URL=$(aws sqs get-queue-url --queue-name \"$DLQ_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n  fi\n\n  DLQ_ARN=$(aws sqs get-queue-attributes --queue-url \"$DLQ_URL\" --attribute-names QueueArn --region \"$REGION\" --output text | awk '{print $2}')\n  log_info \"DLQ ARN: $DLQ_ARN\"\n\n  # Create main queue with DLQ configuration\n  if ! resource_exists \"sqs\" \"$SQS_QUEUE_NAME\"; then\n    log_info \"Creating main SQS queue with DLQ configuration...\"\n    # Build the JSON mapping for the attributes from a file\n    QUEUE_ATTRS_FILE=\"sqs-attributes.json\"\n    cat > \"$QUEUE_ATTRS_FILE\" <<EOF\n{\n  \"RedrivePolicy\": \"{\\\"maxReceiveCount\\\":\\\"5\\\",\\\"deadLetterTargetArn\\\":\\\"$DLQ_ARN\\\"}\",\n  \"VisibilityTimeout\": \"320\"\n}\nEOF\n    log_info \"Using attributes file: $QUEUE_ATTRS_FILE\"\n    QUEUE_URL=$(aws sqs create-queue --queue-name \"$SQS_QUEUE_NAME\" --attributes file://\"$QUEUE_ATTRS_FILE\" --region \"$REGION\" --output text)\n    rm -f \"$QUEUE_ATTRS_FILE\"\n  else\n    log_info \"SQS queue $SQS_QUEUE_NAME already exists\"\n    QUEUE_URL=$(aws sqs get-queue-url --queue-name \"$SQS_QUEUE_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n  fi\n\n  QUEUE_ARN=$(aws sqs get-queue-attributes --queue-url \"$QUEUE_URL\" --attribute-names QueueArn --region \"$REGION\" --output text | awk '{print $2}')\n  log_info \"Main SQS queue ARN: $QUEUE_ARN\"\n}\n\n#-----------------------------------------------------------------------------\n# LAMBDA CODE PACKAGING AND DEPLOYMENT\n#-----------------------------------------------------------------------------\n\n# Package Lambda function code into ZIP archives\npackage_lambda_code() {\n  log_section \"Packaging Lambda code\"\n\n  log_info \"Packaging Master Lambda code...\"\n  zip -j \"$MASTER_LAMBDA_ZIP\" \"$MASTER_LAMBDA_SOURCE\"\n\n  log_info \"Packaging PDF Processor Lambda code...\"\n  if [[ \"$PDF_PROCESSOR_LAMBDA_SOURCE\" == *\"/\"* ]]; then\n    # Source is in a subdirectory, copy it to current directory for zipping\n    cp \"$PDF_PROCESSOR_LAMBDA_SOURCE\" .\n    local base_name=$(basename \"$PDF_PROCESSOR_LAMBDA_SOURCE\")\n    zip -j \"$PDF_PROCESSOR_LAMBDA_ZIP\" \"$base_name\"\n    rm -f \"$base_name\"\n  else\n    zip -j \"$PDF_PROCESSOR_LAMBDA_ZIP\" \"$PDF_PROCESSOR_LAMBDA_SOURCE\"\n  fi\n}\n\n# Create or update Lambda functions\ndeploy_lambda_functions() {\n  local update_only=\"${1:-false}\"\n  log_section \"Deploying Lambda functions\"\n\n  # Package Lambda code\n  package_lambda_code\n\n  # Deploy Master Lambda\n  if ! resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\" || [[ \"$update_only\" == \"false\" ]]; then\n    if resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\"; then\n      log_info \"Updating Master Lambda function...\"\n      aws lambda update-function-code \\\n        --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" \\\n        --zip-file fileb://\"$MASTER_LAMBDA_ZIP\" \\\n        --region \"$REGION\"\n    else\n      log_info \"Creating Master Lambda function...\"\n      aws lambda create-function \\\n        --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" \\\n        --runtime \"$MASTER_LAMBDA_RUNTIME\" \\\n        --role \"$MASTER_LAMBDA_ROLE_ARN\" \\\n        --handler \"$MASTER_LAMBDA_HANDLER\" \\\n        --zip-file fileb://\"$MASTER_LAMBDA_ZIP\" \\\n        --timeout \"$MASTER_LAMBDA_TIMEOUT\" \\\n        --memory-size \"$MASTER_LAMBDA_MEMORY\" \\\n        --region \"$REGION\"\n    fi\n  else\n    log_info \"Skipping Master Lambda function creation/update.\"\n  fi\n\n  # Get Master Lambda ARN\n  MASTER_LAMBDA_ARN=$(aws lambda get-function --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.FunctionArn' --output text)\n\n  # Deploy PDF Processor Lambda\n  if ! resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" || [[ \"$update_only\" == \"false\" ]]; then\n    if resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\"; then\n      log_info \"Updating PDF Processor Lambda function...\"\n      aws lambda update-function-code \\\n        --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n        --zip-file fileb://\"$PDF_PROCESSOR_LAMBDA_ZIP\" \\\n        --region \"$REGION\"\n    else\n      log_info \"Creating PDF Processor Lambda function...\"\n      aws lambda create-function \\\n        --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n        --runtime \"$PDF_PROCESSOR_LAMBDA_RUNTIME\" \\\n        --role \"$PDF_PROCESSOR_LAMBDA_ROLE_ARN\" \\\n        --handler \"$PDF_PROCESSOR_LAMBDA_HANDLER\" \\\n        --zip-file fileb://\"$PDF_PROCESSOR_LAMBDA_ZIP\" \\\n        --timeout \"$PDF_PROCESSOR_LAMBDA_TIMEOUT\" \\\n        --memory-size \"$PDF_PROCESSOR_LAMBDA_MEMORY\" \\\n        --region \"$REGION\"\n    fi\n  else\n    log_info \"Skipping PDF Processor Lambda function creation/update.\"\n  fi\n\n  # Get PDF Processor Lambda ARN\n  PDF_PROCESSOR_LAMBDA_ARN=$(aws lambda get-function --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.FunctionArn' --output text)\n\n  # Clean up ZIP files\n  rm -f \"$MASTER_LAMBDA_ZIP\" \"$PDF_PROCESSOR_LAMBDA_ZIP\"\n}\n\n#-----------------------------------------------------------------------------\n# EVENT TRIGGERING AND SCHEDULING\n#-----------------------------------------------------------------------------\n\n# Create event source mapping between SQS and PDF Processor Lambda\ncreate_event_source_mapping() {\n  log_section \"Creating event source mapping\"\n\n  # Check if there's an existing event source mapping\n  local existing_mapping=$(aws lambda list-event-source-mappings \\\n    --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n    --event-source-arn \"$QUEUE_ARN\" \\\n    --region \"$REGION\" \\\n    --query 'EventSourceMappings[0].UUID' \\\n    --output text)\n\n  if [[ \"$existing_mapping\" == \"None\" || -z \"$existing_mapping\" ]]; then\n    log_info \"Creating event source mapping for PDF Processor Lambda...\"\n    aws lambda create-event-source-mapping \\\n      --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n      --batch-size \"$SQS_BATCH_SIZE\" \\\n      --event-source-arn \"$QUEUE_ARN\" \\\n      --enabled \\\n      --region \"$REGION\"\n  else\n    log_info \"Event source mapping already exists for PDF Processor Lambda\"\n  fi\n}\n\n# Create CloudWatch Event Rule for scheduling the Master Lambda\ncreate_cloudwatch_rule() {\n  log_section \"Creating CloudWatch Event Rule\"\n\n  # Check if rule exists\n  local rule_exists=false\n  if aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" &> /dev/null; then\n    rule_exists=true\n  fi\n\n  if [[ \"$rule_exists\" == \"false\" ]]; then\n    log_info \"Creating CloudWatch Events rule to schedule Master Lambda...\"\n    RULE_ARN=$(aws events put-rule \\\n      --name \"$CLOUDWATCH_RULE_NAME\" \\\n      --schedule-expression \"$CLOUDWATCH_RULE_SCHEDULE\" \\\n      --region \"$REGION\" \\\n      --description \"Daily trigger for Master Lambda\" \\\n      --output text)\n\n    log_info \"CloudWatch rule ARN: $RULE_ARN\"\n  else\n    log_info \"CloudWatch rule $CLOUDWATCH_RULE_NAME already exists\"\n    RULE_ARN=$(aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" --query 'Arn' --output text)\n  fi\n\n  # Add permission for CloudWatch Events to invoke Master Lambda\n  log_info \"Adding permission for CloudWatch Events to invoke Master Lambda...\"\n  aws lambda add-permission \\\n    --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" \\\n    --statement-id \"AllowEventsInvokeMasterLambda\" \\\n    --action \"lambda:InvokeFunction\" \\\n    --principal events.amazonaws.com \\\n    --source-arn \"$RULE_ARN\" \\\n    --region \"$REGION\" 2>/dev/null || true\n\n  # Add CloudWatch Events target for Master Lambda\n  log_info \"Adding CloudWatch Events target for Master Lambda...\"\n  aws events put-targets \\\n    --rule \"$CLOUDWATCH_RULE_NAME\" \\\n    --targets \"Id\"=\"1\",\"Arn\"=\"$MASTER_LAMBDA_ARN\" \\\n    --region \"$REGION\"\n}\n\n# Update Lambda environment variables\nupdate_lambda_env_vars() {\n  log_section \"Updating Lambda environment variables\"\n\n  log_info \"Updating environment variables for Master Lambda...\"\n  aws lambda update-function-configuration \\\n    --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" \\\n    --environment \"Variables={S3_BUCKET=$S3_BUCKET,SQS_QUEUE_URL=$QUEUE_URL}\" \\\n    --region \"$REGION\"\n\n  log_info \"Updating environment variables for PDF Processor Lambda...\"\n  aws lambda update-function-configuration \\\n    --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n    --environment \"Variables={S3_BUCKET=$S3_BUCKET}\" \\\n    --region \"$REGION\"\n}\n\n#-----------------------------------------------------------------------------\n# RESOURCE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Delete Lambda functions and resources\ndelete_lambda_resources() {\n  log_section \"Deleting Lambda resources\"\n\n  # Delete CloudWatch rule\n  if aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" &> /dev/null; then\n    log_info \"Removing CloudWatch rule targets...\"\n    aws events remove-targets --rule \"$CLOUDWATCH_RULE_NAME\" --ids 1 --region \"$REGION\" || true\n\n    log_info \"Deleting CloudWatch rule...\"\n    aws events delete-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" || true\n  fi\n\n  # Delete Lambda functions\n  if resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\"; then\n    log_info \"Deleting Master Lambda function...\"\n    aws lambda delete-function --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" || true\n  fi\n\n  if resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\"; then\n    # Delete Event Source Mappings\n    local MAPPINGS=$(aws lambda list-event-source-mappings --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'EventSourceMappings[].UUID' --output text 2>/dev/null || true)\n    if [[ -n \"$MAPPINGS\" ]]; then\n      for UUID in $MAPPINGS; do\n        log_info \"Deleting event source mapping $UUID...\"\n        aws lambda delete-event-source-mapping --uuid \"$UUID\" --region \"$REGION\" || true\n      done\n    fi\n\n    log_info \"Deleting PDF Processor Lambda function...\"\n    aws lambda delete-function --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" || true\n  fi\n\n  # Delete SQS queues\n  if resource_exists \"sqs\" \"$SQS_QUEUE_NAME\"; then\n    QUEUE_URL=$(aws sqs get-queue-url --queue-name \"$SQS_QUEUE_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    log_info \"Deleting SQS queue $SQS_QUEUE_NAME...\"\n    aws sqs delete-queue --queue-url \"$QUEUE_URL\" --region \"$REGION\" || true\n  fi\n\n  if resource_exists \"sqs\" \"$DLQ_NAME\"; then\n    DLQ_URL=$(aws sqs get-queue-url --queue-name \"$DLQ_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    log_info \"Deleting SQS DLQ $DLQ_NAME...\"\n    aws sqs delete-queue --queue-url \"$DLQ_URL\" --region \"$REGION\" || true\n  fi\n\n  # Delete IAM roles and policies\n  if resource_exists \"iam-role\" \"$MASTER_LAMBDA_ROLE_NAME\"; then\n    log_info \"Deleting inline policy from $MASTER_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role-policy --role-name \"$MASTER_LAMBDA_ROLE_NAME\" --policy-name \"MasterLambdaPolicy\" || true\n\n    log_info \"Deleting IAM role $MASTER_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role --role-name \"$MASTER_LAMBDA_ROLE_NAME\" || true\n  fi\n\n  if resource_exists \"iam-role\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\"; then\n    log_info \"Deleting inline policy from $PDF_PROCESSOR_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role-policy --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" --policy-name \"PDFProcessorLambdaPolicy\" || true\n\n    log_info \"Deleting IAM role $PDF_PROCESSOR_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" || true\n  fi\n\n  # Clean up zip files if they exist\n  rm -f \"$MASTER_LAMBDA_ZIP\" \"$PDF_PROCESSOR_LAMBDA_ZIP\"\n\n  log_info \"Lambda resources deleted\"\n}\n\n#-----------------------------------------------------------------------------\n# STATUS REPORTING\n#-----------------------------------------------------------------------------\n\n# Get status of Lambda functions and resources\nget_lambda_status() {\n  log_section \"Lambda Resources Status\"\n\n  # Check Lambda functions\n  printf \"%-30s %-10s %-20s %-10s\\n\" \"FUNCTION NAME\" \"EXISTS\" \"LAST MODIFIED\" \"RUNTIME\"\n  printf \"%-30s %-10s %-20s %-10s\\n\" \"------------\" \"------\" \"-------------\" \"-------\"\n\n  if resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\"; then\n    local info=$(aws lambda get-function --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.[LastModified,Runtime]' --output text)\n    local last_modified=$(echo \"$info\" | cut -f1)\n    local runtime=$(echo \"$info\" | cut -f2)\n    printf \"%-30s %-10s %-20s %-10s\\n\" \"$MASTER_LAMBDA_FUNCTION_NAME\" \"Yes\" \"$last_modified\" \"$runtime\"\n  else\n    printf \"%-30s %-10s %-20s %-10s\\n\" \"$MASTER_LAMBDA_FUNCTION_NAME\" \"No\" \"N/A\" \"N/A\"\n  fi\n\n  if resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\"; then\n    local info=$(aws lambda get-function --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.[LastModified,Runtime]' --output text)\n    local last_modified=$(echo \"$info\" | cut -f1)\n    local runtime=$(echo \"$info\" | cut -f2)\n    printf \"%-30s %-10s %-20s %-10s\\n\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \"Yes\" \"$last_modified\" \"$runtime\"\n  else\n    printf \"%-30s %-10s %-20s %-10s\\n\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \"No\" \"N/A\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Check SQS queues\n  printf \"%-30s %-10s %-50s\\n\" \"QUEUE NAME\" \"EXISTS\" \"URL\"\n  printf \"%-30s %-10s %-50s\\n\" \"----------\" \"------\" \"---\"\n\n  if resource_exists \"sqs\" \"$SQS_QUEUE_NAME\"; then\n    local url=$(aws sqs get-queue-url --queue-name \"$SQS_QUEUE_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    printf \"%-30s %-10s %-50s\\n\" \"$SQS_QUEUE_NAME\" \"Yes\" \"$url\"\n  else\n    printf \"%-30s %-10s %-50s\\n\" \"$SQS_QUEUE_NAME\" \"No\" \"N/A\"\n  fi\n\n  if resource_exists \"sqs\" \"$DLQ_NAME\"; then\n    local url=$(aws sqs get-queue-url --queue-name \"$DLQ_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    printf \"%-30s %-10s %-50s\\n\" \"$DLQ_NAME\" \"Yes\" \"$url\"\n  else\n    printf \"%-30s %-10s %-50s\\n\" \"$DLQ_NAME\" \"No\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Check IAM roles\n  printf \"%-30s %-10s\\n\" \"IAM ROLE\" \"EXISTS\"\n  printf \"%-30s %-10s\\n\" \"--------\" \"------\"\n\n  if resource_exists \"iam-role\" \"$MASTER_LAMBDA_ROLE_NAME\"; then\n    printf \"%-30s %-10s\\n\" \"$MASTER_LAMBDA_ROLE_NAME\" \"Yes\"\n  else\n    printf \"%-30s %-10s\\n\" \"$MASTER_LAMBDA_ROLE_NAME\" \"No\"\n  fi\n\n  if resource_exists \"iam-role\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\"; then\n    printf \"%-30s %-10s\\n\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" \"Yes\"\n  else\n    printf \"%-30s %-10s\\n\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" \"No\"\n  fi\n\n  echo \"\"\n\n  # Check CloudWatch rule\n  printf \"%-30s %-10s %-20s\\n\" \"CLOUDWATCH RULE\" \"EXISTS\" \"SCHEDULE\"\n  printf \"%-30s %-10s %-20s\\n\" \"---------------\" \"------\" \"--------\"\n\n  if aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" &> /dev/null; then\n    local schedule=$(aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" --query 'ScheduleExpression' --output text)\n    printf \"%-30s %-10s %-20s\\n\" \"$CLOUDWATCH_RULE_NAME\" \"Yes\" \"$schedule\"\n  else\n    printf \"%-30s %-10s %-20s\\n\" \"$CLOUDWATCH_RULE_NAME\" \"No\" \"N/A\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# HIGH-LEVEL OPERATION FUNCTIONS\n#-----------------------------------------------------------------------------\n\n# Function to deploy all Lambda resources\ndeploy_all() {\n  create_iam_roles\n  create_sqs_queues\n  deploy_lambda_functions false\n  create_event_source_mapping\n  create_cloudwatch_rule\n  update_lambda_env_vars\n}\n\n# Function to update Lambda function code only\nupdate_lambda_code() {\n  deploy_lambda_functions true\n}\n\n#-----------------------------------------------------------------------------\n# MAIN FUNCTION\n#-----------------------------------------------------------------------------\n\n# Main function\nmain() {\n  # Parse command line arguments\n  local COMMAND=\"\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -h|--help)\n        show_help\n        ;;\n      deploy|update|delete|status)\n        COMMAND=\"$1\"\n        shift\n        ;;\n      *)\n        log_error \"Unknown option: $1\"\n        show_help\n        ;;\n    esac\n  done\n\n  # Initialize the deployment environment\n  init_deployment\n\n  # Execute the command\n  case \"$COMMAND\" in\n    deploy)\n      deploy_all\n      ;;\n    update)\n      update_lambda_code\n      ;;\n    delete)\n      delete_lambda_resources\n      ;;\n    status)\n      get_lambda_status\n      ;;\n    *)\n      log_error \"No command specified\"\n      show_help\n      ;;\n  esac\n\n  # Finish the deployment\n  finish_deployment\n}\n\n# Execute main function with all arguments\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/manage-lambda.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# common-lib.sh\n# Common functions and utilities for all deployment and management scripts\n#=============================================================================\n\n# Source the configuration\n# shellcheck disable=SC1091\nsource \"$(dirname \"${BASH_SOURCE[0]}\")/config.sh\"\n\n#-----------------------------------------------------------------------------\n# ERROR HANDLING AND LOGGING\n#-----------------------------------------------------------------------------\n\n# Print error message in red text\nlog_error() {\n  echo -e \"\\e[31mERROR: $*\\e[0m\" >&2\n}\n\n# Print warning message in yellow text\nlog_warning() {\n  echo -e \"\\e[33mWARNING: $*\\e[0m\" >&2\n}\n\n# Print info message in green text\nlog_info() {\n  echo -e \"\\e[32mINFO: $*\\e[0m\"\n}\n\n# Print section headers in bold blue text\nlog_section() {\n  echo -e \"\\e[1;34m=== $* ===\\e[0m\"\n}\n\n# Generic error trap function that reports line numbers\ngeneric_trap() {\n  log_error \"An error occurred on line $1. Check the logs for details.\"\n  exit 1\n}\n\n# Enable error trapping to catch failures\nenable_error_trapping() {\n  trap 'generic_trap $LINENO' ERR\n}\n\n# Disable error trapping (typically at successful completion)\ndisable_error_trapping() {\n  trap - ERR\n}\n\n#-----------------------------------------------------------------------------\n# AWS AUTHENTICATION AND VALIDATION\n#-----------------------------------------------------------------------------\n\n# Configure AWS CLI with explicit credentials if provided, otherwise use environment\nconfigure_aws_cli() {\n  if [[ -n \"${AWS_ACCESS_KEY_ID:-}\" && -n \"${AWS_SECRET_ACCESS_KEY:-}\" ]]; then\n    log_info \"Using provided AWS credentials\"\n    export AWS_ACCESS_KEY_ID\n    export AWS_SECRET_ACCESS_KEY\n    export AWS_DEFAULT_REGION=\"$REGION\"\n  else\n    log_info \"Using AWS credentials from environment or profile\"\n    export AWS_DEFAULT_REGION=\"$REGION\"\n  fi\n}\n\n# Check if AWS CLI is installed\ncheck_aws_cli() {\n  if ! command -v aws &> /dev/null; then\n    log_error \"AWS CLI is not installed. Please install it first.\"\n    exit 1\n  fi\n}\n\n# Check if Docker is installed\ncheck_docker() {\n  if ! command -v docker &> /dev/null; then\n    log_error \"Docker is not installed. Please install it first.\"\n    exit 1\n  fi\n}\n\n# Test AWS credentials by making a simple API call\nvalidate_aws_credentials() {\n  log_info \"Validating AWS credentials...\"\n  if ! aws sts get-caller-identity &> /dev/null; then\n    log_error \"AWS credentials are invalid or missing. Please check your configuration.\"\n    exit 1\n  fi\n  log_info \"AWS credentials are valid.\"\n}\n\n# Wait for an AWS resource to become available with configurable timeout\nwait_for_resource() {\n  local resource_type=\"$1\"\n  local resource_id=\"$2\"\n  local max_attempts=\"${3:-30}\"\n  local delay=\"${4:-10}\"\n\n  log_info \"Waiting for $resource_type $resource_id to be available...\"\n\n  local attempts=0\n  while [ $attempts -lt \"$max_attempts\" ]; do\n    case \"$resource_type\" in\n      \"lambda\")\n        if aws lambda get-function --function-name \"$resource_id\" --region \"$REGION\" &> /dev/null; then\n          log_info \"$resource_type $resource_id is now available\"\n          return 0\n        fi\n        ;;\n      \"sqs\")\n        if aws sqs get-queue-url --queue-name \"$resource_id\" --region \"$REGION\" &> /dev/null; then\n          log_info \"$resource_type $resource_id is now available\"\n          return 0\n        fi\n        ;;\n      \"ecs-service\")\n        if aws ecs describe-services --cluster \"$ECS_CLUSTER\" --services \"$resource_id\" --region \"$REGION\" | grep -q \"\\\"status\\\": \\\"ACTIVE\\\"\"; then\n          log_info \"$resource_type $resource_id is now available\"\n          return 0\n        fi\n        ;;\n      *)\n        log_warning \"Unknown resource type: $resource_type\"\n        return 1\n        ;;\n    esac\n\n    attempts=$((attempts + 1))\n    log_info \"Waiting for $resource_type $resource_id, attempt $attempts/$max_attempts\"\n    sleep \"$delay\"\n  done\n\n  log_error \"Timed out waiting for $resource_type $resource_id\"\n  return 1\n}\n\n#-----------------------------------------------------------------------------\n# AWS RESOURCE MANAGEMENT\n#-----------------------------------------------------------------------------\n\n# Check if an AWS resource exists\n# Usage: resource_exists \"resource_type\" \"resource_id\"\n# Returns: 0 if exists, 1 if not exists, 2 if unknown resource type\nresource_exists() {\n  local resource_type=\"$1\"\n  local resource_id=\"$2\"\n\n  case \"$resource_type\" in\n    \"lambda\")\n      aws lambda get-function --function-name \"$resource_id\" --region \"$REGION\" &> /dev/null\n      ;;\n    \"sqs\")\n      aws sqs get-queue-url --queue-name \"$resource_id\" --region \"$REGION\" &> /dev/null\n      ;;\n    \"ecr\")\n      aws ecr describe-repositories --repository-names \"$resource_id\" --region \"$REGION\" &> /dev/null\n      ;;\n    \"ecs-cluster\")\n      aws ecs describe-clusters --clusters \"$resource_id\" --region \"$REGION\" | grep -q \"\\\"status\\\": \\\"ACTIVE\\\"\"\n      ;;\n    \"ecs-service\")\n      aws ecs describe-services --cluster \"$ECS_CLUSTER\" --services \"$resource_id\" --region \"$REGION\" | grep -q \"\\\"status\\\": \\\"ACTIVE\\\"\"\n      ;;\n    \"iam-role\")\n      aws iam get-role --role-name \"$resource_id\" &> /dev/null\n      ;;\n    *)\n      log_warning \"Unknown resource type: $resource_type\"\n      return 2\n      ;;\n  esac\n\n  return $?\n}\n\n#-----------------------------------------------------------------------------\n# DEPLOYMENT HELPERS\n#-----------------------------------------------------------------------------\n\n# Initialize deployment environment\n# Usage: init_deployment [\"docker\"] - Pass \"docker\" if Docker is required\ninit_deployment() {\n  check_aws_cli\n  configure_aws_cli\n  validate_aws_credentials\n  enable_error_trapping\n\n  if [[ \"$1\" == \"docker\" ]]; then\n    check_docker\n  fi\n\n  log_section \"Starting deployment process\"\n}\n\n# Complete deployment and clean up\nfinish_deployment() {\n  disable_error_trapping\n  log_section \"Deployment completed successfully\"\n}\n\n# Display script help with command list\n# Usage: display_help \"command1     Description of command1\\n  command2     Description of command2\"\ndisplay_help() {\n  local script_name=$(basename \"$0\")\n  echo \"Usage: $script_name [OPTIONS] COMMAND\"\n  echo\n  echo \"Options:\"\n  echo \"  -h, --help     Display this help message\"\n  echo\n  echo \"Commands:\"\n  echo \"  $1\"\n  echo\n  exit 0\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/common-lib.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/bash\n# update-lambda.sh\n# Exit immediately if any command fails.\nset -e\n\n# Configuration variables\nREGION=\"af-south-1\"\nACCOUNT_ID=\"<ACCOUNT_ID>\"\nREPO_NAME=\"ona-pdf-processor\"\nLAMBDA_FUNCTION_NAME=\"PDFProcessor\"\nIMAGE_TAG=\"latest\"\nIMAGE_URI=\"$ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/$REPO_NAME:$IMAGE_TAG\"\n\n# Step 1: Build the Docker image (force no-cache to ensure changes are picked up)\necho \"Building Docker image with no cache...\"\ndocker build --no-cache -t $REPO_NAME .\n\n# Step 2: Tag the image with the ECR repository URI\necho \"Tagging image as $IMAGE_URI...\"\ndocker tag $REPO_NAME:$IMAGE_TAG $IMAGE_URI\n\n# Step 3: Log in to Amazon ECR\necho \"Logging in to ECR in region $REGION...\"\naws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com\n\n# Step 4: Push the image to ECR\necho \"Pushing image to ECR...\"\ndocker push $IMAGE_URI\n\n# Step 5: Update the Lambda function to use the new image\necho \"Updating Lambda function $LAMBDA_FUNCTION_NAME with new image...\"\naws lambda update-function-code \\\n  --function-name $LAMBDA_FUNCTION_NAME \\\n  --image-uri $IMAGE_URI \\\n  --region $REGION\n\necho \"Lambda function updated successfully.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/lambda/pdf_processor/update.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Exit on error\nset -e\n\n# Load environment variables from .env file\nif [ -f .env ]; then\n    source .env\nelse\n    echo \"Error: .env file not found\"\n    exit 1\nfi\n\n# Configuration variables\nEC2_ROLE_NAME=\"fred-ec2-s3-role\"\nEVENTBRIDGE_ROLE_NAME=\"fred-eventbridge-ec2-role\"\nRULE_NAME=\"fred-daily-update-rule\"\nTEMPLATE_NAME=\"fred-daily-template\"\nS3_BUCKET=\"policy-database\"\nREGION=\"${AWS_REGION:-us-east-1}\"\nAMI_ID=\"ami-0a38b8c18f189761a\"  # Amazon Linux 2\nINSTANCE_TYPE=\"t3.small\"\nSECURITY_GROUP_NAME=\"FredProcessorSG\"\nSCHEDULE=\"cron(0 1 * * ? *)\"  # Run at 1:00 AM UTC every day\nSEED_HISTORICAL=false  # Default to not seed historical data\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n    key=\"$1\"\n    case $key in\n        --seed-historical)\n            SEED_HISTORICAL=true\n            shift\n            ;;\n        *)\n            echo \"Unknown option: $1\"\n            echo \"Usage: $0 [--seed-historical]\"\n            exit 1\n            ;;\n    esac\ndone\n\n# Store the current directory\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\necho \"Script directory: $SCRIPT_DIR\"\n\n# Check if ec2-daily-update.txt exists\nif [ ! -f \"$SCRIPT_DIR/ec2-daily-update.txt\" ]; then\n    echo \"Error: ec2-daily-update.txt file not found\"\n    exit 1\nfi\n\n# Check if daily.py and transform.py exist\nif [ ! -f \"$SCRIPT_DIR/daily.py\" ] || [ ! -f \"$SCRIPT_DIR/transform.py\" ]; then\n    echo \"Error: daily.py or transform.py files not found\"\n    exit 1\nfi\n\necho \"Starting FRED ETL EC2-based deployment...\"\n\n# Step 0: Create S3 folder structure if it doesn't exist\necho \"Setting up S3 folder structure...\"\n# Create main folder (this is a no-op if it already exists)\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"financial-metrics/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create daily folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"financial-metrics/daily/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create processed folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"financial-metrics/processed/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create failed folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"financial-metrics/failed/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create logs folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"logs/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create scripts folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"scripts/\" --content-type \"application/x-directory\" 2>/dev/null || true\n\n# Step 1: Upload scripts to S3\necho \"Uploading scripts to S3...\"\naws s3 cp \"$SCRIPT_DIR/daily.py\" \"s3://$S3_BUCKET/scripts/daily.py\" || true\naws s3 cp \"$SCRIPT_DIR/transform.py\" \"s3://$S3_BUCKET/scripts/transform.py\" || true\n\n# Upload search_series files to S3 if they exist\necho \"Uploading search_series files to S3...\"\nfor file in \"$SCRIPT_DIR\"/search_series*.json; do\n    if [ -f \"$file\" ]; then\n        filename=$(basename \"$file\")\n        aws s3 cp \"$file\" \"s3://$S3_BUCKET/financial-metrics/$filename\" || true\n    fi\ndone\n\n# Step 1.5: Seed historical data if requested\nif [ \"$SEED_HISTORICAL\" = true ]; then\n    echo \"Seeding historical data from FRED...\"\n\n    # Temporarily download search_series files to verify their existence\n    SEARCH_FILES_EXIST=true\n    for i in \"\" \"2\" \"3\" \"4\"; do\n        aws s3 ls \"s3://$S3_BUCKET/financial-metrics/search_series${i}.json\" &>/dev/null || SEARCH_FILES_EXIST=false\n    done\n\n    if [ \"$SEARCH_FILES_EXIST\" = false ]; then\n        echo \"Error: One or more search_series files not found in S3. Please upload them first.\"\n        exit 1\n    fi\n\n    # Create a temporary EC2 instance to run the seed process\n    echo \"Creating temporary EC2 instance for historical data seeding...\"\n\n    # Create a user data script for seeding\n    SEED_USER_DATA_FILE=\"$SCRIPT_DIR/temp_seed_user_data.txt\"\n    cat > \"$SEED_USER_DATA_FILE\" << 'EOL'\n#!/bin/bash\n\n# Log setup start\necho \"Starting FRED historical data seeding on EC2...\" > /var/log/fred-setup.log\n\n# Update the system and install dependencies\nyum update -y >> /var/log/fred-setup.log 2>&1\nyum install -y python3 python3-pip git awscli >> /var/log/fred-setup.log 2>&1\n\n# Create directory structure\nmkdir -p /home/ec2-user/fred\ncd /home/ec2-user/fred\n\n# Set proper ownership\nchown -R ec2-user:ec2-user /home/ec2-user/fred\n\n# Set environment variables in a .env file\ncat > /home/ec2-user/fred/.env << 'ENV_EOL'\nS3_BUCKET=policy-database\nAWS_REGION=us-east-1\nFRED_API_KEY=YOUR_FRED_API_KEY\nENV_EOL\n\n# Install Python dependencies\npip3 install boto3 python-dotenv requests >> /var/log/fred-setup.log 2>&1\n\n# Create the seed script\ncat > /home/ec2-user/fred/run_seed.py << 'PYTHON_EOL'\n#!/usr/bin/env python3\n\"\"\"\nFRED Historical Data Seeding Script\n\nPurpose:\n    This script seeds historical data for all economic indicators in the search_series files.\n\"\"\"\nimport os\nimport json\nimport requests\nimport boto3\nimport time\nimport logging\nfrom dotenv import load_dotenv\nfrom datetime import datetime\n\n# Load environment variables\nload_dotenv()\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('/home/ec2-user/fred/seed.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger()\n\n# AWS Configuration\nS3_BUCKET = os.getenv('S3_BUCKET')\nREGION = os.getenv('AWS_REGION')\nFRED_API_KEY = os.getenv('FRED_API_KEY')\n\ndef download_search_series():\n    \"\"\"Download search_series files from S3\"\"\"\n    s3_client = boto3.client('s3', region_name=REGION)\n    for i in [\"\", \"2\", \"3\", \"4\"]:\n        try:\n            s3_client.download_file(\n                S3_BUCKET,\n                f\"financial-metrics/search_series{i}.json\",\n                f\"search_series{i}.json\"\n            )\n            logger.info(f\"Downloaded search_series{i}.json from S3\")\n        except Exception as e:\n            logger.error(f\"Error downloading search_series{i}.json: {str(e)}\")\n\ndef extract_series_list(filename):\n    \"\"\"Extract series list from search_series file\"\"\"\n    try:\n        with open(filename, 'r') as f:\n            data = json.load(f)\n        series_list = data.get(\"seriess\", [])\n        logger.info(f\"Successfully loaded {len(series_list)} series from {filename}\")\n        return series_list\n    except Exception as e:\n        logger.error(f\"Failed to load series from {filename}: {str(e)}\")\n        return []\n\ndef get_existing_series(s3_client, bucket, prefix):\n    \"\"\"Get list of series that already exist in S3\"\"\"\n    existing_series = set()\n    try:\n        paginator = s3_client.get_paginator('list_objects_v2')\n        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n            if 'Contents' in page:\n                for obj in page['Contents']:\n                    # Extract series_id from the filename (format: series_id_*.json)\n                    filename = obj['Key'].split('/')[-1]\n                    if filename.endswith('.json'):\n                        series_id = filename.split('_')[0]\n                        existing_series.add(series_id)\n    except Exception as e:\n        logger.error(f\"Error listing existing series: {str(e)}\")\n    return existing_series\n\ndef save_response_to_file(series_id, start_date, end_date, response_json):\n    \"\"\"Save API response to local file\"\"\"\n    filename = f\"{series_id}_{start_date}_{end_date}.json\"\n    with open(filename, 'w') as f:\n        json.dump(response_json, f, indent=2)\n    return filename\n\ndef process_series(series_list, existing_series, s3_client):\n    \"\"\"Process each series in the list\"\"\"\n    base_url = \"https://api.stlouisfed.org/fred/series/observations\"\n    processed_count = 0\n    failed_count = 0\n\n    for series in series_list:\n        series_id = series.get(\"id\")\n        if not series_id:\n            continue\n\n        # Skip if series already exists\n        if series_id in existing_series:\n            logger.info(f\"Skipping series {series_id} - already exists in S3\")\n            continue\n\n        logger.info(f\"Processing series: {series_id}\")\n\n        # Get observation date range\n        obs_start = series.get(\"observation_start\", \"1900-01-01\")\n        obs_end = series.get(\"observation_end\", datetime.now().strftime(\"%Y-%m-%d\"))\n\n        # Set up API request parameters\n        params = {\n            'series_id': series_id,\n            'api_key': FRED_API_KEY,\n            'observation_start': obs_start,\n            'observation_end': obs_end,\n            'file_type': 'json'\n        }\n\n        try:\n            # Make the API request\n            response = requests.get(base_url, params=params)\n            response.raise_for_status()\n            response_json = response.json()\n\n            # Check if there are any observations\n            if response_json.get(\"observations\"):\n                # Save the response to a local file\n                local_filename = save_response_to_file(series_id, obs_start, obs_end, response_json)\n\n                # Upload to S3\n                s3_key = f\"financial-metrics/{local_filename}\"\n                s3_client.upload_file(local_filename, S3_BUCKET, s3_key)\n                logger.info(f\"Uploaded {local_filename} to S3\")\n\n                # Remove local file\n                os.remove(local_filename)\n                processed_count += 1\n                existing_series.add(series_id)\n            else:\n                logger.warning(f\"No observations found for series {series_id}\")\n\n            # Add delay to respect API rate limits\n            time.sleep(0.5)\n\n        except Exception as e:\n            failed_count += 1\n            logger.error(f\"Error processing series {series_id}: {str(e)}\")\n            continue\n\n    return processed_count, failed_count\n\ndef main():\n    \"\"\"Main function\"\"\"\n    logger.info(\"Starting FRED historical data seeding\")\n\n    # Download search_series files from S3\n    download_search_series()\n\n    # Setup S3 client\n    s3_client = boto3.client('s3', region_name=REGION)\n\n    # Get existing series\n    existing_series = get_existing_series(s3_client, S3_BUCKET, \"financial-metrics/\")\n    logger.info(f\"Found {len(existing_series)} existing series in S3\")\n\n    # Process each search series file\n    search_files = [\"search_series.json\", \"search_series2.json\", \"search_series3.json\", \"search_series4.json\"]\n\n    total_processed = 0\n    total_failed = 0\n\n    for search_file in search_files:\n        try:\n            if not os.path.exists(search_file):\n                logger.warning(f\"Search file {search_file} not found, skipping\")\n                continue\n\n            # Extract series list\n            series_list = extract_series_list(search_file)\n\n            # Process series\n            processed, failed = process_series(series_list, existing_series, s3_client)\n\n            total_processed += processed\n            total_failed += failed\n\n        except Exception as e:\n            logger.error(f\"Error processing search file {search_file}: {str(e)}\")\n            continue\n\n    # Run transform on all files\n    logger.info(\"Running transform on historical data...\")\n    try:\n        # Download transform script\n        s3_client.download_file(S3_BUCKET, \"scripts/transform.py\", \"transform.py\")\n\n        # Run transform with --prefix financial-metrics\n        os.system(\"python3 transform.py --prefix financial-metrics --debug\")\n\n        # Upload transform log\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        s3_client.upload_file(\"transform.log\", S3_BUCKET, f\"logs/transform_historical_{timestamp}.log\")\n\n    except Exception as e:\n        logger.error(f\"Error running transform on historical data: {str(e)}\")\n\n    logger.info(f\"Historical data seeding completed! Processed: {total_processed}, Failed: {total_failed}\")\n\n    # Upload seed log to S3\n    try:\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        s3_client.upload_file(\"seed.log\", S3_BUCKET, f\"logs/seed_{timestamp}.log\")\n    except Exception as e:\n        logger.error(f\"Error uploading seed log: {str(e)}\")\n\nif __name__ == \"__main__\":\n    main()\nPYTHON_EOL\n\n# Make the script executable\nchmod +x /home/ec2-user/fred/run_seed.py\nchown ec2-user:ec2-user /home/ec2-user/fred/run_seed.py\n\n# Run the seeding script\nsu - ec2-user -c \"cd /home/ec2-user/fred && python3 run_seed.py\"\n\n# Check if the script ran successfully\nRESULT=$?\nif [ $RESULT -eq 0 ]; then\n  echo \"FRED historical data seeding completed successfully\" >> /var/log/fred-setup.log\nelse\n  echo \"FRED historical data seeding failed with exit code $RESULT\" >> /var/log/fred-setup.log\nfi\n\n# Shutdown the instance after seeding is complete\nshutdown -h now\nEOL\n\n    # Encode the seeding user data script\n    SEED_USER_DATA=$(base64 -w 0 \"$SEED_USER_DATA_FILE\")\n\n    # Launch EC2 instance with the seeding user data\n    echo \"Launching EC2 instance for historical data seeding...\"\n\n    # Create a temporary security group for seeding if it doesn't exist\n    SEED_SG_NAME=\"FredSeedingSG\"\n    SEED_SG_ID=$(aws ec2 describe-security-groups --filters \"Name=group-name,Values=$SEED_SG_NAME\" --query \"SecurityGroups[0].GroupId\" --output text 2>/dev/null || echo \"\")\n    if [ \"$SEED_SG_ID\" == \"\" ] || [ \"$SEED_SG_ID\" == \"None\" ]; then\n        # Get default VPC ID\n        VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=isDefault,Values=true\" --query \"Vpcs[0].VpcId\" --output text)\n        if [ -z \"$VPC_ID\" ]; then\n            echo \"Error: No default VPC found\"\n            exit 1\n        fi\n\n        # Create security group\n        SEED_SG_ID=$(aws ec2 create-security-group --group-name \"$SEED_SG_NAME\" --description \"Security group for FRED ETL seeding\" --vpc-id \"$VPC_ID\" --query \"GroupId\" --output text)\n\n        # Add SSH access rule\n        aws ec2 authorize-security-group-ingress --group-id \"$SEED_SG_ID\" --protocol tcp --port 22 --cidr 0.0.0.0/0\n\n        echo \"Created security group: $SEED_SG_ID\"\n    else\n        echo \"Using existing security group: $SEED_SG_ID\"\n    fi\n\n    # Launch EC2 instance\n    INSTANCE_ID=$(aws ec2 run-instances \\\n        --image-id \"$AMI_ID\" \\\n        --instance-type \"$INSTANCE_TYPE\" \\\n        --security-group-ids \"$SEED_SG_ID\" \\\n        --user-data \"$SEED_USER_DATA\" \\\n        --iam-instance-profile \"Name=$EC2_ROLE_NAME\" \\\n        --tag-specifications \"ResourceType=instance,Tags=[{Key=Name,Value=FRED-Historical-Seeding}]\" \\\n        --query \"Instances[0].InstanceId\" \\\n        --output text)\n\n    echo \"Launched instance $INSTANCE_ID for historical data seeding\"\n    echo \"This process will run in the background and may take several hours to complete\"\n    echo \"You can check the status of the seeding process by monitoring the instance status\"\n    echo \"The instance will shut down automatically when seeding is complete\"\n\n    # Clean up temporary file\n    rm -f \"$SEED_USER_DATA_FILE\"\nfi\n\n# Step 2: Create IAM role for EC2 with S3 access\necho \"Creating IAM role for EC2 instances...\"\naws iam create-role --role-name \"$EC2_ROLE_NAME\" --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n        \"Action\": \"sts:AssumeRole\",\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Service\": \"ec2.amazonaws.com\"\n        }\n    }]\n}' 2>/dev/null || true\n\n# Attach S3 access policy to the EC2 role\naws iam attach-role-policy --role-name \"$EC2_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" 2>/dev/null || true\n\n# Create instance profile and add role\naws iam create-instance-profile --instance-profile-name \"$EC2_ROLE_NAME\" 2>/dev/null || true\naws iam add-role-to-instance-profile --instance-profile-name \"$EC2_ROLE_NAME\" --role-name \"$EC2_ROLE_NAME\" 2>/dev/null || true\n\n# Step 3: Create IAM role for EventBridge to launch EC2 instances\necho \"Creating IAM role for EventBridge...\"\naws iam create-role --role-name \"$EVENTBRIDGE_ROLE_NAME\" --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n        \"Action\": \"sts:AssumeRole\",\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Service\": \"events.amazonaws.com\"\n        }\n    }]\n}' 2>/dev/null || true\n\n# Attach policy to allow launching EC2 instances\naws iam put-role-policy --role-name \"$EVENTBRIDGE_ROLE_NAME\" --policy-name \"LaunchEC2Policy\" --policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n            \"Effect\": \"Allow\",\n            \"Action\": [\n            \"ec2:RunInstances\",\n            \"ec2:CreateTags\",\n            \"iam:PassRole\"\n        ],\n        \"Resource\": \"*\"\n    }]\n}' 2>/dev/null || true\n\n# Get the EventBridge role ARN\nEVENTBRIDGE_ROLE_ARN=$(aws iam get-role --role-name \"$EVENTBRIDGE_ROLE_NAME\" --query 'Role.Arn' --output text)\n\n# Step 4: Create security group for EC2 instances if it doesn't exist\necho \"Creating security group for EC2 instances...\"\nSECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=group-name,Values=$SECURITY_GROUP_NAME\" --query \"SecurityGroups[0].GroupId\" --output text 2>/dev/null || echo \"\")\nif [ \"$SECURITY_GROUP_ID\" == \"\" ] || [ \"$SECURITY_GROUP_ID\" == \"None\" ]; then\n    # Get default VPC ID\n    VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=isDefault,Values=true\" --query \"Vpcs[0].VpcId\" --output text)\n    if [ -z \"$VPC_ID\" ]; then\n        echo \"Error: No default VPC found\"\n        exit 1\n    fi\n\n    # Create security group\n    SECURITY_GROUP_ID=$(aws ec2 create-security-group --group-name \"$SECURITY_GROUP_NAME\" --description \"Security group for FRED ETL EC2 instances\" --vpc-id \"$VPC_ID\" --query \"GroupId\" --output text)\n\n    # Add SSH access rule\n    aws ec2 authorize-security-group-ingress --group-id \"$SECURITY_GROUP_ID\" --protocol tcp --port 22 --cidr 0.0.0.0/0\n\n    echo \"Created security group: $SECURITY_GROUP_ID\"\nelse\n    echo \"Using existing security group: $SECURITY_GROUP_ID\"\nfi\n\n# Step 5: Get subnet ID\necho \"Getting subnet ID...\"\nSUBNET_ID=$(aws ec2 describe-subnets --filters \"Name=default-for-az,Values=true\" --query \"Subnets[0].SubnetId\" --output text)\nif [ -z \"$SUBNET_ID\" ]; then\n    echo \"Error: No default subnet found\"\n    exit 1\nfi\necho \"Using subnet: $SUBNET_ID\"\n\n# Step 6: Encode the user data script\necho \"Encoding user data script...\"\nUSER_DATA=$(base64 -w 0 \"$SCRIPT_DIR/ec2-daily-update.txt\")\n\n# Step 7: Create EC2 launch template\necho \"Creating EC2 launch template...\"\naws ec2 create-launch-template \\\n    --launch-template-name \"$TEMPLATE_NAME\" \\\n    --version-description \"Initial version\" \\\n    --launch-template-data \"{\n        \\\"ImageId\\\": \\\"$AMI_ID\\\",\n        \\\"InstanceType\\\": \\\"$INSTANCE_TYPE\\\",\n        \\\"SecurityGroupIds\\\": [\\\"$SECURITY_GROUP_ID\\\"],\n        \\\"UserData\\\": \\\"$USER_DATA\\\",\n        \\\"TagSpecifications\\\": [{\n            \\\"ResourceType\\\": \\\"instance\\\",\n            \\\"Tags\\\": [{\n                \\\"Key\\\": \\\"Name\\\",\n                \\\"Value\\\": \\\"FRED-Daily-ETL\\\"\n            }]\n        }],\n        \\\"IamInstanceProfile\\\": {\n            \\\"Name\\\": \\\"$EC2_ROLE_NAME\\\"\n        }\n    }\" 2>/dev/null || echo \"Launch template exists, updating...\"\n\n# Step 8: Create EventBridge rule\necho \"Creating EventBridge rule...\"\naws events put-rule \\\n    --name \"$RULE_NAME\" \\\n    --schedule-expression \"$SCHEDULE\" \\\n    --state ENABLED \\\n    2>/dev/null || echo \"Rule exists, updating...\"\n\n# Get the rule ARN\nRULE_ARN=$(aws events describe-rule --name \"$RULE_NAME\" --query \"Arn\" --output text)\n\n# Get the template ID\nTEMPLATE_ID=$(aws ec2 describe-launch-templates \\\n    --launch-template-names \"$TEMPLATE_NAME\" \\\n    --query \"LaunchTemplates[0].LaunchTemplateId\" \\\n    --output text)\n\n# Step 9: Create EventBridge target\necho \"Creating EventBridge target...\"\naws events put-targets \\\n    --rule \"$RULE_NAME\" \\\n    --targets \"[{\n        \\\"Id\\\": \\\"1\\\",\n        \\\"Arn\\\": \\\"arn:aws:events:$REGION::event-bus/default\\\",\n        \\\"RoleArn\\\": \\\"$EVENTBRIDGE_ROLE_ARN\\\",\n        \\\"Input\\\": \\\"{\\\\\\\"source\\\\\\\":[\\\\\\\"aws.events\\\\\\\"],\\\\\\\"detail-type\\\\\\\":[\\\\\\\"EC2 Instance Launch Request\\\\\\\"],\\\\\\\"detail\\\\\\\":{\\\\\\\"launch-template-id\\\\\\\":\\\\\\\"$TEMPLATE_ID\\\\\\\",\\\\\\\"subnet-id\\\\\\\":\\\\\\\"$SUBNET_ID\\\\\\\"}}\\\"\n    }]\" 2>/dev/null || echo \"Target updated.\"\n\necho \"Deployment completed successfully!\"\necho \"FRED ETL EC2-based daily update has been configured to run at 1:00 AM UTC every day.\"\necho \"EventBridge rule: $RULE_NAME\"\necho \"Launch template: $TEMPLATE_NAME\"\necho \"IAM roles: $EC2_ROLE_NAME, $EVENTBRIDGE_ROLE_NAME\"\necho \"S3 bucket: $S3_BUCKET\"\n\nif [ \"$SEED_HISTORICAL\" = true ]; then\n    echo \"\"\n    echo \"Historical data seeding is running in the background on instance ID: $INSTANCE_ID\"\n    echo \"You can check the progress by viewing the instance logs or monitoring the S3 bucket\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/indicators/fred/deploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n#!/bin/bash\n\n# Set your variables\nSEED_FUNCTION_NAME=\"commoditic-seed\"\nSEED_ROLE_NAME=\"commoditic-seed-role\"\nSEED_RULE_NAME=\"commoditic-seed-rule\"\nREGION=$(aws configure get region)\n\necho \"Removing seed Lambda function and related resources...\"\n\n# Delete any EventBridge rule targets associated with seed\necho \"Removing EventBridge rule targets...\"\naws events remove-targets --rule \"$SEED_RULE_NAME\" --ids \"1\" 2>/dev/null || true\n\n# Delete EventBridge rule if it exists\necho \"Removing EventBridge rule...\"\naws events delete-rule --name \"$SEED_RULE_NAME\" 2>/dev/null || true\n\n# Delete Lambda function\necho \"Deleting Lambda function: $SEED_FUNCTION_NAME\"\naws lambda delete-function --function-name \"$SEED_FUNCTION_NAME\" 2>/dev/null || true\n\n# Delete CloudWatch log group\necho \"Deleting CloudWatch log group: /aws/lambda/$SEED_FUNCTION_NAME\"\naws logs delete-log-group --log-group-name \"/aws/lambda/$SEED_FUNCTION_NAME\" 2>/dev/null || true\n\n# Delete IAM role policies\necho \"Deleting IAM role policy...\"\naws iam delete-role-policy --role-name \"$SEED_ROLE_NAME\" --policy-name \"commoditic-seed-policy\" 2>/dev/null || true\n\n# Delete IAM role\necho \"Deleting IAM role: $SEED_ROLE_NAME\"\naws iam delete-role --role-name \"$SEED_ROLE_NAME\" 2>/dev/null || true\n\necho \"Seed Lambda resources have been cleaned up!\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/indicators/commoditic/delete_seed_lambda.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Exit on error\nset -e\n\n# Default: run both seed script and ETL setup\nRUN_SEED=true\nRUN_ETL=true\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n  key=\"$1\"\n  case $key in\n    --seed)\n      RUN_SEED=true\n      RUN_ETL=false\n      shift\n      ;;\n    --etl)\n      RUN_SEED=false\n      RUN_ETL=true\n      shift\n      ;;\n    *)\n      shift\n      ;;\n  esac\ndone\n\n# Load environment variables from .env file - located in the parent directory\nif [ -f \"../.env\" ]; then\n    source \"../.env\"\nelse\n    echo \"Error: .env file not found in /RAG/indicators directory\"\n    exit 1\nfi\n\n# Configuration variables\nDAILY_FUNCTION_NAME=\"commoditic-daily-update\"\nTRANSFORM_FUNCTION_NAME=\"commoditic-transform\"\nDAILY_ROLE_NAME=\"commoditic-daily-update-role\"\nTRANSFORM_ROLE_NAME=\"commoditic-transform-role\"\nDAILY_RULE_NAME=\"commoditic-daily-update-rule\"\nTRANSFORM_RULE_NAME=\"commoditic-transform-rule\"\nSECRET_NAME=\"commoditic-api-key\"\nTRANSFORM_SCRIPT_KEY=\"financial-metrics/commoditic-transform.py\"\nS3_BUCKET=\"policy-database\"\n\n# Store the current directory\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\necho \"Script directory: $SCRIPT_DIR\"\n\n# Run seed script if requested\nif [ \"$RUN_SEED\" = true ]; then\n  echo \"Running seed script to download initial data...\"\n\n  # Create a virtual environment for the seed script\n  SEED_VENV_DIR=$(mktemp -d)\n  echo \"Created temporary directory for seed venv: $SEED_VENV_DIR\"\n\n  # Set up virtual environment\n  python3 -m venv \"$SEED_VENV_DIR/venv\"\n  source \"$SEED_VENV_DIR/venv/bin/activate\"\n\n  # Install dependencies\n  echo \"Installing dependencies in virtual environment...\"\n  pip install -r \"$SCRIPT_DIR/requirements.txt\"\n\n  # Run the seed script\n  echo \"Executing seed.py...\"\n  python \"$SCRIPT_DIR/seed.py\"\n\n  # Deactivate and clean up virtual environment\n  deactivate\n  rm -rf \"$SEED_VENV_DIR\"\n\n  echo \"Seed script completed.\"\nfi\n\n# Setup AWS infrastructure if requested\nif [ \"$RUN_ETL\" = true ]; then\n  # Create temporary directory for packaging\n  TEMP_DIR=$(mktemp -d)\n  echo \"Created temporary directory: $TEMP_DIR\"\n\n  # Copy required files to temporary directory\n  cp \"../lambdas/commoditic_daily.py\" \"$TEMP_DIR/daily.py\"\n  cp \"$SCRIPT_DIR/requirements.txt\" \"$TEMP_DIR/\"\n\n  # Install dependencies in temporary directory\n  cd \"$TEMP_DIR\"\n  pip3 install -r requirements.txt -t .\n\n  # Create ZIP file\n  zip -r \"$SCRIPT_DIR/function.zip\" .\n\n  # Clean up temporary directory\n  cd \"$SCRIPT_DIR\"\n  rm -rf \"$TEMP_DIR\"\n\n  # Create IAM roles (idempotent)\n  echo \"Creating IAM roles...\"\n  aws iam create-role --role-name \"$DAILY_ROLE_NAME\" --assume-role-policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [{\n          \"Action\": \"sts:AssumeRole\",\n          \"Effect\": \"Allow\",\n          \"Principal\": {\n              \"Service\": \"lambda.amazonaws.com\"\n          }\n      }]\n  }' 2>/dev/null || true\n\n  aws iam create-role --role-name \"$TRANSFORM_ROLE_NAME\" --assume-role-policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [{\n          \"Action\": \"sts:AssumeRole\",\n          \"Effect\": \"Allow\",\n          \"Principal\": {\n              \"Service\": \"lambda.amazonaws.com\"\n          }\n      }]\n  }' 2>/dev/null || true\n\n  # Create IAM policies (idempotent)\n  echo \"Creating IAM policies...\"\n  aws iam put-role-policy --role-name \"$DAILY_ROLE_NAME\" --policy-name \"commoditic-daily-update-policy\" --policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"s3:PutObject\",\n                  \"s3:GetObject\",\n                  \"s3:ListBucket\",\n                  \"s3:DeleteObject\"\n              ],\n              \"Resource\": [\n                  \"arn:aws:s3:::policy-database/*\",\n                  \"arn:aws:s3:::policy-database\"\n              ]\n          },\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"secretsmanager:GetSecretValue\"\n              ],\n              \"Resource\": \"arn:aws:secretsmanager:*:*:secret:commoditic-api-key-*\"\n          },\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"logs:CreateLogGroup\",\n                  \"logs:CreateLogStream\",\n                  \"logs:PutLogEvents\"\n              ],\n              \"Resource\": \"arn:aws:logs:*:*:*\"\n          }\n      ]\n  }' || true\n\n  aws iam put-role-policy --role-name \"$TRANSFORM_ROLE_NAME\" --policy-name \"commoditic-transform-policy\" --policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"s3:PutObject\",\n                  \"s3:GetObject\",\n                  \"s3:ListBucket\",\n                  \"s3:DeleteObject\"\n              ],\n              \"Resource\": [\n                  \"arn:aws:s3:::policy-database/*\",\n                  \"arn:aws:s3:::policy-database\"\n              ]\n          },\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"logs:CreateLogGroup\",\n                  \"logs:CreateLogStream\",\n                  \"logs:PutLogEvents\"\n              ],\n              \"Resource\": \"arn:aws:logs:*:*:*\"\n          }\n      ]\n  }' || true\n\n  # Get role ARNs\n  DAILY_ROLE_ARN=$(aws iam get-role --role-name \"$DAILY_ROLE_NAME\" --query 'Role.Arn' --output text)\n  TRANSFORM_ROLE_ARN=$(aws iam get-role --role-name \"$TRANSFORM_ROLE_NAME\" --query 'Role.Arn' --output text)\n\n  # Create or update secret (idempotent)\n  echo \"Creating/updating secret...\"\n  aws secretsmanager create-secret \\\n      --name \"$SECRET_NAME\" \\\n      --secret-string \"{\\\"COMMODITIC_API_KEY\\\":\\\"$COMMODITIC_API_KEY\\\"}\" \\\n      2>/dev/null || aws secretsmanager update-secret \\\n          --secret-id \"$SECRET_NAME\" \\\n          --secret-string \"{\\\"COMMODITIC_API_KEY\\\":\\\"$COMMODITIC_API_KEY\\\"}\"\n\n  # Create a temporary directory for transform.py\n  TRANSFORM_TEMP_DIR=$(mktemp -d)\n  echo \"Created temporary directory for transform.py: $TRANSFORM_TEMP_DIR\"\n\n  # Copy transform.py and requirements to temporary directory\n  echo \"Copying transform.py and requirements.txt to temporary directory...\"\n  cp \"$SCRIPT_DIR/transform.py\" \"$TRANSFORM_TEMP_DIR/\"\n  cp \"$SCRIPT_DIR/requirements.txt\" \"$TRANSFORM_TEMP_DIR/\"\n\n  # Install dependencies in temporary directory\n  cd \"$TRANSFORM_TEMP_DIR\"\n  pip3 install -r requirements.txt -t .\n\n  # Create ZIP file for transform function\n  echo \"Creating ZIP file for transform function...\"\n  zip -r \"$SCRIPT_DIR/transform.zip\" .\n\n  # Upload transform.zip to S3 (idempotent)\n  echo \"Uploading transform.zip to S3...\"\n  aws s3 cp \"$SCRIPT_DIR/transform.zip\" \"s3://$S3_BUCKET/$TRANSFORM_SCRIPT_KEY\" || true\n\n  cd \"$SCRIPT_DIR\"\n\n  # Clean up transform temporary directory\n  rm -rf \"$TRANSFORM_TEMP_DIR\"\n\n  # Create CloudWatch log groups (idempotent)\n  echo \"Creating CloudWatch log groups...\"\n  aws logs create-log-group --log-group-name \"/aws/lambda/$DAILY_FUNCTION_NAME\" 2>/dev/null || true\n  aws logs create-log-group --log-group-name \"/aws/lambda/$TRANSFORM_FUNCTION_NAME\" 2>/dev/null || true\n\n  # Create or update Lambda functions\n  echo \"Creating/updating Lambda functions...\"\n\n  # Check if daily function exists\n  if aws lambda get-function --function-name \"$DAILY_FUNCTION_NAME\" 2>/dev/null; then\n      echo \"Updating daily function...\"\n      aws lambda update-function-code \\\n          --function-name \"$DAILY_FUNCTION_NAME\" \\\n          --zip-file \"fileb://$SCRIPT_DIR/function.zip\"\n  else\n      echo \"Creating daily function...\"\n      aws lambda create-function \\\n          --function-name \"$DAILY_FUNCTION_NAME\" \\\n          --runtime python3.9 \\\n          --handler daily.lambda_handler \\\n          --role \"$DAILY_ROLE_ARN\" \\\n          --zip-file \"fileb://$SCRIPT_DIR/function.zip\" \\\n          --timeout 600 \\\n          --memory-size 256 \\\n          --environment \"Variables={S3_BUCKET=policy-database,SECRET_NAME=$SECRET_NAME}\"\n  fi\n\n  # Wait for a few seconds to ensure the transform.py file is available in S3\n  sleep 5\n\n  # Check if transform function exists\n  if aws lambda get-function --function-name \"$TRANSFORM_FUNCTION_NAME\" 2>/dev/null; then\n      echo \"Updating transform function...\"\n      aws lambda update-function-code \\\n          --function-name \"$TRANSFORM_FUNCTION_NAME\" \\\n          --zip-file \"fileb://$SCRIPT_DIR/transform.zip\"\n  else\n      echo \"Creating transform function...\"\n      aws lambda create-function \\\n          --function-name \"$TRANSFORM_FUNCTION_NAME\" \\\n          --runtime python3.9 \\\n          --handler transform.lambda_handler \\\n          --role \"$TRANSFORM_ROLE_ARN\" \\\n          --zip-file \"fileb://$SCRIPT_DIR/transform.zip\" \\\n          --timeout 300 \\\n          --memory-size 256 \\\n          --environment \"Variables={S3_BUCKET=policy-database,COMMODITIC_API_KEY=$COMMODITIC_API_KEY}\"\n  fi\n\n  # Get function ARNs\n  DAILY_FUNCTION_ARN=$(aws lambda get-function --function-name \"$DAILY_FUNCTION_NAME\" --query 'Configuration.FunctionArn' --output text)\n  TRANSFORM_FUNCTION_ARN=$(aws lambda get-function --function-name \"$TRANSFORM_FUNCTION_NAME\" --query 'Configuration.FunctionArn' --output text)\n\n  # Create EventBridge rules (idempotent)\n  echo \"Creating EventBridge rules...\"\n  aws events put-rule \\\n      --name \"$DAILY_RULE_NAME\" \\\n      --schedule-expression \"cron(59 23 * * ? *)\" \\\n      --state ENABLED \\\n      2>/dev/null || true\n\n  aws events put-rule \\\n      --name \"$TRANSFORM_RULE_NAME\" \\\n      --schedule-expression \"cron(0 0 * * ? *)\" \\\n      --state ENABLED \\\n      2>/dev/null || true\n\n  # Add Lambda functions as targets for EventBridge rules (idempotent)\n  echo \"Adding Lambda functions as EventBridge targets...\"\n  aws events put-targets \\\n      --rule \"$DAILY_RULE_NAME\" \\\n      --targets \"Id\"=\"1\",\"Arn\"=\"$DAILY_FUNCTION_ARN\" \\\n      2>/dev/null || true\n\n  aws events put-targets \\\n      --rule \"$TRANSFORM_RULE_NAME\" \\\n      --targets \"Id\"=\"1\",\"Arn\"=\"$TRANSFORM_FUNCTION_ARN\" \\\n      2>/dev/null || true\n\n  # Grant permission for EventBridge to invoke Lambda functions (idempotent)\n  echo \"Granting EventBridge permissions...\"\n  aws lambda remove-permission \\\n      --function-name \"$DAILY_FUNCTION_NAME\" \\\n      --statement-id \"EventBridgeInvokeFunction\" \\\n      2>/dev/null || true\n\n  aws lambda remove-permission \\\n      --function-name \"$TRANSFORM_FUNCTION_NAME\" \\\n      --statement-id \"EventBridgeInvokeFunction\" \\\n      2>/dev/null || true\n\n  aws lambda add-permission \\\n      --function-name \"$DAILY_FUNCTION_NAME\" \\\n      --statement-id \"EventBridgeInvokeFunction\" \\\n      --action \"lambda:InvokeFunction\" \\\n      --principal \"events.amazonaws.com\" \\\n      --source-arn \"arn:aws:events:$AWS_REGION:$AWS_ACCOUNT_ID:rule/$DAILY_RULE_NAME\" \\\n      2>/dev/null || true\n\n  aws lambda add-permission \\\n      --function-name \"$TRANSFORM_FUNCTION_NAME\" \\\n      --statement-id \"EventBridgeInvokeFunction\" \\\n      --action \"lambda:InvokeFunction\" \\\n      --principal \"events.amazonaws.com\" \\\n      --source-arn \"arn:aws:events:$AWS_REGION:$AWS_ACCOUNT_ID:rule/$TRANSFORM_RULE_NAME\" \\\n      2>/dev/null || true\n\n  # Clean up\n  rm \"$SCRIPT_DIR/function.zip\"\n  rm \"$SCRIPT_DIR/transform.zip\"\n\n  echo \"Deployment completed successfully!\"\n  echo \"Daily update Lambda function: $DAILY_FUNCTION_NAME\"\n  echo \"Transform Lambda function: $TRANSFORM_FUNCTION_NAME\"\n  echo \"Daily update EventBridge rule: $DAILY_RULE_NAME\"\n  echo \"Transform EventBridge rule: $TRANSFORM_RULE_NAME\"\n  echo \"IAM roles: $DAILY_ROLE_NAME, $TRANSFORM_ROLE_NAME\"\n  echo \"Secret name: $SECRET_NAME\"\n  echo \"S3 bucket: $S3_BUCKET\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/indicators/commoditic/deploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Exit on error\nset -e\n\n# Load environment variables\nsource .env\n\n# Configuration\nSTACK_NAME=\"sarb-metrics-stack\"\nREGION=\"us-east-1\"\nBUCKET_NAME=\"policy-database\"\nZIP_FILE=\"sarb_lambda.zip\"\nLAMBDA_FUNCTION_NAME=\"sarb-metrics-processor\"\nEVENT_RULE_NAME=\"sarb-metrics-schedule\"\nCLOUDWATCH_LOG_GROUP=\"/aws/lambda/sarb-metrics-processor\"\nS3_FOLDER=\"sarb-metrics\"\nROLE_NAME=\"fred-daily-update-role\"  # Using the same role as FRED deployment\n\n# Asset descriptions\nLAMBDA_DESCRIPTION=\"SARB metrics processor - Fetches and transforms data from SARB API, stores in S3\"\nEVENT_RULE_DESCRIPTION=\"Triggers SARB metrics processor daily at midnight UTC\"\nCLOUDWATCH_DESCRIPTION=\"Logs for SARB metrics processor Lambda function\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Get AWS account ID\nAWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\necho -e \"${YELLOW}Using AWS Account ID: $AWS_ACCOUNT_ID${NC}\"\n\necho -e \"${YELLOW}Starting SARB metrics deployment...${NC}\"\n\n# Create a temporary directory for packaging\nTEMP_DIR=$(mktemp -d)\necho -e \"${YELLOW}Created temporary directory: $TEMP_DIR${NC}\"\n\n# Copy required files to temporary directory\ncp seed_sarb.py transform_sarb.py requirements.txt \"$TEMP_DIR/\"\n\n# Install dependencies in temporary directory\ncd \"$TEMP_DIR\"\necho -e \"${YELLOW}Installing dependencies...${NC}\"\npip install -r requirements.txt -t .\n\n# Create deployment package\necho -e \"${YELLOW}Creating deployment package...${NC}\"\nzip -r ../$ZIP_FILE .\n\n# Clean up temporary directory\ncd ..\nrm -rf \"$TEMP_DIR\"\n\n# Create or update CloudWatch log group with description\necho -e \"${YELLOW}Setting up CloudWatch log group...${NC}\"\naws logs create-log-group \\\n    --log-group-name $CLOUDWATCH_LOG_GROUP \\\n    --region $REGION \\\n    --tags Key=Description,Value=\"$CLOUDWATCH_DESCRIPTION\" \\\n    || true\n\n# Deploy Lambda function\necho -e \"${YELLOW}Deploying Lambda function...${NC}\"\nif aws lambda get-function --function-name $LAMBDA_FUNCTION_NAME 2>/dev/null; then\n    echo \"Updating existing function...\"\n    aws lambda update-function-code \\\n        --function-name $LAMBDA_FUNCTION_NAME \\\n        --zip-file \"fileb://$ZIP_FILE\" \\\n        --region $REGION\nelse\n    echo \"Creating new function...\"\n    aws lambda create-function \\\n        --function-name $LAMBDA_FUNCTION_NAME \\\n        --runtime python3.9 \\\n        --handler seed_sarb.main \\\n        --role \"arn:aws:iam::${AWS_ACCOUNT_ID}:role/${ROLE_NAME}\" \\\n        --zip-file \"fileb://$ZIP_FILE\" \\\n        --timeout 900 \\\n        --memory-size 256 \\\n        --description \"$LAMBDA_DESCRIPTION\" \\\n        --environment Variables=\"{S3_BUCKET=$BUCKET_NAME,S3_FOLDER=$S3_FOLDER}\" \\\n        --region $REGION\nfi\n\n# Wait for function update to complete\necho -e \"${YELLOW}Waiting for function update to complete...${NC}\"\nwhile true; do\n    STATUS=$(aws lambda get-function --function-name $LAMBDA_FUNCTION_NAME --query 'Configuration.State' --output text)\n    if [ \"$STATUS\" = \"Active\" ]; then\n        break\n    fi\n    echo \"Function status: $STATUS\"\n    sleep 5\ndone\n\n# Update function configuration to set timeout\necho -e \"${YELLOW}Updating function configuration...${NC}\"\naws lambda update-function-configuration \\\n    --function-name $LAMBDA_FUNCTION_NAME \\\n    --timeout 900 \\\n    --region $REGION\n\n# Wait for configuration update to complete\necho -e \"${YELLOW}Waiting for configuration update to complete...${NC}\"\nwhile true; do\n    STATUS=$(aws lambda get-function --function-name $LAMBDA_FUNCTION_NAME --query 'Configuration.State' --output text)\n    if [ \"$STATUS\" = \"Active\" ]; then\n        break\n    fi\n    echo \"Function status: $STATUS\"\n    sleep 5\ndone\n\n# Create or update EventBridge rule with description\necho -e \"${YELLOW}Setting up EventBridge rule...${NC}\"\naws events put-rule \\\n    --name $EVENT_RULE_NAME \\\n    --description \"$EVENT_RULE_DESCRIPTION\" \\\n    --schedule-expression \"cron(0 0 * * ? *)\" \\\n    --state ENABLED \\\n    --region $REGION \\\n    || aws events put-targets \\\n        --rule $EVENT_RULE_NAME \\\n        --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:$REGION:$AWS_ACCOUNT_ID:function:$LAMBDA_FUNCTION_NAME\" \\\n        --region $REGION\n\n# Add Lambda permission for EventBridge\necho -e \"${YELLOW}Adding Lambda permission for EventBridge...${NC}\"\naws lambda add-permission \\\n    --function-name $LAMBDA_FUNCTION_NAME \\\n    --statement-id EventBridgeInvokeFunction \\\n    --action lambda:InvokeFunction \\\n    --principal events.amazonaws.com \\\n    --source-arn \"arn:aws:events:$REGION:$AWS_ACCOUNT_ID:rule/$EVENT_RULE_NAME\" \\\n    --region $REGION || true\n\n# Test the Lambda function\necho -e \"${YELLOW}Testing Lambda function...${NC}\"\naws lambda invoke \\\n    --function-name $LAMBDA_FUNCTION_NAME \\\n    --payload '{}' \\\n    response.json \\\n    --region $REGION\n\n# Wait for Lambda invocation to complete (check response.json)\necho -e \"${YELLOW}Waiting for Lambda function to complete...${NC}\"\nwhile true; do\n    if [ -f response.json ]; then\n        STATUS=$(cat response.json | jq -r '.statusCode')\n        if [ \"$STATUS\" = \"200\" ]; then\n            break\n        fi\n    fi\n    sleep 5\ndone\n\n# Wait a moment for logs to be available\nsleep 10\n\n# Get the latest log stream\necho -e \"${YELLOW}Retrieving Lambda logs...${NC}\"\nLOG_STREAM=$(aws logs describe-log-streams \\\n    --log-group-name $CLOUDWATCH_LOG_GROUP \\\n    --order-by LastEventTime \\\n    --descending \\\n    --limit 1 \\\n    --query 'logStreams[0].logStreamName' \\\n    --output text)\n\nif [ \"$LOG_STREAM\" != \"None\" ]; then\n    echo -e \"${YELLOW}Latest log stream: $LOG_STREAM${NC}\"\n    aws logs get-log-events \\\n        --log-group-name $CLOUDWATCH_LOG_GROUP \\\n        --log-stream-name \"$LOG_STREAM\" \\\n        --query 'events[*].[timestamp,message]' \\\n        --output text\nelse\n    echo -e \"${RED}No log streams found${NC}\"\nfi\n\n# Wait a moment for S3 to be updated\nsleep 10\n\n# Check if files were created in S3\necho -e \"${YELLOW}Verifying S3 output...${NC}\"\nS3_COUNT=$(aws s3 ls s3://$BUCKET_NAME/$S3_FOLDER/ | wc -l)\nif [ $S3_COUNT -gt 0 ]; then\n    echo -e \"${GREEN}Found $S3_COUNT files in s3://$BUCKET_NAME/$S3_FOLDER/${NC}\"\n\n    # Check the structure of a sample file\n    SAMPLE_FILE=$(aws s3 ls s3://$BUCKET_NAME/$S3_FOLDER/ | head -n 1 | awk '{print $4}')\n    aws s3 cp \"s3://$BUCKET_NAME/$S3_FOLDER/$SAMPLE_FILE\" sample.json\n    echo -e \"${YELLOW}Sample file structure:${NC}\"\n    cat sample.json | jq '.'\n    rm sample.json\nelse\n    echo -e \"${RED}No files found in s3://$BUCKET_NAME/$S3_FOLDER/${NC}\"\nfi\n\n# Clean up\necho -e \"${YELLOW}Cleaning up...${NC}\"\nrm $ZIP_FILE response.json\n\necho -e \"${GREEN}SARB metrics deployment completed successfully!${NC}\"\necho -e \"${YELLOW}Lambda function: $LAMBDA_FUNCTION_NAME${NC}\"\necho -e \"${YELLOW}EventBridge rule: $EVENT_RULE_NAME${NC}\"\necho -e \"${YELLOW}CloudWatch log group: $CLOUDWATCH_LOG_GROUP${NC}\"\necho -e \"${YELLOW}S3 bucket: s3://$BUCKET_NAME/$S3_FOLDER${NC}\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/indicators/sarb/deploy_sarb.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\nset -e\necho \"Starting orchestration...\"\necho \"Running redeploy2.sh...\"\nREDEPLOY2_OUTPUT=$(./redeploy2.sh)\necho \"redeploy2.sh output:\"\necho \"$REDEPLOY2_OUTPUT\"\nJOB_RUN_ID=$(echo \"$REDEPLOY2_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID\" ] || [ \"$JOB_RUN_ID\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy2.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETLJob JobRunId: $JOB_RUN_ID\"\necho \"Waiting for KnowledgeBaseETLJob to complete...\"\nwhile true; do\n  STATUS=$(aws glue get-job-run --job-name KnowledgeBaseETLJob --run-id \"$JOB_RUN_ID\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS\"\n  if [ \"$STATUS\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETLJob succeeded.\"\n    break\n  elif [[ \"$STATUS\" == \"FAILED\" || \"$STATUS\" == \"TIMEOUT\" || \"$STATUS\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETLJob ended with terminal state: $STATUS\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy3.sh...\"\nREDEPLOY3_OUTPUT=$(./redeploy3.sh)\necho \"redeploy3.sh output:\"\necho \"$REDEPLOY3_OUTPUT\"\nJOB_RUN_ID2=$(echo \"$REDEPLOY3_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID2\" ] || [ \"$JOB_RUN_ID2\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy3.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETL2ndChanceJob JobRunId: $JOB_RUN_ID2\"\necho \"Waiting for KnowledgeBaseETL2ndChanceJob to complete...\"\nwhile true; do\n  STATUS2=$(aws glue get-job-run --job-name KnowledgeBaseETL2ndChanceJob --run-id \"$JOB_RUN_ID2\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS2\"\n  if [ \"$STATUS2\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETL2ndChanceJob succeeded.\"\n    break\n  elif [[ \"$STATUS2\" == \"FAILED\" || \"$STATUS2\" == \"TIMEOUT\" || \"$STATUS2\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETL2ndChanceJob ended with terminal state: $STATUS2\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy4.sh...\"\n./redeploy4.sh\necho \"Orchestration complete.\"\necho \"Shutting down the instance now...\"\nsudo shutdown -h now\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/orchestrator.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# redeploy2.sh\n# This script uploads the updated etl-s3.py file to S3,\n# updates the Glue job configuration for \"KnowledgeBaseETLJob\",\n# and then starts a new job run immediately.\n#\n# Usage: ./redeploy2.sh\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - The updated etl-s3.py file is present in the glue directory.\n# - The Glue job \"KnowledgeBaseETLJob\" already exists.\n# - IAM role \"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\" has necessary permissions.\n#\n# Environment:\n# - S3 Bucket: policy-database\n# - Script S3 Location: s3://policy-database/etl/etl-s3.py\n# - Temp Directory: s3://policy-database/temp/\n# - Region: us-east-1\n\nset -e  # Exit immediately if any command fails\n\n# Variables\nJOB_NAME=\"KnowledgeBaseETLJob\"\nSCRIPT_LOCAL=\"../glue/etl-s3.py\"\nSCRIPT_S3=\"s3://policy-database/etl/etl-s3.py\"\nTEMP_DIR=\"s3://policy-database/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nREGION=\"us-east-1\"\n\necho \"Uploading updated script ($SCRIPT_LOCAL) to S3 ($SCRIPT_S3)...\"\naws s3 cp \"$SCRIPT_LOCAL\" \"$SCRIPT_S3\" --region \"$REGION\"\n\necho \"Updating Glue job configuration for $JOB_NAME...\"\naws glue update-job \\\n  --job-name \"$JOB_NAME\" \\\n  --job-update '{\n    \"Role\": \"'\"$ROLE\"'\",\n    \"Command\": {\n      \"Name\": \"glueetl\",\n      \"ScriptLocation\": \"'\"$SCRIPT_S3\"'\",\n      \"PythonVersion\": \"3\"\n    },\n    \"DefaultArguments\": {\n      \"--TempDir\": \"'\"$TEMP_DIR\"'\",\n      \"--job-language\": \"python\",\n      \"--additional-python-modules\": \"PyPDF2==3.0.1,pycryptodome\"\n    },\n    \"MaxRetries\": 0,\n    \"Timeout\": 2880,\n    \"MaxCapacity\": 2.0,\n    \"GlueVersion\": \"2.0\"\n  }' \\\n  --region \"$REGION\"\n\necho \"Starting a new run of the Glue job $JOB_NAME...\"\nJOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$JOB_NAME\" --region \"$REGION\")\necho \"Job run started:\"\necho \"$JOB_RUN_OUTPUT\"\n\n# CHANGELOG:\n# 1. Defined variables for job name, script location, temp directory, IAM role, and region.\n# 2. Uploaded the updated etl-s3.py file from the glue directory to S3.\n# 3. Updated the existing Glue job \"KnowledgeBaseETLJob\" via aws glue update-job:\n#    - Set the GlueVersion to \"2.0\".\n#    - Removed any deprecated parameters and used --additional-python-modules to install PyPDF2.\n# 4. Immediately started a new Glue job run with aws glue start-job-run.\n# 5. Detailed inline comments and changelog are provided for clarity and transparency.\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/redeploy2.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# setup.sh\n# This script serves as the single, comprehensive source of truth for the initial\n# infrastructure orchestration and setup for the Knowledge Base ETL system.\n# It creates all necessary AWS resources for the ETL process.\n\nset -e\n\n# Configuration Variables\nREGION=\"us-east-1\"\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nBUCKET_NAME=\"policy-database\"\nLOG_GROUP=\"/aws/etl/orchestration\"\n\n# IAM Role Names\nINSTANCE_ROLE_NAME=\"ETLInstanceRole\"\nINSTANCE_PROFILE_NAME=\"ETLInstanceProfile\"\nEVENTBRIDGE_ROLE_NAME=\"EventBridgeSSMRole\"\nLAMBDA_ROLE_NAME=\"StartEC2LambdaRole\"\nGLUE_ROLE_NAME=\"AWSGluePolicyDatabaseRole\"\n\n# Lambda function configuration\nLAMBDA_FUNCTION_NAME=\"StartEC2InstanceFunction\"\nETL_LAMBDA_NAME=\"etl-orchestration-etl\"\n\n# EC2 Instance configuration\nAMI_ID=\"ami-0c2b8ca1dad447f8a\"  # Amazon Linux 2 in us-east-1\nINSTANCE_TYPE=\"t2.micro\"\nSECURITY_GROUP_NAME=\"ETLInstanceSG\"\n\n# EventBridge rules and schedule\nCRON_EXPRESSION=\"cron(0 2 * * ? *)\"  # Daily at 2:00 AM UTC\nRULE_INSTANCE_STATE=\"InstanceRunningRule\"\n\n# Glue Job Names\nMAIN_JOB_NAME=\"KnowledgeBaseETLJob\"\nSECOND_CHANCE_JOB_NAME=\"KnowledgeBaseETL2ndChanceJob\"\nREHOME_JOB_NAME=\"KnowledgeBaseETLRehomeJob\"\n\n# Function to log messages with colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date '+%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date '+%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\n# Utility function to check if a resource exists\nresource_exists() {\n  TYPE=\"$1\"\n  NAME=\"$2\"\n  case \"$TYPE\" in\n    role)\n      if aws iam get-role --role-name \"$NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n        return 0\n      fi ;;\n    instance-profile)\n      if aws iam get-instance-profile --instance-profile-name \"$NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n        return 0\n      fi ;;\n    lambda)\n      if aws lambda get-function --function-name \"$NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n        return 0\n      fi ;;\n    glue-job)\n      if aws glue get-job --job-name \"$NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n        return 0\n      fi ;;\n    *)\n      return 1 ;;\n  esac\n  return 1\n}\n\n# Function to wait for IAM role propagation\nwait_for_propagation() {\n  DELAY=${1:-10}\n  log \"Waiting for $DELAY seconds for IAM role propagation...\"\n  sleep \"$DELAY\"\n}\n\n# Main setup starts here\nlog \"Starting Knowledge Base ETL infrastructure setup...\"\n\n# Create S3 bucket if it doesn't exist\nlog \"Checking for S3 bucket $BUCKET_NAME...\"\nif ! aws s3api head-bucket --bucket \"$BUCKET_NAME\" 2>/dev/null; then\n  log \"Creating S3 bucket $BUCKET_NAME...\"\n  aws s3api create-bucket --bucket \"$BUCKET_NAME\" --region \"$REGION\"\nelse\n  log \"S3 bucket $BUCKET_NAME already exists.\"\nfi\n\n# Create CloudWatch Log Group\nlog \"Checking for CloudWatch Log Group $LOG_GROUP...\"\nif aws logs describe-log-groups --log-group-name-prefix \"$LOG_GROUP\" --region \"$REGION\" | grep -q \"$LOG_GROUP\"; then\n  log \"Log group $LOG_GROUP already exists.\"\nelse\n  log \"Creating log group $LOG_GROUP...\"\n  aws logs create-log-group --log-group-name \"$LOG_GROUP\" --region \"$REGION\"\nfi\n\n# Create IAM role for Glue\nlog \"Creating IAM role for Glue jobs ($GLUE_ROLE_NAME)...\"\nif resource_exists role \"$GLUE_ROLE_NAME\"; then\n  log \"IAM role $GLUE_ROLE_NAME already exists.\"\nelse\n  # Create Glue trust policy file\n  cat > glue-trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"glue.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  # Create Glue role\n  aws iam create-role --role-name \"$GLUE_ROLE_NAME\" --assume-role-policy-document file://glue-trust-policy.json --region \"$REGION\"\n\n  # Create and attach S3 policy for Glue\n  cat > glue-s3-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:*\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::$BUCKET_NAME\",\n        \"arn:aws:s3:::$BUCKET_NAME/*\"\n      ]\n    }\n  ]\n}\nEOF\n\n  aws iam put-role-policy --role-name \"$GLUE_ROLE_NAME\" --policy-name \"GlueS3Policy\" --policy-document file://glue-s3-policy.json --region \"$REGION\"\n\n  # Attach AWS managed policies for Glue\n  aws iam attach-role-policy --role-name \"$GLUE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole\" --region \"$REGION\"\n  aws iam attach-role-policy --role-name \"$GLUE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/CloudWatchLogsFullAccess\" --region \"$REGION\"\nfi\n\n# Add CloudWatch Logs access for the Glue role\nlog \"Adding CloudWatch Logs access to $GLUE_ROLE_NAME...\"\ncat > glue-cloudwatch-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"logs:FilterLogEvents\",\n        \"logs:DescribeLogStreams\",\n        \"logs:GetLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:$REGION:$ACCOUNT_ID:log-group:/aws-glue/jobs/output:*\"\n    }\n  ]\n}\nEOF\n\naws iam put-role-policy --role-name \"$GLUE_ROLE_NAME\" --policy-name \"GlueCloudWatchLogAccessPolicy\" --policy-document file://glue-cloudwatch-policy.json --region \"$REGION\"\n\n# Create IAM role for EC2 instance\nlog \"Creating IAM role for EC2 instance ($INSTANCE_ROLE_NAME)...\"\nif resource_exists role \"$INSTANCE_ROLE_NAME\"; then\n  log \"IAM role $INSTANCE_ROLE_NAME already exists.\"\nelse\n  # Create EC2 trust policy file\n  cat > ec2-trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  # Create EC2 role\n  aws iam create-role --role-name \"$INSTANCE_ROLE_NAME\" --assume-role-policy-document file://ec2-trust-policy.json --region \"$REGION\"\n\n  # Attach AWS managed policies for EC2 instance\n  aws iam attach-role-policy --role-name \"$INSTANCE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\" --region \"$REGION\"\n  aws iam attach-role-policy --role-name \"$INSTANCE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\" --region \"$REGION\"\n  aws iam attach-role-policy --role-name \"$INSTANCE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/AWSGlueConsoleFullAccess\" --region \"$REGION\"\n  aws iam attach-role-policy --role-name \"$INSTANCE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy\" --region \"$REGION\"\nfi\n\n# Create instance profile and attach role\nlog \"Creating instance profile $INSTANCE_PROFILE_NAME...\"\nif resource_exists instance-profile \"$INSTANCE_PROFILE_NAME\"; then\n  log \"Instance profile $INSTANCE_PROFILE_NAME already exists.\"\nelse\n  aws iam create-instance-profile --instance-profile-name \"$INSTANCE_PROFILE_NAME\" --region \"$REGION\"\nfi\n\n# Check if role is already attached to instance profile\nEXISTING_ROLE=$(aws iam get-instance-profile --instance-profile-name \"$INSTANCE_PROFILE_NAME\" --region \"$REGION\" --query 'InstanceProfile.Roles[0].RoleName' --output text 2>/dev/null || echo \"None\")\nif [ \"$EXISTING_ROLE\" = \"$INSTANCE_ROLE_NAME\" ]; then\n  log \"Role $INSTANCE_ROLE_NAME already attached to instance profile $INSTANCE_PROFILE_NAME.\"\nelse\n  log \"Attaching role $INSTANCE_ROLE_NAME to instance profile $INSTANCE_PROFILE_NAME...\"\n  aws iam add-role-to-instance-profile --instance-profile-name \"$INSTANCE_PROFILE_NAME\" --role-name \"$INSTANCE_ROLE_NAME\" --region \"$REGION\"\nfi\n\nwait_for_propagation 10\n\n# Create security group for EC2 instance\nlog \"Creating security group for EC2 instance...\"\nDEFAULT_VPC_ID=$(aws ec2 describe-vpcs --filters Name=isDefault,Values=true --query \"Vpcs[0].VpcId\" --output text --region \"$REGION\")\nlog \"Default VPC ID: $DEFAULT_VPC_ID\"\n\nSECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=group-name,Values=$SECURITY_GROUP_NAME\" \"Name=vpc-id,Values=$DEFAULT_VPC_ID\" --query \"SecurityGroups[0].GroupId\" --output text --region \"$REGION\" 2>/dev/null || echo \"None\")\nif [ \"$SECURITY_GROUP_ID\" = \"None\" ] || [ -z \"$SECURITY_GROUP_ID\" ]; then\n  log \"Creating security group $SECURITY_GROUP_NAME...\"\n  SECURITY_GROUP_ID=$(aws ec2 create-security-group --group-name \"$SECURITY_GROUP_NAME\" --description \"Security group for ETL instance\" --vpc-id \"$DEFAULT_VPC_ID\" --query 'GroupId' --output text --region \"$REGION\")\n  log \"Security Group ID: $SECURITY_GROUP_ID\"\n  aws ec2 authorize-security-group-ingress --group-id \"$SECURITY_GROUP_ID\" --protocol tcp --port 22 --cidr 0.0.0.0/0 --region \"$REGION\"\nelse\n  log \"Security group $SECURITY_GROUP_NAME already exists with ID $SECURITY_GROUP_ID.\"\nfi\n\n# Create IAM role for EventBridge\nlog \"Creating IAM role for EventBridge ($EVENTBRIDGE_ROLE_NAME)...\"\nif resource_exists role \"$EVENTBRIDGE_ROLE_NAME\"; then\n  log \"IAM role $EVENTBRIDGE_ROLE_NAME already exists.\"\nelse\n  # Create EventBridge trust policy file\n  cat > eventbridge-trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"events.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  # Create EventBridge role\n  aws iam create-role --role-name \"$EVENTBRIDGE_ROLE_NAME\" --assume-role-policy-document file://eventbridge-trust-policy.json --region \"$REGION\"\n\n  # Create and attach policy for SSM commands\n  cat > eventbridge-ssm-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"ssm:SendCommand\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n\n  aws iam put-role-policy --role-name \"$EVENTBRIDGE_ROLE_NAME\" --policy-name \"SendCommandPolicy\" --policy-document file://eventbridge-ssm-policy.json --region \"$REGION\"\nfi\n\n# Create IAM role for Lambda function\nlog \"Creating IAM role for Lambda function ($LAMBDA_ROLE_NAME)...\"\nif resource_exists role \"$LAMBDA_ROLE_NAME\"; then\n  log \"IAM role $LAMBDA_ROLE_NAME already exists.\"\nelse\n  # Create Lambda trust policy file\n  cat > lambda-trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  # Create Lambda role\n  aws iam create-role --role-name \"$LAMBDA_ROLE_NAME\" --assume-role-policy-document file://lambda-trust-policy.json --region \"$REGION\"\n\n  # Attach AWS managed policies for Lambda\n  aws iam attach-role-policy --role-name \"$LAMBDA_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\" --region \"$REGION\"\nfi\n\nwait_for_propagation 10\n\n# Define EC2 user data script\nlog \"Creating EC2 user data script...\"\nUSER_DATA=$(cat <<'EOF'\n#!/bin/bash\n# Redirect all output to /var/log/orchestration.log for debugging\ntouch /var/log/orchestration.log\nchmod 644 /var/log/orchestration.log\nexec > >(tee -a /var/log/orchestration.log) 2>&1\nset -x\n# Update packages and install aws-cli, jq, and the CloudWatch Agent.\nyum update -y\nyum install -y aws-cli jq amazon-cloudwatch-agent\n# Configure CloudWatch Agent.\ncat <<'CWCONFIG' > /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json\n{\n  \"logs\": {\n    \"logs_collected\": {\n      \"files\": {\n        \"collect_list\": [\n          {\n            \"file_path\": \"/var/log/orchestration.log\",\n            \"log_group_name\": \"/aws/etl/orchestration\",\n            \"log_stream_name\": \"{instance_id}\"\n          }\n        ]\n      }\n    }\n  }\n}\nCWCONFIG\n/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json -s\n# Change to ec2-user home directory.\ncd /home/ec2-user\n# Download redeploy scripts from S3.\naws s3 cp s3://policy-database/etl/scripts/redeploy2.sh ./redeploy2.sh --region us-east-1\naws s3 cp s3://policy-database/etl/scripts/redeploy3.sh ./redeploy3.sh --region us-east-1\naws s3 cp s3://policy-database/etl/scripts/redeploy4.sh ./redeploy4.sh --region us-east-1\nchmod +x redeploy2.sh redeploy3.sh redeploy4.sh\n# Create orchestrator.sh.\ncat <<'EOS' > orchestrator.sh\n#!/bin/bash\nset -e\necho \"Starting orchestration...\"\necho \"Running redeploy2.sh...\"\nREDEPLOY2_OUTPUT=$(./redeploy2.sh)\necho \"redeploy2.sh output:\"\necho \"$REDEPLOY2_OUTPUT\"\nJOB_RUN_ID=$(echo \"$REDEPLOY2_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID\" ] || [ \"$JOB_RUN_ID\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy2.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETLJob JobRunId: $JOB_RUN_ID\"\necho \"Waiting for KnowledgeBaseETLJob to complete...\"\nwhile true; do\n  STATUS=$(aws glue get-job-run --job-name KnowledgeBaseETLJob --run-id \"$JOB_RUN_ID\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS\"\n  if [ \"$STATUS\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETLJob succeeded.\"\n    break\n  elif [[ \"$STATUS\" == \"FAILED\" || \"$STATUS\" == \"TIMEOUT\" || \"$STATUS\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETLJob ended with terminal state: $STATUS\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy3.sh...\"\nREDEPLOY3_OUTPUT=$(./redeploy3.sh)\necho \"redeploy3.sh output:\"\necho \"$REDEPLOY3_OUTPUT\"\nJOB_RUN_ID2=$(echo \"$REDEPLOY3_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID2\" ] || [ \"$JOB_RUN_ID2\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy3.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETL2ndChanceJob JobRunId: $JOB_RUN_ID2\"\necho \"Waiting for KnowledgeBaseETL2ndChanceJob to complete...\"\nwhile true; do\n  STATUS2=$(aws glue get-job-run --job-name KnowledgeBaseETL2ndChanceJob --run-id \"$JOB_RUN_ID2\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS2\"\n  if [ \"$STATUS2\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETL2ndChanceJob succeeded.\"\n    break\n  elif [[ \"$STATUS2\" == \"FAILED\" || \"$STATUS2\" == \"TIMEOUT\" || \"$STATUS2\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETL2ndChanceJob ended with terminal state: $STATUS2\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy4.sh...\"\n./redeploy4.sh\necho \"Orchestration complete.\"\necho \"Shutting down the instance now...\"\nsudo shutdown -h now\nEOS\nchmod +x orchestrator.sh\necho \"User data initialization complete. orchestrator.sh and redeploy scripts are ready.\"\nEOF\n\n# Launch EC2 instance\nlog \"Launching EC2 instance...\"\nINSTANCE_ID=$(aws ec2 run-instances \\\n  --image-id \"$AMI_ID\" \\\n  --instance-type \"$INSTANCE_TYPE\" \\\n  --iam-instance-profile Name=\"$INSTANCE_PROFILE_NAME\" \\\n  --security-group-ids \"$SECURITY_GROUP_ID\" \\\n  --user-data \"$USER_DATA\" \\\n  --query 'Instances[0].InstanceId' --output text --region \"$REGION\")\n\nlog \"Launched EC2 Instance ID: $INSTANCE_ID\"\naws ec2 create-tags --resources \"$INSTANCE_ID\" --tags Key=Name,Value=ETL-Orchestration-Instance --region \"$REGION\"\n\n# Create Lambda function for starting the EC2 instance\nlog \"Creating Lambda function code...\"\nmkdir -p lambda_code\ncat > lambda_code/start_instance.py <<EOF\nimport boto3\nimport os\n\ndef lambda_handler(event, context):\n    instance_id = os.environ.get('INSTANCE_ID')\n    if not instance_id:\n        return {\"error\": \"INSTANCE_ID environment variable not set\"}\n    ec2 = boto3.client('ec2', region_name=os.environ.get('AWS_REGION', 'us-east-1'))\n    response = ec2.start_instances(InstanceIds=[instance_id])\n    return response\nEOF\n\ncd lambda_code\nzip -q start_instance.zip start_instance.py\ncd ..\n\nlog \"Creating Lambda function $LAMBDA_FUNCTION_NAME...\"\nif resource_exists lambda \"$LAMBDA_FUNCTION_NAME\"; then\n  log \"Lambda function $LAMBDA_FUNCTION_NAME already exists.\"\nelse\n  LAMBDA_ROLE_ARN=$(aws iam get-role --role-name \"$LAMBDA_ROLE_NAME\" --region \"$REGION\" --query 'Role.Arn' --output text)\n  aws lambda create-function \\\n    --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n    --runtime python3.8 \\\n    --role \"$LAMBDA_ROLE_ARN\" \\\n    --handler start_instance.lambda_handler \\\n    --zip-file fileb://lambda_code/start_instance.zip \\\n    --region \"$REGION\"\nfi\n\n# Update Lambda environment with instance ID\nlog \"Updating Lambda environment variables...\"\naws lambda update-function-configuration \\\n  --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n  --environment \"Variables={INSTANCE_ID=${INSTANCE_ID}}\" \\\n  --region \"$REGION\"\n\n# Create Lambda permissions for EC2 instance\ncat > lambda-ec2-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"ec2:StartInstances\",\n      \"Resource\": \"arn:aws:ec2:${REGION}:${ACCOUNT_ID}:instance/${INSTANCE_ID}\"\n    }\n  ]\n}\nEOF\n\naws iam put-role-policy \\\n  --role-name \"$LAMBDA_ROLE_NAME\" \\\n  --policy-name \"StartInstancePolicy\" \\\n  --policy-document file://lambda-ec2-policy.json \\\n  --region \"$REGION\"\n\n# Create EventBridge scheduled rule for starting the instance\nlog \"Creating EventBridge scheduled rule...\"\nSCHEDULED_RULE_NAME=\"StartInstanceScheduleRule\"\nif aws events describe-rule --name \"$SCHEDULED_RULE_NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n  log \"EventBridge rule $SCHEDULED_RULE_NAME already exists.\"\nelse\n  aws events put-rule \\\n    --name \"$SCHEDULED_RULE_NAME\" \\\n    --schedule-expression \"$CRON_EXPRESSION\" \\\n    --region \"$REGION\"\nfi\n\n# Add Lambda as target for the scheduled rule\nLAMBDA_FUNCTION_ARN=$(aws lambda get-function --function-name \"$LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.FunctionArn' --output text)\naws events put-targets \\\n  --rule \"$SCHEDULED_RULE_NAME\" \\\n  --targets \"Id=1,Arn=$LAMBDA_FUNCTION_ARN\" \\\n  --region \"$REGION\"\n\n# Add permission for EventBridge to invoke Lambda\naws lambda add-permission \\\n  --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n  --statement-id \"EventBridgeInvoke\" \\\n  --action \"lambda:InvokeFunction\" \\\n  --principal events.amazonaws.com \\\n  --source-arn \"$(aws events describe-rule --name $SCHEDULED_RULE_NAME --region $REGION --query 'Arn' --output text)\" \\\n  --region \"$REGION\"\n\n# Create EventBridge rule for instance state changes\nlog \"Creating EventBridge rule for instance state changes...\"\ncat > instance-state-pattern.json <<EOF\n{\n  \"source\": [\"aws.ec2\"],\n  \"detail-type\": [\"EC2 Instance State-change Notification\"],\n  \"detail\": {\n    \"instance-id\": [\"$INSTANCE_ID\"],\n    \"state\": [\"running\"]\n  }\n}\nEOF\n\nif aws events describe-rule --name \"$RULE_INSTANCE_STATE\" --region \"$REGION\" >/dev/null 2>&1; then\n  log \"EventBridge rule $RULE_INSTANCE_STATE already exists.\"\nelse\n  aws events put-rule \\\n    --name \"$RULE_INSTANCE_STATE\" \\\n    --event-pattern file://instance-state-pattern.json \\\n    --region \"$REGION\"\nfi\n\n# Create SSM command input for EventBridge rule\ncat > ssm-input.json <<EOF\n{\n  \"InstanceIds\": [\"$INSTANCE_ID\"],\n  \"DocumentName\": \"AWS-RunShellScript\",\n  \"Parameters\": {\n    \"commands\": [\"/home/ec2-user/orchestrator.sh\"]\n  }\n}\nEOF\n\n# Add SSM command target to EventBridge rule\nEB_ROLE_ARN=$(aws iam get-role --role-name \"$EVENTBRIDGE_ROLE_NAME\" --region \"$REGION\" --query 'Role.Arn' --output text)\naws events put-targets \\\n  --rule \"$RULE_INSTANCE_STATE\" \\\n  --targets \"Id=1,Arn=arn:aws:ssm:${REGION}:${ACCOUNT_ID}:document/AWS-RunShellScript,RoleArn=$EB_ROLE_ARN,Input=$(cat ssm-input.json | jq -c .)\" \\\n  --region \"$REGION\"\n\n# Clean up temporary files\nlog \"Cleaning up temporary files...\"\nrm -f glue-trust-policy.json glue-s3-policy.json glue-cloudwatch-policy.json\nrm -f ec2-trust-policy.json eventbridge-trust-policy.json eventbridge-ssm-policy.json\nrm -f lambda-trust-policy.json lambda-ec2-policy.json\nrm -f instance-state-pattern.json ssm-input.json\nrm -rf lambda_code\n\nlog \"Infrastructure setup completed successfully. Now you can run the individual redeploy scripts to deploy and update the ETL jobs.\"\nlog \"Next steps:\"\nlog \"1. Upload your ETL scripts to S3 bucket: $BUCKET_NAME\"\nlog \"2. Run the redeploy scripts to create and configure Glue jobs:\"\nlog \"   - ./scripts/redeploy2.sh for the main ETL job\"\nlog \"   - ./scripts/redeploy3.sh for the 2nd chance ETL job\"\nlog \"   - ./scripts/redeploy4.sh for the rehoming ETL job\"\nlog \"3. The EC2 instance with ID $INSTANCE_ID has been created and will automatically:\"\nlog \"   - Download the redeploy scripts from S3\"\nlog \"   - Create and run the orchestrator.sh script when started\"\nlog \"   - Start daily at $CRON_EXPRESSION via the EventBridge rule\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/setup.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# redeploy4.sh\n# This script uploads the rehoming_etl.py file to S3,\n# creates/updates the Glue job configuration for \"KnowledgeBaseETLRehomeJob\",\n# updates the IAM role to include permissions to query CloudWatch logs (logs:FilterLogEvents,\n# logs:DescribeLogStreams, and logs:GetLogEvents),\n# and then starts a new job run immediately.\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - The updated rehoming_etl.py file is present in the glue directory.\n# - The Glue job \"KnowledgeBaseETLRehomeJob\" will be created if it does not exist.\n# - IAM role \"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\" has permissions\n#   to update its inline policies.\n#\n# Environment:\n# - S3 Bucket: policy-database\n# - Script S3 Location: s3://policy-database/etl/rehoming_etl.py\n# - Temp Directory: s3://policy-database/temp/\n# - Region: us-east-1\n\nset -e  # Exit immediately if any command fails\n\n# Variables\nJOB_NAME=\"KnowledgeBaseETLRehomeJob\"\nSCRIPT_LOCAL=\"../glue/rehoming_etl.py\"\nSCRIPT_S3=\"s3://policy-database/etl/rehoming_etl.py\"\nTEMP_DIR=\"s3://policy-database/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nROLE_NAME=\"AWSGluePolicyDatabaseRole\"  # Extracted from the ARN\nREGION=\"us-east-1\"\n\n# Define the inline policy to add necessary CloudWatch Logs permissions.\nINLINE_POLICY_NAME=\"GlueCloudWatchLogAccessPolicy\"\nINLINE_POLICY_DOCUMENT=$(cat <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n          \"logs:FilterLogEvents\",\n          \"logs:DescribeLogStreams\",\n          \"logs:GetLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:$REGION:<ACCOUNT_ID>:log-group:/aws-glue/jobs/output:*\"\n    }\n  ]\n}\nEOF\n)\n\necho \"Uploading rehoming_etl.py to S3 ($SCRIPT_S3)...\"\naws s3 cp \"$SCRIPT_LOCAL\" \"$SCRIPT_S3\" --region \"$REGION\"\n\necho \"Updating IAM role ($ROLE_NAME) to allow CloudWatch Logs access...\"\naws iam put-role-policy \\\n  --role-name \"$ROLE_NAME\" \\\n  --policy-name \"$INLINE_POLICY_NAME\" \\\n  --policy-document \"$INLINE_POLICY_DOCUMENT\" \\\n  --region \"$REGION\"\n\n# Check if the job exists. If it does, update it; otherwise, create it.\nJOB_EXISTS=$(aws glue get-job --job-name \"$JOB_NAME\" --region \"$REGION\" 2>/dev/null || echo \"NotFound\")\nif [ \"$JOB_EXISTS\" == \"NotFound\" ]; then\n    echo \"Creating new Glue job $JOB_NAME...\"\n    aws glue create-job \\\n      --name \"$JOB_NAME\" \\\n      --role \"$ROLE\" \\\n      --command \"Name=glueetl,ScriptLocation=$SCRIPT_S3,PythonVersion=3\" \\\n      --default-arguments \"{\\\"--TempDir\\\":\\\"$TEMP_DIR\\\",\\\"--job-language\\\":\\\"python\\\",\\\"--additional-python-modules\\\":\\\"PyPDF2==3.0.1\\\"}\" \\\n      --max-retries 0 \\\n      --timeout 2880 \\\n      --max-capacity 2.0 \\\n      --glue-version \"2.0\" \\\n      --region \"$REGION\"\nelse\n    echo \"Updating existing Glue job $JOB_NAME...\"\n    aws glue update-job \\\n      --job-name \"$JOB_NAME\" \\\n      --job-update \"{\n        \\\"Role\\\": \\\"$ROLE\\\",\n        \\\"Command\\\": {\n          \\\"Name\\\": \\\"glueetl\\\",\n          \\\"ScriptLocation\\\": \\\"$SCRIPT_S3\\\",\n          \\\"PythonVersion\\\": \\\"3\\\"\n        },\n        \\\"DefaultArguments\\\": {\n          \\\"--TempDir\\\": \\\"$TEMP_DIR\\\",\n          \\\"--job-language\\\": \\\"python\\\",\n          \\\"--additional-python-modules\\\": \\\"PyPDF2==3.0.1\\\"\n        },\n        \\\"MaxRetries\\\": 0,\n        \\\"Timeout\\\": 2880,\n        \\\"MaxCapacity\\\": 2.0,\n        \\\"GlueVersion\\\": \\\"2.0\\\"\n      }\" --region \"$REGION\"\nfi\n\necho \"Starting a new run of the Glue job $JOB_NAME...\"\nJOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$JOB_NAME\" --region \"$REGION\")\necho \"Job run started:\"\necho \"$JOB_RUN_OUTPUT\"\n\n# ------------------------------------------------------------------------------\n# Changelog:\n# 1. Defined an inline policy document (GlueCloudWatchLogAccessPolicy) that grants\n#    logs:FilterLogEvents, logs:DescribeLogStreams, and logs:GetLogEvents permissions\n#    on the log group arn:aws:logs:us-east-1:<ACCOUNT_ID>:log-group:/aws-glue/jobs/output:*.\n# 2. Added a call to aws iam put-role-policy to attach the inline policy to AWSGluePolicyDatabaseRole.\n# 3. The rest of the script remains unchanged.\n# ------------------------------------------------------------------------------\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/redeploy4.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# redeploy3.sh\n# This script uploads the updated etl-s3-failed.py file to S3,\n# checks for the existence of the Glue job \"KnowledgeBaseETL2ndChanceJob\" and creates it if it doesn't exist,\n# then updates the Glue job configuration and starts a new job run.\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - The updated etl-s3-failed.py file is present in the glue directory.\n# - IAM role \"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\" exists and has necessary permissions.\n#\n# Environment:\n# - S3 Bucket: policy-database\n# - Script S3 Location: s3://policy-database/etl/etl-s3-failed.py\n# - Temp Directory: s3://policy-database/temp/\n# - Region: us-east-1\n\nset -e  # Exit immediately if any command fails\n\n# Variables\nJOB_NAME=\"KnowledgeBaseETL2ndChanceJob\"\nSCRIPT_LOCAL=\"../glue/etl-s3-failed.py\"\nSCRIPT_S3=\"s3://policy-database/etl/etl-s3-failed.py\"\nTEMP_DIR=\"s3://policy-database/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nREGION=\"us-east-1\"\nGLUE_VERSION=\"2.0\"\nMAX_CAPACITY=\"2.0\"\nTIMEOUT=\"2880\"\nADDITIONAL_MODULES=\"PyPDF2==3.0.1,pycryptodome\"\n\necho \"Uploading updated script ($SCRIPT_LOCAL) to S3 ($SCRIPT_S3)...\"\naws s3 cp \"$SCRIPT_LOCAL\" \"$SCRIPT_S3\" --region \"$REGION\"\n\necho \"Checking if Glue job $JOB_NAME exists...\"\nif aws glue get-job --job-name \"$JOB_NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n    echo \"Job exists. Updating job configuration...\"\n    aws glue update-job \\\n      --job-name \"$JOB_NAME\" \\\n      --job-update '{\n        \"Role\": \"'\"$ROLE\"'\",\n        \"Command\": {\n          \"Name\": \"glueetl\",\n          \"ScriptLocation\": \"'\"$SCRIPT_S3\"'\",\n          \"PythonVersion\": \"3\"\n        },\n        \"DefaultArguments\": {\n          \"--TempDir\": \"'\"$TEMP_DIR\"'\",\n          \"--job-language\": \"python\",\n          \"--additional-python-modules\": \"'\"$ADDITIONAL_MODULES\"'\"\n        },\n        \"MaxRetries\": 0,\n        \"Timeout\": '\"$TIMEOUT\"',\n        \"MaxCapacity\": '\"$MAX_CAPACITY\"',\n        \"GlueVersion\": \"'\"$GLUE_VERSION\"'\"\n      }' \\\n      --region \"$REGION\"\nelse\n    echo \"Job does not exist. Creating Glue job $JOB_NAME...\"\n    aws glue create-job \\\n      --name \"$JOB_NAME\" \\\n      --role \"$ROLE\" \\\n      --command \"Name=glueetl,ScriptLocation=$SCRIPT_S3,PythonVersion=3\" \\\n      --default-arguments \"{\\\"--TempDir\\\":\\\"$TEMP_DIR\\\",\\\"--job-language\\\":\\\"python\\\",\\\"--additional-python-modules\\\":\\\"$ADDITIONAL_MODULES\\\"}\" \\\n      --max-retries 0 \\\n      --timeout \"$TIMEOUT\" \\\n      --max-capacity \"$MAX_CAPACITY\" \\\n      --glue-version \"$GLUE_VERSION\" \\\n      --region \"$REGION\"\nfi\n\necho \"Starting a new run of the Glue job $JOB_NAME...\"\nJOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$JOB_NAME\" --region \"$REGION\")\necho \"Job run started:\"\necho \"$JOB_RUN_OUTPUT\"\n\n# ------------------------------------------------------------------------------\n# Changelog:\n# 1. Defined variables for the secondary job name, script location, temp directory, IAM role, region, etc.\n# 2. Uploaded etl-s3-failed.py from the glue directory to s3://policy-database/etl/etl-s3-failed.py.\n# 3. Added a check using aws glue get-job to determine if \"KnowledgeBaseETL2ndChanceJob\" exists.\n#    - If it exists, the script updates its configuration with the new script location and parameters.\n#    - If it does not exist, the script creates the Glue job with the appropriate parameters.\n# 4. Finally, the script starts a new job run for \"KnowledgeBaseETL2ndChanceJob\" and outputs the job run details.\n# ------------------------------------------------------------------------------\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/redeploy3.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\n#!/bin/bash\n\n# Configure logging\nLOG_FILE=\"etl_$(date +%Y%m%d_%H%M%S).log\"\nexec 1> >(tee -a \"$LOG_FILE\")\nexec 2> >(tee -a \"$LOG_FILE\" >&2)\n\n# Function to log messages\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\"\n}\n\n# Function to run a script with timeout\nrun_script() {\n    local script_name=$1\n    local timeout=$2\n    local start_time=$(date +%s)\n\n    log \"Starting $script_name with ${timeout}s timeout\"\n\n    # Run the script with timeout\n    timeout $timeout python3 \"$script_name\"\n    local exit_code=$?\n\n    local end_time=$(date +%s)\n    local duration=$((end_time - start_time))\n\n    if [ $exit_code -eq 124 ]; then\n        log \"ERROR: $script_name timed out after ${timeout}s\"\n        return 1\n    elif [ $exit_code -ne 0 ]; then\n        log \"ERROR: $script_name failed with exit code $exit_code\"\n        return 1\n    else\n        log \"SUCCESS: $script_name completed in ${duration}s\"\n        return 0\n    fi\n}\n\n# Main execution\nlog \"Starting ETL process\"\n\n# Run main ETL (4 hour timeout)\nif ! run_script \"../glue/etl-s3.py\" 14400; then\n    log \"Main ETL failed. Stopping process.\"\n    exit 1\nfi\n\n# Wait 1 hour before running failed ETL\nlog \"Waiting 1 hour before running failed ETL...\"\nsleep 3600\n\n# Run failed ETL (4 hour timeout)\nif ! run_script \"../glue/etl-s3-failed.py\" 14400; then\n    log \"Failed ETL failed. Stopping process.\"\n    exit 1\nfi\n\n# Wait 1 hour before running rehoming ETL\nlog \"Waiting 1 hour before running rehoming ETL...\"\nsleep 3600\n\n# Run rehoming ETL (4 hour timeout)\nif ! run_script \"../glue/rehoming_etl.py\" 14400; then\n    log \"Rehoming ETL failed. Stopping process.\"\n    exit 1\nfi\n\nlog \"All ETL processes completed successfully\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/run_etl.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# redeploy.sh\n# This script automates the redeployment of the \"etl-google-alerts\" Lambda function in us-east-1.\n# It performs the following steps:\n#   1. Installs production dependencies.\n#   2. Zips the Lambda handler file and node_modules folder.\n#   3. Updates the Lambda function code using the AWS CLI.\n#\n# Usage: ./redeploy.sh\n\nset -e  # Exit immediately if any command fails\n\n# Variables - adjust these if your file/folder names change\nFUNCTION_NAME=\"etl-google-alerts\"\nZIP_FILE=\"../lambda/etl-lambda.zip\"\nHANDLER_FILE=\"../lambda/etl-google-alerts-lambda.js\"\nNODE_MODULES_DIR=\"../node_modules\"\nREGION=\"us-east-1\"\n\necho \"Starting redeployment of Lambda function: $FUNCTION_NAME\"\n\n# 1. Install production dependencies\necho \"Installing production dependencies...\"\ncd .. && npm install --production && cd scripts\n\n# 2. Create the deployment package zip file\necho \"Creating deployment package: $ZIP_FILE\"\ncd ..\nzip -r \"lambda/etl-lambda.zip\" \"lambda/etl-google-alerts-lambda.js\" \"node_modules\"\ncd scripts\n\n# 3. Update the Lambda function code using AWS CLI\necho \"Updating Lambda function code in region $REGION...\"\naws lambda update-function-code \\\n  --function-name \"$FUNCTION_NAME\" \\\n  --zip-file fileb://\"$ZIP_FILE\" \\\n  --region \"$REGION\"\n\necho \"Redeployment complete.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/redeploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# deploy.sh\n# Comprehensive deployment script for Knowledge Base ETL system\n#\n# This script handles deployment of all components:\n#   1. Lambda Function (etl-google-alerts)\n#   2. Primary Glue Job (KnowledgeBaseETLJob) - etl-s3.py\n#   3. Second Chance Glue Job (KnowledgeBaseETL2ndChanceJob) - etl-s3-failed.py\n#   4. Rehoming Glue Job (KnowledgeBaseETLRehomeJob) - rehoming_etl.py\n#\n# Usage:\n#   ./deploy.sh [--all] [--lambda] [--primary] [--second-chance] [--rehome]\n#\n# Options:\n#   --all            Deploy all components (default if no flag is provided)\n#   --lambda         Deploy only the Lambda function (etl-google-alerts)\n#   --primary        Deploy only the primary ETL job\n#   --second-chance  Deploy only the second chance ETL job\n#   --rehome         Deploy only the rehoming ETL job\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - Script files must be present in the respective directories.\n# - IAM role with necessary permissions must exist.\n\nset -e  # Exit immediately if any command fails\n\n# Common variables\nREGION=\"us-east-1\"\nS3_BUCKET=\"policy-database\"\nTEMP_DIR=\"s3://$S3_BUCKET/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nROLE_NAME=\"AWSGluePolicyDatabaseRole\"  # Extracted from the ARN\nGLUE_VERSION=\"2.0\"\nMAX_CAPACITY=\"2.0\"\nTIMEOUT=\"2880\"\n\n# Lambda variables\nLAMBDA_FUNCTION_NAME=\"etl-google-alerts\"\nLAMBDA_ZIP_FILE=\"../lambda/etl-lambda.zip\"\nLAMBDA_HANDLER_FILE=\"../lambda/etl-google-alerts-lambda.js\"\nNODE_MODULES_DIR=\"../node_modules\"\n\n# Glue job variables\nPRIMARY_JOB_NAME=\"KnowledgeBaseETLJob\"\nPRIMARY_SCRIPT_LOCAL=\"../glue/etl-s3.py\"\nPRIMARY_SCRIPT_S3=\"s3://$S3_BUCKET/etl/etl-s3.py\"\nPRIMARY_MODULES=\"PyPDF2==3.0.1,pycryptodome\"\n\nSECOND_CHANCE_JOB_NAME=\"KnowledgeBaseETL2ndChanceJob\"\nSECOND_CHANCE_SCRIPT_LOCAL=\"../glue/etl-s3-failed.py\"\nSECOND_CHANCE_SCRIPT_S3=\"s3://$S3_BUCKET/etl/etl-s3-failed.py\"\nSECOND_CHANCE_MODULES=\"PyPDF2==3.0.1,pycryptodome\"\n\nREHOME_JOB_NAME=\"KnowledgeBaseETLRehomeJob\"\nREHOME_SCRIPT_LOCAL=\"../glue/rehoming_etl.py\"\nREHOME_SCRIPT_S3=\"s3://$S3_BUCKET/etl/rehoming_etl.py\"\nREHOME_MODULES=\"PyPDF2==3.0.1\"\n\n# CloudWatch logs inline policy document for rehoming job\nINLINE_POLICY_NAME=\"GlueCloudWatchLogAccessPolicy\"\nINLINE_POLICY_DOCUMENT=$(cat <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n          \"logs:FilterLogEvents\",\n          \"logs:DescribeLogStreams\",\n          \"logs:GetLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:$REGION:<ACCOUNT_ID>:log-group:/aws-glue/jobs/output:*\"\n    }\n  ]\n}\nEOF\n)\n\n# Function to deploy a Glue job\ndeploy_glue_job() {\n    local job_name=$1\n    local script_local=$2\n    local script_s3=$3\n    local additional_modules=$4\n    local extra_setup=$5\n\n    echo \"Uploading script $script_local to $script_s3...\"\n    aws s3 cp \"$script_local\" \"$script_s3\" --region \"$REGION\"\n\n    # Run any extra setup if provided (e.g., for rehome job IAM policy)\n    if [ -n \"$extra_setup\" ]; then\n        eval \"$extra_setup\"\n    fi\n\n    echo \"Checking if Glue job $job_name exists...\"\n    if aws glue get-job --job-name \"$job_name\" --region \"$REGION\" >/dev/null 2>&1; then\n        echo \"Job exists. Updating job configuration...\"\n        aws glue update-job \\\n          --job-name \"$job_name\" \\\n          --job-update '{\n            \"Role\": \"'\"$ROLE\"'\",\n            \"Command\": {\n              \"Name\": \"glueetl\",\n              \"ScriptLocation\": \"'\"$script_s3\"'\",\n              \"PythonVersion\": \"3\"\n            },\n            \"DefaultArguments\": {\n              \"--TempDir\": \"'\"$TEMP_DIR\"'\",\n              \"--job-language\": \"python\",\n              \"--additional-python-modules\": \"'\"$additional_modules\"'\"\n            },\n            \"MaxRetries\": 0,\n            \"Timeout\": '\"$TIMEOUT\"',\n            \"MaxCapacity\": '\"$MAX_CAPACITY\"',\n            \"GlueVersion\": \"'\"$GLUE_VERSION\"'\"\n          }' \\\n          --region \"$REGION\"\n    else\n        echo \"Job does not exist. Creating Glue job $job_name...\"\n        aws glue create-job \\\n          --name \"$job_name\" \\\n          --role \"$ROLE\" \\\n          --command \"Name=glueetl,ScriptLocation=$script_s3,PythonVersion=3\" \\\n          --default-arguments \"{\\\"--TempDir\\\":\\\"$TEMP_DIR\\\",\\\"--job-language\\\":\\\"python\\\",\\\"--additional-python-modules\\\":\\\"$additional_modules\\\"}\" \\\n          --max-retries 0 \\\n          --timeout \"$TIMEOUT\" \\\n          --max-capacity \"$MAX_CAPACITY\" \\\n          --glue-version \"$GLUE_VERSION\" \\\n          --region \"$REGION\"\n    fi\n\n    echo \"Starting a new run of the Glue job $job_name...\"\n    JOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$job_name\" --region \"$REGION\")\n    echo \"Job run started:\"\n    echo \"$JOB_RUN_OUTPUT\"\n    echo \"---------------------------------------------\"\n}\n\n# Function to deploy Lambda\ndeploy_lambda() {\n    echo \"Starting deployment of Lambda function: $LAMBDA_FUNCTION_NAME\"\n\n    # 1. Install production dependencies\n    echo \"Installing production dependencies...\"\n    (cd .. && npm install --production)\n\n    # 2. Create the deployment package zip file\n    echo \"Creating deployment package: $LAMBDA_ZIP_FILE\"\n    (cd .. && zip -r \"lambda/etl-lambda.zip\" \"lambda/etl-google-alerts-lambda.js\" \"node_modules\")\n\n    # 3. Upload the ZIP file to the same S3 location where Glue scripts are stored\n    echo \"Uploading Lambda package to S3...\"\n    aws s3 cp \"$LAMBDA_ZIP_FILE\" \"s3://$S3_BUCKET/etl/etl-lambda.zip\" --region \"$REGION\"\n\n    # 4. Update the Lambda function code using the S3 reference\n    echo \"Updating Lambda function code from S3 in region $REGION...\"\n    aws lambda update-function-code \\\n      --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n      --s3-bucket \"$S3_BUCKET\" \\\n      --s3-key \"etl/etl-lambda.zip\" \\\n      --region \"$REGION\"\n\n    echo \"Lambda deployment complete.\"\n    echo \"---------------------------------------------\"\n}\n\n# Process command-line arguments\nDEPLOY_LAMBDA=false\nDEPLOY_PRIMARY=false\nDEPLOY_SECOND_CHANCE=false\nDEPLOY_REHOME=false\n\n# Default to deploying all if no arguments provided\nif [ $# -eq 0 ]; then\n    DEPLOY_LAMBDA=true\n    DEPLOY_PRIMARY=true\n    DEPLOY_SECOND_CHANCE=true\n    DEPLOY_REHOME=true\nelse\n    while [ $# -gt 0 ]; do\n        case \"$1\" in\n            --all)\n                DEPLOY_LAMBDA=true\n                DEPLOY_PRIMARY=true\n                DEPLOY_SECOND_CHANCE=true\n                DEPLOY_REHOME=true\n                ;;\n            --lambda)\n                DEPLOY_LAMBDA=true\n                ;;\n            --primary)\n                DEPLOY_PRIMARY=true\n                ;;\n            --second-chance)\n                DEPLOY_SECOND_CHANCE=true\n                ;;\n            --rehome)\n                DEPLOY_REHOME=true\n                ;;\n            *)\n                echo \"Unknown option: $1\"\n                echo \"Usage: ./deploy.sh [--all] [--lambda] [--primary] [--second-chance] [--rehome]\"\n                exit 1\n                ;;\n        esac\n        shift\n    done\nfi\n\n# Extra setup command for rehome job (IAM policy update)\nREHOME_EXTRA_SETUP='echo \"Updating IAM role ($ROLE_NAME) to allow CloudWatch Logs access...\"; aws iam put-role-policy --role-name \"$ROLE_NAME\" --policy-name \"$INLINE_POLICY_NAME\" --policy-document \"$INLINE_POLICY_DOCUMENT\" --region \"$REGION\"'\n\n# Deploy selected components\nif [ \"$DEPLOY_LAMBDA\" = true ]; then\n    echo \"Deploying Lambda Function ($LAMBDA_FUNCTION_NAME)...\"\n    deploy_lambda\nfi\n\nif [ \"$DEPLOY_PRIMARY\" = true ]; then\n    echo \"Deploying Primary ETL Job ($PRIMARY_JOB_NAME)...\"\n    deploy_glue_job \"$PRIMARY_JOB_NAME\" \"$PRIMARY_SCRIPT_LOCAL\" \"$PRIMARY_SCRIPT_S3\" \"$PRIMARY_MODULES\"\nfi\n\nif [ \"$DEPLOY_SECOND_CHANCE\" = true ]; then\n    echo \"Deploying Second Chance ETL Job ($SECOND_CHANCE_JOB_NAME)...\"\n    deploy_glue_job \"$SECOND_CHANCE_JOB_NAME\" \"$SECOND_CHANCE_SCRIPT_LOCAL\" \"$SECOND_CHANCE_SCRIPT_S3\" \"$SECOND_CHANCE_MODULES\"\nfi\n\nif [ \"$DEPLOY_REHOME\" = true ]; then\n    echo \"Deploying Rehoming ETL Job ($REHOME_JOB_NAME)...\"\n    deploy_glue_job \"$REHOME_JOB_NAME\" \"$REHOME_SCRIPT_LOCAL\" \"$REHOME_SCRIPT_S3\" \"$REHOME_MODULES\" \"$REHOME_EXTRA_SETUP\"\nfi\n\necho \"Deployment completed successfully!\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/deploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# CloudWatch Monitoring Agent - Lambda Deployment Script\n# Deploys the monitoring agent as an AWS Lambda function\n\nset -e\n\nFUNCTION_NAME=\"cloudwatch-monitoring-agent-api\"\nREGION=\"us-east-1\"\nROLE_NAME=\"CloudWatchMonitoringLambdaRole\"\n\necho \"🚀 Deploying CloudWatch Monitoring Agent to Lambda...\"\n\n# 1. Create IAM role if it doesn't exist\necho \"📋 Creating IAM role...\"\naws iam create-role \\\n    --role-name $ROLE_NAME \\\n    --assume-role-policy-document '{\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Principal\": {\n                    \"Service\": \"lambda.amazonaws.com\"\n                },\n                \"Action\": \"sts:AssumeRole\"\n            }\n        ]\n    }' 2>/dev/null || echo \"Role already exists\"\n\n# 2. Attach required policies\necho \"🔐 Attaching IAM policies...\"\naws iam attach-role-policy \\\n    --role-name $ROLE_NAME \\\n    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n\naws iam put-role-policy \\\n    --role-name $ROLE_NAME \\\n    --policy-name CloudWatchMonitoringPolicy \\\n    --policy-document '{\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"cloudwatch:DescribeAlarms\",\n                    \"logs:FilterLogEvents\",\n                    \"ses:SendEmail\"\n                ],\n                \"Resource\": \"*\"\n            }\n        ]\n    }'\n\n# 3. Get role ARN\nROLE_ARN=$(aws iam get-role --role-name $ROLE_NAME --query 'Role.Arn' --output text)\necho \"📝 Role ARN: $ROLE_ARN\"\n\n# 4. Create deployment package\necho \"📦 Creating deployment package...\"\nmkdir -p lambda_package\ncp cloudwatch_agent.py lambda_package/\ncp lambda_function.py lambda_package/\ncp config.json lambda_package/\ncp requirements-lambda.txt lambda_package/requirements.txt\n\ncd lambda_package\n\n# Install dependencies\npip install -r requirements.txt -t .\n\n# Create zip file\nzip -r ../cloudwatch-monitoring-agent-api.zip . -x \"*.pyc\" \"__pycache__/*\"\n\ncd ..\n\n# 5. Create or update Lambda function\necho \"⚡ Deploying Lambda function...\"\nif aws lambda get-function --function-name $FUNCTION_NAME --region $REGION 2>/dev/null; then\n    echo \"Updating existing function...\"\n    aws lambda update-function-code \\\n        --function-name $FUNCTION_NAME \\\n        --zip-file fileb://cloudwatch-monitoring-agent-api.zip \\\n        --region $REGION\n\n    aws lambda update-function-configuration \\\n        --function-name $FUNCTION_NAME \\\n        --timeout 300 \\\n        --memory-size 512 \\\n        --region $REGION\nelse\n    echo \"Creating new function...\"\n    aws lambda create-function \\\n        --function-name $FUNCTION_NAME \\\n        --runtime python3.9 \\\n        --role $ROLE_ARN \\\n        --handler lambda_function.lambda_handler \\\n        --zip-file fileb://cloudwatch-monitoring-agent-api.zip \\\n        --timeout 300 \\\n        --memory-size 512 \\\n        --region $REGION\nfi\n\n# 6. Create CloudWatch Events rule for scheduling\necho \"⏰ Setting up CloudWatch Events rule...\"\nRULE_NAME=\"cloudwatch-monitoring-schedule\"\n\naws events put-rule \\\n    --name $RULE_NAME \\\n    --schedule-expression \"rate(5 minutes)\" \\\n    --description \"Trigger CloudWatch monitoring agent every 5 minutes\" \\\n    --region $REGION\n\n# 7. Add permission for EventBridge to invoke Lambda\necho \"🔗 Adding EventBridge permissions...\"\naws lambda add-permission \\\n    --function-name $FUNCTION_NAME \\\n    --statement-id cloudwatch-monitoring-schedule \\\n    --action lambda:InvokeFunction \\\n    --principal events.amazonaws.com \\\n    --source-arn \"arn:aws:events:$REGION:$(aws sts get-caller-identity --query Account --output text):rule/$RULE_NAME\" \\\n    --region $REGION 2>/dev/null || echo \"Permission already exists\"\n\n# 8. Add Lambda function as target to the rule\necho \"🎯 Adding Lambda as target...\"\naws events put-targets \\\n    --rule $RULE_NAME \\\n    --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:$REGION:$(aws sts get-caller-identity --query Account --output text):function:$FUNCTION_NAME\" \\\n    --region $REGION\n\n# Cleanup\nrm -rf lambda_package\nrm cloudwatch-monitoring-agent-api.zip\n\necho \"✅ Deployment complete!\"\necho \"📊 Function: $FUNCTION_NAME\"\necho \"⏰ Schedule: Every 5 minutes\"\necho \"📍 Region: $REGION\"\necho \"\"\necho \"🔍 Monitor logs with:\"\necho \"aws logs tail /aws/lambda/$FUNCTION_NAME --follow --region $REGION\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/monitoring/deploy_lambda.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/usr/bin/env bash\n# setup-monitoring.sh — CLAUDE.md compliant monitoring with security metrics and business analytics\n# Follows CLAUDE.md principles: No fallbacks, fail-fast, comprehensive tagging for cost analysis\n\nset -euo pipefail\n\n# Add trap for script exit\nfinish() {\n  EXIT_CODE=$?\n  if [ $EXIT_CODE -eq 0 ]; then\n    echo\n    echo \"🎉 Enhanced monitoring setup completed successfully!\"\n    echo \"   Security monitoring, webhook protection, and business analytics enabled.\"\n    echo \"   Test Slack integration with:\"\n    echo \"   aws sns publish --topic-arn $TOPIC_ARN --message '🚀 Enhanced monitoring operational!'\"\n    echo\n  else\n    echo\n    echo \"❌ Enhanced monitoring setup failed (exit code: $EXIT_CODE)\"\n    echo \"   CLAUDE.md principle: Failing fast to surface real issues.\"\n    echo \"   Fix the error above and retry - no fallbacks will mask problems.\"\n    echo\n  fi\n}\ntrap finish EXIT\n\n# 1️⃣ Load .env with CLAUDE.md compliance (no fallbacks)\nif [ ! -f .env ]; then\n  echo \"❌ .env not found. Required for security monitoring and business analytics setup.\"\n  echo \"   Add SERVICE_NAME, STAGE, AWS_REGION, SLACK_WEBHOOK_URL,\"\n  echo \"   AMPLIFY_APP_ID, API_NAME, REQUESTS_PER_MONTH, COST_PER_BEDROCK_REQ\"\n  exit 1\nfi\n\nwhile IFS='=' read -r k v || [ -n \"$k\" ]; do\n  [[ \"$k\" =~ ^# ]] && continue\n  [[ -z \"$k\" ]] && continue\n  v=\"${v%\\\"}\"; v=\"${v#\\\"}\"\n  export \"$k=$v\"\ndone < <(sed 's/\\r$//' .env)\n\n# Trim whitespace from critical variables\nSERVICE_NAME=$(echo \"$SERVICE_NAME\" | xargs)\nSTAGE=$(echo \"$STAGE\" | xargs)\nAPI_NAME=$(echo \"$API_NAME\" | xargs)\n\n# Required variables - fail fast if missing (CLAUDE.md compliance)\n: \"${SERVICE_NAME:?SERVICE_NAME required for monitoring setup}\"\n: \"${STAGE:?STAGE required for monitoring setup}\"\n: \"${AWS_REGION:?AWS_REGION required for monitoring setup}\"\n: \"${SLACK_WEBHOOK_URL:?SLACK_WEBHOOK_URL required for monitoring setup}\"\n: \"${AMPLIFY_APP_ID:?AMPLIFY_APP_ID required for monitoring setup}\"\n: \"${API_NAME:?API_NAME required for monitoring setup}\"\n: \"${API_ID:?API_ID required for monitoring setup}\"\n: \"${REQUESTS_PER_MONTH:?REQUESTS_PER_MONTH required for monitoring setup}\"\n: \"${COST_PER_BEDROCK_REQ:?COST_PER_BEDROCK_REQ required for monitoring setup}\"\n\n# 2️⃣ Derived vars and business analytics tagging\nAWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nif [ -z \"$AWS_ACCOUNT_ID\" ]; then\n  echo \"❌ Failed to get AWS account ID. Check AWS credentials.\"\n  exit 1\nfi\n\nBEDROCK_MONTHLY_BUDGET=$(\n  awk \\\n    -v r=\"$REQUESTS_PER_MONTH\" \\\n    -v c=\"$COST_PER_BEDROCK_REQ\" \\\n    'BEGIN { printf \"%.2f\", r * c }'\n)\n\n# Business Analytics Tagging Strategy\nPROJECT_TAG=\"Project\"\nPROJECT_VALUE=\"${SERVICE_NAME}-${STAGE}\"\nPROJECT_VALUE=$(echo \"$PROJECT_VALUE\" | tr -d ' \\t')\n\n# Cost tracking by business line (endpoint)\nBUSINESS_LINE_TAG=\"BusinessLine\"\nENVIRONMENT_TAG=\"Environment\"\nCOST_TYPE_TAG=\"CostType\"\nENDPOINT_TAG=\"Endpoint\"\n\n# Determine environment and cost types\nif [[ \"$STAGE\" =~ ^(prod|production)$ ]]; then\n  ENVIRONMENT_VALUE=\"production\"\nelse\n  ENVIRONMENT_VALUE=\"development\"\nfi\n\n# Common tag set for all resources\ndeclare -A COMMON_TAGS=(\n  [$PROJECT_TAG]=\"$PROJECT_VALUE\"\n  [$ENVIRONMENT_TAG]=\"$ENVIRONMENT_VALUE\"\n  [\"Owner\"]=\"express-chatbot-team\"\n  [\"Application\"]=\"ona-chatbot\"\n  [\"Version\"]=\"1.0\"\n)\n\necho \"➡️  Setting up CLAUDE.md compliant monitoring for $SERVICE_NAME-$STAGE\"\necho \"   • Enhanced security monitoring enabled\"\necho \"   • Business analytics tagging for cost tracking\"\necho \"   • Environment: $ENVIRONMENT_VALUE\"\necho \"   • Target: $REQUESTS_PER_MONTH req/mo @ \\$$COST_PER_BEDROCK_REQ each\"\necho \"   • Monthly budget: \\$$BEDROCK_MONTHLY_BUDGET\"\necho \"   • No fallback patterns - fail fast on errors\"\necho\n\n# Helper function for applying business analytics tags\napply_business_tags() {\n  local resource_arn=$1\n  local business_line=${2:-\"infrastructure\"}\n  local cost_type=${3:-\"fixed\"}\n  local endpoint=${4:-\"system\"}\n\n  # Apply tags with correct format for each service type\n  if [[ \"$resource_arn\" =~ sns ]]; then\n    # SNS expects list of Key=Value pairs\n    aws sns tag-resource --resource-arn \"$resource_arn\" --region \"$AWS_REGION\" \\\n      --tags Key=Project,Value=\"$PROJECT_VALUE\" Key=Environment,Value=\"$ENVIRONMENT_VALUE\" Key=Owner,Value=\"express-chatbot-team\" Key=Application,Value=\"ona-chatbot\" Key=Version,Value=\"1.0\" Key=BusinessLine,Value=\"$business_line\" Key=CostType,Value=\"$cost_type\" Key=Endpoint,Value=\"$endpoint\"\n\n  elif [[ \"$resource_arn\" =~ lambda ]]; then\n    # Lambda expects JSON object format\n    aws lambda tag-resource --resource \"$resource_arn\" --region \"$AWS_REGION\" \\\n      --tags \"{\\\"Project\\\":\\\"$PROJECT_VALUE\\\",\\\"Environment\\\":\\\"$ENVIRONMENT_VALUE\\\",\\\"Owner\\\":\\\"express-chatbot-team\\\",\\\"Application\\\":\\\"ona-chatbot\\\",\\\"Version\\\":\\\"1.0\\\",\\\"BusinessLine\\\":\\\"$business_line\\\",\\\"CostType\\\":\\\"$cost_type\\\",\\\"Endpoint\\\":\\\"$endpoint\\\"}\"\n\n  elif [[ \"$resource_arn\" =~ amplify ]]; then\n    # Amplify expects comma-separated key=value pairs\n    aws amplify tag-resource --resource-arn \"$resource_arn\" --region \"$AWS_REGION\" \\\n      --tags \"Project=$PROJECT_VALUE,Environment=$ENVIRONMENT_VALUE,Owner=express-chatbot-team,Application=ona-chatbot,Version=1.0,BusinessLine=$business_line,CostType=$cost_type,Endpoint=$endpoint\"\n\n  elif [[ \"$resource_arn\" =~ apigateway ]]; then\n    # API Gateway expects comma-separated key=value pairs\n    aws apigateway tag-resource --resource-arn \"$resource_arn\" --region \"$AWS_REGION\" \\\n      --tags \"Project=$PROJECT_VALUE,Environment=$ENVIRONMENT_VALUE,Owner=express-chatbot-team,Application=ona-chatbot,Version=1.0,BusinessLine=$business_line,CostType=$cost_type,Endpoint=$endpoint\"\n  fi\n}\n\n# 3️⃣ SNS topic (fail fast - no error handling)\nTOPIC_NAME=\"${SERVICE_NAME}-${STAGE}-alerts\"\nTOPIC_NAME=$(echo \"$TOPIC_NAME\" | tr -d ' \\t')\necho \"Creating SNS topic: '$TOPIC_NAME'\"\n\nTOPIC_ARN=$(aws sns create-topic --name \"$TOPIC_NAME\" \\\n  --region \"$AWS_REGION\" --query TopicArn --output text)\n\n# Apply business analytics tags\napply_business_tags \"$TOPIC_ARN\" \"infrastructure\" \"fixed\" \"monitoring\"\n\necho \"✅ SNS topic: $TOPIC_ARN\"\n\n# 4️⃣ Enhanced IAM role for SlackNotifier with CloudWatch permissions\nROLE_NAME=\"${SERVICE_NAME}-${STAGE}-SlackNotifyRole\"\nif aws iam get-role --role-name \"$ROLE_NAME\" &>/dev/null; then\n  ROLE_ARN=$(aws iam get-role --role-name \"$ROLE_NAME\" \\\n    --query 'Role.Arn' --output text)\nelse\n  # Create trust policy file\n  cat > /tmp/trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  ROLE_ARN=$(aws iam create-role \\\n    --role-name \"$ROLE_NAME\" \\\n    --assume-role-policy-document file:///tmp/trust-policy.json \\\n    --region \"$AWS_REGION\" \\\n    --query 'Role.Arn' --output text)\n\n  aws iam attach-role-policy \\\n    --role-name \"$ROLE_NAME\" \\\n    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole \\\n    --region \"$AWS_REGION\"\n\n  # Add CloudWatch permissions for custom metrics\n  aws iam put-role-policy \\\n    --role-name \"$ROLE_NAME\" \\\n    --policy-name \"CloudWatchMetricsPolicy\" \\\n    --policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\n            \"cloudwatch:PutMetricData\"\n          ],\n          \"Resource\": \"*\"\n        }\n      ]\n    }'\n\n  # Wait for propagation\n  sleep 10\n  rm /tmp/trust-policy.json\nfi\necho \"✅ IAM role: $ROLE_ARN\"\n\n# 5️⃣ Enhanced SlackNotifier Lambda with security alert formatting\nLAMBDA_NAME=\"${SERVICE_NAME}-${STAGE}-SlackNotifier\"\nTMP_ZIP=$(mktemp /tmp/sn.XXXX.zip)\nrm -f \"$TMP_ZIP\"\n\ncat > /tmp/slack_notifier_enhanced.py <<'EOF'\nimport os, json, urllib.request, re\nfrom datetime import datetime, timezone\n\nWEBHOOK = os.environ['SLACK_WEBHOOK_URL']\n\ndef generate_sbar_alert(alarm_data):\n    \"\"\"Generate SBAR format alert for CloudWatch alarms\"\"\"\n    alarm_name = alarm_data.get('AlarmName', '')\n    description = alarm_data.get('AlarmDescription', '')\n    state = alarm_data.get('NewStateValue', '')\n    reason = alarm_data.get('NewStateReason', '')\n    timestamp = alarm_data.get('StateChangeTime', '')\n\n    # Determine alert type and severity\n    if 'SigFail' in alarm_name or 'SecurityFail' in alarm_name:\n        icon = \":warning:\"\n        severity = \"CRITICAL SECURITY\"\n        alert_type = \"SECURITY BREACH\"\n    elif 'Webhook' in alarm_name and 'Security' in alarm_name:\n        icon = \":shield:\"\n        severity = \"HIGH SECURITY\"\n        alert_type = \"WEBHOOK ATTACK\"\n    elif '5XX' in alarm_name:\n        icon = \":rotating_light:\"\n        severity = \"HIGH AVAILABILITY\"\n        alert_type = \"SERVICE OUTAGE\"\n    elif 'Auth0' in alarm_name:\n        icon = \":closed_lock_with_key:\"\n        severity = \"HIGH SECURITY\"\n        alert_type = \"AUTHENTICATION FAILURE\"\n    elif 'CustomerLookup' in alarm_name:\n        icon = \":exclamation:\"\n        severity = \"MEDIUM BUSINESS\"\n        alert_type = \"DATA INTEGRITY\"\n    elif 'Bedrock' in alarm_name:\n        icon = \":brain:\"\n        severity = \"HIGH BUSINESS\"\n        alert_type = \"AI SERVICE FAILURE\"\n    else:\n        icon = \":warning:\"\n        severity = \"MEDIUM SYSTEM\"\n        alert_type = \"SYSTEM ALERT\"\n\n    # Extract meaningful context from reason\n    context = extract_context_from_reason(reason, alarm_name)\n\n    # Generate SBAR sections\n    situation = generate_situation(alarm_name, state, severity)\n    background = generate_background(description, reason, timestamp, context)\n    assessment = generate_assessment(alarm_name, context, severity)\n    recommendation = generate_recommendation(alarm_name, context)\n\n    return f\"\"\"\n{icon} *{severity} - {alert_type}*\n\n📋 *SITUATION*\n{situation}\n\n📊 *BACKGROUND*\n{background}\n\n🔍 *ASSESSMENT*\n{assessment}\n\n💡 *RECOMMENDATION*\n{recommendation}\n\"\"\"\n\ndef extract_context_from_reason(reason, alarm_name):\n    \"\"\"Extract actionable context from CloudWatch alarm reason\"\"\"\n    context = {}\n\n    # Extract threshold information\n    if 'datapoint' in reason.lower():\n        threshold_match = re.search(r'(\\d+\\.?\\d*)\\s*.*?threshold\\s*\\((\\d+\\.?\\d*)\\)', reason)\n        if threshold_match:\n            context['current_value'] = threshold_match.group(1)\n            context['threshold'] = threshold_match.group(2)\n\n    # Extract error counts for security patterns\n    if 'SigFail' in alarm_name or 'SecurityFail' in alarm_name:\n        context['error_type'] = 'signature_verification'\n    elif 'Auth0' in alarm_name:\n        context['error_type'] = 'authentication'\n    elif 'CustomerLookup' in alarm_name:\n        context['error_type'] = 'data_integrity'\n\n    return context\n\ndef generate_situation(alarm_name, state, severity):\n    \"\"\"Generate clear situation statement\"\"\"\n    if 'SigFail' in alarm_name:\n        return f\"Webhook signature verification failures detected. System state: {state}\"\n    elif 'SecurityPattern' in alarm_name:\n        return f\"Repeated webhook security failures indicate ongoing attack. System state: {state}\"\n    elif '5XX' in alarm_name:\n        return f\"API Gateway returning server errors. System state: {state}\"\n    elif 'Auth0' in alarm_name:\n        return f\"Authentication service failures detected. System state: {state}\"\n    elif 'CustomerLookup' in alarm_name:\n        return f\"Customer data lookup failures detected. System state: {state}\"\n    elif 'Bedrock' in alarm_name:\n        return f\"AI service experiencing errors. System state: {state}\"\n    else:\n        return f\"System monitoring alert triggered. State: {state}\"\n\ndef generate_background(description, reason, timestamp, context):\n    \"\"\"Generate technical background with context\"\"\"\n    background = f\"Alert triggered at: {timestamp}\\n\"\n    background += f\"Description: {description}\\n\"\n\n    if context.get('current_value') and context.get('threshold'):\n        background += f\"Current value: {context['current_value']}, Threshold: {context['threshold']}\\n\"\n\n    background += f\"Trigger reason: {reason}\"\n\n    return background\n\ndef generate_assessment(alarm_name, context, severity):\n    \"\"\"Generate impact assessment\"\"\"\n    if 'SigFail' in alarm_name:\n        return f\"{severity}: Potential security breach attempt. Invalid webhook requests being processed. User authentication and payment processing may be compromised.\"\n    elif 'SecurityPattern' in alarm_name:\n        return f\"{severity}: Active attack detected. Multiple signature verification failures suggest coordinated attack on webhook endpoint.\"\n    elif '5XX' in alarm_name:\n        return f\"{severity}: Service degradation affecting user experience. Users cannot access application features.\"\n    elif 'Auth0' in alarm_name:\n        return f\"{severity}: User authentication system compromised. New user registrations and login attempts failing.\"\n    elif 'CustomerLookup' in alarm_name:\n        return f\"{severity}: Payment processing integrity issue. Webhook processing failing for customer data validation.\"\n    elif 'Bedrock' in alarm_name:\n        return f\"{severity}: AI chat functionality unavailable. Core application features not working.\"\n    else:\n        return f\"{severity}: System component experiencing issues. Monitor for user impact.\"\n\ndef generate_recommendation(alarm_name, context):\n    \"\"\"Generate specific actionable recommendations\"\"\"\n    if 'SigFail' in alarm_name:\n        return \"\"\"1. Check webhook endpoint logs for signature verification details\n2. Verify Stripe webhook secret configuration\n3. Investigate source IP addresses of failed requests\n4. Consider blocking suspicious IPs if pattern detected\n5. Review webhook endpoint security configuration\"\"\"\n    elif 'SecurityPattern' in alarm_name:\n        return \"\"\"1. IMMEDIATE: Block source IPs causing repeated failures\n2. Check AWS CloudTrail for related security events\n3. Review webhook logs for attack patterns\n4. Verify webhook endpoint is not exposed to public scanning\n5. Consider implementing rate limiting on webhook endpoint\"\"\"\n    elif '5XX' in alarm_name:\n        return \"\"\"1. Check Lambda function logs for specific error details\n2. Verify Lambda function memory and timeout settings\n3. Check downstream service health (Auth0, Stripe, Bedrock)\n4. Review API Gateway configuration\n5. Monitor error patterns and implement circuit breakers if needed\"\"\"\n    elif 'Auth0' in alarm_name:\n        return \"\"\"1. Check Auth0 service status and quotas\n2. Verify Auth0 API credentials and permissions\n3. Review Auth0 management API logs\n4. Check user lookup and role assignment endpoints\n5. Verify Auth0 domain and client configuration\"\"\"\n    elif 'CustomerLookup' in alarm_name:\n        return \"\"\"1. Check Stripe customer database for data consistency\n2. Review webhook event data for invalid customer IDs\n3. Verify Stripe API connectivity and quotas\n4. Check customer creation/update processes\n5. Implement customer ID validation in webhook processing\"\"\"\n    elif 'Bedrock' in alarm_name:\n        return \"\"\"1. Check AWS Bedrock service quotas and limits\n2. Verify Bedrock model permissions and access\n3. Review Lambda function invoking Bedrock for errors\n4. Check Bedrock model availability and region settings\n5. Implement fallback response for Bedrock failures\"\"\"\n    else:\n        return \"\"\"1. Check CloudWatch logs for detailed error information\n2. Review recent deployments for potential causes\n3. Verify system resource utilization\n4. Check dependent service health\n5. Escalate to on-call engineer if issue persists\"\"\"\n\ndef lambda_handler(event, context):\n    for r in event.get('Records', []):\n        msg = r['Sns']['Message']\n        try:\n            data = json.loads(msg)\n\n            # CloudWatch Alarm - Generate SBAR format\n            if 'AlarmName' in data:\n                text = generate_sbar_alert(data)\n\n            # Budget Alert - SBAR format\n            elif 'BudgetName' in data:\n                notification = data.get('Notification', {})\n                threshold = notification.get('Threshold', 0)\n                budget_name = data.get('BudgetName', '')\n\n                text = f\"\"\"\n:money_with_wings: *HIGH FINANCIAL - BUDGET EXCEEDED*\n\n📋 *SITUATION*\nBudget '{budget_name}' has exceeded {threshold}% threshold\n\n📊 *BACKGROUND*\nAlert Type: {notification.get('NotificationType', 'N/A')}\nThreshold: {threshold}%\nBudget Period: {data.get('TimePeriod', {}).get('Start', 'N/A')}\nCurrent Status: Budget limit reached or exceeded\n\n🔍 *ASSESSMENT*\nHIGH FINANCIAL: Monthly spending has exceeded planned budget. Continued spending may result in unexpected costs.\n\n💡 *RECOMMENDATION*\n1. Review current month spending in AWS Cost Explorer\n2. Identify highest cost services and resources\n3. Verify spending is expected for business operations\n4. Consider implementing cost controls or alerts\n5. Update budget if spending increase is justified\n\"\"\"\n\n            # Cost Anomaly Alert - SBAR format\n            elif 'AnomalyId' in data or 'AnomalyScore' in data:\n                impact = data.get('Impact', {})\n                score = data.get('AnomalyScore', 'N/A')\n\n                text = f\"\"\"\n:chart_with_upwards_trend: *MEDIUM FINANCIAL - COST ANOMALY*\n\n📋 *SITUATION*\nUnusual spending pattern detected in AWS account\n\n📊 *BACKGROUND*\nAnomaly Score: {score}\nImpact: ${impact.get('MaxImpact', 'N/A')}\nStart Date: {data.get('AnomalyStartDate', 'N/A')}\nEnd Date: {data.get('AnomalyEndDate', 'N/A')}\n\n🔍 *ASSESSMENT*\nMEDIUM FINANCIAL: Spending pattern deviation detected. May indicate service misconfiguration or unexpected usage.\n\n💡 *RECOMMENDATION*\n1. Review AWS Cost Explorer for detailed anomaly analysis\n2. Check for new resource deployments or configuration changes\n3. Verify usage patterns match expected business activity\n4. Investigate highest contributing services to anomaly\n5. Set up additional cost monitoring if pattern continues\n\"\"\"\n\n            # Fallback for unknown types\n            else:\n                text = f\"\"\"\n:grey_question: *MEDIUM SYSTEM - UNKNOWN ALERT*\n\n📋 *SITUATION*\nUnrecognized alert type received from monitoring system\n\n📊 *BACKGROUND*\nRaw alert data received but format not recognized by SBAR processor\n\n🔍 *ASSESSMENT*\nMEDIUM SYSTEM: Alert processing needs update to handle new alert type\n\n💡 *RECOMMENDATION*\n1. Review raw alert data below for details\n2. Update SBAR alert processor if new alert type identified\n3. Check CloudWatch and SNS configuration\n```\n{json.dumps(data, indent=2)}\n```\n\"\"\"\n\n        except Exception as e:\n            # CLAUDE.md compliance: Don't hide parsing errors\n            text = f\"\"\"\n:interrobang: *HIGH SYSTEM - ALERT PROCESSING FAILED*\n\n📋 *SITUATION*\nAlert processing system failed to parse incoming notification\n\n📊 *BACKGROUND*\nError: {str(e)}\nRaw message: {msg[:500]}...\n\n🔍 *ASSESSMENT*\nHIGH SYSTEM: Alert processing failure may cause missed critical notifications\n\n💡 *RECOMMENDATION*\n1. Check SlackNotifier Lambda function logs\n2. Verify SNS message format compatibility\n3. Update alert processor for new message formats\n4. Test alert processing with sample messages\n5. Implement alert processing monitoring\n\"\"\"\n\n        req = urllib.request.Request(\n            WEBHOOK,\n            data=json.dumps({\"text\": text}).encode(),\n            headers={'Content-Type': 'application/json'}\n        )\n        urllib.request.urlopen(req)\n\n    return {\"statusCode\": 200, \"body\": \"SBAR alerts processed\"}\nEOF\ncd /tmp && zip -j \"$TMP_ZIP\" slack_notifier_enhanced.py && cd - >/dev/null\n\nif aws lambda get-function --function-name \"$LAMBDA_NAME\" \\\n     --region \"$AWS_REGION\" &>/dev/null; then\n  aws lambda update-function-code \\\n    --function-name \"$LAMBDA_NAME\" \\\n    --zip-file \"fileb://$TMP_ZIP\" \\\n    --region \"$AWS_REGION\"\nelse\n  aws lambda create-function \\\n    --function-name \"$LAMBDA_NAME\" \\\n    --runtime python3.9 \\\n    --handler slack_notifier_enhanced.lambda_handler \\\n    --role \"$ROLE_ARN\" \\\n    --zip-file \"fileb://$TMP_ZIP\" \\\n    --environment \"Variables={SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}}\" \\\n    --timeout 30 --memory-size 128 \\\n    --region \"$AWS_REGION\"\nfi\n\nrm \"$TMP_ZIP\" /tmp/slack_notifier_enhanced.py\n\n# Apply business analytics tags to Lambda\nLAMBDA_ARN=\"arn:aws:lambda:${AWS_REGION}:${AWS_ACCOUNT_ID}:function:${LAMBDA_NAME}\"\napply_business_tags \"$LAMBDA_ARN\" \"infrastructure\" \"fixed\" \"monitoring\"\n\necho \"✅ Enhanced Lambda: $LAMBDA_NAME\"\n\n# Grant SNS invoke permission (idempotent)\naws lambda add-permission \\\n  --function-name \"$LAMBDA_NAME\" \\\n  --statement-id \"AllowSNSTrigger\" \\\n  --action lambda:InvokeFunction \\\n  --principal sns.amazonaws.com \\\n  --source-arn \"$TOPIC_ARN\" \\\n  --region \"$AWS_REGION\" 2>/dev/null || true\n\n# Subscribe Lambda if missing\nif ! aws sns list-subscriptions-by-topic --topic-arn \"$TOPIC_ARN\" \\\n     --region \"$AWS_REGION\" \\\n     --query \"Subscriptions[?Endpoint=='arn:aws:lambda:${AWS_REGION}:${AWS_ACCOUNT_ID}:function:${LAMBDA_NAME}']\" \\\n     --output text | grep -q .; then\n  aws sns subscribe \\\n    --topic-arn \"$TOPIC_ARN\" \\\n    --protocol lambda \\\n    --notification-endpoint \"arn:aws:lambda:${AWS_REGION}:${AWS_ACCOUNT_ID}:function:${LAMBDA_NAME}\" \\\n    --region \"$AWS_REGION\"\nfi\n\n# 6️⃣ Tag resources with business analytics tags\necho \"Applying business analytics tags to AWS resources...\"\n\n# Amplify (frontend hosting - variable cost by traffic)\nAMPLIFY_ARN=\"arn:aws:amplify:${AWS_REGION}:${AWS_ACCOUNT_ID}:apps/${AMPLIFY_APP_ID}\"\napply_business_tags \"$AMPLIFY_ARN\" \"frontend\" \"variable\" \"app-hosting\"\n\n# API Gateway (API endpoints - variable cost by requests)\nAPI_GATEWAY_ARN=\"arn:aws:apigateway:${AWS_REGION}::/restapis/${API_ID}/stages/${STAGE}\"\napply_business_tags \"$API_GATEWAY_ARN\" \"api\" \"variable\" \"gateway\"\n\necho \"✅ Applied business analytics tags to Amplify & API Gateway\"\n\n# 7️⃣ Enhanced CloudWatch alarms with security monitoring\necho \"⏳ Creating enhanced CloudWatch alarms...\"\nCW=\"aws cloudwatch put-metric-alarm --region $AWS_REGION\"\n\n# Original system alarms\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Amplify-5XX\" \\\n    --namespace AWS/AmplifyHosting --metric-name 5xxErrors \\\n    --dimensions Name=App,Value=\"$AMPLIFY_APP_ID\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Amplify 5xx errors\"\n\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-API-5XX\" \\\n    --namespace AWS/ApiGateway --metric-name 5XXError \\\n    --dimensions Name=ApiName,Value=\"$API_NAME\" Name=Stage,Value=\"$STAGE\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"API Gateway 5xx errors\"\n\n# Enhanced Lambda monitoring with security focus\nfor fn in bedrock-post webhook usage-metrics; do\n  $CW --alarm-name \"${SERVICE_NAME}-${STAGE}-LambdaErr-${fn}\" \\\n      --namespace AWS/Lambda --metric-name Errors \\\n      --dimensions Name=FunctionName,Value=\"${SERVICE_NAME}-${STAGE}-${fn}\" \\\n      --statistic Sum --period 300 --evaluation-periods 1 \\\n      --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n      --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n      --alarm-description \"Lambda ${fn} errors\"\ndone\n\n# 🔒 NEW: Security-specific alarms\necho \"⏳ Creating security-specific monitoring alarms...\"\n\n# Webhook signature verification failures\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Webhook-SigFail\" \\\n    --namespace \"Custom/Security\" --metric-name SignatureFailures \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Webhook signature verification failures - potential security breach\"\n\n# Repeated webhook security failures (pattern detection)\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Webhook-SecurityPattern\" \\\n    --namespace \"Custom/Security\" --metric-name SignatureFailures \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 900 --evaluation-periods 2 \\\n    --threshold 3 --comparison-operator GreaterThanThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Repeated webhook signature failures indicate ongoing attack\"\n\n# Customer lookup failures (data integrity)\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-CustomerLookupFail\" \\\n    --namespace \"Custom/Business\" --metric-name CustomerLookupFailures \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 600 --evaluation-periods 2 \\\n    --threshold 3 --comparison-operator GreaterThanThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Repeated customer lookup failures indicate data corruption or attack\"\n\n# Auth0 integration failures\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Auth0-Failures\" \\\n    --namespace \"Custom/Security\" --metric-name Auth0Failures \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 2 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Auth0 integration failures in webhook processing\"\n\n# Stripe API errors (separate from customer lookup)\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Stripe-APIErrors\" \\\n    --namespace \"Custom/Business\" --metric-name StripeAPIErrors \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Stripe API errors in webhook processing\"\n\n# Bedrock errors\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Bedrock-Err\" \\\n    --namespace AWS/Bedrock --metric-name InvocationServerErrors \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Bedrock invocation errors\"\n\necho \"✅ Enhanced alarms created (system + security)\"\n\n# 8️⃣ AWS Budgets\necho \"⏳ Upserting Budgets…\"\nupsert_budget(){\n  NAME=$1 LIMIT=$2\n  # Convert LIMIT to string to avoid type errors\n  LIMIT_STR=\\\"$LIMIT\\\"\n\n  # Directly try to get the specific budget by name\n  if aws budgets describe-budget \\\n    --account-id \"$AWS_ACCOUNT_ID\" \\\n    --region \"$AWS_REGION\" \\\n    --budget-name \"$NAME\" \\\n    --output text >/dev/null 2>&1; then\n\n    echo \"  • Budget '$NAME' exists, updating it...\"\n    aws budgets update-budget \\\n      --account-id \"$AWS_ACCOUNT_ID\" \\\n      --region \"$AWS_REGION\" \\\n      --new-budget \"{\n        \\\"BudgetName\\\":\\\"$NAME\\\",\n        \\\"BudgetType\\\":\\\"COST\\\",\n        \\\"TimeUnit\\\":\\\"MONTHLY\\\",\n        \\\"BudgetLimit\\\":{\\\"Amount\\\":$LIMIT_STR,\\\"Unit\\\":\\\"USD\\\"},\n        \\\"CostFilters\\\":{\n          \\\"TagKeyValue\\\":[\\\"${PROJECT_TAG}\\$${PROJECT_VALUE}\\\"]\n        }\n      }\"\n    echo \"  • Updated budget $NAME = \\$$LIMIT/mo\"\n  else\n    echo \"  • Budget '$NAME' doesn't exist, creating it...\"\n    aws budgets create-budget \\\n      --account-id \"$AWS_ACCOUNT_ID\" \\\n      --region \"$AWS_REGION\" \\\n      --budget \"{\n        \\\"BudgetName\\\":\\\"$NAME\\\",\n        \\\"BudgetType\\\":\\\"COST\\\",\n        \\\"TimeUnit\\\":\\\"MONTHLY\\\",\n        \\\"BudgetLimit\\\":{\\\"Amount\\\":$LIMIT_STR,\\\"Unit\\\":\\\"USD\\\"},\n        \\\"CostFilters\\\":{\n          \\\"TagKeyValue\\\":[\\\"${PROJECT_TAG}\\$${PROJECT_VALUE}\\\"]\n        }\n      }\" \\\n      --notifications-with-subscribers \"[\n        {\\\"Notification\\\":{\n           \\\"NotificationType\\\":\\\"ACTUAL\\\",\n           \\\"ComparisonOperator\\\":\\\"GREATER_THAN\\\",\n           \\\"Threshold\\\":80,\n           \\\"ThresholdType\\\":\\\"PERCENTAGE\\\"},\n         \\\"Subscribers\\\":[{\\\"SubscriptionType\\\":\\\"SNS\\\",\\\"Address\\\":\\\"$TOPIC_ARN\\\"}]\n        },\n        {\\\"Notification\\\":{\n           \\\"NotificationType\\\":\\\"ACTUAL\\\",\n           \\\"ComparisonOperator\\\":\\\"GREATER_THAN\\\",\n           \\\"Threshold\\\":100,\n           \\\"ThresholdType\\\":\\\"PERCENTAGE\\\"},\n         \\\"Subscribers\\\":[{\\\"SubscriptionType\\\":\\\"SNS\\\",\\\"Address\\\":\\\"$TOPIC_ARN\\\"}]\n        }\n      ]\"\n    echo \"  • Created budget $NAME = \\$$LIMIT/mo\"\n  fi\n}\n\nupsert_budget \"BedrockBudget\" \"$BEDROCK_MONTHLY_BUDGET\"\necho \"✅ Budgets upserted\"\n\n# 9️⃣ Cost Anomaly Detection (CLAUDE.md compliant - no fallbacks)\necho \"⏳ Configuring Cost Anomaly Detection...\"\nMON_NAME=\"OverallCostMonitor\"\n\n# Check for existing monitor first\necho \"   Checking for existing monitors...\"\nMON_ARN=$(aws ce get-anomaly-monitors \\\n  --region \"$AWS_REGION\" \\\n  --query \"AnomalyMonitors[?MonitorName=='$MON_NAME'].MonitorArn\" \\\n  --output text)\n\nif [ -z \"$MON_ARN\" ]; then\n  # Try to find ANY existing dimensional monitor to reuse\n  echo \"   No named monitor found, checking for any existing dimensional monitor...\"\n  MON_ARN=$(aws ce get-anomaly-monitors \\\n    --region \"$AWS_REGION\" \\\n    --query \"AnomalyMonitors[?MonitorType=='DIMENSIONAL'] | [0].MonitorArn\" \\\n    --output text)\n\n  if [ -z \"$MON_ARN\" ] || [ \"$MON_ARN\" = \"None\" ]; then\n    echo \"   Creating custom cost anomaly monitor (to avoid dimensional limits)...\"\n    # Use CUSTOM monitor with cost filter instead of DIMENSIONAL\n    MON_ARN=$(aws ce create-anomaly-monitor \\\n      --region \"$AWS_REGION\" \\\n      --anomaly-monitor '{\n        \"MonitorName\":\"'\"$MON_NAME\"'\",\n        \"MonitorType\":\"CUSTOM\",\n        \"MonitorSpecification\":\"{\\\"Dimension\\\":{\\\"Key\\\":\\\"SERVICE\\\",\\\"Values\\\":[\\\"Amazon Elastic Compute Cloud - Compute\\\",\\\"AWS Lambda\\\",\\\"Amazon API Gateway\\\",\\\"Amazon Simple Notification Service\\\",\\\"Amazon Bedrock\\\"],\\\"MatchOptions\\\":[\\\"EQUALS\\\"]}}\"\n      }' \\\n      --query 'MonitorArn' --output text)\n\n    echo \"   Created custom monitor: $MON_ARN\"\n  else\n    echo \"   Reusing existing dimensional monitor: $MON_ARN\"\n  fi\nelse\n  echo \"   Using existing named monitor: $MON_ARN\"\nfi\n\n# Create subscription (fail fast)\nSUB_NAME=\"CostSpikeSub\"\necho \"   Checking for existing subscriptions...\"\nEXISTS=$(aws ce get-anomaly-subscriptions \\\n  --region \"$AWS_REGION\" \\\n  --query \"AnomalySubscriptions[?SubscriptionName=='$SUB_NAME']\" \\\n  --output text)\n\nif [ -z \"$EXISTS\" ]; then\n  echo \"   Creating anomaly subscription...\"\n  aws ce create-anomaly-subscription \\\n    --region \"$AWS_REGION\" \\\n    --anomaly-subscription '{\n      \"SubscriptionName\":\"'\"$SUB_NAME\"'\",\n      \"Threshold\":10,\n      \"Frequency\":\"IMMEDIATE\",\n      \"MonitorArnList\":[\"'\"$MON_ARN\"'\"],\n      \"Subscribers\":[{\"Type\":\"SNS\",\"Address\":\"'\"$TOPIC_ARN\"'\"}]\n    }' >/dev/null\n\n  echo \"   Created subscription: $SUB_NAME\"\nelse\n  echo \"   Using existing subscription: $SUB_NAME\"\nfi\n\necho \"✅ Cost Anomaly Detection configured\"\n\n# 🔟 Final summary\necho\necho \"📋 CLAUDE.md Compliant Enhanced Monitoring Summary:\"\necho \"   ✅ SNS topic: $TOPIC_ARN\"\necho \"   ✅ Enhanced Lambda function: $LAMBDA_NAME\"\necho \"   ✅ System alarms: API Gateway, Lambda, Bedrock\"\necho \"   ✅ Security alarms: Signature failures, auth errors, attack patterns\"\necho \"   ✅ Business alarms: Customer lookup failures, Stripe API errors\"\necho \"   ✅ Budget monitoring: BedrockBudget = \\$$BEDROCK_MONTHLY_BUDGET/mo\"\necho \"   ✅ Cost anomaly detection: $MON_NAME\"\necho \"   ✅ No fallback patterns - fail fast on all errors\"\necho \"   ✅ Business analytics tagging applied to all resources\"\necho\necho \"🔒 Security Features Added:\"\necho \"   • Webhook signature verification failure detection\"\necho \"   • Attack pattern recognition (repeated failures)\"\necho \"   • Customer data integrity monitoring\"\necho \"   • Auth0 integration failure alerts\"\necho \"   • SBAR-format Slack notifications with actionable recommendations\"\necho\necho \"💰 Business Analytics Tags Applied:\"\necho \"   • Environment: $ENVIRONMENT_VALUE (production/development)\"\necho \"   • Cost tracking by business line (frontend/api/infrastructure)\"\necho \"   • Cost type classification (fixed/variable)\"\necho \"   • Endpoint-specific attribution for detailed cost analysis\"\necho\necho \"🎉 Enhanced monitoring setup complete! Test Slack with:\"\necho \"  aws sns publish --topic-arn $TOPIC_ARN --message '🚀 Enhanced monitoring operational!'\"\necho\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/ona-front-end/express-chatbot/setup-monitoring.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Check if AWS CLI is installed\nif ! command -v aws &> /dev/null; then\n    echo \"AWS CLI is not installed. Please install it first.\"\n    exit 1\nfi\n\n# Default region\nREGION=\"us-east-1\"\nAPI_ID=\"\"\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n  case $1 in\n    --region)\n      REGION=\"$2\"\n      shift 2\n      ;;\n    --api-id)\n      API_ID=\"$2\"\n      shift 2\n      ;;\n    --help)\n      echo \"Usage: $0 [options] API_ID\"\n      echo \"Options:\"\n      echo \"  --region REGION     AWS region (default: us-east-1)\"\n      echo \"  --api-id ID         API Gateway ID (required)\"\n      echo \"  --help              Show this help message\"\n      echo \"\"\n      echo \"Or simply provide the API ID as the first argument:\"\n      echo \"  $0 API_ID\"\n      exit 0\n      ;;\n    *)\n      # If no flag but a value, assume it's the API ID\n      if [[ \"$1\" != -* && -z \"$API_ID\" ]]; then\n        API_ID=\"$1\"\n        shift\n      else\n        echo \"Unknown option: $1\"\n        echo \"Run with --help for usage information\"\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# If API ID is not provided via arguments, check if it's the first positional argument\nif [ -z \"$API_ID\" ] && [ $# -gt 0 ]; then\n  API_ID=\"$1\"\nfi\n\n# Validate arguments\nif [ -z \"$API_ID\" ]; then\n    echo \"API Gateway ID is required. Use --api-id parameter or provide it as the first argument.\"\n    exit 1\nfi\n\n# Validate AWS credentials are configured\necho \"Validating AWS credentials...\"\nif ! aws sts get-caller-identity &> /dev/null; then\n    echo \"AWS credentials not configured or invalid. Please run 'aws configure' first.\"\n    exit 1\nfi\n\necho \"Fetching API Gateway resources for API ID: $API_ID\"\necho \"Region: $REGION\"\n\n# Get resources and format the output\naws apigateway get-resources \\\n  --rest-api-id $API_ID \\\n  --region $REGION \\\n  --output table\n\necho \"\"\necho \"To find the root resource ID, look for a resource with path '/' in the output above.\"\necho \"Use this ID with the --root-resource-id parameter in the deploy script.\"\necho \"\"\necho \"Example deployment command:\"\necho \"./deploy-conversation-storage.sh --api-id $API_ID --root-resource-id YOUR_ROOT_RESOURCE_ID --region $REGION\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/ona-front-end/express-chatbot/deployment/conversation-storage/get-api-resources.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\nset -e\n\n# Default parameters\nSTAGE=\"dev\"\nREGION=\"us-east-1\"\nBACKUP_SUFFIX=$(date +%Y%m%d-%H%M%S)\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n  case $1 in\n    --stage)\n      STAGE=\"$2\"\n      shift 2\n      ;;\n    --region)\n      REGION=\"$2\"\n      shift 2\n      ;;\n    --suffix)\n      BACKUP_SUFFIX=\"$2\"\n      shift 2\n      ;;\n    --help)\n      echo \"Usage: $0 [options]\"\n      echo \"Options:\"\n      echo \"  --stage STAGE        Deployment stage - dev, staging, prod (default: dev)\"\n      echo \"  --region REGION      AWS region (default: us-east-1)\"\n      echo \"  --suffix SUFFIX      Backup name suffix (default: current timestamp)\"\n      echo \"  --help               Show this help message\"\n      exit 0\n      ;;\n    *)\n      echo \"Unknown option: $1\"\n      echo \"Run with --help for usage information\"\n      exit 1\n      ;;\n  esac\ndone\n\n# Validate AWS credentials are configured\necho \"Validating AWS credentials...\"\nif ! aws sts get-caller-identity &> /dev/null; then\n    echo \"AWS credentials not configured or invalid. Please run 'aws configure' first.\"\n    exit 1\nfi\n\n# Create backups for all conversation storage tables\necho \"Starting backup process for $STAGE environment in $REGION region...\"\n\n# List of tables to backup\nTABLES=(\n  \"${STAGE}-PolicyAnalyst-Conversations\"\n  \"${STAGE}-PolicyAnalyst-Messages\"\n  \"${STAGE}-PolicyAnalyst-UserConversationMeta\"\n)\n\nfor TABLE in \"${TABLES[@]}\"; do\n  echo \"Creating backup for $TABLE...\"\n\n  # Check if table exists\n  if aws dynamodb describe-table --table-name \"$TABLE\" --region \"$REGION\" &>/dev/null; then\n    # Create backup\n    BACKUP_NAME=\"${TABLE}-${BACKUP_SUFFIX}\"\n\n    aws dynamodb create-backup \\\n      --table-name \"$TABLE\" \\\n      --backup-name \"$BACKUP_NAME\" \\\n      --region \"$REGION\"\n\n    echo \"Backup created: $BACKUP_NAME\"\n  else\n    echo \"Table $TABLE does not exist, skipping backup.\"\n  fi\ndone\n\necho \"Backup process completed successfully!\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/ona-front-end/express-chatbot/deployment/conversation-storage/backup-tables.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# fix-lambda-with-deps.sh - Package Lambda functions with all dependencies and update them using S3\n\nset -e  # Exit immediately if a command fails\n\n# Set variables\nREGION=\"us-east-1\"\nFUNCTION_OPTIONS=\"express-chatbot-dev-subscription-details-options\"\nFUNCTION_MAIN=\"express-chatbot-dev-subscription-details\"\nPACKAGE_DIR=\"lambda-package\"\nOPTIONS_ZIP=\"options-function.zip\"\nMAIN_ZIP=\"main-function.zip\"\nS3_BUCKET=\"express-chatbot-lambda-packages-$(date +%s)\"\n\necho \"=== Lambda Package and Update Script (via S3) ===\"\necho \"Options function: $FUNCTION_OPTIONS\"\necho \"Main function: $FUNCTION_MAIN\"\necho \"\"\n\n# Check if we have server.js\nif [ ! -f \"server.js\" ]; then\n  echo \"Error: server.js file not found in current directory!\"\n  echo \"Please run this script from the directory containing your server.js file.\"\n  exit 1\nfi\n\n# Create S3 bucket for temporary storage\necho \"Creating S3 bucket for package storage...\"\naws s3 mb s3://$S3_BUCKET --region $REGION\naws s3api put-bucket-lifecycle-configuration \\\n  --bucket $S3_BUCKET \\\n  --lifecycle-configuration '{\"Rules\":[{\"ID\":\"DeleteAfterOneDay\",\"Status\":\"Enabled\",\"Expiration\":{\"Days\":1},\"Prefix\":\"\"}]}' \\\n  --region $REGION\n\n# Prepare packaging directory - clean contents but keep directory\necho \"Preparing packaging directory...\"\nif [ -d \"$PACKAGE_DIR\" ]; then\n  # Clear contents but keep the directory\n  echo \"Cleaning existing $PACKAGE_DIR directory...\"\n  rm -rf \"$PACKAGE_DIR\"/*\nelse\n  # Create directory if it doesn't exist\n  echo \"Creating $PACKAGE_DIR directory...\"\n  mkdir -p \"$PACKAGE_DIR\"\nfi\n\n# Copy server files and package.json\necho \"Copying server files...\"\ncp server.js \"$PACKAGE_DIR/\"\ncp package.json \"$PACKAGE_DIR/\"\ncp -r handlers \"$PACKAGE_DIR/\" 2>/dev/null || echo \"No handlers directory found, skipping\"\ncp -r helpers \"$PACKAGE_DIR/\" 2>/dev/null || echo \"No helpers directory found, skipping\"\ncp -r utils \"$PACKAGE_DIR/\" 2>/dev/null || echo \"No utils directory found, skipping\"\ncp -r lib \"$PACKAGE_DIR/\" 2>/dev/null || echo \"No lib directory found, skipping\"\n\n# Install dependencies\necho \"Installing dependencies (this may take a while)...\"\ncd \"$PACKAGE_DIR\"\nnpm install --production\ncd ..\n\n# Create ZIP files\necho \"Creating Lambda deployment package...\"\ncd \"$PACKAGE_DIR\"\nzip -r \"../$OPTIONS_ZIP\" .\nzip -r \"../$MAIN_ZIP\" .\ncd ..\n\n# Upload packages to S3\necho \"Uploading packages to S3...\"\naws s3 cp \"$OPTIONS_ZIP\" s3://$S3_BUCKET/ --region $REGION\naws s3 cp \"$MAIN_ZIP\" s3://$S3_BUCKET/ --region $REGION\n\n# Update Lambda functions\necho \"Updating OPTIONS Lambda function from S3...\"\naws lambda update-function-code \\\n  --function-name \"$FUNCTION_OPTIONS\" \\\n  --s3-bucket \"$S3_BUCKET\" \\\n  --s3-key \"$OPTIONS_ZIP\" \\\n  --region \"$REGION\"\n\necho \"Updating main Lambda function from S3...\"\naws lambda update-function-code \\\n  --function-name \"$FUNCTION_MAIN\" \\\n  --s3-bucket \"$S3_BUCKET\" \\\n  --s3-key \"$MAIN_ZIP\" \\\n  --region \"$REGION\"\n\n# Clean up temporary files but keep the directory structure\necho \"Cleaning up temporary files...\"\nrm \"$OPTIONS_ZIP\" \"$MAIN_ZIP\"\nrm -rf \"$PACKAGE_DIR/node_modules\"\n\necho \"\"\necho \"Lambda functions updated successfully with all dependencies!\"\necho \"Note: The S3 bucket $S3_BUCKET will be automatically deleted after 1 day.\"\necho \"Testing...\"\n\n# Wait for function to update\necho \"Waiting 15 seconds for Lambda functions to update...\"\nsleep 15\n\n# Test the OPTIONS endpoint\necho \"Testing OPTIONS request...\"\ncurl -i -X OPTIONS \\\n  \"https://y1spda7tbb.execute-api.us-east-1.amazonaws.com/dev/api/subscription-details\" \\\n  -H \"Origin: https://app.asoba.co\" \\\n  -H \"Access-Control-Request-Method: POST\" \\\n  -H \"Access-Control-Request-Headers: Content-Type,Authorization\"\n\necho \"\"\necho \"Lambda update complete. Please check your web application to verify that it works correctly.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/ona-front-end/express-chatbot/fix-lambda-with-deps.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Stop Mistral LLM Deployment Script\n# This script safely terminates the Mistral LLM instance and cleans up resources\n\nset -e\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Logging function\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Configuration\nPROJECT_NAME=\"mistral-base\"  # Match deploy script\nREGION=\"${AWS_REGION:-us-west-2}\"   # Default to us-west-2 (matches deploy script)\n\n# Function to stop instance\nstop_instance() {\n    local instance_id=$1\n    local volume_id=$2\n\n    if [ -z \"$instance_id\" ]; then\n        error \"No instance ID provided\"\n    fi\n\n    log \"Stopping Mistral LLM deployment...\"\n    log \"Instance ID: $instance_id\"\n\n    # Check if instance exists and is running\n    INSTANCE_STATE=$(aws ec2 describe-instances \\\n        --region $REGION \\\n        --instance-ids $instance_id \\\n        --query 'Reservations[0].Instances[0].State.Name' \\\n        --output text 2>/dev/null || echo \"not-found\")\n\n    if [ \"$INSTANCE_STATE\" = \"not-found\" ]; then\n        warn \"Instance $instance_id not found or already terminated\"\n        return 0\n    fi\n\n    log \"Current instance state: $INSTANCE_STATE\"\n\n    # Create snapshot if volume exists\n    if [ -n \"$volume_id\" ]; then\n        log \"Creating snapshot of volume $volume_id before termination...\"\n        SNAPSHOT_ID=$(aws ec2 create-snapshot \\\n            --region $REGION \\\n            --volume-id $volume_id \\\n            --description \"Mistral LLM snapshot created on $(date +%Y-%m-%d-%H-%M-%S)\" \\\n            --tag-specifications \"ResourceType=snapshot,Tags=[{Key=Name,Value=${PROJECT_NAME}-snapshot-$(date +%Y%m%d)},{Key=Project,Value=${PROJECT_NAME}}]\" \\\n            --query 'SnapshotId' --output text 2>/dev/null || echo \"failed\")\n\n        if [ \"$SNAPSHOT_ID\" != \"failed\" ]; then\n            log \"Created snapshot: $SNAPSHOT_ID\"\n        else\n            warn \"Failed to create snapshot, continuing with termination\"\n        fi\n    fi\n\n    # Terminate instance\n    if [ \"$INSTANCE_STATE\" != \"terminated\" ] && [ \"$INSTANCE_STATE\" != \"terminating\" ]; then\n        log \"Terminating instance...\"\n        aws ec2 terminate-instances --region $REGION --instance-ids $instance_id\n\n        log \"Waiting for instance to terminate...\"\n        aws ec2 wait instance-terminated --region $REGION --instance-ids $instance_id\n        log \"Instance terminated successfully\"\n    else\n        log \"Instance already terminated or terminating\"\n    fi\n\n    # Delete volume (optional)\n    if [ -n \"$volume_id\" ]; then\n        read -p \"Delete the EBS volume $volume_id? (y/N): \" -r\n        if [[ $REPLY =~ ^[Yy]$ ]]; then\n            log \"Deleting EBS volume...\"\n            aws ec2 delete-volume --volume-id $volume_id 2>/dev/null || warn \"Failed to delete volume (it may already be deleted)\"\n            log \"Volume deletion initiated\"\n        else\n            log \"Keeping EBS volume: $volume_id\"\n        fi\n    fi\n}\n\n# Function to get cost summary\nget_cost_summary() {\n    local instance_id=$1\n\n    if [ -z \"$instance_id\" ]; then\n        return\n    fi\n\n    log \"Calculating cost summary...\"\n\n    # Get instance launch time\n    LAUNCH_TIME=$(aws ec2 describe-instances \\\n        --instance-ids $instance_id \\\n        --query 'Reservations[0].Instances[0].LaunchTime' \\\n        --output text 2>/dev/null || echo \"unknown\")\n\n    if [ \"$LAUNCH_TIME\" != \"unknown\" ]; then\n        # Calculate runtime (rough estimate)\n        LAUNCH_EPOCH=$(date -d \"$LAUNCH_TIME\" +%s 2>/dev/null || echo \"0\")\n        CURRENT_EPOCH=$(date +%s)\n        RUNTIME_HOURS=$(( (CURRENT_EPOCH - LAUNCH_EPOCH) / 3600 ))\n\n        # Cost calculation (c7g.2xlarge = $0.289/hour)\n        COMPUTE_COST=$(echo \"$RUNTIME_HOURS * 0.289\" | bc -l 2>/dev/null || echo \"0\")\n\n        log \"Runtime: ~$RUNTIME_HOURS hours\"\n        log \"Estimated compute cost: ~\\$$(printf \"%.2f\" $COMPUTE_COST)\"\n        log \"Plus storage costs: ~\\$0.80/day for EBS volume\"\n    fi\n}\n\n# Function to cleanup tracking files\ncleanup_files() {\n    log \"Cleaning up tracking files...\"\n\n    if [ -f .mistral-instance-id ]; then\n        rm .mistral-instance-id\n        log \"Removed .mistral-instance-id\"\n    fi\n\n    if [ -f .mistral-volume-id ]; then\n        rm .mistral-volume-id\n        log \"Removed .mistral-volume-id\"\n    fi\n\n    if [ -f mistral_client.py ]; then\n        log \"Keeping mistral_client.py for future use\"\n    fi\n}\n\n# Function to optionally cleanup infrastructure\ncleanup_infrastructure() {\n    read -p \"Do you want to delete ALL infrastructure (VPC, subnets, etc.)? This will remove everything created by deploy-mistral.sh (y/N): \" -r\n\n    if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n        log \"Keeping infrastructure for future use\"\n        return 0\n    fi\n\n    warn \"This will delete ALL Mistral LLM infrastructure!\"\n    read -p \"Are you absolutely sure? Type 'DELETE' to confirm: \" -r\n\n    if [ \"$REPLY\" != \"DELETE\" ]; then\n        log \"Infrastructure deletion cancelled\"\n        return 0\n    fi\n\n    log \"Deleting infrastructure...\"\n\n    # Get VPC ID\n    VPC_ID=$(aws ec2 describe-vpcs \\\n        --filters \"Name=tag:Name,Values=${PROJECT_NAME}-vpc\" \\\n        --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$VPC_ID\" = \"None\" ]; then\n        log \"No infrastructure found to delete\"\n        return 0\n    fi\n\n    log \"Found VPC: $VPC_ID\"\n\n    # Delete NAT Gateway\n    NAT_GW_ID=$(aws ec2 describe-nat-gateways \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=state,Values=available\" \\\n        --query 'NatGateways[0].NatGatewayId' --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$NAT_GW_ID\" != \"None\" ]; then\n        log \"Deleting NAT Gateway: $NAT_GW_ID\"\n        aws ec2 delete-nat-gateway --nat-gateway-id $NAT_GW_ID\n        log \"Waiting for NAT Gateway deletion...\"\n        aws ec2 wait nat-gateway-deleted --nat-gateway-ids $NAT_GW_ID 2>/dev/null || true\n    fi\n\n    # Delete Internet Gateway\n    IGW_ID=$(aws ec2 describe-internet-gateways \\\n        --filters \"Name=attachment.vpc-id,Values=$VPC_ID\" \\\n        --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$IGW_ID\" != \"None\" ]; then\n        log \"Detaching and deleting Internet Gateway: $IGW_ID\"\n        aws ec2 detach-internet-gateway --vpc-id $VPC_ID --internet-gateway-id $IGW_ID\n        aws ec2 delete-internet-gateway --internet-gateway-id $IGW_ID\n    fi\n\n    # Delete subnets\n    SUBNET_IDS=$(aws ec2 describe-subnets \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \\\n        --query 'Subnets[].SubnetId' --output text 2>/dev/null || echo \"\")\n\n    for SUBNET_ID in $SUBNET_IDS; do\n        if [ -n \"$SUBNET_ID\" ]; then\n            log \"Deleting subnet: $SUBNET_ID\"\n            aws ec2 delete-subnet --subnet-id $SUBNET_ID 2>/dev/null || true\n        fi\n    done\n\n    # Delete route tables (except main)\n    RT_IDS=$(aws ec2 describe-route-tables \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \\\n        --query 'RouteTables[?Associations[0].Main==`false`].RouteTableId' --output text 2>/dev/null || echo \"\")\n\n    for RT_ID in $RT_IDS; do\n        if [ -n \"$RT_ID\" ]; then\n            log \"Deleting route table: $RT_ID\"\n            aws ec2 delete-route-table --route-table-id $RT_ID 2>/dev/null || true\n        fi\n    done\n\n    # Delete security groups (except default)\n    SG_IDS=$(aws ec2 describe-security-groups \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \\\n        --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text 2>/dev/null || echo \"\")\n\n    for SG_ID in $SG_IDS; do\n        if [ -n \"$SG_ID\" ]; then\n            log \"Deleting security group: $SG_ID\"\n            aws ec2 delete-security-group --group-id $SG_ID 2>/dev/null || true\n        fi\n    done\n\n    # Delete VPC\n    log \"Deleting VPC: $VPC_ID\"\n    aws ec2 delete-vpc --vpc-id $VPC_ID 2>/dev/null || warn \"Failed to delete VPC (may have dependencies)\"\n\n    # Delete IAM resources\n    ROLE_NAME=\"${PROJECT_NAME}-role\"\n    PROFILE_NAME=\"${PROJECT_NAME}-profile\"\n\n    if aws iam get-instance-profile --instance-profile-name $PROFILE_NAME &>/dev/null; then\n        log \"Deleting IAM instance profile: $PROFILE_NAME\"\n        aws iam remove-role-from-instance-profile --instance-profile-name $PROFILE_NAME --role-name $ROLE_NAME 2>/dev/null || true\n        aws iam delete-instance-profile --instance-profile-name $PROFILE_NAME 2>/dev/null || true\n    fi\n\n    if aws iam get-role --role-name $ROLE_NAME &>/dev/null; then\n        log \"Deleting IAM role: $ROLE_NAME\"\n        aws iam delete-role-policy --role-name $ROLE_NAME --policy-name \"${PROJECT_NAME}-policy\" 2>/dev/null || true\n        aws iam delete-role --role-name $ROLE_NAME 2>/dev/null || true\n    fi\n\n    # Release Elastic IPs\n    EIP_ALLOC_IDS=$(aws ec2 describe-addresses \\\n        --filters \"Name=domain,Values=vpc\" \\\n        --query 'Addresses[?AssociationId==null].AllocationId' --output text 2>/dev/null || echo \"\")\n\n    for EIP_ID in $EIP_ALLOC_IDS; do\n        if [ -n \"$EIP_ID\" ]; then\n            log \"Releasing Elastic IP: $EIP_ID\"\n            aws ec2 release-address --allocation-id $EIP_ID 2>/dev/null || true\n        fi\n    done\n\n    log \"Infrastructure cleanup completed\"\n}\n\n# Main function\nmain() {\n    log \"Mistral LLM Stop Script\"\n\n    # Check if tracking files exist (try multiple possible names)\n    if [ -f .mistral-base-instance-id ]; then\n        INSTANCE_ID=$(cat .mistral-base-instance-id)\n        VOLUME_ID=$(cat .mistral-volume-id 2>/dev/null || echo \"\")\n        log \"Found marketplace tracking files\"\n    elif [ -f .mistral-instance-id ]; then\n        INSTANCE_ID=$(cat .mistral-instance-id)\n        VOLUME_ID=$(cat .mistral-volume-id 2>/dev/null || echo \"\")\n        log \"Found tracking files\"\n    else\n        # Check command line argument\n        if [ $# -eq 1 ]; then\n            INSTANCE_ID=$1\n            VOLUME_ID=\"\"\n            log \"Using instance ID from command line: $INSTANCE_ID\"\n        else\n            error \"No instance ID found. Either run from the deployment directory or provide instance ID as argument.\"\n        fi\n    fi\n\n    # Get cost summary before stopping\n    get_cost_summary $INSTANCE_ID\n\n    # Stop the instance\n    stop_instance $INSTANCE_ID $VOLUME_ID\n\n    # Cleanup tracking files\n    cleanup_files\n\n    # Ask about infrastructure cleanup\n    cleanup_infrastructure\n\n    log \"=== STOP COMPLETE ===\"\n    log \"\"\n    log \"Mistral LLM instance has been stopped\"\n    log \"Any snapshots created are preserved for future use\"\n    log \"\"\n    log \"To redeploy, run: ./deploy-mistral.sh\"\n}\n\n# Check prerequisites\nif ! command -v aws &> /dev/null; then\n    error \"AWS CLI not found. Please install AWS CLI.\"\nfi\n\nif ! aws sts get-caller-identity &> /dev/null; then\n    error \"AWS credentials not configured. Run 'aws configure' first.\"\nfi\n\n# Run main function\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/scripts/stop-mistral.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for system service management", "completion": "```bash\n#!/bin/bash\n\n# Unified AI Services Control Script\n# Manages both Flux.1 Dev (image generation) and Mistral (text generation)\n\nset -e\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n}\n\ninfo() {\n    echo -e \"${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\n# Show usage\nusage() {\n    echo \"\"\n    echo \"🤖 AI Services Control Panel\"\n    echo \"\"\n    echo \"Usage: $0 <command> [service]\"\n    echo \"\"\n    echo \"Commands:\"\n    echo \"  start [flux|mistral|all]     Start AI service(s)\"\n    echo \"  stop [flux|mistral|all]      Stop AI service(s)\"\n    echo \"  status                       Show status of all services\"\n    echo \"  costs                        Show estimated running costs\"\n    echo \"\"\n    echo \"Examples:\"\n    echo \"  $0 start flux               Start only Flux image generation\"\n    echo \"  $0 start mistral            Start only Mistral chat\"\n    echo \"  $0 start all                Start both services\"\n    echo \"  $0 stop all                 Stop both services\"\n    echo \"  $0 status                   Check what's running\"\n    echo \"\"\n}\n\n# Check service status\ncheck_status() {\n    local service=\"$1\"\n    local instance_file=\"\"\n    local service_name=\"\"\n\n    case \"$service\" in\n        \"flux\")\n            instance_file=\".flux-dev-instance-id\"\n            service_name=\"Flux.1 Dev\"\n            ;;\n        \"mistral\")\n            instance_file=\".mistral-base-instance-id\"\n            service_name=\"Mistral Chat\"\n            ;;\n        *)\n            error \"Unknown service: $service\"\n            ;;\n    esac\n\n    if [ ! -f \"$instance_file\" ]; then\n        echo \"None\"\n        return\n    fi\n\n    local instance_id=$(cat \"$instance_file\")\n    local regions=\"us-east-1 us-west-2\"\n\n    for region in $regions; do\n        local state=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].State.Name' \\\n            --output text 2>/dev/null || echo \"None\")\n\n        if [ \"$state\" != \"None\" ]; then\n            echo \"$state\"\n            return\n        fi\n    done\n\n    echo \"Not found\"\n}\n\n# Get instance details\nget_instance_details() {\n    local service=\"$1\"\n    local instance_file=\"\"\n\n    case \"$service\" in\n        \"flux\")\n            instance_file=\".flux-dev-instance-id\"\n            ;;\n        \"mistral\")\n            instance_file=\".mistral-base-instance-id\"\n            ;;\n        *)\n            return\n            ;;\n    esac\n\n    if [ ! -f \"$instance_file\" ]; then\n        return\n    fi\n\n    local instance_id=$(cat \"$instance_file\")\n    local regions=\"us-east-1 us-west-2\"\n\n    for region in $regions; do\n        local instance_info=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].[PublicIpAddress,InstanceType,State.Name]' \\\n            --output text 2>/dev/null || echo \"None None None\")\n\n        if [ \"$(echo \"$instance_info\" | cut -f3)\" != \"None\" ]; then\n            echo \"$instance_info|$region\"\n            return\n        fi\n    done\n}\n\n# Show status command\nshow_status() {\n    log \"🔍 AI Services Status\"\n    echo \"\"\n\n    # Check Flux\n    local flux_status=$(check_status \"flux\")\n    info \"🎨 Flux.1 Dev (Image Generation): $flux_status\"\n\n    if [ \"$flux_status\" = \"running\" ]; then\n        local details=$(get_instance_details \"flux\")\n        local public_ip=$(echo \"$details\" | cut -d'|' -f1 | cut -f1)\n        local instance_type=$(echo \"$details\" | cut -d'|' -f1 | cut -f2)\n        local region=$(echo \"$details\" | cut -d'|' -f2)\n\n        echo \"  💻 Instance: $instance_type in $region\"\n        echo \"  🌐 Web Interface: http://$public_ip\"\n        echo \"  📡 API: http://$public_ip/api/generate\"\n    fi\n\n    echo \"\"\n\n    # Check Mistral\n    local mistral_status=$(check_status \"mistral\")\n    info \"💬 Mistral Chat (Text Generation): $mistral_status\"\n\n    if [ \"$mistral_status\" = \"running\" ]; then\n        local details=$(get_instance_details \"mistral\")\n        local public_ip=$(echo \"$details\" | cut -d'|' -f1 | cut -f1)\n        local instance_type=$(echo \"$details\" | cut -d'|' -f1 | cut -f2)\n        local region=$(echo \"$details\" | cut -d'|' -f2)\n\n        echo \"  💻 Instance: $instance_type in $region\"\n        echo \"  🌐 Chat Interface: http://$public_ip:8080\"\n        echo \"  📡 API: http://$public_ip:8000/v1/completions\"\n    fi\n\n    echo \"\"\n}\n\n# Show costs\nshow_costs() {\n    log \"💰 Estimated Running Costs (per hour)\"\n    echo \"\"\n\n    local flux_status=$(check_status \"flux\")\n    local mistral_status=$(check_status \"mistral\")\n    local total_cost=0\n\n    if [ \"$flux_status\" = \"running\" ]; then\n        local details=$(get_instance_details \"flux\")\n        local instance_type=$(echo \"$details\" | cut -d'|' -f1 | cut -f2)\n\n        case \"$instance_type\" in\n            \"g4dn.xlarge\")\n                echo \"🎨 Flux.1 Dev: ~$0.53/hour (g4dn.xlarge)\"\n                total_cost=$(echo \"$total_cost + 0.53\" | bc -l)\n                ;;\n            \"g5.xlarge\")\n                echo \"🎨 Flux.1 Dev: ~$1.01/hour (g5.xlarge)\"\n                total_cost=$(echo \"$total_cost + 1.01\" | bc -l)\n                ;;\n        esac\n    else\n        echo \"🎨 Flux.1 Dev: $0.00/hour (stopped)\"\n    fi\n\n    if [ \"$mistral_status\" = \"running\" ]; then\n        local details=$(get_instance_details \"mistral\")\n        local instance_type=$(echo \"$details\" | cut -d'|' -f1 | cut -f2)\n\n        case \"$instance_type\" in\n            \"g4dn.xlarge\")\n                echo \"💬 Mistral Chat: ~$0.53/hour\"\n                total_cost=$(echo \"$total_cost + 0.53\" | bc -l)\n                ;;\n            \"g5.xlarge\")\n                echo \"💬 Mistral Chat: ~$1.01/hour\"\n                total_cost=$(echo \"$total_cost + 1.01\" | bc -l)\n                ;;\n        esac\n    else\n        echo \"💬 Mistral Chat: $0.00/hour (stopped)\"\n    fi\n\n    echo \"\"\n    echo \"📊 Total Base Cost: ~$$(printf \"%.2f\" $total_cost)/hour\"\n    if [ \"$mistral_status\" = \"running\" ]; then\n        echo \"   (base model costs only)\"\n    fi\n    echo \"\"\n}\n\n# Start service\nstart_service() {\n    local service=\"$1\"\n\n    case \"$service\" in\n        \"flux\")\n            log \"🎨 Starting Flux.1 Dev...\"\n            ./start-flux-dev.sh\n            ;;\n        \"mistral\")\n            log \"💬 Starting Mistral...\"\n            ./start-mistral-simple.sh\n            ;;\n        \"all\")\n            log \"🚀 Starting all AI services...\"\n            ./start-flux-dev.sh\n            echo \"\"\n            ./start-mistral-simple.sh\n            ;;\n        *)\n            error \"Unknown service: $service. Use 'flux', 'mistral', or 'all'\"\n            ;;\n    esac\n}\n\n# Stop service\nstop_service() {\n    local service=\"$1\"\n\n    case \"$service\" in\n        \"flux\")\n            log \"🎨 Stopping Flux.1 Dev...\"\n            ./stop-flux-dev.sh\n            ;;\n        \"mistral\")\n            log \"💬 Stopping Mistral...\"\n            ./stop-mistral-simple.sh\n            ;;\n        \"all\")\n            log \"🛑 Stopping all AI services...\"\n            ./stop-flux-dev.sh\n            echo \"\"\n            ./stop-mistral-simple.sh\n            ;;\n        *)\n            error \"Unknown service: $service. Use 'flux', 'mistral', or 'all'\"\n            ;;\n    esac\n}\n\n# Main function\nmain() {\n    if [ $# -eq 0 ]; then\n        usage\n        exit 1\n    fi\n\n    local command=\"$1\"\n    local service=\"${2:-all}\"\n\n    case \"$command\" in\n        \"start\")\n            start_service \"$service\"\n            ;;\n        \"stop\")\n            stop_service \"$service\"\n            ;;\n        \"status\")\n            show_status\n            ;;\n        \"costs\")\n            show_costs\n            ;;\n        \"help\"|\"-h\"|\"--help\")\n            usage\n            ;;\n        *)\n            error \"Unknown command: $command\"\n            usage\n            exit 1\n            ;;\n    esac\n}\n\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/scripts/ai-services.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\necho \"🔧 Setting up Flux API as systemd service...\"\n\n# Copy service file\nsudo cp flux-api.service /etc/systemd/system/\n\n# Set proper permissions\nsudo chmod 644 /etc/systemd/system/flux-api.service\n\n# Create log directory\nsudo mkdir -p /var/log/flux\nsudo chown ubuntu:ubuntu /var/log/flux\n\n# Reload systemd\nsudo systemctl daemon-reload\n\n# Enable service for startup\nsudo systemctl enable flux-api\n\necho \"✅ Flux API service installed and enabled for startup\"\necho \"📋 Service commands:\"\necho \"  sudo systemctl start flux-api     # Start service\"\necho \"  sudo systemctl stop flux-api      # Stop service\"\necho \"  sudo systemctl status flux-api    # Check status\"\necho \"  sudo journalctl -u flux-api -f    # View logs\"\n\n# Check if service can start\necho \"🧪 Testing service startup...\"\nif sudo systemctl start flux-api; then\n    echo \"✅ Service started successfully\"\n    sleep 5\n    sudo systemctl status flux-api --no-pager\nelse\n    echo \"❌ Service failed to start\"\n    sudo journalctl -u flux-api --no-pager -l\n    exit 1\nfi\n\necho \"🎉 Flux API service setup complete!\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/scripts/setup_flux_service.sh", "category": "infrastructure", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# PRODUCTION AMI AVAILABLE: ami-0e6b0570006182a68\n# For production use, launch directly from AMI instead of running this script:\n# aws ec2 run-instances --image-id ami-0e6b0570006182a68 --instance-type g5.4xlarge --key-name mistral-base\n\n# Load environment variables\nif [[ -f .env ]]; then\n  # shellcheck disable=SC1091\n  source .env\nelse\n  echo \"❌ .env file not found\" >&2\n  exit 1\nfi\n\ndie() { echo \"❌ $*\" >&2; exit 1; }\n\n#######################################\n# 0. Configuration & Secrets\n#######################################\nREGION=\"${AWS_REGION:-us-west-2}\"\nINSTANCE_TYPE=\"g5.4xlarge\"  # Updated: g5.2xlarge causes OOM, g5.4xlarge required\nPROJECT_TAG=\"FluxDeploy\"\nOWNER_TAG=\"$(whoami)\"\nVOLUME_SIZE=500  # GiB\nKEY_NAME=\"mistral-base\"\nREMOTE_CHECK_SCRIPT='/tmp/flux_sanity.sh'\nS3_MODEL_PATH=\"s3://flux-model-cache-1752234728/flux-complete/\"\nDLAMI_OWNER=\"<ACCOUNT_ID>\"      # AWS DLAMI publishing account\n# SSH username for this DLAMI (ubuntu instead of ec2-user)\nREMOTE_USER=\"ubuntu\"\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nKEY_PATH=\"$SCRIPT_DIR/${KEY_NAME}.pem\"\n[[ -f \"$KEY_PATH\" ]] || die \"SSH key not found at $KEY_PATH\"\n\n# SSH username for this DLAMI (ubuntu instead of ec2-user)\nREMOTE_USER=\"ubuntu\"\n\n\n\n#######################################\n# 1. vCPU Quota Pre-Flight\n#######################################\npreflight() {\n  echo \"🔍 1/6  vCPU quota pre-flight…\"\n  local requested=8 used total\n  used=$(aws ec2 describe-instances --region \"$REGION\" \\\n    --filters Name=instance-state-name,Values=pending,running Name=tag:Project,Values=\"$PROJECT_TAG\" \\\n    --query 'Reservations[].Instances[].CpuOptions.CoreCount' --output text \\\n    | awk 'BEGIN{sum=0}!/^(None)?$/{sum+=$1}END{print sum}')\n  used=${used:-0}\n  total=$(aws service-quotas get-service-quota --service-code ec2 --quota-code L-1216C47A --region \"$REGION\" \\\n    --query 'ServiceQuota.Value' --output text 2>/dev/null || echo 64)\n  [[ \"$total\" == \"None\" ]] && total=64\n  if (( used + requested > total )); then\n    die \"vCPU limit ($total) insufficient (used=$used, req=$requested)\"\n  fi\n}\n\n#######################################\n# 2. Locate GPU PyTorch DLAMI\n#######################################\nlocate_dlami() {\n  echo \"🔍 2/6  Locating GPU PyTorch DLAMI…\"\n  local ssm\n  ssm=\"/aws/service/deeplearning/ami/x86_64/oss-nvidia-driver-gpu-pytorch-2.7-ubuntu-22.04/latest/ami-id\"\n  AMI_ID=$(aws ssm get-parameter --name \"$ssm\" --region \"$REGION\" --query 'Parameter.Value' --output text) || die \"SSM query failed\"\n  [[ \"$AMI_ID\" =~ ^ami- ]] || die \"Invalid AMI ID: $AMI_ID\"\n  echo \"✅ Found DLAMI: $AMI_ID\"\n}\n\n#######################################\n# 3. Locate & Health-Check Existing Instance\n#######################################\nfind_existing() {\n  echo \"🔍 3/6  Checking for existing instance…\"\n  local json\n  json=$(aws ec2 describe-instances --region \"$REGION\" \\\n    --filters Name=tag:Project,Values=\"$PROJECT_TAG\" Name=instance-state-name,Values=pending,running \\\n    --query 'Reservations[].Instances[].{Id:InstanceId,IP:PublicIpAddress}' --output json)\n  INSTANCE_ID=$(jq -r '.[0].Id // empty' <<<\"$json\")\n  PUBLIC_IP=$(jq -r '.[0].IP // empty' <<<\"$json\")\n  # --- detect actual key-pair name on the instance ---\nINSTANCE_KEY_NAME=$(aws ec2 describe-instances \\\n  --instance-ids \"$INSTANCE_ID\" \\\n  --region \"$REGION\" \\\n  --query 'Reservations[0].Instances[0].KeyName' \\\n  --output text)\n\necho \"🔍 3.1/6  Instance $INSTANCE_ID uses key-pair: $INSTANCE_KEY_NAME\"\n\nif [[ \"$INSTANCE_KEY_NAME\" != \"$KEY_NAME\" ]]; then\n  echo \"⚠️ 3.2/6  Key-pair mismatch! Updating to use '$INSTANCE_KEY_NAME'.pem\"\n  KEY_NAME=\"$INSTANCE_KEY_NAME\"\n  KEY_PATH=\"$SCRIPT_DIR/${KEY_NAME}.pem\"\n  [[ -f \"$KEY_PATH\" ]] || die \"Private key not found at $KEY_PATH for instance key-pair '$KEY_NAME'\"\nfi\n\necho \"✅ 3.3/6  Using SSH key: $KEY_PATH\"\n\n  if [[ -n \"$INSTANCE_ID\" ]]; then\n    echo \"✅ Found instance $INSTANCE_ID at $PUBLIC_IP. Repairing/updating…\"\n    # Copy .env file for AWS credentials\n    scp -o StrictHostKeyChecking=no -i \"$KEY_PATH\" .env ${REMOTE_USER}@\"$PUBLIC_IP\":/tmp/.env\n    ssh -o StrictHostKeyChecking=no -i \"$KEY_PATH\" ${REMOTE_USER}@\"$PUBLIC_IP\" bash -s \"$S3_MODEL_PATH\" << 'REPAIR'\nset -euo pipefail\n# Set up AWS credentials file\nmkdir -p ~/.aws\ngrep AWS_ACCESS_KEY_ID /tmp/.env | cut -d= -f2 > /tmp/access_key\ngrep AWS_SECRET_ACCESS_KEY /tmp/.env | cut -d= -f2 > /tmp/secret_key\ncat > ~/.aws/credentials << EOF\n[default]\naws_access_key_id = $(cat /tmp/access_key)\naws_secret_access_key = $(cat /tmp/secret_key)\nEOF\ncat > ~/.aws/config << EOF\n[default]\nregion = us-west-2\noutput = json\nEOF\nrm /tmp/access_key /tmp/secret_key\nS3_MODEL_PATH=\"$1\"\nsource /opt/pytorch/bin/activate\n# Fix XFormers compatibility\npip uninstall xformers -y\npip install xformers==0.0.29.post2 --no-deps\nsudo mkdir -p /opt/models/flux\nsudo chown -R ubuntu:ubuntu /opt/models\n\n# Check if model files already exist in expected structure\necho \"🔍 Checking for model files in expected structure: /opt/models/flux/model_index.json\"\nif [[ -f \"/opt/models/flux/model_index.json\" ]]; then\n    echo \"✅ Model files already in correct structure\"\nelse\n    echo \"❌ Model files not in expected structure\"\n    # Check if model exists in HuggingFace cache structure\n    hf_model_path=\"/opt/models/flux/models--black-forest-labs--FLUX.1-dev/snapshots/3de623fc3c33e44ffbe2bad470d0f45bccf2eb21\"\n    echo \"🔍 Checking for HuggingFace cache: $hf_model_path/model_index.json\"\n    if [[ -f \"$hf_model_path/model_index.json\" ]]; then\n        echo \"✅ Found model in HuggingFace cache structure\"\n        echo \"🔄 Restructuring existing model files from HuggingFace cache\"\n        # Copy files from HF cache to expected structure\n        cp -r \"$hf_model_path\"/* /opt/models/flux/\n        echo \"🧹 Cleaning up old HuggingFace cache structure\"\n        # Clean up old structure\n        rm -rf /opt/models/flux/models--black-forest-labs--FLUX.1-dev\n        rm -rf /opt/models/flux/.locks\n        rm -rf /opt/models/flux/blobs\n    else\n        echo \"❌ No model found in HuggingFace cache either\"\n        echo \"⬇️ Downloading model from S3\"\n        aws s3 sync \"$S3_MODEL_PATH/models--black-forest-labs--FLUX.1-dev/snapshots/3de623fc3c33e44ffbe2bad470d0f45bccf2eb21/\" /opt/models/flux --region us-west-2\n    fi\nfi\n\n# Verify specific files needed by health check exist\nrequired_files=(\"model_index.json\" \"transformer/config.json\" \"text_encoder/config.json\" \"vae/config.json\")\nmissing_files=()\nfor file in \"${required_files[@]}\"; do\n    if [[ ! -f \"/opt/models/flux/$file\" ]]; then\n        missing_files+=(\"$file\")\n    fi\ndone\nif [[ ${#missing_files[@]} -eq 0 ]]; then\n    echo \"✅ Model files ready - all required files present\"\nelse\n    echo \"❌ Model setup incomplete - missing files: ${missing_files[*]}\"\n    echo \"Files in /opt/models/flux: $(find /opt/models/flux -type f | head -10)\"\n    exit 1\nfi\nREPAIR\n\n    # Now run health check AFTER repair\n    echo \"🔍 Running health check after setup…\"\n    cat << 'EOF' > \"$REMOTE_CHECK_SCRIPT\"\n#!/usr/bin/env bash\nset -euo pipefail\nsource /opt/pytorch/bin/activate || exit 1\n\n# Diagnostic collection function\ncollect_failure_diagnostics() {\n    local failure_type=\"$1\"\n    echo \"🔍 Collecting diagnostics for: $failure_type\"\n\n    echo \"=== FAILURE DIAGNOSTICS ===\"\n    echo \"Failure Type: $failure_type\"\n    echo \"Time: $(date)\"\n    echo\n\n    echo \"--- Last 50 lines of health check log ---\"\n    tail -50 /tmp/flux_health.log 2>/dev/null || echo \"No log available\"\n    echo\n\n    echo \"--- GPU Status ---\"\n    nvidia-smi 2>/dev/null || echo \"nvidia-smi failed\"\n    echo\n\n    echo \"--- System Memory ---\"\n    free -h 2>/dev/null || echo \"free command failed\"\n    echo\n\n    echo \"--- Recent kernel messages ---\"\n    sudo dmesg 2>/dev/null | tail -20 || echo \"dmesg not accessible\"\n    echo\n\n    echo \"--- Python processes ---\"\n    ps aux | grep python 2>/dev/null || echo \"No python processes\"\n    echo\n\n    echo \"=== END DIAGNOSTICS ===\"\n}\n\n# Start health check in background and monitor\nscreen -dmS flux_health bash -c '\npython - << \"PY\" 2>&1 | tee /tmp/flux_health.log\nimport importlib.util,sys,pathlib\nmods=[\"torch\",\"diffusers\",\"transformers\",\"accelerate\",\"xformers\"]\nif any(importlib.util.find_spec(m) is None for m in mods): sys.exit(1)\n\n# Test image generation\nfrom diffusers import FluxPipeline\nimport torch\npipe = FluxPipeline.from_pretrained(\"/opt/models/flux/\", torch_dtype=torch.float16, local_files_only=True)\npipe.enable_model_cpu_offload()\npipe.safety_checker = None  # Remove NSFW filter\nimage = pipe(\"test\", height=512, width=512, num_inference_steps=4).images[0]\nprint(\"✅ Image generation test passed - NSFW filter removed\")\nPY\necho \"Exit code: $?\" >> /tmp/flux_health.log\n'\n\n# Monitor the health check process with comprehensive logic\nstart_time=$(date +%s)\nlast_log_size=0\nstuck_counter=0\nmax_runtime=900  # 15 minutes max\n\necho \"🔍 Starting comprehensive health monitoring...\"\n\nwhile true; do\n    current_time=$(date +%s)\n    elapsed=$((current_time - start_time))\n\n    # Check if process completed normally\n    if ! screen -list | grep -q flux_health; then\n        if tail -1 /tmp/flux_health.log 2>/dev/null | grep -q \"Exit code: 0\"; then\n            echo \"✅ Health check passed\"\n            exit 0\n        else\n            echo \"❌ Health check failed\"\n            collect_failure_diagnostics \"process_exit_failure\"\n            exit 1\n        fi\n    fi\n\n    # FAST FAIL CONDITIONS (check every iteration)\n\n    # 1. Check for OOM in dmesg (skip if no permission)\n    if sudo dmesg 2>/dev/null | tail -20 | grep -qi \"out of memory\\|killed process.*python\"; then\n        echo \"❌ OOM detected in system logs\"\n        collect_failure_diagnostics \"oom_detected\"\n        screen -S flux_health -X quit 2>/dev/null || true\n        exit 1\n    fi\n\n    # 2. Check for CUDA errors (skip if no permission)\n    if sudo dmesg 2>/dev/null | tail -10 | grep -qi \"cuda\\|nvidia.*error\"; then\n        echo \"❌ CUDA/driver errors detected\"\n        collect_failure_diagnostics \"cuda_error\"\n        screen -S flux_health -X quit 2>/dev/null || true\n        exit 1\n    fi\n\n    # 3. Check if Python process crashed\n    if ! pgrep -f \"python.*flux\" > /dev/null; then\n        if [[ -f /tmp/flux_health.log ]] && [[ $(wc -l < /tmp/flux_health.log) -gt 0 ]]; then\n            echo \"❌ Python process crashed unexpectedly\"\n            collect_failure_diagnostics \"process_crash\"\n            exit 1\n        fi\n    fi\n\n    # LOG ANALYSIS\n    if [[ -f /tmp/flux_health.log ]]; then\n        current_log_size=$(wc -c < /tmp/flux_health.log)\n\n        # Check for error accumulation\n        error_count=$(grep -c \"ERROR\\|WARN\\|Failed\\|Exception\\|Traceback\" /tmp/flux_health.log 2>/dev/null || echo 0)\n        if [[ $error_count -gt 10 ]]; then\n            echo \"❌ High error count detected ($error_count errors)\"\n            collect_failure_diagnostics \"error_accumulation\"\n            screen -S flux_health -X quit 2>/dev/null || true\n            exit 1\n        fi\n\n        # Check for infinite loops (same line repeated many times)\n        max_repeats=$(tail -30 /tmp/flux_health.log | sort | uniq -c | sort -nr | head -1 | awk '{print $1}' 2>/dev/null || echo 0)\n        if [[ $max_repeats -gt 15 ]]; then\n            echo \"❌ Infinite loop detected (line repeated $max_repeats times)\"\n            collect_failure_diagnostics \"infinite_loop\"\n            screen -S flux_health -X quit 2>/dev/null || true\n            exit 1\n        fi\n\n        # Progress detection\n        if [[ $current_log_size -gt $last_log_size ]]; then\n            stuck_counter=0  # Reset stuck counter on progress\n            echo \"📊 Progress detected (log: ${current_log_size} bytes, elapsed: ${elapsed}s)\"\n        else\n            ((stuck_counter++))\n            echo \"⏳ No log progress (stuck count: $stuck_counter, elapsed: ${elapsed}s)\"\n        fi\n\n        last_log_size=$current_log_size\n    else\n        if [[ $elapsed -gt 120 ]]; then  # No log file after 2 minutes\n            echo \"❌ No log file created after 2 minutes\"\n            collect_failure_diagnostics \"no_log_file\"\n            screen -S flux_health -X quit 2>/dev/null || true\n            exit 1\n        fi\n    fi\n\n    # GPU ANALYSIS\n    gpu_info=$(nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits 2>/dev/null || echo \"0,0,0\")\n    gpu_mem_used=$(echo \"$gpu_info\" | cut -d',' -f1 | tr -d ' \\n')\n    gpu_mem_total=$(echo \"$gpu_info\" | cut -d',' -f2 | tr -d ' \\n')\n    gpu_util=$(echo \"$gpu_info\" | cut -d',' -f3 | tr -d ' \\n')\n\n    # Ensure numeric values (default to 0 if empty/invalid)\n    gpu_mem_used=${gpu_mem_used:-0}\n    gpu_mem_total=${gpu_mem_total:-0}\n    gpu_util=${gpu_util:-0}\n\n    # Check for GPU memory allocation failure\n    if [[ $gpu_mem_used -eq 0 ]] && [[ $elapsed -gt 300 ]]; then  # No GPU memory after 5 minutes\n        echo \"❌ No GPU memory allocated after 5 minutes\"\n        collect_failure_diagnostics \"no_gpu_allocation\"\n        screen -S flux_health -X quit 2>/dev/null || true\n        exit 1\n    fi\n\n    # STUCK DETECTION (no progress for 3 minutes = 12 iterations of 15s)\n    if [[ $stuck_counter -gt 12 ]]; then\n        # But allow if GPU is actively computing\n        if [[ ${gpu_util:-0} -gt 5 ]]; then\n            echo \"🔄 No log progress but GPU active (${gpu_util}% util) - continuing...\"\n            stuck_counter=0  # Reset since GPU is working\n        else\n            echo \"❌ Process stuck (no progress for 3+ minutes, GPU idle)\"\n            collect_failure_diagnostics \"stuck_process\"\n            screen -S flux_health -X quit 2>/dev/null || true\n            exit 1\n        fi\n    fi\n\n    # MAXIMUM RUNTIME CHECK (only if genuinely stuck)\n    if [[ $elapsed -gt $max_runtime ]]; then\n        echo \"❌ Maximum runtime exceeded (${max_runtime}s) - forcing termination\"\n        collect_failure_diagnostics \"max_runtime_exceeded\"\n        screen -S flux_health -X quit 2>/dev/null || true\n        exit 1\n    fi\n\n    # Show current status\n    last_log_line=$(tail -1 /tmp/flux_health.log 2>/dev/null | head -c 80 || echo \"Starting...\")\n    echo \"📊 Status: GPU ${gpu_mem_used}MB/${gpu_mem_total}MB (${gpu_util}% util) | ${last_log_line}\"\n\n    sleep 15\ndone\nEOF\n    chmod +x \"$REMOTE_CHECK_SCRIPT\"\n    scp -o StrictHostKeyChecking=no -i \"$KEY_PATH\" \"$REMOTE_CHECK_SCRIPT\" ${REMOTE_USER}@\"$PUBLIC_IP\":$REMOTE_CHECK_SCRIPT >/dev/null\n    if ssh -o StrictHostKeyChecking=no -i \"$KEY_PATH\" ${REMOTE_USER}@\"$PUBLIC_IP\" \"bash $REMOTE_CHECK_SCRIPT\"; then\n      echo \"🎉 Deployment successful! SSH: ssh -i $KEY_PATH ${REMOTE_USER}@$PUBLIC_IP\"\n      exit 0\n    else\n      echo \"❌ Health check failed after repair\"\n      exit 1\n    fi\n  fi\n}\n\n#######################################\n# 4. Launch New Instance\n#######################################\nlaunch_new() {\n  echo \"🚀 4/6  No healthy instance. Launching new one…\"\n  USER_DATA=$(base64 << 'CLOUD'\n#!/bin/bash\nset -euo pipefail\nexec > >(tee /var/log/flux-bootstrap.log) 2>&1\napt-get update && apt-get install -y git jq\nsource /opt/pytorch/bin/activate\npip install --upgrade pip setuptools wheel\npip install diffusers>=0.34.0 transformers>=4.44 accelerate>=0.30 safetensors>=0.8 ninja triton xformers\ngit clone https://github.com/black-forest-labs/flux /opt/flux\npip install -e \"/opt/flux[all]\"\nmkdir -p /opt/models/flux\naws s3 sync $S3_MODEL_PATH /opt/models/flux --region $REGION\nCLOUD\n)\n  local resp\n  resp=$(aws ec2 run-instances --region \"$REGION\" --image-id \"$AMI_ID\" \\\n    --instance-type \"$INSTANCE_TYPE\" --key-name \"$KEY_NAME\" \\\n    --block-device-mappings '[{\"DeviceName\":\"/dev/sda1\",\"Ebs\":{\"VolumeSize\":'$VOLUME_SIZE',\"VolumeType\":\"gp3\"}}]' \\\n    --tag-specifications '[{\"ResourceType\":\"instance\",\"Tags\":[{\"Key\":\"Project\",\"Value\":\"'$PROJECT_TAG'\"},{\"Key\":\"Owner\",\"Value\":\"'$OWNER_TAG'\"}]}]' \\\n    --user-data \"$USER_DATA\")\n  INSTANCE_ID=$(jq -r '.Instances[0].InstanceId' <<<\"$resp\")\n  echo \"🔍 5/6  Waiting for instance $INSTANCE_ID to run…\"\n  aws ec2 wait instance-running --instance-ids \"$INSTANCE_ID\" --region \"$REGION\"\n  PUBLIC_IP=$(aws ec2 describe-instances --instance-ids \"$INSTANCE_ID\" --region \"$REGION\" --query 'Reservations[0].Instances[0].PublicIpAddress' --output text)\n  echo \"🔍 6/6  New instance ready at $PUBLIC_IP\"\n  echo \"🎯 SSH: ssh -i $KEY_PATH ${REMOTE_USER}@$PUBLIC_IP\"\n}\n\nmain() {\n  preflight\n  locate_dlami\n  find_existing\n  launch_new\n}\n\nmain\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/infrastructure/flux_one_shot.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Auto-retry Mistral deployment script\n# Runs every hour until successful, then notifies you\n\nset -e\n\n# Configuration\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nDEPLOY_SCRIPT=\"$SCRIPT_DIR/deploy-mistral.sh\"\nLOG_FILE=\"$SCRIPT_DIR/auto-deploy.log\"\nSTATUS_FILE=\"$SCRIPT_DIR/.deployment-status\"\nMAX_ATTEMPTS=168  # 7 days worth of hourly attempts\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Logging function\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\n# Send notification function\nsend_notification() {\n    local status=\"$1\"\n    local message=\"$2\"\n    local instance_id=\"$3\"\n    local public_ip=\"$4\"\n\n    # Multiple notification methods\n\n    # Method 1: Email via AWS SES (if configured)\n    if command -v aws &> /dev/null; then\n        aws ses send-email \\\n            --source \"<EMAIL>\" \\\n            --destination ToAddresses=\"<EMAIL>\" \\\n            --message \"Subject={Data='Mistral Deployment $status'},Body={Text={Data='$message\\n\\nInstance ID: $instance_id\\nPublic IP: $public_ip\\n\\nTime: $(date)'}}\" \\\n            2>/dev/null || log \"Email notification failed (SES not configured)\"\n    fi\n\n    # Method 2: Slack webhook (if you have one)\n    SLACK_WEBHOOK=\"${SLACK_WEBHOOK_URL:-}\"\n    if [ -n \"$SLACK_WEBHOOK\" ]; then\n        curl -X POST -H 'Content-type: application/json' \\\n            --data \"{\\\"text\\\":\\\"🤖 Mistral Deployment $status\\\\n$message\\\\nInstance: $instance_id\\\\nIP: $public_ip\\\"}\" \\\n            \"$SLACK_WEBHOOK\" 2>/dev/null || log \"Slack notification failed\"\n    fi\n\n    # Method 3: System notification (local desktop)\n    if command -v notify-send &> /dev/null; then\n        notify-send \"Mistral Deployment $status\" \"$message\"\n    fi\n\n    # Method 4: Write to a status file you can monitor\n    echo \"STATUS: $status\" > \"$STATUS_FILE\"\n    echo \"MESSAGE: $message\" >> \"$STATUS_FILE\"\n    echo \"INSTANCE_ID: $instance_id\" >> \"$STATUS_FILE\"\n    echo \"PUBLIC_IP: $public_ip\" >> \"$STATUS_FILE\"\n    echo \"TIMESTAMP: $(date)\" >> \"$STATUS_FILE\"\n\n    log \"Notification sent: $status - $message\"\n}\n\n# Check if already deployed\ncheck_existing_deployment() {\n    if [ -f \".mistral-base-instance-id\" ]; then\n        local existing_id=$(cat .mistral-base-instance-id)\n        # Check both regions\n        for region in us-east-1 us-west-2; do\n            local state=$(aws ec2 describe-instances --region \"$region\" --instance-ids \"$existing_id\" --query 'Reservations[0].Instances[0].State.Name' --output text 2>/dev/null || echo \"None\")\n\n            if [ \"$state\" = \"running\" ]; then\n                local public_ip=$(aws ec2 describe-instances --region \"$region\" --instance-ids \"$existing_id\" --query 'Reservations[0].Instances[0].PublicIpAddress' --output text 2>/dev/null || echo \"None\")\n                log \"Found existing running instance in $region: $existing_id (IP: $public_ip)\"\n                send_notification \"ALREADY RUNNING\" \"Mistral base model instance was already deployed and running\" \"$existing_id\" \"$public_ip\"\n                exit 0\n            fi\n        done\n    fi\n}\n\n# Single deployment attempt\nattempt_deployment() {\n    local attempt_num=\"$1\"\n\n    log \"=== DEPLOYMENT ATTEMPT #$attempt_num ===\"\n    log \"Starting deployment attempt at $(date)\"\n\n    # Run the deployment script and capture output\n    if timeout 600 \"$DEPLOY_SCRIPT\" &>> \"$LOG_FILE\"; then\n        log \"✅ DEPLOYMENT SUCCESSFUL!\"\n\n        # Get instance details\n        if [ -f \".mistral-base-instance-id\" ]; then\n            local instance_id=$(cat .mistral-base-instance-id)\n            # Find which region the instance is in\n            local region=\"\"\n            for r in us-east-1 us-west-2; do\n                if aws ec2 describe-instances --region \"$r\" --instance-ids \"$instance_id\" &>/dev/null; then\n                    region=\"$r\"\n                    break\n                fi\n            done\n\n            local instance_info=$(aws ec2 describe-instances --region \"$region\" --instance-ids \"$instance_id\" --query 'Reservations[0].Instances[0].[PublicIpAddress,InstanceType,State.Name]' --output text 2>/dev/null || echo \"None None None\")\n            local public_ip=$(echo \"$instance_info\" | cut -f1)\n            local instance_type=$(echo \"$instance_info\" | cut -f2)\n            local state=$(echo \"$instance_info\" | cut -f3)\n\n            local success_message=\"Mistral base model deployment successful after $attempt_num attempts!\nInstance Type: $instance_type\nState: $state\nRegion: $region\nWeb Interface: http://$public_ip\nAPI Endpoint: http://$public_ip/api/v1/completions\nSSH: ssh -i ~/.ssh/mistral-base-key.pem ubuntu@$public_ip\n\nThe uncensored Mistral 7B v0.3 base model is now being set up.\nInitial setup takes 15-30 minutes. Check progress:\nssh -i ~/.ssh/mistral-base-key.pem ubuntu@$public_ip 'tail -f /var/log/user-data.log'\"\n\n            send_notification \"SUCCESS\" \"$success_message\" \"$instance_id\" \"$public_ip\"\n            log \"$success_message\"\n            return 0\n        else\n            warn \"Deployment script succeeded but no instance ID found\"\n            return 1\n        fi\n    else\n        warn \"❌ Deployment attempt #$attempt_num failed\"\n        return 1\n    fi\n}\n\n# Main retry loop\nmain() {\n    log \"Starting auto-deployment monitoring at $(date)\"\n    log \"Will attempt deployment every hour for up to $MAX_ATTEMPTS attempts\"\n    log \"Logs: $LOG_FILE\"\n    log \"Status: $STATUS_FILE\"\n\n    # Check if already deployed\n    check_existing_deployment\n\n    local attempt=1\n\n    while [ $attempt -le $MAX_ATTEMPTS ]; do\n        log \"--- Attempt $attempt of $MAX_ATTEMPTS ---\"\n\n        if attempt_deployment \"$attempt\"; then\n            log \"Deployment successful! Exiting auto-retry loop.\"\n            exit 0\n        fi\n\n        if [ $attempt -lt $MAX_ATTEMPTS ]; then\n            log \"Attempt $attempt failed. Waiting 1 hour before next attempt...\"\n            log \"Next attempt will be at $(date -d '+1 hour')\"\n\n            # Sleep for 1 hour (3600 seconds)\n            sleep 3600\n        fi\n\n        ((attempt++))\n    done\n\n    # All attempts failed\n    local failure_message=\"All $MAX_ATTEMPTS deployment attempts failed over 7 days. AWS GPU capacity may be severely constrained. Consider:\n1. Requesting quota in different region (us-west-2)\n2. Using CPU instance temporarily\n3. Trying during off-peak hours manually\"\n\n    error \"$failure_message\"\n    send_notification \"FAILED\" \"$failure_message\" \"None\" \"None\"\n    exit 1\n}\n\n# Handle script interruption\ncleanup() {\n    log \"Auto-deployment script interrupted. Status saved to $STATUS_FILE\"\n    exit 1\n}\n\ntrap cleanup INT TERM\n\n# Run main function\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/infrastructure/auto-deploy-mistral.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Mistral Deployment Script for us-west-2 (Oregon)\n# Uses your approved 8 vCPU Spot quota\n\nset -e\n\n# Configuration\nREGION=\"us-west-2\"\nPROJECT_NAME=\"mistral-uswest2\"\nINSTANCE_TYPES=(\"g4dn.xlarge\" \"g5.xlarge\")  # 4 vCPUs each, saving 4 vCPUs for SDXL\nPRODUCT_CODE=\"prod-md5sjr2k4sdu6\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Logging function\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Find Ubuntu AMI for base model installation in us-west-2\nfind_base_ami() {\n    log \"Looking for Ubuntu 22.04 LTS AMI in us-west-2...\"\n\n    # Try to find AMI by product code\n    AMI_ID=$(aws ec2 describe-images \\\n        --region $REGION \\\n        --owners <ACCOUNT_ID> \\\n        --filters \"Name=product-code,Values=${PRODUCT_CODE}\" \\\n        --query 'Images[0].ImageId' \\\n        --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$AMI_ID\" = \"None\" ] || [ -z \"$AMI_ID\" ]; then\n        # Try to find by name pattern\n        log \"Searching by name pattern in us-west-2...\"\n        AMI_ID=$(aws ec2 describe-images \\\n            --region $REGION \\\n            --owners <ACCOUNT_ID> \\\n            --filters \"Name=name,Values=*mistral*7b*\" \"Name=state,Values=available\" \\\n            --query 'Images | sort_by(@, &CreationDate) | [-1].ImageId' \\\n            --output text 2>/dev/null || echo \"None\")\n    fi\n\n    if [ \"$AMI_ID\" = \"None\" ] || [ -z \"$AMI_ID\" ]; then\n        error \"Could not find Ubuntu AMI in us-west-2.\"\n    fi\n\n    # Get AMI details\n    AMI_NAME=$(aws ec2 describe-images \\\n        --region $REGION \\\n        --image-ids $AMI_ID \\\n        --query 'Images[0].Name' \\\n        --output text)\n\n    log \"Found AMI: $AMI_ID\"\n    log \"AMI Name: $AMI_NAME\"\n\n    export AMI_ID\n}\n\n# Setup network configuration in us-west-2\nsetup_network() {\n    log \"Setting up network configuration in us-west-2...\"\n\n    # Use default VPC in us-west-2\n    VPC_ID=$(aws ec2 describe-vpcs \\\n        --region $REGION \\\n        --filters \"Name=is-default,Values=true\" \\\n        --query 'Vpcs[0].VpcId' \\\n        --output text)\n\n    if [ \"$VPC_ID\" = \"None\" ]; then\n        error \"No default VPC found in us-west-2. Please create a VPC first.\"\n    fi\n\n    # Get all public subnets in default VPC (for multiple AZ fallback)\n    SUBNETS=$(aws ec2 describe-subnets \\\n        --region $REGION \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=default-for-az,Values=true\" \\\n        --query 'Subnets[*].[SubnetId,AvailabilityZone]' \\\n        --output text)\n\n    # Store subnets for fallback\n    echo \"$SUBNETS\" > /tmp/available_subnets_uswest2.txt\n\n    log \"Using VPC: $VPC_ID\"\n    log \"Available subnets in us-west-2:\"\n    while read -r subnet_line; do\n        if [ -n \"$subnet_line\" ]; then\n            subnet_id=$(echo \"$subnet_line\" | cut -f1)\n            subnet_az=$(echo \"$subnet_line\" | cut -f2)\n            log \"  - $subnet_id ($subnet_az)\"\n        fi\n    done < /tmp/available_subnets_uswest2.txt\n\n    export VPC_ID\n}\n\n# Create security group in us-west-2\nsetup_security_group() {\n    log \"Setting up security group in us-west-2...\"\n\n    # Get your public IP\n    YOUR_IP=$(curl -s ipinfo.io/ip 2>/dev/null || echo \"0.0.0.0\")\n    if [ \"$YOUR_IP\" = \"0.0.0.0\" ]; then\n        warn \"Could not determine your IP. Using 0.0.0.0/0 (not recommended for production)\"\n        YOUR_IP=\"0.0.0.0/0\"\n    else\n        YOUR_IP=\"$YOUR_IP/32\"\n        log \"Detected your IP: $YOUR_IP\"\n    fi\n\n    # Check if security group exists\n    SG_ID=$(aws ec2 describe-security-groups \\\n        --region $REGION \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=group-name,Values=${PROJECT_NAME}-sg\" \\\n        --query 'SecurityGroups[0].GroupId' \\\n        --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$SG_ID\" = \"None\" ]; then\n        log \"Creating security group in us-west-2...\"\n        SG_ID=$(aws ec2 create-security-group \\\n            --region $REGION \\\n            --group-name \"${PROJECT_NAME}-sg\" \\\n            --description \"Security group for ${PROJECT_NAME} in us-west-2\" \\\n            --vpc-id $VPC_ID \\\n            --query 'GroupId' \\\n            --output text)\n\n        # Add rules for SSH and API access\n        aws ec2 authorize-security-group-ingress \\\n            --region $REGION \\\n            --group-id $SG_ID \\\n            --protocol tcp \\\n            --port 22 \\\n            --cidr $YOUR_IP\n\n        aws ec2 authorize-security-group-ingress \\\n            --region $REGION \\\n            --group-id $SG_ID \\\n            --protocol tcp \\\n            --port 8000 \\\n            --cidr $YOUR_IP\n\n        aws ec2 authorize-security-group-ingress \\\n            --region $REGION \\\n            --group-id $SG_ID \\\n            --protocol tcp \\\n            --port 8080 \\\n            --cidr $YOUR_IP\n\n        log \"Created security group: $SG_ID\"\n    else\n        log \"Using existing security group: $SG_ID\"\n    fi\n\n    export SG_ID\n}\n\n# Setup SSH key in us-west-2\nsetup_ssh_key() {\n    log \"Setting up SSH key in us-west-2...\"\n\n    SSH_KEY_NAME=\"${PROJECT_NAME}-key\"\n\n    # Check if key exists in us-west-2\n    if aws ec2 describe-key-pairs \\\n        --region $REGION \\\n        --key-names $SSH_KEY_NAME &>/dev/null; then\n        log \"Using existing SSH key: $SSH_KEY_NAME\"\n    else\n        log \"Creating SSH key: $SSH_KEY_NAME\"\n        aws ec2 create-key-pair \\\n            --region $REGION \\\n            --key-name $SSH_KEY_NAME \\\n            --query 'KeyMaterial' \\\n            --output text > ~/.ssh/$SSH_KEY_NAME.pem\n        chmod 600 ~/.ssh/$SSH_KEY_NAME.pem\n        log \"SSH key saved to ~/.ssh/$SSH_KEY_NAME.pem\"\n    fi\n\n    export SSH_KEY_NAME\n}\n\n# Launch instance in us-west-2\nlaunch_instance() {\n    log \"Launching Mistral instance in us-west-2...\"\n    log \"Using Spot instance (you have 8 vCPU Spot quota approved)\"\n\n    # Check if instance already running\n    EXISTING_INSTANCE=$(aws ec2 describe-instances \\\n        --region $REGION \\\n        --filters \"Name=tag:Name,Values=${PROJECT_NAME}-instance\" \"Name=instance-state-name,Values=running,pending\" \\\n        --query 'Reservations[].Instances[0].InstanceId' \\\n        --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$EXISTING_INSTANCE\" != \"None\" ] && [ \"$EXISTING_INSTANCE\" != \"\" ]; then\n        log \"Found existing instance: $EXISTING_INSTANCE\"\n        INSTANCE_ID=$EXISTING_INSTANCE\n        USED_INSTANCE_TYPE=\"existing\"\n    else\n        # Try each instance type and availability zone combination\n        INSTANCE_ID=\"\"\n        USED_INSTANCE_TYPE=\"\"\n\n        for instance_type in \"${INSTANCE_TYPES[@]}\"; do\n            log \"Trying instance type: $instance_type\"\n\n            while read -r subnet_line; do\n                if [ -n \"$subnet_line\" ]; then\n                    try_subnet_id=$(echo \"$subnet_line\" | cut -f1)\n                    try_subnet_az=$(echo \"$subnet_line\" | cut -f2)\n\n                    log \"  → Trying $instance_type in AZ: $try_subnet_az\"\n\n                    INSTANCE_ID=$(aws ec2 run-instances \\\n                        --region $REGION \\\n                        --image-id $AMI_ID \\\n                        --instance-type $instance_type \\\n                        --key-name $SSH_KEY_NAME \\\n                        --security-group-ids $SG_ID \\\n                        --subnet-id $try_subnet_id \\\n                        --associate-public-ip-address \\\n                        --instance-market-options '{\n                            \"MarketType\": \"spot\",\n                            \"SpotOptions\": {\n                                \"MaxPrice\": \"1.00\",\n                                \"SpotInstanceType\": \"one-time\"\n                            }\n                        }' \\\n                        --tag-specifications \"ResourceType=instance,Tags=[{Key=Name,Value=${PROJECT_NAME}-instance},{Key=Project,Value=${PROJECT_NAME}},{Key=InstanceType,Value=$instance_type},{Key=Region,Value=us-west-2}]\" \\\n                        --query 'Instances[0].InstanceId' \\\n                        --output text 2>/dev/null || echo \"\")\n\n                    if [ -n \"$INSTANCE_ID\" ] && [ \"$INSTANCE_ID\" != \"None\" ]; then\n                        log \"✅ Successfully launched $instance_type in AZ: $try_subnet_az\"\n                        USED_INSTANCE_TYPE=$instance_type\n                        break 2  # Break out of both loops\n                    else\n                        warn \"    ❌ No $instance_type capacity in AZ: $try_subnet_az\"\n                    fi\n                fi\n            done < /tmp/available_subnets_uswest2.txt\n        done\n\n        if [ -z \"$INSTANCE_ID\" ] || [ \"$INSTANCE_ID\" = \"None\" ]; then\n            error \"Failed to launch instance in any availability zone in us-west-2.\"\n        fi\n\n        log \"Launched instance: $INSTANCE_ID ($USED_INSTANCE_TYPE)\"\n        log \"Waiting for instance to be running...\"\n        aws ec2 wait instance-running \\\n            --region $REGION \\\n            --instance-ids $INSTANCE_ID\n\n        # Save instance ID\n        echo $INSTANCE_ID > .mistral-uswest2-instance-id\n    fi\n\n    # Get instance details\n    INSTANCE_INFO=$(aws ec2 describe-instances \\\n        --region $REGION \\\n        --instance-ids $INSTANCE_ID \\\n        --query 'Reservations[0].Instances[0].[PrivateIpAddress,PublicIpAddress,State.Name,InstanceType,Placement.AvailabilityZone]' \\\n        --output text)\n\n    PRIVATE_IP=$(echo $INSTANCE_INFO | cut -d' ' -f1)\n    PUBLIC_IP=$(echo $INSTANCE_INFO | cut -d' ' -f2)\n    STATE=$(echo $INSTANCE_INFO | cut -d' ' -f3)\n    ACTUAL_TYPE=$(echo $INSTANCE_INFO | cut -d' ' -f4)\n    ACTUAL_AZ=$(echo $INSTANCE_INFO | cut -d' ' -f5)\n\n    log \"Instance Details:\"\n    log \"  Instance ID: $INSTANCE_ID\"\n    log \"  Instance Type: $ACTUAL_TYPE\"\n    log \"  Availability Zone: $ACTUAL_AZ\"\n    log \"  State: $STATE\"\n    log \"  Private IP: $PRIVATE_IP\"\n    log \"  Public IP: $PUBLIC_IP\"\n    log \"\"\n    log \"🎉 Mistral deployment successful in us-west-2!\"\n    log \"SSH: ssh -i ~/.ssh/${SSH_KEY_NAME}.pem ubuntu@$PUBLIC_IP\"\n    log \"API: http://$PUBLIC_IP:8000\"\n    log \"Wait 5-15 minutes for Mistral service to start, then test:\"\n    log \"curl http://$PUBLIC_IP:8000/health\"\n}\n\n# Main execution\nmain() {\n    log \"Starting Mistral deployment in us-west-2 (Oregon)...\"\n    log \"Using 4 vCPUs (saving 4 vCPUs for SDXL server)\"\n\n    find_base_ami\n    setup_network\n    setup_security_group\n    setup_ssh_key\n    launch_instance\n\n    log \"Deployment complete! Instance running in us-west-2.\"\n}\n\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/infrastructure/deploy-mistral-us-west-2.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for application deployment", "completion": "```bash\n#!/bin/bash\n# QLoRA Instance Setup Script\n# Following CLAUDE.md: Automate environment setup and run TDD tests\n\nset -euo pipefail\n\n# Configuration\nINSTANCE_IP=\"54.197.142.172\"\nKEY_PATH=\"/home/shingai/sort/deployments/mistral-base.pem\"\nINSTANCE_USER=\"ubuntu\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Verify connection\ncheck_connection() {\n    log \"Checking SSH connection to g5.2xlarge instance...\"\n\n    if ! ssh -i \"$KEY_PATH\" -o ConnectTimeout=10 -o StrictHostKeyChecking=no \\\n        \"$INSTANCE_USER@$INSTANCE_IP\" \"echo 'Connection successful'\" 2>/dev/null; then\n        error \"Cannot connect to instance $INSTANCE_IP\"\n    fi\n\n    log \"✅ SSH connection verified\"\n}\n\n# Validate GPU environment\nvalidate_gpu_environment() {\n    log \"Validating GPU environment on instance...\"\n\n    ssh -i \"$KEY_PATH\" \"$INSTANCE_USER@$INSTANCE_IP\" << 'EOF'\n        echo \"=== GPU Environment Check ===\"\n\n        # Check NVIDIA driver\n        if ! nvidia-smi >/dev/null 2>&1; then\n            echo \"❌ NVIDIA driver not working\"\n            exit 1\n        fi\n\n        echo \"✅ NVIDIA driver working\"\n        nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits\n\n        # Check Python and basic packages\n        echo -e \"\\n=== Python Environment ===\"\n        python3 --version\n\n        if python3 -c \"import torch\" 2>/dev/null; then\n            echo \"✅ PyTorch available\"\n            python3 -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\n            python3 -c \"import torch; print(f'GPU count: {torch.cuda.device_count()}')\"\n        else\n            echo \"❌ PyTorch not available\"\n        fi\n\n        # Check disk space\n        echo -e \"\\n=== Disk Space ===\"\n        df -h / | grep -v Filesystem\n\n        # Check memory\n        echo -e \"\\n=== System Memory ===\"\n        free -h\nEOF\n\n    log \"✅ Environment validation complete\"\n}\n\n# Transfer test file\ntransfer_test_file() {\n    log \"Transferring QLoRA test file to instance...\"\n\n    scp -i \"$KEY_PATH\" -o StrictHostKeyChecking=no \\\n        \"test_qlora_setup.py\" \"$INSTANCE_USER@$INSTANCE_IP:~/\" || \\\n        error \"Failed to transfer test file\"\n\n    log \"✅ Test file transferred\"\n}\n\n# Install QLoRA dependencies\ninstall_qlora_dependencies() {\n    log \"Installing QLoRA dependencies on instance...\"\n\n    ssh -i \"$KEY_PATH\" \"$INSTANCE_USER@$INSTANCE_IP\" << 'EOF'\n        echo \"=== Installing QLoRA Dependencies ===\"\n\n        # Update pip first\n        python3 -m pip install --upgrade pip\n\n        # Install QLoRA packages with specific versions\n        echo \"Installing core QLoRA packages...\"\n        pip install transformers>=4.36.0\n        pip install accelerate>=0.25.0\n        pip install peft>=0.8.0\n        pip install bitsandbytes>=0.41.0\n        pip install datasets>=2.16.0\n\n        # Install additional dependencies\n        echo \"Installing additional packages...\"\n        pip install pytest psutil scipy\n\n        # Verify installations\n        echo -e \"\\n=== Verification ===\"\n        python3 -c \"\nimport transformers, accelerate, peft, bitsandbytes, datasets\nprint(f'✅ transformers: {transformers.__version__}')\nprint(f'✅ accelerate: {accelerate.__version__}')\nprint(f'✅ peft: {peft.__version__}')\nprint(f'✅ bitsandbytes: {bitsandbytes.__version__}')\nprint(f'✅ datasets: {datasets.__version__}')\n\"\n\n        echo \"✅ All QLoRA dependencies installed\"\nEOF\n\n    log \"✅ QLoRA dependencies installation complete\"\n}\n\n# Run TDD tests\nrun_tdd_tests() {\n    log \"Running TDD tests (should show initial failures and first successes)...\"\n\n    ssh -i \"$KEY_PATH\" \"$INSTANCE_USER@$INSTANCE_IP\" << 'EOF'\n        echo \"=== Running QLoRA Setup Tests ===\"\n\n        # Run tests with verbose output\n        python3 test_qlora_setup.py\nEOF\n\n    local exit_code=$?\n\n    if [ $exit_code -eq 0 ]; then\n        warn \"Tests passed - this is unexpected in TDD red phase!\"\n        warn \"Some tests may need to be updated to ensure proper failure initially\"\n    else\n        log \"✅ Tests failed as expected (TDD red phase)\"\n        log \"Next step: Implement features to make tests pass (TDD green phase)\"\n    fi\n}\n\n# Main execution\nmain() {\n    log \"🚀 Starting QLoRA Instance Setup (CLAUDE.md TDD approach)\"\n    log \"Instance: $INSTANCE_IP\"\n\n    check_connection\n    validate_gpu_environment\n    transfer_test_file\n    install_qlora_dependencies\n    run_tdd_tests\n\n    log \"🎯 Setup phase complete!\"\n    log \"Next: Implement QLoRA features to make tests pass\"\n\n    echo -e \"\\n${GREEN}=== Connection Command ===${NC}\"\n    echo \"ssh -i $KEY_PATH $INSTANCE_USER@$INSTANCE_IP\"\n}\n\n# Run if executed directly\nif [[ \"${BASH_SOURCE[0]}\" == \"${0}\" ]]; then\n    main \"$@\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/infrastructure/setup_qlora_instance.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#!/bin/bash\nset -euo pipefail\n\n# Comprehensive monitoring setup for Flux model loading\necho \"Setting up monitoring infrastructure...\"\n\n# Install monitoring tools\nsudo apt update\nsudo apt install -y htop iotop sysstat nethogs\n\n# Create monitoring directories\nsudo mkdir -p /var/log/flux-monitoring\nsudo chown ubuntu:ubuntu /var/log/flux-monitoring\n\n# System resource monitoring script\ncat > /tmp/system_monitor.py << 'EOF'\n#!/usr/bin/env python3\nimport psutil\nimport subprocess\nimport time\nimport json\nimport sys\nfrom datetime import datetime\n\ndef get_gpu_info():\n    try:\n        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total,utilization.gpu,temperature.gpu'],\n                              capture_output=True, text=True, check=True)\n        lines = result.stdout.strip().split('\\n')[1:]  # Skip header\n        if lines:\n            memory_used, memory_total, gpu_util, temp = lines[0].split(', ')\n            return {\n                'memory_used_mb': int(memory_used.split()[0]),\n                'memory_total_mb': int(memory_total.split()[0]),\n                'utilization_percent': int(gpu_util.split()[0]),\n                'temperature_c': int(temp.split()[0])\n            }\n    except:\n        pass\n    return {'error': 'GPU info unavailable'}\n\ndef get_process_info(process_name):\n    processes = []\n    for proc in psutil.process_iter(['pid', 'name', 'memory_info', 'cpu_percent', 'status']):\n        try:\n            if process_name.lower() in proc.info['name'].lower():\n                processes.append({\n                    'pid': proc.info['pid'],\n                    'memory_mb': proc.info['memory_info'].rss / 1024 / 1024,\n                    'cpu_percent': proc.info['cpu_percent'],\n                    'status': proc.info['status']\n                })\n        except:\n            continue\n    return processes\n\ndef monitor_system():\n    timestamp = datetime.now().isoformat()\n\n    # System metrics\n    memory = psutil.virtual_memory()\n    cpu = psutil.cpu_percent(interval=1)\n    disk = psutil.disk_usage('/')\n\n    # Network stats\n    net = psutil.net_io_counters()\n\n    data = {\n        'timestamp': timestamp,\n        'memory': {\n            'total_gb': memory.total / 1024**3,\n            'used_gb': memory.used / 1024**3,\n            'available_gb': memory.available / 1024**3,\n            'percent': memory.percent\n        },\n        'cpu_percent': cpu,\n        'disk': {\n            'total_gb': disk.total / 1024**3,\n            'used_gb': disk.used / 1024**3,\n            'free_gb': disk.free / 1024**3\n        },\n        'network': {\n            'bytes_sent': net.bytes_sent,\n            'bytes_recv': net.bytes_recv\n        },\n        'gpu': get_gpu_info(),\n        'python_processes': get_process_info('python')\n    }\n\n    return data\n\nif __name__ == '__main__':\n    if len(sys.argv) > 1 and sys.argv[1] == '--continuous':\n        # Continuous monitoring mode\n        log_file = '/var/log/flux-monitoring/system_metrics.log'\n        while True:\n            try:\n                data = monitor_system()\n                with open(log_file, 'a') as f:\n                    f.write(json.dumps(data) + '\\n')\n                time.sleep(5)\n            except KeyboardInterrupt:\n                break\n            except Exception as e:\n                print(f\"Monitoring error: {e}\")\n    else:\n        # Single measurement\n        data = monitor_system()\n        print(json.dumps(data, indent=2))\nEOF\n\nchmod +x /tmp/system_monitor.py\n\n# Process monitoring script\ncat > /tmp/process_monitor.sh << 'EOF'\n#!/bin/bash\nset -euo pipefail\n\nLOG_FILE=\"/var/log/flux-monitoring/process.log\"\n\nmonitor_process() {\n    local pid=$1\n    local name=$2\n\n    echo \"$(date): Monitoring process $name (PID: $pid)\" >> \"$LOG_FILE\"\n\n    while kill -0 \"$pid\" 2>/dev/null; do\n        # Get process stats\n        ps -o pid,ppid,rss,vsz,pcpu,time,cmd -p \"$pid\" >> \"$LOG_FILE\" 2>/dev/null || break\n\n        # Check if process is responding\n        if [ -d \"/proc/$pid\" ]; then\n            echo \"$(date): Process $pid still alive\" >> \"$LOG_FILE\"\n        else\n            echo \"$(date): Process $pid disappeared\" >> \"$LOG_FILE\"\n            break\n        fi\n\n        sleep 10\n    done\n\n    echo \"$(date): Process $name (PID: $pid) monitoring ended\" >> \"$LOG_FILE\"\n}\n\n# Export function for external use\nexport -f monitor_process\nEOF\n\nchmod +x /tmp/process_monitor.sh\n\n# Kernel message monitoring\ncat > /tmp/kernel_monitor.sh << 'EOF'\n#!/bin/bash\nset -euo pipefail\n\nLOG_FILE=\"/var/log/flux-monitoring/kernel.log\"\n\necho \"$(date): Starting kernel message monitoring\" >> \"$LOG_FILE\"\n\n# Monitor dmesg for OOM, GPU, and other critical messages\nsudo dmesg -w | while read line; do\n    echo \"$(date): $line\" >> \"$LOG_FILE\"\n\n    # Alert on critical messages\n    if echo \"$line\" | grep -i -E \"(oom|killed|cuda|nvidia|memory|hung|panic)\"; then\n        echo \"$(date): CRITICAL: $line\" >> \"$LOG_FILE\"\n    fi\ndone &\n\necho $! > /tmp/kernel_monitor_pid\nEOF\n\nchmod +x /tmp/kernel_monitor.sh\n\necho \"Monitoring infrastructure installed\"\necho \"Available commands:\"\necho \"  - /tmp/system_monitor.py                 # Single system snapshot\"\necho \"  - /tmp/system_monitor.py --continuous    # Continuous monitoring\"\necho \"  - /tmp/process_monitor.sh                # Process monitoring functions\"\necho \"  - /tmp/kernel_monitor.sh                 # Kernel message monitoring\"\necho \"\"\necho \"Logs will be written to /var/log/flux-monitoring/\"\nEOF\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/monitoring/setup_monitoring.sh", "category": "monitoring", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\necho \"🧪 Testing Server Status Page Resilience\"\necho \"========================================\"\n\nFLUX_IP=\"34.217.17.67\"\nFLUX_PORT=\"8000\"\nFLUX_ENDPOINT=\"http://${FLUX_IP}:${FLUX_PORT}\"\n\necho \"📍 Testing Flux instance: ${FLUX_ENDPOINT}\"\n\n# Test 1: Basic connectivity\necho \"🔍 Test 1: Basic connectivity to Flask server\"\nif curl -s --connect-timeout 10 \"${FLUX_ENDPOINT}/\" >/dev/null 2>&1; then\n    echo \"✅ Flask server is reachable\"\nelse\n    echo \"❌ Flask server not reachable\"\nfi\n\n# Test 2: Health endpoint (model may still be loading)\necho \"🔍 Test 2: Health endpoint status\"\nhealth_response=$(curl -s --connect-timeout 15 \"${FLUX_ENDPOINT}/health\" 2>/dev/null || echo \"FAILED\")\nif [[ \"$health_response\" == \"FAILED\" ]]; then\n    echo \"⏳ Health endpoint not ready (model likely loading)\"\nelse\n    echo \"✅ Health endpoint responding:\"\n    echo \"$health_response\" | jq . 2>/dev/null || echo \"$health_response\"\nfi\n\n# Test 3: Service auto-start verification\necho \"🔍 Test 3: Systemd service configuration\"\nssh -o StrictHostKeyChecking=no -i mistral-base.pem ubuntu@${FLUX_IP} \"\n    echo '  Service enabled:' \\$(sudo systemctl is-enabled flux-api)\n    echo '  Service active:' \\$(sudo systemctl is-active flux-api)\n    echo '  Service uptime:' \\$(sudo systemctl show flux-api --property=ActiveEnterTimestamp --value)\n\"\n\n# Test 4: Server discovery resilience\necho \"🔍 Test 4: Testing local status page discovery\"\ncat > test_discovery.html << 'EOF'\n<!DOCTYPE html>\n<html>\n<head><title>Status Test</title></head>\n<body>\n<div id=\"result\"></div>\n<script>\n// Test the same discovery logic as the status page\nasync function testFluxDiscovery() {\n    const fluxEndpoint = 'http://34.217.17.67:8000/health';\n    try {\n        const response = await fetch(fluxEndpoint, {\n            signal: AbortSignal.timeout(8000),\n            mode: 'no-cors'  // Avoid CORS issues for test\n        });\n        document.getElementById('result').textContent = 'Flux discovery: SUCCESS';\n    } catch (error) {\n        document.getElementById('result').textContent = 'Flux discovery: ' + error.message;\n    }\n}\ntestFluxDiscovery();\n</script>\n</body>\n</html>\nEOF\n\necho \"📁 Created test_discovery.html for manual browser testing\"\n\n# Test 5: Restart resilience\necho \"🔍 Test 5: Service restart resilience\"\necho \"  Testing if service can restart gracefully...\"\nssh -o StrictHostKeyChecking=no -i mistral-base.pem ubuntu@${FLUX_IP} \"\n    echo '  Restarting flux-api service...'\n    sudo systemctl restart flux-api\n    sleep 3\n    echo '  Service status after restart:' \\$(sudo systemctl is-active flux-api)\n\"\n\necho \"\"\necho \"🎯 Summary:\"\necho \"✅ Flux API Server configured as systemd service\"\necho \"✅ Auto-start on boot enabled\"\necho \"✅ Service restart resilience tested\"\necho \"✅ Server status page updated with robust discovery\"\necho \"✅ Lambda function updated with dynamic instance detection\"\necho \"\"\necho \"📋 Manual verification steps:\"\necho \"1. Open server-status.html in browser to test UI\"\necho \"2. Reboot instance to verify auto-start: 'sudo reboot'\"\necho \"3. Test image generation once model loads: 'curl -X POST http://${FLUX_IP}:8000/generate ...'\"\necho \"\"\necho \"🔧 Service management commands:\"\necho \"  sudo systemctl status flux-api    # Check status\"\necho \"  sudo systemctl restart flux-api   # Restart service\"\necho \"  sudo journalctl -u flux-api -f    # View logs\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/monitoring/test_server_resilience.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for system service management", "completion": "```bash\n#!/bin/bash\n\n# AI Server Status API\n# Returns JSON with current running instance information\n\nset -e\n\n# Output JSON header\necho \"Content-Type: application/json\"\necho \"\"\n\n# Initialize JSON response\necho \"{\"\n\n# Function to get instance details\nget_instance_info() {\n    local instance_file=\"$1\"\n    local service_name=\"$2\"\n\n    if [ ! -f \"$instance_file\" ]; then\n        echo \"null\"\n        return\n    fi\n\n    local instance_id=$(cat \"$instance_file\" 2>/dev/null | tr -d '\\n\\r')\n    if [ -z \"$instance_id\" ]; then\n        echo \"null\"\n        return\n    fi\n\n    # Try both regions\n    for region in us-east-1 us-west-2; do\n        local state=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].State.Name' \\\n            --output text 2>/dev/null || echo \"None\")\n\n        if [ \"$state\" = \"None\" ]; then\n            continue\n        fi\n\n        local public_ip=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].PublicIpAddress' \\\n            --output text 2>/dev/null || echo \"None\")\n\n        local instance_type=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].InstanceType' \\\n            --output text 2>/dev/null || echo \"None\")\n\n        if [ \"$state\" != \"None\" ]; then\n            echo \"{\"\n            echo \"  \\\"instance_id\\\": \\\"$instance_id\\\",\"\n            echo \"  \\\"state\\\": \\\"$state\\\",\"\n            echo \"  \\\"public_ip\\\": \\\"$public_ip\\\",\"\n            echo \"  \\\"instance_type\\\": \\\"$instance_type\\\",\"\n            echo \"  \\\"region\\\": \\\"$region\\\"\"\n            echo \"}\"\n            return\n        fi\n    done\n\n    echo \"null\"\n}\n\n# Check Mistral Base instance\necho \"  \\\"mistral_base\\\": $(get_instance_info \".mistral-base-instance-id\" \"mistral-base\"),\"\n\n# Check Flux instance\necho \"  \\\"flux\\\": $(get_instance_info \".flux-dev-instance-id\" \"flux-dev\"),\"\n\n# Add timestamp\necho \"  \\\"timestamp\\\": \\\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\\\",\"\necho \"  \\\"status\\\": \\\"success\\\"\"\n\necho \"}\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/monitoring/get-server-status.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/bash\n\n# Copyright The OpenTelemetry Authors\n# SPDX-License-Identifier: Apache-2.0\n\nset -euo pipefail\n\nTARGET=\"${1:?Must provide target ref}\"\n\nFILE=\"CHANGELOG.md\"\nTEMP_DIR=$(mktemp -d)\necho \"Temp folder: $TEMP_DIR\"\n\n# Only the latest commit of the feature branch is available\n# automatically. To diff with the base branch, we need to\n# fetch that too (and we only need its latest commit).\ngit fetch origin \"${TARGET}\" --depth=1\n\n# Checkout the previous version on the base branch of the changelog to tmpfolder\ngit --work-tree=\"$TEMP_DIR\" checkout FETCH_HEAD $FILE\n\nPREVIOUS_FILE=\"$TEMP_DIR/$FILE\"\nCURRENT_FILE=\"$FILE\"\nPREVIOUS_LOCKED_FILE=\"$TEMP_DIR/previous_locked_section.md\"\nCURRENT_LOCKED_FILE=\"$TEMP_DIR/current_locked_section.md\"\n\n# Extract released sections from the previous version\nawk '/^<!-- Released section -->/ {flag=1} /^<!-- Released section ended -->/ {flag=0} flag' \"$PREVIOUS_FILE\" > \"$PREVIOUS_LOCKED_FILE\"\n\n# Extract released sections from the current version\nawk '/^<!-- Released section -->/ {flag=1} /^<!-- Released section ended -->/ {flag=0} flag' \"$CURRENT_FILE\" > \"$CURRENT_LOCKED_FILE\"\n\n# Compare the released sections\nif ! diff -q \"$PREVIOUS_LOCKED_FILE\" \"$CURRENT_LOCKED_FILE\"; then\n    echo \"Error: The released sections of the changelog file have been modified.\"\n    diff \"$PREVIOUS_LOCKED_FILE\" \"$CURRENT_LOCKED_FILE\"\n    rm -rf \"$TEMP_DIR\"\n    false\nfi\n\nrm -rf \"$TEMP_DIR\"\necho \"The released sections remain unchanged.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/vendor/go.opentelemetry.io/otel/verify_released_changelog.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright 2009 The Go Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style\n# license that can be found in the LICENSE file.\n\n# This script runs or (given -n) prints suggested commands to generate files for\n# the Architecture/OS specified by the GOARCH and GOOS environment variables.\n# See README.md for more information about how the build system works.\n\nGOOSARCH=\"${GOOS}_${GOARCH}\"\n\n# defaults\nmksyscall=\"go run mksyscall.go\"\nmkerrors=\"./mkerrors.sh\"\nzerrors=\"zerrors_$GOOSARCH.go\"\nmksysctl=\"\"\nzsysctl=\"zsysctl_$GOOSARCH.go\"\nmksysnum=\nmktypes=\nmkasm=\nrun=\"sh\"\ncmd=\"\"\n\ncase \"$1\" in\n-syscalls)\n\tfor i in zsyscall*go\n\tdo\n\t\t# Run the command line that appears in the first line\n\t\t# of the generated file to regenerate it.\n\t\tsed 1q $i | sed 's;^// ;;' | sh > _$i && gofmt < _$i > $i\n\t\trm _$i\n\tdone\n\texit 0\n\t;;\n-n)\n\trun=\"cat\"\n\tcmd=\"echo\"\n\tshift\nesac\n\ncase \"$#\" in\n0)\n\t;;\n*)\n\techo 'usage: mkall.sh [-n]' 1>&2\n\texit 2\nesac\n\nif [[ \"$GOOS\" = \"linux\" ]]; then\n\t# Use the Docker-based build system\n\t# Files generated through docker (use $cmd so you can Ctl-C the build or run)\n\t$cmd docker build --tag generate:$GOOS $GOOS\n\t$cmd docker run --interactive --tty --volume $(cd -- \"$(dirname -- \"$0\")/..\" && pwd):/build generate:$GOOS\n\texit\nfi\n\nGOOSARCH_in=syscall_$GOOSARCH.go\ncase \"$GOOSARCH\" in\n_* | *_ | _)\n\techo 'undefined $GOOS_$GOARCH:' \"$GOOSARCH\" 1>&2\n\texit 1\n\t;;\naix_ppc)\n\tmkerrors=\"$mkerrors -maix32\"\n\tmksyscall=\"go run mksyscall_aix_ppc.go -aix\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\naix_ppc64)\n\tmkerrors=\"$mkerrors -maix64\"\n\tmksyscall=\"go run mksyscall_aix_ppc64.go -aix\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\ndarwin_amd64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\tmkasm=\"go run mkasm.go\"\n\t;;\ndarwin_arm64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\tmkasm=\"go run mkasm.go\"\n\t;;\ndragonfly_amd64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -dragonfly\"\n\tmksysnum=\"go run mksysnum.go 'https://gitweb.dragonflybsd.org/dragonfly.git/blob_plain/HEAD:/sys/kern/syscalls.master'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nfreebsd_386)\n\tmkerrors=\"$mkerrors -m32\"\n\tmksyscall=\"go run mksyscall.go -l32\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nfreebsd_amd64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nfreebsd_arm)\n\tmkerrors=\"$mkerrors\"\n\tmksyscall=\"go run mksyscall.go -l32 -arm\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nfreebsd_arm64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nfreebsd_riscv64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nnetbsd_386)\n\tmkerrors=\"$mkerrors -m32\"\n\tmksyscall=\"go run mksyscall.go -l32 -netbsd\"\n\tmksysnum=\"go run mksysnum.go 'http://cvsweb.netbsd.org/bsdweb.cgi/~checkout~/src/sys/kern/syscalls.master'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nnetbsd_amd64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -netbsd\"\n\tmksysnum=\"go run mksysnum.go 'http://cvsweb.netbsd.org/bsdweb.cgi/~checkout~/src/sys/kern/syscalls.master'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nnetbsd_arm)\n\tmkerrors=\"$mkerrors\"\n\tmksyscall=\"go run mksyscall.go -l32 -netbsd -arm\"\n\tmksysnum=\"go run mksysnum.go 'http://cvsweb.netbsd.org/bsdweb.cgi/~checkout~/src/sys/kern/syscalls.master'\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nnetbsd_arm64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -netbsd\"\n\tmksysnum=\"go run mksysnum.go 'http://cvsweb.netbsd.org/bsdweb.cgi/~checkout~/src/sys/kern/syscalls.master'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nopenbsd_386)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m32\"\n\tmksyscall=\"go run mksyscall.go -l32 -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nopenbsd_amd64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nopenbsd_arm)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors\"\n\tmksyscall=\"go run mksyscall.go -l32 -openbsd -arm -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nopenbsd_arm64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nopenbsd_mips64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nopenbsd_ppc64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nopenbsd_riscv64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nsolaris_amd64)\n\tmksyscall=\"go run mksyscall_solaris.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksysnum=\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nillumos_amd64)\n        mksyscall=\"go run mksyscall_solaris.go\"\n\tmkerrors=\n\tmksysnum=\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\n*)\n\techo 'unrecognized $GOOS_$GOARCH: ' \"$GOOSARCH\" 1>&2\n\texit 1\n\t;;\nesac\n\n(\n\tif [ -n \"$mkerrors\" ]; then echo \"$mkerrors |gofmt >$zerrors\"; fi\n\tcase \"$GOOS\" in\n\t*)\n\t\tsyscall_goos=\"syscall_$GOOS.go\"\n\t\tcase \"$GOOS\" in\n\t\tdarwin | dragonfly | freebsd | netbsd | openbsd)\n\t\t\tsyscall_goos=\"syscall_bsd.go $syscall_goos\"\n\t\t\t;;\n\t\tesac\n\t\tif [ -n \"$mksyscall\" ]; then\n\t\t\tif [ \"$GOOSARCH\" == \"aix_ppc64\" ]; then\n\t\t\t\t# aix/ppc64 script generates files instead of writing to stdin.\n\t\t\t\techo \"$mksyscall -tags $GOOS,$GOARCH $syscall_goos $GOOSARCH_in && gofmt -w zsyscall_$GOOSARCH.go && gofmt -w zsyscall_\"$GOOSARCH\"_gccgo.go && gofmt -w zsyscall_\"$GOOSARCH\"_gc.go \" ;\n\t\t\telif [ \"$GOOS\" == \"illumos\" ]; then\n\t\t\t        # illumos code generation requires a --illumos switch\n\t\t\t        echo \"$mksyscall -illumos -tags illumos,$GOARCH syscall_illumos.go |gofmt > zsyscall_illumos_$GOARCH.go\";\n\t\t\t        # illumos implies solaris, so solaris code generation is also required\n\t\t\t\techo \"$mksyscall -tags solaris,$GOARCH syscall_solaris.go syscall_solaris_$GOARCH.go |gofmt >zsyscall_solaris_$GOARCH.go\";\n\t\t\telse\n\t\t\t\techo \"$mksyscall -tags $GOOS,$GOARCH $syscall_goos $GOOSARCH_in |gofmt >zsyscall_$GOOSARCH.go\";\n\t\t\tfi\n\t\tfi\n\tesac\n\tif [ -n \"$mksysctl\" ]; then echo \"$mksysctl |gofmt >$zsysctl\"; fi\n\tif [ -n \"$mksysnum\" ]; then echo \"$mksysnum |gofmt >zsysnum_$GOOSARCH.go\"; fi\n\tif [ -n \"$mktypes\" ]; then echo \"$mktypes types_$GOOS.go | go run mkpost.go > ztypes_$GOOSARCH.go\"; fi\n\tif [ -n \"$mkasm\" ]; then echo \"$mkasm $GOOS $GOARCH\"; fi\n) | $run\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/vendor/golang.org/x/sys/unix/mkall.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for backup automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright 2009 The Go Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style\n# license that can be found in the LICENSE file.\n\n# Generate Go code listing errors and other #defined constant\n# values (ENAMETOOLONG etc.), by asking the preprocessor\n# about the definitions.\n\nunset LANG\nexport LC_ALL=C\nexport LC_CTYPE=C\n\nif test -z \"$GOARCH\" -o -z \"$GOOS\"; then\n\techo 1>&2 \"GOARCH or GOOS not defined in environment\"\n\texit 1\nfi\n\n# Check that we are using the new build system if we should\nif [[ \"$GOOS\" = \"linux\" ]] && [[ \"$GOLANG_SYS_BUILD\" != \"docker\" ]]; then\n\techo 1>&2 \"In the Docker based build system, mkerrors should not be called directly.\"\n\techo 1>&2 \"See README.md\"\n\texit 1\nfi\n\nif [[ \"$GOOS\" = \"aix\" ]]; then\n\tCC=${CC:-gcc}\nelse\n\tCC=${CC:-cc}\nfi\n\nif [[ \"$GOOS\" = \"solaris\" ]]; then\n\t# Assumes GNU versions of utilities in PATH.\n\texport PATH=/usr/gnu/bin:$PATH\nfi\n\nuname=$(uname)\n\nincludes_AIX='\n#include <net/if.h>\n#include <net/netopt.h>\n#include <netinet/ip_mroute.h>\n#include <sys/protosw.h>\n#include <sys/stropts.h>\n#include <sys/mman.h>\n#include <sys/poll.h>\n#include <sys/select.h>\n#include <sys/termio.h>\n#include <termios.h>\n#include <fcntl.h>\n\n#define AF_LOCAL AF_UNIX\n'\n\nincludes_Darwin='\n#define _DARWIN_C_SOURCE\n#define KERNEL 1\n#define _DARWIN_USE_64_BIT_INODE\n#define __APPLE_USE_RFC_3542\n#include <stdint.h>\n#include <sys/stdio.h>\n#include <sys/attr.h>\n#include <sys/clonefile.h>\n#include <sys/kern_control.h>\n#include <sys/types.h>\n#include <sys/event.h>\n#include <sys/ptrace.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/stat.h>\n#include <sys/un.h>\n#include <sys/sockio.h>\n#include <sys/sys_domain.h>\n#include <sys/sysctl.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/utsname.h>\n#include <sys/wait.h>\n#include <sys/xattr.h>\n#include <sys/vsock.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <termios.h>\n\n// for backwards compatibility because moved TIOCREMOTE to Kernel.framework after MacOSX12.0.sdk.\n#define TIOCREMOTE 0x80047469\n'\n\nincludes_DragonFly='\n#include <sys/types.h>\n#include <sys/event.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/sockio.h>\n#include <sys/stat.h>\n#include <sys/sysctl.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/wait.h>\n#include <sys/ioctl.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_clone.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <termios.h>\n#include <netinet/ip.h>\n#include <net/ip_mroute/ip_mroute.h>\n'\n\nincludes_FreeBSD='\n#include <sys/capsicum.h>\n#include <sys/param.h>\n#include <sys/types.h>\n#include <sys/disk.h>\n#include <sys/event.h>\n#include <sys/sched.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/un.h>\n#include <sys/sockio.h>\n#include <sys/stat.h>\n#include <sys/sysctl.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/wait.h>\n#include <sys/ioctl.h>\n#include <sys/ptrace.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <termios.h>\n#include <netinet/ip.h>\n#include <netinet/ip_mroute.h>\n#include <sys/extattr.h>\n\n#if __FreeBSD__ >= 10\n#define IFT_CARP\t0xf8\t// IFT_CARP is deprecated in FreeBSD 10\n#undef SIOCAIFADDR\n#define SIOCAIFADDR\t_IOW(105, 26, struct oifaliasreq)\t// ifaliasreq contains if_data\n#undef SIOCSIFPHYADDR\n#define SIOCSIFPHYADDR\t_IOW(105, 70, struct oifaliasreq)\t// ifaliasreq contains if_data\n#endif\n'\n\nincludes_Linux='\n#define _LARGEFILE_SOURCE\n#define _LARGEFILE64_SOURCE\n#ifndef __LP64__\n#define _FILE_OFFSET_BITS 64\n#endif\n#define _GNU_SOURCE\n\n// See the description in unix/linux/types.go\n#if defined(__ARM_EABI__) || \\\n\t(defined(__mips__) && (_MIPS_SIM == _ABIO32)) || \\\n\t(defined(__powerpc__) && (!defined(__powerpc64__)))\n# ifdef   _TIME_BITS\n#  undef  _TIME_BITS\n# endif\n# define  _TIME_BITS 32\n#endif\n\n// <sys/ioctl.h> is broken on powerpc64, as it fails to include definitions of\n// these structures. We just include them copied from <bits/termios.h>.\n#if defined(__powerpc__)\nstruct sgttyb {\n        char    sg_ispeed;\n        char    sg_ospeed;\n        char    sg_erase;\n        char    sg_kill;\n        short   sg_flags;\n};\n\nstruct tchars {\n        char    t_intrc;\n        char    t_quitc;\n        char    t_startc;\n        char    t_stopc;\n        char    t_eofc;\n        char    t_brkc;\n};\n\nstruct ltchars {\n        char    t_suspc;\n        char    t_dsuspc;\n        char    t_rprntc;\n        char    t_flushc;\n        char    t_werasc;\n        char    t_lnextc;\n};\n#endif\n\n#include <bits/sockaddr.h>\n#include <sys/epoll.h>\n#include <sys/eventfd.h>\n#include <sys/inotify.h>\n#include <sys/ioctl.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/prctl.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <sys/time.h>\n#include <sys/select.h>\n#include <sys/signalfd.h>\n#include <sys/socket.h>\n#include <sys/timerfd.h>\n#include <sys/uio.h>\n#include <sys/xattr.h>\n#include <netinet/udp.h>\n#include <linux/audit.h>\n#include <linux/bpf.h>\n#include <linux/can.h>\n#include <linux/can/error.h>\n#include <linux/can/netlink.h>\n#include <linux/can/raw.h>\n#include <linux/capability.h>\n#include <linux/cryptouser.h>\n#include <linux/devlink.h>\n#include <linux/dm-ioctl.h>\n#include <linux/errqueue.h>\n#include <linux/ethtool_netlink.h>\n#include <linux/falloc.h>\n#include <linux/fanotify.h>\n#include <linux/fib_rules.h>\n#include <linux/filter.h>\n#include <linux/fs.h>\n#include <linux/fscrypt.h>\n#include <linux/fsverity.h>\n#include <linux/genetlink.h>\n#include <linux/hdreg.h>\n#include <linux/hidraw.h>\n#include <linux/if.h>\n#include <linux/if_addr.h>\n#include <linux/if_alg.h>\n#include <linux/if_arp.h>\n#include <linux/if_ether.h>\n#include <linux/if_ppp.h>\n#include <linux/if_tun.h>\n#include <linux/if_packet.h>\n#include <linux/if_xdp.h>\n#include <linux/input.h>\n#include <linux/kcm.h>\n#include <linux/kexec.h>\n#include <linux/keyctl.h>\n#include <linux/landlock.h>\n#include <linux/loop.h>\n#include <linux/lwtunnel.h>\n#include <linux/magic.h>\n#include <linux/memfd.h>\n#include <linux/module.h>\n#include <linux/mount.h>\n#include <linux/netfilter/nfnetlink.h>\n#include <linux/netfilter/nf_tables.h>\n#include <linux/netlink.h>\n#include <linux/net_namespace.h>\n#include <linux/nfc.h>\n#include <linux/nsfs.h>\n#include <linux/perf_event.h>\n#include <linux/pps.h>\n#include <linux/ptp_clock.h>\n#include <linux/ptrace.h>\n#include <linux/random.h>\n#include <linux/reboot.h>\n#include <linux/rtc.h>\n#include <linux/rtnetlink.h>\n#include <linux/sched.h>\n#include <linux/seccomp.h>\n#include <linux/serial.h>\n#include <linux/sock_diag.h>\n#include <linux/sockios.h>\n#include <linux/taskstats.h>\n#include <linux/tipc.h>\n#include <linux/vm_sockets.h>\n#include <linux/wait.h>\n#include <linux/watchdog.h>\n#include <linux/wireguard.h>\n\n#include <mtd/ubi-user.h>\n#include <mtd/mtd-user.h>\n#include <net/route.h>\n\n#if defined(__sparc__)\n// On sparc{,64}, the kernel defines struct termios2 itself which clashes with the\n// definition in glibc. As only the error constants are needed here, include the\n// generic termibits.h (which is included by termbits.h on sparc).\n#include <asm-generic/termbits.h>\n#else\n#include <asm/termbits.h>\n#endif\n\n#ifndef PTRACE_GETREGS\n#define PTRACE_GETREGS\t0xc\n#endif\n\n#ifndef PTRACE_SETREGS\n#define PTRACE_SETREGS\t0xd\n#endif\n\n#ifdef SOL_BLUETOOTH\n// SPARC includes this in /usr/include/sparc64-linux-gnu/bits/socket.h\n// but it is already in bluetooth_linux.go\n#undef SOL_BLUETOOTH\n#endif\n\n// Certain constants are missing from the fs/crypto UAPI\n#define FS_KEY_DESC_PREFIX              \"fscrypt:\"\n#define FS_KEY_DESC_PREFIX_SIZE         8\n#define FS_MAX_KEY_SIZE                 64\n\n// The code generator produces -0x1 for (~0), but an unsigned value is necessary\n// for the tipc_subscr timeout __u32 field.\n#undef TIPC_WAIT_FOREVER\n#define TIPC_WAIT_FOREVER 0xffffffff\n\n// Copied from linux/netfilter/nf_nat.h\n// Including linux/netfilter/nf_nat.h here causes conflicts between linux/in.h\n// and netinet/in.h.\n#define NF_NAT_RANGE_MAP_IPS\t\t\t(1 << 0)\n#define NF_NAT_RANGE_PROTO_SPECIFIED\t\t(1 << 1)\n#define NF_NAT_RANGE_PROTO_RANDOM\t\t(1 << 2)\n#define NF_NAT_RANGE_PERSISTENT\t\t\t(1 << 3)\n#define NF_NAT_RANGE_PROTO_RANDOM_FULLY\t\t(1 << 4)\n#define NF_NAT_RANGE_PROTO_OFFSET\t\t(1 << 5)\n#define NF_NAT_RANGE_NETMAP\t\t\t(1 << 6)\n#define NF_NAT_RANGE_PROTO_RANDOM_ALL\t\t\\\n\t(NF_NAT_RANGE_PROTO_RANDOM | NF_NAT_RANGE_PROTO_RANDOM_FULLY)\n#define NF_NAT_RANGE_MASK\t\t\t\t\t\\\n\t(NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED |\t\\\n\t NF_NAT_RANGE_PROTO_RANDOM | NF_NAT_RANGE_PERSISTENT |\t\\\n\t NF_NAT_RANGE_PROTO_RANDOM_FULLY | NF_NAT_RANGE_PROTO_OFFSET | \\\n\t NF_NAT_RANGE_NETMAP)\n\n// Copied from linux/hid.h.\n// Keep in sync with the size of the referenced fields.\n#define _HIDIOCGRAWNAME_LEN\t128 // sizeof_field(struct hid_device, name)\n#define _HIDIOCGRAWPHYS_LEN\t64  // sizeof_field(struct hid_device, phys)\n#define _HIDIOCGRAWUNIQ_LEN\t64  // sizeof_field(struct hid_device, uniq)\n\n#define _HIDIOCGRAWNAME\t\tHIDIOCGRAWNAME(_HIDIOCGRAWNAME_LEN)\n#define _HIDIOCGRAWPHYS\t\tHIDIOCGRAWPHYS(_HIDIOCGRAWPHYS_LEN)\n#define _HIDIOCGRAWUNIQ\t\tHIDIOCGRAWUNIQ(_HIDIOCGRAWUNIQ_LEN)\n\n'\n\nincludes_NetBSD='\n#include <sys/types.h>\n#include <sys/param.h>\n#include <sys/event.h>\n#include <sys/extattr.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/sched.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/sockio.h>\n#include <sys/sysctl.h>\n#include <sys/termios.h>\n#include <sys/ttycom.h>\n#include <sys/wait.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <netinet/in_systm.h>\n#include <netinet/ip.h>\n#include <netinet/ip_mroute.h>\n#include <netinet/if_ether.h>\n\n// Needed since <sys/param.h> refers to it...\n#define schedppq 1\n'\n\nincludes_OpenBSD='\n#include <sys/types.h>\n#include <sys/param.h>\n#include <sys/event.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/select.h>\n#include <sys/sched.h>\n#include <sys/socket.h>\n#include <sys/sockio.h>\n#include <sys/stat.h>\n#include <sys/sysctl.h>\n#include <sys/termios.h>\n#include <sys/ttycom.h>\n#include <sys/unistd.h>\n#include <sys/wait.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_types.h>\n#include <net/if_var.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <netinet/in_systm.h>\n#include <netinet/ip.h>\n#include <netinet/ip_mroute.h>\n#include <netinet/if_ether.h>\n#include <net/if_bridge.h>\n\n// We keep some constants not supported in OpenBSD 5.5 and beyond for\n// the promise of compatibility.\n#define EMUL_ENABLED\t\t0x1\n#define EMUL_NATIVE\t\t0x2\n#define IPV6_FAITH\t\t0x1d\n#define IPV6_OPTIONS\t\t0x1\n#define IPV6_RTHDR_STRICT\t0x1\n#define IPV6_SOCKOPT_RESERVED1\t0x3\n#define SIOCGIFGENERIC\t\t0xc020693a\n#define SIOCSIFGENERIC\t\t0x80206939\n#define WALTSIG\t\t\t0x4\n'\n\nincludes_SunOS='\n#include <limits.h>\n#include <sys/types.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/sockio.h>\n#include <sys/stat.h>\n#include <sys/stream.h>\n#include <sys/mman.h>\n#include <sys/wait.h>\n#include <sys/ioctl.h>\n#include <sys/mkdev.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_arp.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/icmp6.h>\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <netinet/ip_mroute.h>\n#include <termios.h>\n'\n\n\nincludes='\n#include <sys/types.h>\n#include <sys/file.h>\n#include <fcntl.h>\n#include <dirent.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <netinet/ip6.h>\n#include <netinet/tcp.h>\n#include <errno.h>\n#include <sys/signal.h>\n#include <signal.h>\n#include <sys/resource.h>\n#include <time.h>\n'\nccflags=\"$@\"\n\n# Write go tool cgo -godefs input.\n(\n\techo package unix\n\techo\n\techo '/*'\n\tindirect=\"includes_$(uname)\"\n\techo \"${!indirect} $includes\"\n\techo '*/'\n\techo 'import \"C\"'\n\techo 'import \"syscall\"'\n\techo\n\techo 'const ('\n\n\t# The gcc command line prints all the #defines\n\t# it encounters while processing the input\n\techo \"${!indirect} $includes\" | $CC -x c - -E -dM $ccflags |\n\tawk '\n\t\t$1 != \"#define\" || $2 ~ /\\(/ || $3 == \"\" {next}\n\n\t\t$2 ~ /^E([ABCD]X|[BIS]P|[SD]I|S|FL)$/ {next}  # 386 registers\n\t\t$2 ~ /^(SIGEV_|SIGSTKSZ|SIGRT(MIN|MAX))/ {next}\n\t\t$2 ~ /^(SCM_SRCRT)$/ {next}\n\t\t$2 ~ /^(MAP_FAILED)$/ {next}\n\t\t$2 ~ /^ELF_.*$/ {next}# <asm/elf.h> contains ELF_ARCH, etc.\n\n\t\t$2 ~ /^EXTATTR_NAMESPACE_NAMES/ ||\n\t\t$2 ~ /^EXTATTR_NAMESPACE_[A-Z]+_STRING/ {next}\n\n\t\t$2 !~ /^ECCAPBITS/ &&\n\t\t$2 !~ /^ETH_/ &&\n\t\t$2 !~ /^EPROC_/ &&\n\t\t$2 !~ /^EQUIV_/ &&\n\t\t$2 !~ /^EXPR_/ &&\n\t\t$2 !~ /^EVIOC/ &&\n\t\t$2 ~ /^E[A-Z0-9_]+$/ ||\n\t\t$2 ~ /^B[0-9_]+$/ ||\n\t\t$2 ~ /^(OLD|NEW)DEV$/ ||\n\t\t$2 == \"BOTHER\" ||\n\t\t$2 ~ /^CI?BAUD(EX)?$/ ||\n\t\t$2 == \"IBSHIFT\" ||\n\t\t$2 ~ /^V[A-Z0-9]+$/ ||\n\t\t$2 ~ /^CS[A-Z0-9]/ ||\n\t\t$2 ~ /^I(SIG|CANON|CRNL|UCLC|EXTEN|MAXBEL|STRIP|UTF8)$/ ||\n\t\t$2 ~ /^IGN/ ||\n\t\t$2 ~ /^IX(ON|ANY|OFF)$/ ||\n\t\t$2 ~ /^IN(LCR|PCK)$/ ||\n\t\t$2 !~ \"X86_CR3_PCID_NOFLUSH\" &&\n\t\t$2 ~ /(^FLU?SH)|(FLU?SH$)/ ||\n\t\t$2 ~ /^C(LOCAL|READ|MSPAR|RTSCTS)$/ ||\n\t\t$2 == \"BRKINT\" ||\n\t\t$2 == \"HUPCL\" ||\n\t\t$2 == \"PENDIN\" ||\n\t\t$2 == \"TOSTOP\" ||\n\t\t$2 == \"XCASE\" ||\n\t\t$2 == \"ALTWERASE\" ||\n\t\t$2 == \"NOKERNINFO\" ||\n\t\t$2 == \"NFDBITS\" ||\n\t\t$2 ~ /^PAR/ ||\n\t\t$2 ~ /^SIG[^_]/ ||\n\t\t$2 ~ /^O[CNPFPL][A-Z]+[^_][A-Z]+$/ ||\n\t\t$2 ~ /^(NL|CR|TAB|BS|VT|FF)DLY$/ ||\n\t\t$2 ~ /^(NL|CR|TAB|BS|VT|FF)[0-9]$/ ||\n\t\t$2 ~ /^O?XTABS$/ ||\n\t\t$2 ~ /^TC[IO](ON|OFF)$/ ||\n\t\t$2 ~ /^IN_/ ||\n\t\t$2 ~ /^KCM/ ||\n\t\t$2 ~ /^LANDLOCK_/ ||\n\t\t$2 ~ /^LOCK_(SH|EX|NB|UN)$/ ||\n\t\t$2 ~ /^LO_(KEY|NAME)_SIZE$/ ||\n\t\t$2 ~ /^LOOP_(CLR|CTL|GET|SET)_/ ||\n\t\t$2 == \"LOOP_CONFIGURE\" ||\n\t\t$2 ~ /^(AF|SOCK|SO|SOL|IPPROTO|IP|IPV6|TCP|MCAST|EVFILT|NOTE|SHUT|PROT|MAP|MREMAP|MFD|T?PACKET|MSG|SCM|MCL|DT|MADV|PR|LOCAL|TCPOPT|UDP)_/ ||\n\t\t$2 ~ /^NFC_(GENL|PROTO|COMM|RF|SE|DIRECTION|LLCP|SOCKPROTO)_/ ||\n\t\t$2 ~ /^NFC_.*_(MAX)?SIZE$/ ||\n\t\t$2 ~ /^PTP_/ ||\n\t\t$2 ~ /^RAW_PAYLOAD_/ ||\n\t\t$2 ~ /^[US]F_/ ||\n\t\t$2 ~ /^TP_STATUS_/ ||\n\t\t$2 ~ /^FALLOC_/ ||\n\t\t$2 ~ /^ICMPV?6?_(FILTER|SEC)/ ||\n\t\t$2 == \"SOMAXCONN\" ||\n\t\t$2 == \"NAME_MAX\" ||\n\t\t$2 == \"IFNAMSIZ\" ||\n\t\t$2 ~ /^CTL_(HW|KERN|MAXNAME|NET|QUERY)$/ ||\n\t\t$2 ~ /^KERN_(HOSTNAME|OS(RELEASE|TYPE)|VERSION)$/ ||\n\t\t$2 ~ /^HW_MACHINE$/ ||\n\t\t$2 ~ /^SYSCTL_VERS/ ||\n\t\t$2 !~ \"MNT_BITS\" &&\n\t\t$2 ~ /^(MS|MNT|MOUNT|UMOUNT)_/ ||\n\t\t$2 ~ /^NS_GET_/ ||\n\t\t$2 ~ /^TUN(SET|GET|ATTACH|DETACH)/ ||\n\t\t$2 ~ /^(O|F|[ES]?FD|NAME|S|PTRACE|PT|PIOD|TFD)_/ ||\n\t\t$2 ~ /^KEXEC_/ ||\n\t\t$2 ~ /^LINUX_REBOOT_CMD_/ ||\n\t\t$2 ~ /^LINUX_REBOOT_MAGIC[12]$/ ||\n\t\t$2 ~ /^MODULE_INIT_/ ||\n\t\t$2 !~ \"NLA_TYPE_MASK\" &&\n\t\t$2 !~ /^RTC_VL_(ACCURACY|BACKUP|DATA)/ &&\n\t\t$2 ~ /^(NETLINK|NLM|NLMSG|NLA|IFA|IFAN|RT|RTC|RTCF|RTN|RTPROT|RTNH|ARPHRD|ETH_P|NETNSA)_/ ||\n\t\t$2 ~ /^SOCK_|SK_DIAG_|SKNLGRP_$/ ||\n\t\t$2 ~ /^(CONNECT|SAE)_/ ||\n\t\t$2 ~ /^FIORDCHK$/ ||\n\t\t$2 ~ /^SIOC/ ||\n\t\t$2 ~ /^TIOC/ ||\n\t\t$2 ~ /^TCGET/ ||\n\t\t$2 ~ /^TCSET/ ||\n\t\t$2 ~ /^TC(FLSH|SBRKP?|XONC)$/ ||\n\t\t$2 !~ \"RTF_BITS\" &&\n\t\t$2 ~ /^(IFF|IFT|NET_RT|RTM(GRP)?|RTF|RTV|RTA|RTAX)_/ ||\n\t\t$2 ~ /^BIOC/ ||\n\t\t$2 ~ /^DIOC/ ||\n\t\t$2 ~ /^RUSAGE_(SELF|CHILDREN|THREAD)/ ||\n\t\t$2 ~ /^RLIMIT_(AS|CORE|CPU|DATA|FSIZE|LOCKS|MEMLOCK|MSGQUEUE|NICE|NOFILE|NPROC|RSS|RTPRIO|RTTIME|SIGPENDING|STACK)|RLIM_INFINITY/ ||\n\t\t$2 ~ /^PRIO_(PROCESS|PGRP|USER)/ ||\n\t\t$2 ~ /^CLONE_[A-Z_]+/ ||\n\t\t$2 !~ /^(BPF_TIMEVAL|BPF_FIB_LOOKUP_[A-Z]+|BPF_F_LINK)$/ &&\n\t\t$2 ~ /^(BPF|DLT)_/ ||\n\t\t$2 ~ /^AUDIT_/ ||\n\t\t$2 ~ /^(CLOCK|TIMER)_/ ||\n\t\t$2 ~ /^CAN_/ ||\n\t\t$2 ~ /^CAP_/ ||\n\t\t$2 ~ /^CP_/ ||\n\t\t$2 ~ /^CPUSTATES$/ ||\n\t\t$2 ~ /^CTLIOCGINFO$/ ||\n\t\t$2 ~ /^ALG_/ ||\n\t\t$2 ~ /^FI(CLONE|DEDUPERANGE)/ ||\n\t\t$2 ~ /^FS_(POLICY_FLAGS|KEY_DESC|ENCRYPTION_MODE|[A-Z0-9_]+_KEY_SIZE)/ ||\n\t\t$2 ~ /^FS_IOC_.*(ENCRYPTION|VERITY|[GS]ETFLAGS)/ ||\n\t\t$2 ~ /^FS_VERITY_/ ||\n\t\t$2 ~ /^FSCRYPT_/ ||\n\t\t$2 ~ /^DM_/ ||\n\t\t$2 ~ /^GRND_/ ||\n\t\t$2 ~ /^RND/ ||\n\t\t$2 ~ /^KEY_(SPEC|REQKEY_DEFL)_/ ||\n\t\t$2 ~ /^KEYCTL_/ ||\n\t\t$2 ~ /^PERF_/ ||\n\t\t$2 ~ /^SECCOMP_/ ||\n\t\t$2 ~ /^SEEK_/ ||\n\t\t$2 ~ /^SCHED_/ ||\n\t\t$2 ~ /^SPLICE_/ ||\n\t\t$2 ~ /^SYNC_FILE_RANGE_/ ||\n\t\t$2 !~ /IOC_MAGIC/ &&\n\t\t$2 ~ /^[A-Z][A-Z0-9_]+_MAGIC2?$/ ||\n\t\t$2 ~ /^(VM|VMADDR)_/ ||\n\t\t$2 ~ /^IOCTL_VM_SOCKETS_/ ||\n\t\t$2 ~ /^(TASKSTATS|TS)_/ ||\n\t\t$2 ~ /^CGROUPSTATS_/ ||\n\t\t$2 ~ /^GENL_/ ||\n\t\t$2 ~ /^STATX_/ ||\n\t\t$2 ~ /^RENAME/ ||\n\t\t$2 ~ /^UBI_IOC[A-Z]/ ||\n\t\t$2 ~ /^UTIME_/ ||\n\t\t$2 ~ /^XATTR_(CREATE|REPLACE|NO(DEFAULT|FOLLOW|SECURITY)|SHOWCOMPRESSION)/ ||\n\t\t$2 ~ /^ATTR_(BIT_MAP_COUNT|(CMN|VOL|FILE)_)/ ||\n\t\t$2 ~ /^FSOPT_/ ||\n\t\t$2 ~ /^WDIO[CFS]_/ ||\n\t\t$2 ~ /^NFN/ ||\n\t\t$2 !~ /^NFT_META_IIFTYPE/ &&\n\t\t$2 ~ /^NFT_/ ||\n\t\t$2 ~ /^NF_NAT_/ ||\n\t\t$2 ~ /^XDP_/ ||\n\t\t$2 ~ /^RWF_/ ||\n\t\t$2 ~ /^(HDIO|WIN|SMART)_/ ||\n\t\t$2 ~ /^CRYPTO_/ ||\n\t\t$2 ~ /^TIPC_/ ||\n\t\t$2 !~  \"DEVLINK_RELOAD_LIMITS_VALID_MASK\" &&\n\t\t$2 ~ /^DEVLINK_/ ||\n\t\t$2 ~ /^ETHTOOL_/ ||\n\t\t$2 ~ /^LWTUNNEL_IP/ ||\n\t\t$2 ~ /^ITIMER_/ ||\n\t\t$2 !~ \"WMESGLEN\" &&\n\t\t$2 ~ /^W[A-Z0-9]+$/ ||\n\t\t$2 ~ /^P_/ ||\n\t\t$2 ~/^PPPIOC/ ||\n\t\t$2 ~ /^FAN_|FANOTIFY_/ ||\n\t\t$2 == \"HID_MAX_DESCRIPTOR_SIZE\" ||\n\t\t$2 ~ /^_?HIDIOC/ ||\n\t\t$2 ~ /^BUS_(USB|HIL|BLUETOOTH|VIRTUAL)$/ ||\n\t\t$2 ~ /^MTD/ ||\n\t\t$2 ~ /^OTP/ ||\n\t\t$2 ~ /^MEM/ ||\n\t\t$2 ~ /^WG/ ||\n\t\t$2 ~ /^FIB_RULE_/ ||\n\t\t$2 ~ /^BLK[A-Z]*(GET$|SET$|BUF$|PART$|SIZE|IOMIN$|IOOPT$|ALIGNOFF$|DISCARD|ROTATIONAL$|ZEROOUT$|GETDISKSEQ$)/ {printf(\"\\t%s = C.%s\\n\", $2, $2)}\n\t\t$2 ~ /^__WCOREFLAG$/ {next}\n\t\t$2 ~ /^__W[A-Z0-9]+$/ {printf(\"\\t%s = C.%s\\n\", substr($2,3), $2)}\n\n\t\t{next}\n\t' | sort\n\n\techo ')'\n) >_const.go\n\n# Pull out the error names for later.\nerrors=$(\n\techo '#include <errno.h>' | $CC -x c - -E -dM $ccflags |\n\tawk '$1==\"#define\" && $2 ~ /^E[A-Z0-9_]+$/ { print $2 }' |\n\tsort\n)\n\n# Pull out the signal names for later.\nsignals=$(\n\techo '#include <signal.h>' | $CC -x c - -E -dM $ccflags |\n\tawk '$1==\"#define\" && $2 ~ /^SIG[A-Z0-9]+$/ { print $2 }' |\n\tgrep -E -v '(SIGSTKSIZE|SIGSTKSZ|SIGRT|SIGMAX64)' |\n\tsort\n)\n\n# Again, writing regexps to a file.\necho '#include <errno.h>' | $CC -x c - -E -dM $ccflags |\n\tawk '$1==\"#define\" && $2 ~ /^E[A-Z0-9_]+$/ { print \"^\\t\" $2 \"[ \\t]*=\" }' |\n\tsort >_error.grep\necho '#include <signal.h>' | $CC -x c - -E -dM $ccflags |\n\tawk '$1==\"#define\" && $2 ~ /^SIG[A-Z0-9]+$/ { print \"^\\t\" $2 \"[ \\t]*=\" }' |\n\tgrep -E -v '(SIGSTKSIZE|SIGSTKSZ|SIGRT|SIGMAX64)' |\n\tsort >_signal.grep\n\necho '// mkerrors.sh' \"$@\"\necho '// Code generated by the command above; see README.md. DO NOT EDIT.'\necho\necho \"//go:build ${GOARCH} && ${GOOS}\"\necho\ngo tool cgo -godefs -- \"$@\" _const.go >_error.out\ncat _error.out | grep -vf _error.grep | grep -vf _signal.grep\necho\necho '// Errors'\necho 'const ('\ncat _error.out | grep -f _error.grep | sed 's/=\\(.*\\)/= syscall.Errno(\\1)/'\necho ')'\n\necho\necho '// Signals'\necho 'const ('\ncat _error.out | grep -f _signal.grep | sed 's/=\\(.*\\)/= syscall.Signal(\\1)/'\necho ')'\n\n# Run C program to print error and syscall strings.\n(\n\techo -E \"\n#include <stdio.h>\n#include <stdlib.h>\n#include <errno.h>\n#include <ctype.h>\n#include <string.h>\n#include <signal.h>\n\n#define nelem(x) (sizeof(x)/sizeof((x)[0]))\n\nenum { A = 'A', Z = 'Z', a = 'a', z = 'z' }; // avoid need for single quotes below\n\nstruct tuple {\n\tint num;\n\tconst char *name;\n};\n\nstruct tuple errors[] = {\n\"\n\tfor i in $errors\n\tdo\n\t\techo -E '\t{'$i', \"'$i'\" },'\n\tdone\n\n\techo -E \"\n};\n\nstruct tuple signals[] = {\n\"\n\tfor i in $signals\n\tdo\n\t\techo -E '\t{'$i', \"'$i'\" },'\n\tdone\n\n\t# Use -E because on some systems bash builtin interprets \\n itself.\n\techo -E '\n};\n\nstatic int\ntuplecmp(const void *a, const void *b)\n{\n\treturn ((struct tuple *)a)->num - ((struct tuple *)b)->num;\n}\n\nint\nmain(void)\n{\n\tint i, e;\n\tchar buf[1024], *p;\n\n\tprintf(\"\\n\\n// Error table\\n\");\n\tprintf(\"var errorList = [...]struct {\\n\");\n\tprintf(\"\\tnum  syscall.Errno\\n\");\n\tprintf(\"\\tname string\\n\");\n\tprintf(\"\\tdesc string\\n\");\n\tprintf(\"} {\\n\");\n\tqsort(errors, nelem(errors), sizeof errors[0], tuplecmp);\n\tfor(i=0; i<nelem(errors); i++) {\n\t\te = errors[i].num;\n\t\tif(i > 0 && errors[i-1].num == e)\n\t\t\tcontinue;\n\t\tstrncpy(buf, strerror(e), sizeof(buf) - 1);\n\t\tbuf[sizeof(buf) - 1] = '\\0';\n\t\t// lowercase first letter: Bad -> bad, but STREAM -> STREAM.\n\t\tif(A <= buf[0] && buf[0] <= Z && a <= buf[1] && buf[1] <= z)\n\t\t\tbuf[0] += a - A;\n\t\tprintf(\"\\t{ %d, \\\"%s\\\", \\\"%s\\\" },\\n\", e, errors[i].name, buf);\n\t}\n\tprintf(\"}\\n\\n\");\n\n\tprintf(\"\\n\\n// Signal table\\n\");\n\tprintf(\"var signalList = [...]struct {\\n\");\n\tprintf(\"\\tnum  syscall.Signal\\n\");\n\tprintf(\"\\tname string\\n\");\n\tprintf(\"\\tdesc string\\n\");\n\tprintf(\"} {\\n\");\n\tqsort(signals, nelem(signals), sizeof signals[0], tuplecmp);\n\tfor(i=0; i<nelem(signals); i++) {\n\t\te = signals[i].num;\n\t\tif(i > 0 && signals[i-1].num == e)\n\t\t\tcontinue;\n\t\tstrncpy(buf, strsignal(e), sizeof(buf) - 1);\n\t\tbuf[sizeof(buf) - 1] = '\\0';\n\t\t// lowercase first letter: Bad -> bad, but STREAM -> STREAM.\n\t\tif(A <= buf[0] && buf[0] <= Z && a <= buf[1] && buf[1] <= z)\n\t\t\tbuf[0] += a - A;\n\t\t// cut trailing : number.\n\t\tp = strrchr(buf, \":\"[0]);\n\t\tif(p)\n\t\t\t*p = '\\0';\n\t\tprintf(\"\\t{ %d, \\\"%s\\\", \\\"%s\\\" },\\n\", e, signals[i].name, buf);\n\t}\n\tprintf(\"}\\n\\n\");\n\n\treturn 0;\n}\n\n'\n) >_errors.c\n\n$CC $ccflags -o _errors _errors.c && $GORUN ./_errors && rm -f _errors.c _errors _const.go _error.grep _signal.grep _error.out\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/vendor/golang.org/x/sys/unix/mkerrors.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/bash\nset -e\nset -x\n\nif [ ! -d /tmp/build-golang/src/github.com/json-iterator ]; then\n    mkdir -p /tmp/build-golang/src/github.com/json-iterator\n    ln -s $PWD /tmp/build-golang/src/github.com/json-iterator/go\nfi\nexport GOPATH=/tmp/build-golang\ngo get -u github.com/golang/dep/cmd/dep\ncd /tmp/build-golang/src/github.com/json-iterator/go\nexec $GOPATH/bin/dep ensure -update\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/vendor/github.com/json-iterator/go/build.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Usage: get-logs.sh [<job ID>]\n#\n# Downloads the latest job output or the one with the specified ID\n# and prepares running benchmarks for it.\n\nset -o pipefail\nset -o errexit\nset -x\n\ncd \"$(dirname \"$0\")\"\n\nlatest_job () {\n    gsutil cat gs://kubernetes-jenkins/logs/ci-kubernetes-kind-e2e-json-logging/latest-build.txt\n}\n\njob=${1:-$(latest_job)}\n\nrm -rf ci-kubernetes-kind-e2e-json-logging\nmkdir ci-kubernetes-kind-e2e-json-logging\ngsutil -m cp -R \"gs://kubernetes-jenkins/logs/ci-kubernetes-kind-e2e-json-logging/${job}/*\" ci-kubernetes-kind-e2e-json-logging/\n\nfor i in kube-apiserver kube-controller-manager kube-scheduler; do\n    # Before (container runtime log dump (?)):\n    #   2023-03-07T07:30:52.193301924Z stderr F {\"ts\":1678174252192.0676,\"caller\":\"scheduler/schedule_one.go:81\",\"msg\":\"Attempting to schedule pod\",\"v\":3,\"pod\":{\"name\":\"simpletest.rc-zgd47\",\"namespace\":\"gc-5422\"}}\n    # After:\n    #   {\"ts\":1678174252192.0676,\"caller\":\"scheduler/schedule_one.go:81\",\"msg\":\"Attempting to schedule pod\",\"v\":3,\"pod\":{\"name\":\"simpletest.rc-zgd47\",\"namespace\":\"gc-5422\"}}\n    sed -e 's/^20[^ ]* stderr . //' \\\n        ci-kubernetes-kind-e2e-json-logging/artifacts/kind-control-plane/containers/$i-*.log \\\n        > ci-kubernetes-kind-e2e-json-logging/$i.log;\ndone\n\n# Before (systemd format):\n#   Mar 07 07:22:05 kind-control-plane kubelet[288]: {\"ts\":1678173725722.4487,\"caller\":\"flag/flags.go:64\",\"msg\":\"FLAG: --address=\\\"0.0.0.0\\\"\\n\",\"v\":1}\n# After:\n#   {\"ts\":1678173725722.4487,\"caller\":\"flag/flags.go:64\",\"msg\":\"FLAG: --address=\\\"0.0.0.0\\\"\\n\",\"v\":1}\ngrep 'kind-worker kubelet' ci-kubernetes-kind-e2e-json-logging/artifacts/kind-worker/kubelet.log | \\\n    sed -e 's;^.* kind-worker kubelet[^ ]*: ;;' > ci-kubernetes-kind-e2e-json-logging/kind-worker-kubelet.log\n\n# Create copies of the actual files, whether they already exist or not. To\n# clean up disk space, use \"git clean -fx test/integration/logs/benchmark\".\ncopy () {\n    from=\"$1\"\n    to=\"$2\"\n\n    mkdir -p \"$(dirname \"$to\")\"\n    rm -f \"$to\"\n    cp \"$from\" \"$to\"\n}\ncopy ci-kubernetes-kind-e2e-json-logging/kind-worker-kubelet.log data/kind-worker-kubelet.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-apiserver.log data/kube-apiserver.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-controller-manager.log data/kube-controller-manager.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-scheduler.log data/kube-scheduler.log\n\ncopy ci-kubernetes-kind-e2e-json-logging/kind-worker-kubelet.log data/v3/kind-worker-kubelet.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-apiserver.log data/v3/kube-apiserver.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-controller-manager.log data/v3/kube-controller-manager.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-scheduler.log data/v3/kube-scheduler.log\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/logs/benchmark/get-logs.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Create a shell script for Kubernetes cluster management", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2024 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Invoke this script with a list of *.dat and it'll plot them with gnuplot.\n# Any non-file parameter is passed through to gnuplot. By default,\n# an X11 window is used to display the result. To write into a file,\n# use\n#  -e \"set term png; set output <output>.png\"\n\nfiles=()\nargs=( -e \"set term x11 persist\" )\n\nfor i in \"$@\"; do\n    if [ -f \"$i\" ]; then\n        files+=(\"$i\")\n    else\n        args+=(\"$i\")\n    fi\ndone\n\n(\n    cat <<EOF\nset ytics autofreq nomirror tc lt 1\nset xlabel 'measurement runtime [seconds]'\nset ylabel 'scheduling rate [pods/second]' tc lt 1\nset y2tics autofreq nomirror tc lt 2\nset y2label 'scheduling attempts per pod' tc lt 2\n\n# Derivative from https://stackoverflow.com/questions/15751226/how-can-i-plot-the-derivative-of-a-graph-in-gnuplot.\nd2(x,y) = (\\$0 == 0) ? (x1 = x, y1 = y, 1/0) : (x2 = x1, x1 = x, y2 = y1, y1 = y, (y1-y2)/(x1-x2))\ndx = 0.25\n\nEOF\n    echo -n \"plot \"\n    for file in \"${files[@]}\"; do\n        echo -n \"'${file}' using (\\$1 - dx):(d2(\\$1, \\$2)) with linespoints title '$(basename \"$file\" .dat | sed -e 's/_/ /g') metric rate' axis x1y1, \"\n        echo -n \"'${file}' using (\\$1 - dx):(d2(\\$1, \\$4)) with linespoints title '$(basename \"$file\" .dat | sed -e 's/_/ /g') observed rate' axis x1y1, \"\n        echo -n \"'${file}' using 1:(\\$3/\\$2) with linespoints title '$(basename \"$file\" .dat | sed -e 's/_/ /g') attempts' axis x1y2, \"\n    done\n    echo\n) | tee /dev/stderr | gnuplot \"${args[@]}\" -\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/scheduler_perf/gnuplot.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Create a shell script for Kubernetes cluster management", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\nif [[ -n \"${EXEC_PLUGIN_OUTPUT_FILE-\"\"}\" ]]; then\n  cat \"$EXEC_PLUGIN_OUTPUT_FILE\"\n  exit\nfi\n\necho \"${EXEC_PLUGIN_OUTPUT-\"\"}\"\n\nexit \"${EXEC_PLUGIN_EXEC_CODE-0}\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/client/testdata/exec-plugin.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Create a shell script for Kubernetes cluster management", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This file is not executable, and therefore it will not be run.\nexit 1\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/client/testdata/exec-plugin-not-executable.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\nTEST_ARGS=\"\"\nRUN_PATTERN=\".*\"\nPROFILE_OPTS=\"\"\n\nfunction usage() {\n  echo \"usage: $0 <options>\"\n  echo \" -h display this help message\"\n  echo \" -d enable debug logs in tests\"\n  echo \" -r <pattern> regex pattern to match for tests\"\n  echo \" -o <filename> file to write JSON formatted results to\"\n  echo \" -p <id> enable cpu and memory profiles, output written to mem-<id>.out and cpu-<id>.out\"\n  echo \" -c enable custom test configuration\"\n  echo \" -a <name> allocator name, one of RangeAllocator, CloudAllocator, IPAMFromCluster, IPAMFromCloud\"\n  echo \" -k <num> api server qps for allocator\"\n  echo \" -n <num> number of nodes to simulate\"\n  echo \" -m <num> api server qps for node creation\"\n  echo \" -l <num> gce cloud endpoint qps\"\n  exit 1\n}\n\nwhile getopts \":hdr:o:p:ca:k:n:m:l:\" opt; do\n  case ${opt} in\n    d) TEST_ARGS=\"${TEST_ARGS} -v=6\"\n      ;;\n    r) RUN_PATTERN=\"${OPTARG}\"\n      ;;\n    o) TEST_ARGS=\"${TEST_ARGS} -log ${OPTARG}\"\n      ;;\n    p) PROFILE_OPTS=\"-memprofile mem-${OPTARG}.out -cpuprofile cpu-${OPTARG}.out\"\n      ;;\n    c) TEST_ARGS=\"${TEST_ARGS} -custom\"\n      ;;\n    a) TEST_ARGS=\"${TEST_ARGS} -allocator ${OPTARG}\"\n      ;;\n    k) TEST_ARGS=\"${TEST_ARGS} -kube-qps ${OPTARG}\"\n      ;;\n    n) TEST_ARGS=\"${TEST_ARGS} -num-nodes ${OPTARG}\"\n      ;;\n    m) TEST_ARGS=\"${TEST_ARGS} -create-qps ${OPTARG}\"\n      ;;\n    l) TEST_ARGS=\"${TEST_ARGS} -cloud-qps ${OPTARG}\"\n      ;;\n    h) usage\n      ;;\n    \\?) usage\n      ;;\n  esac\ndone\n\nKUBE_ROOT=$(dirname \"${BASH_SOURCE[0]}\")/../../../\nsource \"${KUBE_ROOT}/hack/lib/init.sh\"\n\nkube::golang::setup_env\n\nDIR_BASENAME=$(dirname \"${BASH_SOURCE[0]}\")\npushd \"${DIR_BASENAME}\"\n\ncleanup() {\n  popd 2> /dev/null\n  kube::etcd::cleanup\n  kube::log::status \"performance test cleanup complete\"\n}\n\ntrap cleanup EXIT\n\nkube::etcd::start\n\n# Running IPAM tests. It might take a long time.\nkube::log::status \"performance test (IPAM) start\"\ngo test \"${PROFILE_OPTS}\" -test.run=\"${RUN_PATTERN}\" -test.timeout=60m -test.short=false -v -args \"${TEST_ARGS}\"\nkube::log::status \"... IPAM tests finished.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/ipamperf/test-performance.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#! /bin/bash\n\n# Copyright 2016 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This volume is assumed to exist and is shared with parent of the init\n# container. It contains the zookeeper installation.\nINSTALL_VOLUME=\"/opt\"\n\n# This volume is assumed to exist and is shared with the peer-finder\n# init container. It contains on-start/change configuration scripts.\nWORKDIR_VOLUME=\"/work-dir\"\n\n# As of April-2016 is 3.4.8 is the latest stable, but versions 3.5.0 onward\n# allow dynamic reconfiguration.\nVERSION=\"3.5.0-alpha\"\n\nfor i in \"$@\"\ndo\ncase $i in\n    -i=*|--install-into=*)\n    INSTALL_VOLUME=\"${i#*=}\"\n    shift\n    ;;\n    -w=*|--work-dir=*)\n    WORKDIR_VOLUME=\"${i#*=}\"\n    shift\n    ;;\n    *)\n    # unknown option\n    ;;\nesac\ndone\n\necho installing config scripts into \"${WORKDIR_VOLUME}\"\nmkdir -p \"${WORKDIR_VOLUME}\"\ncp /on-start.sh \"${WORKDIR_VOLUME}\"/\ncp /peer-finder \"${WORKDIR_VOLUME}\"/\n\necho installing zookeeper-\"${VERSION}\" into \"${INSTALL_VOLUME}\"\nmkdir -p \"${INSTALL_VOLUME}\"\nmv /zookeeper \"${INSTALL_VOLUME}\"/zookeeper\ncp \"${INSTALL_VOLUME}\"/zookeeper/conf/zoo_sample.cfg \"${INSTALL_VOLUME}\"/zookeeper/conf/zoo.cfg\n\n# TODO: Should dynamic config be tied to the version?\nIFS=\".\" read -ra RELEASE <<< \"${VERSION}\"\nif [ \"$((\"${RELEASE[1]}\"))\" -gt 4 ]; then\n    echo zookeeper-\"${VERSION}\" supports dynamic reconfiguration, enabling it\n    echo \"standaloneEnabled=false\" >> \"${INSTALL_VOLUME}\"/zookeeper/conf/zoo.cfg\n    echo \"dynamicConfigFile=${INSTALL_VOLUME}/zookeeper/conf/zoo.cfg.dynamic\" >> \"${INSTALL_VOLUME}\"/zookeeper/conf/zoo.cfg\nfi\n\n# TODO: This is a hack, netcat is convenient to have in the zookeeper container\n# I want to avoid using a custom zookeeper image just for this. So copy it.\nNC=$(which nc)\nif [ \"${NC}\" != \"\" ]; then\n    echo copying nc into \"${INSTALL_VOLUME}\"\n    cp \"${NC}\" \"${INSTALL_VOLUME}\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/images/pets/zookeeper-installer/install.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env sh\n\n# Test script checking that all expected os/arch compile properly.\n# Does not actually test the logic, just the compilation so we make sure we don't break code depending on the lib.\n\necho2() {\n  echo $@ >&2\n}\n\ntrap end 0\nend() {\n  [ \"$?\" = 0 ] && echo2 \"Pass.\" || (echo2 \"Fail.\"; exit 1)\n}\n\ncross() {\n  os=$1\n  shift\n  echo2 \"Build for $os.\"\n  for arch in $@; do\n    echo2 \"  - $os/$arch\"\n    GOOS=$os GOARCH=$arch go build\n  done\n  echo2\n}\n\nset -e\n\ncross linux     amd64 386 arm arm64 ppc64 ppc64le s390x mips mipsle mips64 mips64le riscv64\ncross darwin    amd64 arm64\ncross freebsd   amd64 386 arm arm64 riscv64\ncross netbsd    amd64 386 arm arm64\ncross openbsd   amd64 386 arm arm64\ncross dragonfly amd64\ncross solaris   amd64\n\n# Not expected to work but should still compile.\ncross windows amd64 386 arm\n\n# TODO: Fix compilation error on openbsd/arm.\n# TODO: Merge the solaris PR.\n\n# Some os/arch require a different compiler. Run in docker.\nif ! hash docker; then\n  # If docker is not present, stop here.\n  return\nfi\n\n# Golang dropped support for darwin 32bits since go1.15. Make sure the lib still compile with go1.14 on those archs.\necho2 \"Build for darwin (32bits).\"\necho2 \"  - darwin/386\"\ndocker build -t creack-pty-test -f Dockerfile.golang --build-arg=GOVERSION=1.14 --build-arg=GOOS=darwin --build-arg=GOARCH=386 .\necho2 \"  - darwin/arm\"\ndocker build -t creack-pty-test -f Dockerfile.golang --build-arg=GOVERSION=1.14 --build-arg=GOOS=darwin --build-arg=GOARCH=arm .\n\n# Run a single test for an old go version. Would be best with go1.0, but not available on Dockerhub.\n# Using 1.6 as it is the base version for the RISCV compiler.\n# Would also be better to run all the tests, not just one, need to refactor this file to allow for specifc archs per version.\necho2 \"Build for linux - go1.6.\"\necho2 \"  - linux/amd64\"\ndocker build -t creack-pty-test -f Dockerfile.golang --build-arg=GOVERSION=1.6 --build-arg=GOOS=linux --build-arg=GOARCH=amd64 .\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/creack/pty/test_crosscompile.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for Git workflow automation", "completion": "```bash\n#1/usr/bin/env bash\n\nPROJECT_DIR=\"\"\nSMITHY_SOURCE_DIR=$(cd `dirname $0` && pwd)\n\nusage() {\n  echo \"Usage: $0 [-s SMITHY_SOURCE_DIR] [-d PROJECT_DIR]\" 1>&2\n  exit 1\n}\n\nwhile getopts \"hs:d:\" options; do\n  case \"${options}\" in\n  s)\n    SMITHY_SOURCE_DIR=${OPTARG}\n    if [ \"$SMITHY_SOURCE_DIR\" == \"\" ]; then\n      echo \"path to smithy-go source directory is required\" || exit\n      usage\n    fi\n    ;;\n  d)\n    PROJECT_DIR=${OPTARG}\n    ;;\n  h)\n    usage\n    ;;\n  *)\n    usage\n    ;;\n  esac\ndone\n\nif [ \"$PROJECT_DIR\" != \"\" ]; then\n  cd $PROJECT_DIR || exit\nfi\n\ngo mod graph | awk '{print $1}' | cut -d '@' -f 1 | sort | uniq | grep \"github.com/aws/smithy-go\" | while read x; do\n  repPath=${x/github.com\\/aws\\/smithy-go/${SMITHY_SOURCE_DIR}}\n  echo -replace $x=$repPath\ndone | xargs go mod edit\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/aws/smithy-go/local-mod-replace.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\nset -ev\n\nif [[ \"$1\" == \"goveralls\" ]]; then\n\techo \"Testing with goveralls...\"\n\tgo get github.com/mattn/goveralls\n\t$HOME/gopath/bin/goveralls -service=travis-ci\nelse\n\techo \"Testing with go test...\"\n\tgo test -v ./...\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/agext/levenshtein/test.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#! /bin/sh\nset -eu\n\ngo get github.com/dvyukov/go-fuzz/go-fuzz\ngo get github.com/dvyukov/go-fuzz/go-fuzz-build\n\nif [ ! -e toml-fuzz.zip ]; then\n    go-fuzz-build github.com/pelletier/go-toml\nfi\n\nrm -fr fuzz\nmkdir -p fuzz/corpus\ncp *.toml fuzz/corpus\n\ngo-fuzz -bin=toml-fuzz.zip -workdir=fuzz\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/pelletier/go-toml/fuzz.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/bash\n\nset -ex\n\nreference_ref=${1:-master}\nreference_git=${2:-.}\n\nif ! `hash benchstat 2>/dev/null`; then\n    echo \"Installing benchstat\"\n    go get golang.org/x/perf/cmd/benchstat\nfi\n\ntempdir=`mktemp -d /tmp/go-toml-benchmark-XXXXXX`\nref_tempdir=\"${tempdir}/ref\"\nref_benchmark=\"${ref_tempdir}/benchmark-`echo -n ${reference_ref}|tr -s '/' '-'`.txt\"\nlocal_benchmark=\"`pwd`/benchmark-local.txt\"\n\necho \"=== ${reference_ref} (${ref_tempdir})\"\ngit clone ${reference_git} ${ref_tempdir} >/dev/null 2>/dev/null\npushd ${ref_tempdir} >/dev/null\ngit checkout ${reference_ref} >/dev/null 2>/dev/null\ngo test -bench=. -benchmem | tee ${ref_benchmark}\ncd benchmark\ngo test -bench=. -benchmem | tee -a ${ref_benchmark}\npopd >/dev/null\n\necho \"\"\necho \"=== local\"\ngo test -bench=. -benchmem  | tee ${local_benchmark}\ncd benchmark\ngo test -bench=. -benchmem | tee -a ${local_benchmark}\n\necho \"\"\necho \"=== diff\"\nbenchstat -delta-test=none ${ref_benchmark} ${local_benchmark}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/pelletier/go-toml/benchmark.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\n#\n# This script is used to coerce certain commands which rely on the presence of\n# a go.mod into working with our repository. It works by creating a fake\n# go.mod, running a specified command (passed via arguments), and removing it\n# when the command is finished. This script should be dropped when this\n# repository is a proper Go module with a permanent go.mod.\n\nset -e\n\nSCRIPTDIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nROOTDIR=\"$(cd \"${SCRIPTDIR}/..\" && pwd)\"\n\nif test -e \"${ROOTDIR}/go.mod\"; then\n\t{\n\t\tscriptname=$(basename \"$0\")\n\t\tcat >&2 <<- EOF\n\t\t\t$scriptname: WARN: go.mod exists in the repository root!\n\t\t\t$scriptname: WARN: Using your go.mod instead of our generated version -- this may misbehave!\n\t\tEOF\n\t} >&2\nelse\n\tset -x\n\n\ttee \"${ROOTDIR}/go.mod\" >&2 <<- EOF\n\t\tmodule github.com/docker/docker\n\n\t\tgo 1.23.0\n\tEOF\n\ttrap 'rm -f \"${ROOTDIR}/go.mod\"' EXIT\nfi\n\nGO111MODULE=on GOTOOLCHAIN=local \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/with-go-mod.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for system service management", "completion": "```bash\n#!/bin/sh\nset -eu\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types --skip-validator -C api/swagger-gen.yaml \\\n\t-n ErrorResponse \\\n\t-n Plugin \\\n\t-n PluginDevice \\\n\t-n PluginMount \\\n\t-n PluginEnv \\\n\t-n PluginInterfaceType\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/common --skip-validator -C api/swagger-gen.yaml \\\n\t-n IDResponse\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/storage --skip-validator -C api/swagger-gen.yaml \\\n\t-n DriverData\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/container --skip-validator -C api/swagger-gen.yaml \\\n\t-n ContainerCreateResponse \\\n\t-n ContainerUpdateResponse \\\n\t-n ContainerTopResponse \\\n\t-n ContainerWaitResponse \\\n\t-n ContainerWaitExitError \\\n\t-n ChangeType \\\n\t-n FilesystemChange \\\n\t-n Port\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/image --skip-validator -C api/swagger-gen.yaml \\\n\t-n ImageDeleteResponseItem\n#-n ImageSummary TODO: Restore when go-swagger is updated\n# See https://github.com/moby/moby/pull/47526#discussion_r1551800022\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/network --skip-validator -C api/swagger-gen.yaml \\\n\t-n NetworkCreateResponse\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/volume --skip-validator -C api/swagger-gen.yaml \\\n\t-n Volume \\\n\t-n VolumeCreateOptions \\\n\t-n VolumeListResponse\n\nswagger generate operation -f api/swagger.yaml \\\n\t-t api -a types -m types -C api/swagger-gen.yaml \\\n\t-T api/templates --skip-responses --skip-parameters --skip-validator \\\n\t-n Authenticate \\\n\t-n ImageHistory\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/swarm --skip-validator -C api/swagger-gen.yaml \\\n\t-n ServiceCreateResponse \\\n\t-n ServiceUpdateResponse\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/generate-swagger-api.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\nset -e\n\n# This script builds various binary artifacts from a checkout of the docker\n# source code.\n#\n# Requirements:\n# - The current directory should be a checkout of the docker source code\n#   (https://github.com/docker/docker). Whatever version is checked out\n#   will be built.\n# - The VERSION file, at the root of the repository, should exist, and\n#   will be used as Docker binary version and package version.\n# - The hash of the git commit will also be included in the Docker binary,\n#   with the suffix -unsupported if the repository isn't clean.\n# - The script is intended to be run inside the docker container specified\n#   in the Dockerfile at the root of the source. In other words:\n#   DO NOT CALL THIS SCRIPT DIRECTLY.\n# - The right way to call this script is to invoke \"make\" from\n#   your checkout of the Docker repository.\n#   the Makefile will do a \"docker build -t docker .\" and then\n#   \"docker run hack/make.sh\" in the resulting image.\n#\n\nset -o pipefail\n\nexport DOCKER_PKG='github.com/docker/docker'\nexport SCRIPTDIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nexport MAKEDIR=\"$SCRIPTDIR/make\"\nexport PKG_CONFIG=${PKG_CONFIG:-pkg-config}\n\necho\n\n# List of bundles to create when no argument is passed\nDEFAULT_BUNDLES=(\n\tbinary-daemon\n\tdynbinary\n\ttest-integration\n\ttest-docker-py\n)\n\nVERSION=${VERSION:-dev}\ncase \"$VERSION\" in\n\trefs/tags/v*) VERSION=${VERSION#refs/tags/v} ;;\n\trefs/tags/*) VERSION=${VERSION#refs/tags/} ;;\n\trefs/heads/*) VERSION=$(echo \"${VERSION#refs/heads/}\" | sed -r 's#/+#-#g') ;;\n\trefs/pull/*) VERSION=pr-$(echo \"$VERSION\" | grep -o '[0-9]\\+') ;;\nesac\n\n! BUILDTIME=$(date -u -d \"@${SOURCE_DATE_EPOCH:-$(date +%s)}\" --rfc-3339 ns 2> /dev/null | sed -e 's/ /T/')\nif [ \"$DOCKER_GITCOMMIT\" ]; then\n\tGITCOMMIT=\"$DOCKER_GITCOMMIT\"\nelif command -v git &> /dev/null && [ -e .git ] && git rev-parse &> /dev/null; then\n\tGITCOMMIT=$(git rev-parse HEAD)\n\tif [ -n \"$(git status --porcelain --untracked-files=no)\" ]; then\n\t\tGITCOMMIT=\"$GITCOMMIT-unsupported\"\n\t\techo \"#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\t\techo \"# GITCOMMIT = $GITCOMMIT\"\n\t\techo \"# The version you are building is listed as unsupported because\"\n\t\techo \"# there are some files in the git repository that are in an uncommitted state.\"\n\t\techo \"# Commit these changes, or add to .gitignore to remove the -unsupported from the version.\"\n\t\techo \"# Here is the current list:\"\n\t\tgit status --porcelain --untracked-files=no\n\t\techo \"#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\tfi\nelse\n\techo >&2 'error: .git directory missing and DOCKER_GITCOMMIT not specified'\n\techo >&2 '  Please either build with the .git directory accessible, or specify the'\n\techo >&2 '  exact commit hash you are building using DOCKER_GITCOMMIT for future'\n\techo >&2 '  accountability in diagnosing build issues.  Thanks!'\n\texit 1\nfi\n\nif [ \"$AUTO_GOPATH\" ]; then\n\trm -rf .gopath\n\tmkdir -p .gopath/src/\"$(dirname \"${DOCKER_PKG}\")\"\n\tln -sf ../../../.. .gopath/src/\"${DOCKER_PKG}\"\n\texport GOPATH=\"${PWD}/.gopath\"\nfi\n\nif [ -z \"${EXCLUDE_AUTO_BUILDTAG_JOURNALD:-}\" ] && ${PKG_CONFIG} 'libsystemd' 2> /dev/null; then\n\tDOCKER_BUILDTAGS+=\" journald\"\nfi\n\n# Use these flags when compiling the tests and final binary\n\nif [ -z \"$DOCKER_DEBUG\" ]; then\n\tLDFLAGS='-w'\nfi\n\nBUILDFLAGS=(${BUILDFLAGS} -tags \"netgo osusergo static_build $DOCKER_BUILDTAGS\")\nLDFLAGS_STATIC=\"-extldflags -static\"\n\nif [ \"$(uname -s)\" = 'FreeBSD' ]; then\n\t# Tell cgo the compiler is Clang, not GCC\n\t# https://code.google.com/p/go/source/browse/src/cmd/cgo/gcc.go?spec=svne77e74371f2340ee08622ce602e9f7b15f29d8d3&r=e6794866ebeba2bf8818b9261b54e2eef1c9e588#752\n\texport CC=clang\n\n\t# \"-extld clang\" is a workaround for\n\t# https://code.google.com/p/go/issues/detail?id=6845\n\tLDFLAGS=\"$LDFLAGS -extld clang\"\nfi\n\nbundle() {\n\tlocal bundle=\"$1\"\n\tshift\n\techo \"---> Making bundle: $(basename \"$bundle\") (in $DEST)\"\n\tsource \"$SCRIPTDIR/make/$bundle\" \"$@\"\n}\n\nmain() {\n\tbundle_dir=\"bundles\"\n\tif [ -n \"${PREFIX}\" ]; then\n\t\tbundle_dir=\"${PREFIX}/${bundle_dir}\"\n\tfi\n\n\tif [ -z \"${KEEPBUNDLE-}\" ]; then\n\t\techo \"Removing ${bundle_dir}/\"\n\t\trm -rf \"${bundle_dir}\"/*\n\t\techo\n\tfi\n\tmkdir -p \"${bundle_dir}\"\n\n\tif [ $# -lt 1 ]; then\n\t\tbundles=(${DEFAULT_BUNDLES[@]})\n\telse\n\t\tbundles=($@)\n\tfi\n\tfor bundle in ${bundles[@]}; do\n\t\texport DEST=\"${bundle_dir}/$(basename \"$bundle\")\"\n\t\t# Cygdrive paths don't play well with go build -o.\n\t\tif [[ \"$(uname -s)\" == CYGWIN* ]]; then\n\t\t\texport DEST=\"$(cygpath -mw \"$DEST\")\"\n\t\tfi\n\t\tmkdir -p \"$DEST\"\n\t\tABS_DEST=\"$(cd \"$DEST\" && pwd -P)\"\n\t\tbundle \"$bundle\"\n\t\techo\n\tdone\n}\n\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/make.sh", "category": "containerization", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#!/bin/bash\n\nset -e\nset -x\n\nRM_GOPATH=0\n\nTMP_GOPATH=${TMP_GOPATH:-\"\"}\n\n: ${PREFIX:=\"/usr/local/bin\"}\n\nif [ -z \"$TMP_GOPATH\" ]; then\n\texport GOPATH=\"$(mktemp -d)\"\n\tRM_GOPATH=1\nelse\n\texport GOPATH=\"$TMP_GOPATH\"\nfi\ncase \"$(go env GOARCH)\" in\n\tmips* | ppc64)\n\t\t# pie build mode is not supported on mips architectures\n\t\texport GO_BUILDMODE=\"\"\n\t\t;;\n\t*)\n\t\texport GO_BUILDMODE=\"-buildmode=pie\"\n\t\t;;\nesac\n\ndir=\"$(dirname $0)\"\n\nbin=$1\nshift\n\nif [ ! -f \"${dir}/${bin}.installer\" ]; then\n\techo \"Could not find installer for \\\"$bin\\\"\"\n\texit 1\nfi\n\n. ${dir}/${bin}.installer\ninstall_${bin} \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/dockerfile/install/install.sh", "category": "infrastructure", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/sh\n\nset -e\nversion=\"$1\"\nrepository=\"$2\"\noutdir=\"$3\"\n\nDOWNLOAD_URL=\"https://download.docker.com/linux/static/stable/$(xx-info march)/docker-${version#v}.tgz\"\n\nmkdir \"$outdir\"\nif curl --head --silent --fail \"${DOWNLOAD_URL}\" 1> /dev/null 2>&1; then\n\tcurl -fsSL \"${DOWNLOAD_URL}\" | tar -xz docker/docker\n\tmv docker/docker \"${outdir}/docker\"\nelse\n\tgit init -q .\n\tgit remote remove origin 2> /dev/null || true\n\tgit remote add origin \"${repository}\"\n\tgit fetch -q --depth 1 origin \"${version}\" +refs/tags/*:refs/tags/*\n\tgit checkout -fq \"${version}\"\n\tif [ -d ./components/cli ]; then\n\t\tmv ./components/cli/* ./\n\t\tCGO_ENABLED=0 xx-go build -o \"${outdir}/docker\" ./cmd/docker\n\t\tgit reset --hard \"${version}\"\n\telse\n\t\txx-go --wrap && CGO_ENABLED=0 TARGET=\"${outdir}\" ./scripts/build/binary\n\tfi\nfi\n\nxx-verify \"${outdir}/docker\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/dockerfile/cli.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for Git workflow automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n# This repository contains one logical codebase but as an implementation detail\n# it's split into multiple modules at the boundaries of code ownership, so\n# that we can keep track of which dependency changes might affect which\n# components.\n#\n# This script runs \"go mod tidy\" in each module to synchronize any dependency\n# updates that were made in any one of the modules.\n\nset -eufo pipefail\n\n# We'll do our work in the root of the repository, which is the parent\n# directory of where this script is.\ncd \"$( dirname \"${BASH_SOURCE[0]}\" )/..\"\n\n# We need to make sure the root go.mod is synchronized first, because otherwise\n# the \"go list\" command below might fail.\ngo mod tidy\n\n# Each of the modules starting at our root gets its go.mod and go.sum\n# synchronized, so that we can see which components are affected by an\n# update and therefore which codeowners might be interested in the change.\nfor dir in $(go list -m -f '{{.Dir}}' github.com/hashicorp/terraform/...); do\n    (cd $dir && go mod tidy)\ndone\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/scripts/syncdeps.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Create a shell script for Git workflow automation", "completion": "```bash\n#!/bin/bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n\n# This script rewrites [GH-nnnn]-style references in the CHANGELOG.md file to\n# be Markdown links to the given github issues.\n#\n# This is run during releases so that the issue references in all of the\n# released items are presented as clickable links, but we can just use the\n# easy [GH-nnnn] shorthand for quickly adding items to the \"Unrelease\" section\n# while merging things between releases.\n\nset -e\n\nif [[ ! -f CHANGELOG.md ]]; then\n  echo \"ERROR: CHANGELOG.md not found in pwd.\"\n  echo \"Please run this from the root of the terraform source repository\"\n  exit 1\nfi\n\nif [[ `uname` == \"Darwin\" ]]; then\n  echo \"Using BSD sed\"\n  SED=\"sed -i.bak -E -e\"\nelse\n  echo \"Using GNU sed\"\n  SED=\"sed -i.bak -r -e\"\nfi\n\n$SED 's/GH-([0-9]+)/\\[#\\1\\]\\(https:\\/\\/github.com\\/hashicorp\\/terraform\\/issues\\/\\1\\)/g' -e 's/\\[\\[#(.+)([0-9])\\)]$/(\\[#\\1\\2))/g' CHANGELOG.md\n\nrm CHANGELOG.md.bak\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/scripts/changelog-links.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n#\n# This script builds the application from source for multiple platforms.\n\n# Get the parent directory of where this script is.\nSOURCE=\"${BASH_SOURCE[0]}\"\nwhile [ -h \"$SOURCE\" ] ; do SOURCE=\"$(readlink \"$SOURCE\")\"; done\nDIR=\"$( cd -P \"$( dirname \"$SOURCE\" )/..\" && pwd )\"\n\n# Change into that directory\ncd \"$DIR\" || exit\n\n# Determine the arch/os combos we're building for\nXC_ARCH=${XC_ARCH:-\"386 amd64 arm\"}\nXC_OS=${XC_OS:-linux darwin windows freebsd openbsd solaris}\nXC_EXCLUDE_OSARCH=\"!darwin/arm !darwin/386\"\n\n# Delete the old dir\necho \"==> Removing old directory...\"\nrm -f bin/*\nrm -rf pkg/*\nmkdir -p bin/\n\n# If its dev mode, only build for ourself\nif [[ -n \"${TF_DEV}\" ]]; then\n    XC_OS=$(go env GOOS)\n    XC_ARCH=$(go env GOARCH)\nfi\n\nif ! which gox > /dev/null; then\n    echo \"==> Installing gox...\"\n    go install github.com/mitchellh/gox\nfi\n\n# Instruct gox to build statically linked binaries\nexport CGO_ENABLED=0\n\n# Set module download mode to readonly to not implicitly update go.mod\nexport GOFLAGS=\"-mod=readonly\"\n\n# In release mode we don't want debug information in the binary and we don't\n# want the -dev version marker\nif [[ -n \"${TF_RELEASE}\" ]]; then\n    LD_FLAGS=\"-s -w -X 'github.com/hashicorp/terraform/version.dev=no'\"\nfi\n\n# Ensure all remote modules are downloaded and cached before build so that\n# the concurrent builds launched by gox won't race to redundantly download them.\ngo mod download\n\n# Build!\necho \"==> Building...\"\ngox \\\n    -os=\"${XC_OS}\" \\\n    -arch=\"${XC_ARCH}\" \\\n    -osarch=\"${XC_EXCLUDE_OSARCH}\" \\\n    -ldflags \"${LD_FLAGS}\" \\\n    -output \"pkg/{{.OS}}_{{.Arch}}/terraform\" \\\n    .\n\n# Move all the compiled things to the $GOPATH/bin\nGOPATH=${GOPATH:-$(go env GOPATH)}\ncase $(uname) in\n    CYGWIN*)\n        GOPATH=\"$(cygpath $GOPATH)\"\n        ;;\nesac\nOLDIFS=$IFS\nIFS=: MAIN_GOPATH=($GOPATH)\nIFS=$OLDIFS\n\n# Create GOPATH/bin if it's doesn't exists\nif [ ! -d $MAIN_GOPATH/bin ]; then\n    echo \"==> Creating GOPATH/bin directory...\"\n    mkdir -p $MAIN_GOPATH/bin\nfi\n\n# Copy our OS/Arch to the bin/ directory\nDEV_PLATFORM=\"./pkg/$(go env GOOS)_$(go env GOARCH)\"\nif [[ -d \"${DEV_PLATFORM}\" ]]; then\n    for F in $(find ${DEV_PLATFORM} -mindepth 1 -maxdepth 1 -type f); do\n        cp ${F} bin/\n        cp ${F} ${MAIN_GOPATH}/bin/\n    done\nfi\n\nif [ \"${TF_DEV}x\" = \"x\" ]; then\n    # Zip and copy to the dist dir\n    echo \"==> Packaging...\"\n    for PLATFORM in $(find ./pkg -mindepth 1 -maxdepth 1 -type d); do\n        OSARCH=$(basename ${PLATFORM})\n        echo \"--> ${OSARCH}\"\n\n        pushd $PLATFORM >/dev/null 2>&1\n        zip ../${OSARCH}.zip ./*\n        popd >/dev/null 2>&1\n    done\nfi\n\n# Done!\necho\necho \"==> Results:\"\nls -hl bin/\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/scripts/build.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n\nset -uo pipefail\n\nCHANGIE_VERSION=\"${CHANGIE_VERSION:-1.21.0}\"\nSEMVER_VERSION=\"${SEMVER_VERSION:-7.6.3}\"\n\nfunction usage {\n  cat <<-'EOF'\nUsage: ./changelog.sh <command> [<options>]\n\nDescription:\n  This script will update CHANGELOG.md with the given version and date and add the changelog entries.\n  It will also set the version/VERSION file to the correct version.\n  In general this script should handle most release related tasks within this repository.\n\nCommands:\n  generate <release-type>\n    generate will create a new section in the CHANGELOG.md file for the given release\n    type. The release type should be one of \"dev\", \"alpha\", \"rc\", \"release\", or \"patch\".\n    `dev`: will update the changelog with the latest unreleased changes.\n    `alpha`: will generate a new section with an alpha version for today.\n    `beta`: will generate a new beta release.\n    `rc`: will generate a new rc release.\n    `release`: will make the initial minor release for this branch.\n    `patch`: will generate a new patch release\n\n  nextminor:\n    Run on main branch: Updates the minor version.\n\n  listIssuesInRelease:\n    Lists all issues in the release passed as an argument.\nEOF\n}\n\nfunction generate {\n    RELEASE_TYPE=\"${1:-}\"\n\n    if [[ -z \"$RELEASE_TYPE\" ]]; then\n        echo \"missing <release-type> argument\"\n        usage\n        exit 1\n    fi\n\n    FOOTER_FILE='footer.md'\n\n    case \"$RELEASE_TYPE\" in\n\n        dev)\n        FOOTER_FILE='footer-with-experiments.md'\n        LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n\n        # Check if we already released this version already\n        if git tag -l \"v$LATEST_VERSION\" | grep -q \"v$LATEST_VERSION\"; then\n            LATEST_VERSION=$(npx -y semver@$SEMVER_VERSION -i patch $LATEST_VERSION)\n        fi\n\n        COMPLETE_VERSION=\"$LATEST_VERSION-dev\"\n\n        npx -y changie@$CHANGIE_VERSION merge -u \"## $LATEST_VERSION (Unreleased)\"\n\n        # If we have no changes yet, the changelog is empty now, so we need to add a header\n        if ! grep -q \"## $LATEST_VERSION\" CHANGELOG.md; then\n            CURRENT_CHANGELOG=$(cat CHANGELOG.md)\n            echo \"## $LATEST_VERSION (Unreleased)\" > CHANGELOG.md\n            echo \"\" >> CHANGELOG.md\n            echo \"$CURRENT_CHANGELOG\" >> CHANGELOG.md\n        fi\n        ;;\n\n        alpha)\n        FOOTER_FILE='footer-with-experiments.md'\n        PRERELEASE_VERSION=$(date +\"alpha%Y%m%d\")\n        LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n        HUMAN_DATE=$(date +\"%B %d, %Y\") # Date in Janurary 1st, 2022 format\n        COMPLETE_VERSION=\"$LATEST_VERSION-$PRERELEASE_VERSION\"\n\n        npx -y changie@$CHANGIE_VERSION merge -u \"## $COMPLETE_VERSION ($HUMAN_DATE)\"\n        ;;\n\n        beta)\n        LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n        # We need to check if this is the first RC of the version\n        BETA_NUMBER=$(git tag -l \"v$LATEST_VERSION-beta*\" | wc -l)\n        BETA_NUMBER=$((BETA_NUMBER + 1))\n        HUMAN_DATE=$(date +\"%B %d, %Y\") # Date in Janurary 1st, 2022 format\n        COMPLETE_VERSION=\"$LATEST_VERSION-beta$BETA_NUMBER\"\n\n        npx -y changie@$CHANGIE_VERSION merge -u \"## $COMPLETE_VERSION ($HUMAN_DATE)\"\n        ;;\n\n        rc)\n        LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n        # We need to check if this is the first RC of the version\n        RC_NUMBER=$(git tag -l \"v$LATEST_VERSION-rc*\" | wc -l)\n        RC_NUMBER=$((RC_NUMBER + 1))\n        HUMAN_DATE=$(date +\"%B %d, %Y\") # Date in Janurary 1st, 2022 format\n        COMPLETE_VERSION=\"$LATEST_VERSION-rc$RC_NUMBER\"\n\n        npx -y changie@$CHANGIE_VERSION merge -u \"## $COMPLETE_VERSION ($HUMAN_DATE)\"\n        ;;\n\n        patch)\n        COMPLETE_VERSION=$(npx -y changie@$CHANGIE_VERSION next patch)\n        npx -y changie@$CHANGIE_VERSION batch patch\n        npx -y changie@$CHANGIE_VERSION merge\n        ;;\n\n        release)\n        # This is the first release of the branch, releasing the new minor version\n        COMPLETE_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n        # We currently keep a file that looks like this release to ensure the alphas and dev versions are generated correctly\n        rm ./.changes/$COMPLETE_VERSION.md\n\n        npx -y changie@$CHANGIE_VERSION batch $COMPLETE_VERSION\n        npx -y changie@$CHANGIE_VERSION merge\n        ;;\n\n        *)\n        echo \"invalid <release-type> argument\"\n        usage\n        exit 1\n\n        ;;\n    esac\n\n    # Set version/VERSION to the to be released version\n    echo \"$COMPLETE_VERSION\" > version/VERSION\n\n    # Add footer to the changelog\n    cat ./.changes/$FOOTER_FILE >> CHANGELOG.md\n    echo \"\" >> CHANGELOG.md\n    cat ./.changes/previous-releases.md >> CHANGELOG.md\n}\n\n# This function expects the current branch to be main. Run it if you want to set main to the next\n# minor version.\nfunction nextminor {\n    # Prepend the latest version to the previous releases\n    LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n    LATEST_VERSION=${LATEST_VERSION%.*} # Remove the patch version\n    CURRENT_FILE_CONTENT=$(cat ./.changes/previous-releases.md)\n    echo \"- [v$LATEST_VERSION](https://github.com/hashicorp/terraform/blob/v$LATEST_VERSION/CHANGELOG.md)\" > ./.changes/previous-releases.md\n    echo \"$CURRENT_FILE_CONTENT\" >> ./.changes/previous-releases.md\n\n    NEXT_VERSION=$(npx -y changie@$CHANGIE_VERSION next minor)\n    # Remove all existing per-release changelogs\n    rm ./.changes/*.*.*.md\n\n    # Remove all old changelog entries\n    rm ./.changes/v*/*.yaml\n\n\n\n    # Create a new empty version file for the next minor version\n    touch ./.changes/$NEXT_VERSION.md\n\n    LATEST_MAJOR_MINOR=$(echo $LATEST_VERSION | awk -F. '{print $1\".\"$2}')\n    NEXT_MAJOR_MINOR=$(echo $NEXT_VERSION | awk -F. '{print $1\".\"$2}')\n\n    # Create a new changes directory for the next minor version\n    mkdir ./.changes/v$NEXT_MAJOR_MINOR\n    touch ./.changes/v$NEXT_MAJOR_MINOR/.gitkeep\n\n    # Set changies changes dir to the new version\n    awk \"{sub(/unreleasedDir: v$LATEST_MAJOR_MINOR/, \\\"unreleasedDir: v$NEXT_MAJOR_MINOR\\\")}1\" ./.changie.yaml > temp && mv temp ./.changie.yaml\n    generate \"dev\"\n}\n\nfunction listIssuesInRelease() {\n    RELEASE_MAJOR_MINOR=\"${1:-}\"\n    if [ -z \"$RELEASE_MAJOR_MINOR\" ]; then\n        echo \"No release version specified\"\n        exit 1\n    fi\n\n    # Check if yq is installed\n    if ! command -v yq &> /dev/null; then\n        echo \"yq could not be found\"\n        exit 1\n    fi\n\n    echo \"Listing issues in release $RELEASE_MAJOR_MINOR\"\n    # Loop through files in .changes/v$RELEASE_MAJOR_MINOR\n    for file in ./.changes/v$RELEASE_MAJOR_MINOR/*.yaml; do\n        ISSUE=$(cat \"$file\" | yq '.custom.Issue')\n        echo \"- https://github.com/hashicorp/terraform/issues/$ISSUE\"\n    done\n}\n\nfunction main {\n  case \"$1\" in\n    generate)\n    generate \"${@:2}\"\n      ;;\n\n    nextminor)\n    nextminor \"${@:2}\"\n      ;;\n\n    listIssuesInRelease)\n    listIssuesInRelease \"${@:2}\"\n      ;;\n\n    *)\n      usage\n      exit 1\n\n      ;;\n  esac\n}\n\nmain \"$@\"\nexit $?\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/scripts/changelog.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n\n# For normal use this package can just be tested with \"go test\" as standard,\n# but this script is an alternative to allow the tests to be run somewhere\n# other than where they are built.\n\n# The primary use for this is cross-compilation, where e.g. we can produce an\n# archive that can be extracted on a Windows system to run the e2e tests there:\n#    $ GOOS=windows GOARCH=amd64 ./make-archive.sh\n#\n# This will produce a zip file build/terraform-e2etest_windows_amd64.zip which\n# can be shipped off to a Windows amd64 system, extracted to some directory,\n# and then executed as follows:\n#    set TF_ACC=1\n#    ./e2etest.exe\n#\n# Because separated e2etest harnesses are intended for testing against \"real\"\n# release executables, the generated archives don't include a copy of\n# the Terraform executable. Instead, the caller of the tests must retrieve\n# and extract a release package into the working directory before running\n# the e2etest executable, so that \"e2etest\" can find and execute it.\n\nset +euo pipefail\n\n# Always run from the directory where this script lives\ncd \"$( dirname \"${BASH_SOURCE[0]}\" )\"\n\nGOOS=\"$(go env GOOS)\"\nGOARCH=\"$(go env GOARCH)\"\nGOEXE=\"$(go env GOEXE)\"\nOUTDIR=\"build/${GOOS}_${GOARCH}\"\nOUTFILE=\"terraform-e2etest_${GOOS}_${GOARCH}.zip\"\n\nLDFLAGS=\"-X github.com/hashicorp/terraform/internal/command/e2etest.terraformBin=./terraform$GOEXE\"\n# Caller may pass in the environment variable GO_LDFLAGS with additional\n# flags we'll use when building.\nif [ -n \"${GO_LDFLAGS+set}\" ]; then\n    LDFLAGS=\"${GO_LDFLAGS} ${LDFLAGS}\"\nfi\n\nmkdir -p \"$OUTDIR\"\n\n# We need the test fixtures available when we run the tests.\ncp -r testdata \"$OUTDIR/testdata\"\n\n# Build the test program\ngo test -o \"$OUTDIR/e2etest$GOEXE\" -c -ldflags \"$LDFLAGS\" github.com/hashicorp/terraform/internal/command/e2etest\n\n# Now bundle it all together for easy shipping!\ncd \"$OUTDIR\"\nzip -r \"../$OUTFILE\" *\n\necho \"e2etest archive created at build/$OUTFILE\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/internal/command/e2etest/make-archive.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n\n######################################################\n# NOTE: This file is managed by the Digital Team's   #\n# Terraform configuration @ hashicorp/mktg-terraform #\n######################################################\n\n# This is run during the website build step to determine if we should skip the build or not.\n# More information: https://vercel.com/docs/platform/projects#ignored-build-step\n\nif [[ \"$VERCEL_GIT_COMMIT_REF\" == \"stable-website\"  ]] ; then\n  # Proceed with the build if the branch is stable-website\n  echo \"✅ - Build can proceed\"\n  exit 1;\nelse\n  # Check for differences in the website directory\n  git diff --quiet HEAD^ HEAD ./\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/website/scripts/should-build.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for application deployment", "completion": "```bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n######################################################\n# NOTE: This file is managed by the Digital Team's   #\n# Terraform configuration @ hashicorp/mktg-terraform #\n######################################################\n\n# Repo which we are cloning and executing npm run build:deploy-preview within\nREPO_TO_CLONE=dev-portal\n# Set the subdirectory name for the dev-portal app\nPREVIEW_DIR=website-preview\n# The product for which we are building the deploy preview\nPRODUCT=terraform\n# Preview mode, controls the UI rendered (either the product site or developer). Can be `io` or `developer`\nPREVIEW_MODE=developer\n\n# Get the git branch of the commit that triggered the deploy preview\n# This will power remote image assets in local and deploy previews\nCURRENT_GIT_BRANCH=$(git rev-parse --abbrev-ref HEAD)\n\n# This is where content files live, relative to the website-preview dir. If omitted, \"../content\" will be used\nLOCAL_CONTENT_DIR=../docs\n\nshould_pull=true\n\n# Clone the dev-portal project, if needed\nif [ ! -d \"$PREVIEW_DIR\" ]; then\n    echo \"⏳ Cloning the $REPO_TO_CLONE repo, this might take a while...\"\n    git clone --depth=1 https://github.com/hashicorp/$REPO_TO_CLONE.git \"$PREVIEW_DIR\"\n    should_pull=false\nfi\n\ncd \"$PREVIEW_DIR\"\n\n# If the directory already existed, pull to ensure the clone is fresh\nif [ \"$should_pull\" = true ]; then\n    git pull origin main\nfi\n\n# Run the dev-portal content-repo start script\nREPO=$PRODUCT \\\nPREVIEW_FROM_REPO=$PRODUCT \\\nLOCAL_CONTENT_DIR=$LOCAL_CONTENT_DIR \\\nCURRENT_GIT_BRANCH=$CURRENT_GIT_BRANCH \\\nPREVIEW_MODE=$PREVIEW_MODE \\\nnpm run start:local-preview\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/website/scripts/website-start.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for application deployment", "completion": "```bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n######################################################\n# NOTE: This file is managed by the Digital Team's   #\n# Terraform configuration @ hashicorp/mktg-terraform #\n######################################################\n\n# Repo which we are cloning and executing npm run build:deploy-preview within\nREPO_TO_CLONE=dev-portal\n# Set the subdirectory name for the base project\nPREVIEW_DIR=website-preview\n# The directory we want to clone the project into\nCLONE_DIR=website-preview\n# The product for which we are building the deploy preview\nPRODUCT=terraform\n# Preview mode, controls the UI rendered (either the product site or developer). Can be `io` or `developer`\nPREVIEW_MODE=developer\n\n# Get the git branch of the commit that triggered the deploy preview\n# This will power remote image assets in local and deploy previews\nCURRENT_GIT_BRANCH=$VERCEL_GIT_COMMIT_REF\n\n# This is where content files live, relative to the website-preview dir. If omitted, \"../content\" will be used\nLOCAL_CONTENT_DIR=../docs\n\nfrom_cache=false\n\nif [ -d \"$PREVIEW_DIR\" ]; then\n  echo \"$PREVIEW_DIR found\"\n  CLONE_DIR=\"$PREVIEW_DIR-tmp\"\n  from_cache=true\nfi\n\n# Clone the base project, if needed\necho \"⏳ Cloning the $REPO_TO_CLONE repo, this might take a while...\"\ngit clone --depth=1 \"https://github.com/hashicorp/$REPO_TO_CLONE.git\" \"$CLONE_DIR\"\n\nif [ \"$from_cache\" = true ]; then\n  echo \"Setting up $PREVIEW_DIR\"\n  cp -R \"./$CLONE_DIR/.\" \"./$PREVIEW_DIR\"\nfi\n\n# cd into the preview directory project\ncd \"$PREVIEW_DIR\"\n\n# Run the build:deploy-preview start script\nPREVIEW_FROM_REPO=$PRODUCT \\\nIS_CONTENT_PREVIEW=true \\\nPREVIEW_MODE=$PREVIEW_MODE \\\nREPO=$PRODUCT \\\nHASHI_ENV=project-preview \\\nLOCAL_CONTENT_DIR=$LOCAL_CONTENT_DIR \\\nCURRENT_GIT_BRANCH=$CURRENT_GIT_BRANCH \\\nnpm run build:deploy-preview\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/website/scripts/website-build.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\nset -uo pipefail\n\nfunction usage {\n  cat <<-'EOF'\nUsage: ./equivalence-test.sh <command> [<args>] [<options>]\n\nDescription:\n  This script will handle various commands related to the execution of the\n  Terraform equivalence tests.\n\nCommands:\n  get_target_branch <version>\n    get_target_branch returns the default target branch for a given Terraform\n    version.\n\n    target_branch=$(./equivalence-test.sh get_target_branch v1.4.3); target_branch=v1.4\n    target_branch=$(./equivalence-test.sh get_target_branch 1.4.3); target_branch=v1.4\n\n  download_equivalence_test_binary <version> <target> <os> <arch>\n    download_equivalence_test_binary downloads the equivalence testing binary\n    for a given version and places it at the target path.\n\n    ./equivalence-test.sh download_equivalence_test_binary 0.3.0 ./bin/terraform-equivalence-testing linux amd64\n\n  build_terraform_binary <target>\n    download_terraform_binary builds the Terraform binary and places it at the\n    target path.\n\n    ./equivalence-test.sh build_terraform_binary ./bin/terraform\nEOF\n}\n\nfunction download_equivalence_test_binary {\n  VERSION=\"${1:-}\"\n  TARGET=\"${2:-}\"\n  OS=\"${3:-}\"\n  ARCH=\"${4:-}\"\n\n  if [[ -z \"$VERSION\" || -z \"$TARGET\" || -z \"$OS\" || -z \"$ARCH\" ]]; then\n    echo \"missing at least one of [<version>, <target>, <os>, <arch>] arguments\"\n    usage\n    exit 1\n  fi\n\n  curl \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"https://api.github.com/repos/hashicorp/terraform-equivalence-testing/releases\" > releases.json\n\n  ASSET=\"terraform-equivalence-testing_v${VERSION}_${OS}_${ARCH}.zip\"\n  ASSET_ID=$(jq -r --arg VERSION \"v$VERSION\" --arg ASSET \"$ASSET\" '.[] | select(.name == $VERSION) | .assets[] | select(.name == $ASSET) | .id' releases.json)\n\n  mkdir -p zip\n  curl -L \\\n    -H \"Accept: application/octet-stream\" \\\n    \"https://api.github.com/repos/hashicorp/terraform-equivalence-testing/releases/assets/$ASSET_ID\" > \"zip/$ASSET\"\n\n  mkdir -p bin\n  unzip -p \"zip/$ASSET\" terraform-equivalence-testing > \"$TARGET\"\n  chmod u+x \"$TARGET\"\n  rm -r zip\n  rm releases.json\n}\n\nfunction build_terraform_binary {\n  TARGET=\"${1:-}\"\n\n  if [[ -z \"$TARGET\" ]]; then\n    echo \"target argument\"\n    usage\n    exit 1\n  fi\n\n  go build -o \"$TARGET\" ./\n  chmod u+x \"$TARGET\"\n}\n\nfunction get_target_branch {\n  VERSION=\"${1:-}\"\n\n  if [ -z \"$VERSION\" ]; then\n    echo \"missing <version> argument\"\n    usage\n    exit 1\n  fi\n\n\n  # Split off the build metadata part, if any\n  # (we won't actually include it in our final version, and handle it only for\n  # completeness against semver syntax.)\n  IFS='+' read -ra VERSION BUILD_META <<< \"$VERSION\"\n\n  # Separate out the prerelease part, if any\n  IFS='-' read -r BASE_VERSION PRERELEASE <<< \"$VERSION\"\n\n  # Separate out major, minor and patch versions.\n  IFS='.' read -r MAJOR_VERSION MINOR_VERSION PATCH_VERSION <<< \"$BASE_VERSION\"\n\n  if [[ \"$PRERELEASE\" == *\"alpha\"* ]]; then\n    TARGET_BRANCH=main\n  else\n    if [[ $MAJOR_VERSION = v* ]]; then\n      TARGET_BRANCH=${MAJOR_VERSION}.${MINOR_VERSION}\n    else\n      TARGET_BRANCH=v${MAJOR_VERSION}.${MINOR_VERSION}\n    fi\n  fi\n\n  echo \"$TARGET_BRANCH\"\n}\n\nfunction main {\n  case \"$1\" in\n    get_target_branch)\n      if [ \"${#@}\" != 2 ]; then\n        echo \"invalid number of arguments\"\n        usage\n        exit 1\n      fi\n\n      get_target_branch \"$2\"\n\n      ;;\n    download_equivalence_test_binary)\n      if [ \"${#@}\" != 5 ]; then\n        echo \"invalid number of arguments\"\n        usage\n        exit 1\n      fi\n\n      download_equivalence_test_binary \"$2\" \"$3\" \"$4\" \"$5\"\n\n      ;;\n    build_terraform_binary)\n      if [ \"${#@}\" != 2 ]; then\n        echo \"invalid number of arguments\"\n        usage\n        exit 1\n      fi\n\n      build_terraform_binary \"$2\"\n\n      ;;\n    *)\n      echo \"unrecognized command $*\"\n      usage\n      exit 1\n\n      ;;\n  esac\n}\n\nmain \"$@\"\nexit $?\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/.github/scripts/equivalence-test.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\nset -uo pipefail\n\nif [[ $arch == 'arm' || $arch == 'arm64' ]]\nthen\n    export DIR=$(mktemp -d)\n    unzip -d $DIR \"${e2e_cache_path}/terraform-e2etest_${os}_${arch}.zip\"\n    unzip -d $DIR \"./terraform_${version}_${os}_${arch}.zip\"\n    sudo chmod +x $DIR/e2etest\n    docker run --platform=linux/arm64 -v $DIR:/src -w /src arm64v8/alpine ./e2etest -test.v\nelse\n    unzip \"${e2e_cache_path}/terraform-e2etest_${os}_${arch}.zip\"\n    unzip \"./terraform_${version}_${os}_${arch}.zip\"\n    TF_ACC=1 ./e2etest -test.v\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/.github/scripts/e2e_test_linux_darwin.sh", "category": "containerization", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/bash\n#\n# Review the cron tasks defined in the system and warn the admin\n# if some of the files will not be run\n#\n# This program is copyright 2011 by Javier Fernandez-Sanguino <<EMAIL>>\n#\n#    This program is free software; you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation; either version 2 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program; if not, write to the Free Software\n#    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n#\n# For more information please see\n#  http://www.gnu.org/licenses/licenses.html#GPL\n\n\nset -e\n# reset locale, just in case\nLC_ALL=C\nexport LC_ALL\n\nPROGNAME=${0##*/}\nPROGVERSION=1.0\n# Command line options\nSHORTOPTS=hvsi\nLONGOPTS=help,version,syslog,info\nset -- $(getopt -s bash -o $SHORTOPTS -l $LONGOPTS --n $PROGNAME -- \"$@\")\n\nversion () {\n  echo \"$PROGNAME $PROGVERSION\"\n  echo \"$PROGNAME is copyright © Javier Fernandez-Sanguino <<EMAIL>>\"\n  echo \"Released under the terms of the GPL version 2 or later\"\n  echo \"This program is part of the cron package\"\n}\n\nusage () {\n    cat <<EOUSE\n    Usage: $PROGNAME [-si]\n\n    Reviews the directories used by cron and reports scripts that\n    might not be run by cron due to problems in their naming or\n    in their setup.\n\n    You should run this program as root to prevent false positives.\n\n    Options:\n        -s       -- Use syslog to report information\n        -i       -- Report also informational messages\nEOUSE\n}\n\nsyslog=\"no\"\nsend_info=\"no\"\nfor opt in $@; do\n    case $opt in\n        -h|--help) usage; exit 0;;\n        -v|--version) version; exit 0;;\n        -s|--syslog) syslog=\"yes\";;\n        -i|--info)   send_info=\"yes\";;\n        *)  ;;\n    esac\ndone\n\n\nsend_message () {\n\n    level=$1\n    msg=$2\n    [ \"$level\" = \"info\" ] && [ \"$send_info\" = \"no\" ] && return\n\n    if [ \"$syslog\" = \"yes\" ] ; then\n        logger -p cron.$level -t CRON $msg\n    else\n        case $level in\n            \"warn\")\n                echo \"WARN: $msg\" >&2\n                ;;\n            \"info\")\n                echo \"INFO: $msg\"\n                ;;\n        esac\n    fi\n}\n\nwarn () {\n# Send a warning to the user\n    file=$1\n    reason=$2\n\n    name=`basename $file`\n    # Skip hidden files\n    echo $name | grep -q -E '^\\.' && return\n    # Skip disabled files\n    echo $name | grep -q -E '\\.disabled' && return\n\n    # TODO: Should we send warnings for '.old' or '.orig'?\n\n    # Do not send a warning if the file is '.dpkg-old' or '.dpkg-dist'\n    if ! echo $file | grep -q -E '\\.dpkg-(old|dist)$' ; then\n        send_message \"warn\" \"The file $file will not be executed by cron: $reason\"\n    else\n        send_message \"info\" \"The file $file is a leftover from the Debian package manager\"\n    fi\n}\n\ncheck_results () {\n\n    dir=$1\n    run_file=$2\n    exec_test=$3\n\n    # Now check the files we found and the ones that exist in the directory\n    find $dir \\( -type f -o -type l \\) -printf '%p %l\\n'  |\n    while read file pointer; do\n        if ! grep -q \"^$file$\" $run_file; then\n            [ -L \"$file\" ] && [ ! -e \"$pointer\" ] && \\\n                    warn $file \"Points to an nonexistent location ($pointer)\" && continue\n            [ \"$exec_test\" = \"yes\" ]  && [ ! -x \"$file\" ] &&  \\\n                    warn $file \"Is not executable\" && continue\n            [ ! -r \"$file\" ] && [ \"`id -u`\" != \"0\" ] && \\\n                    warn $file \"Cannot read the file to determine if it will be run ($PROGNAME is not running as root)\" && continue\n            [ ! -r \"$file\" ] && \\\n                    warn $file \"File is unreadable\" && continue\n             warn $file \"Does not conform to the run-parts convention\"\n        else\n\n# do additional checks for symlinks for files that *are* listed by run-parts\n            if [ -L \"$file\" ] ; then\n# for symlinks: does the file exist?\n                if [ ! -e \"$pointer\" ] ; then\n                    warn $file \"Points to an nonexistent location ($pointer)\"\n                fi\n# for symlinks: is it owned by root?\n                 owner=`ls -l $pointer  | awk '{print $3}'`\n                 if [ \"$owner\" != \"root\" ]; then\n                       warn $file \"Is not owned by root\"\n                 fi\n            fi\n\n       fi\n    done\n\n}\n\n# Setup for the tests\n\n# First: check if we are using -l\n[ -r /etc/default/cron ] &&  . /etc/default/cron\nuse_lsb=\"no\"\n[ \"$LSBNAMES\" = \"-l\" ] && use_lsb=\"yes\"\necho $EXTRA_OPTS | grep -q -- '-l' && use_lsb=\"yes\"\n# Set the options for run parts\nrun_opts=\"\"\n[ \"$use_lsb\" = \"yes\" ] &&  run_opts=\"--lsbsysinit\"\n\ntemp=`tempfile` || { echo \"ERROR: Cannot create temporary file\" >&2 ; exit 1; }\ntrap \"rm -f $temp\" 0 1 2 3 13 15\n\n# Now review the scripts, note that cron does not use run-parts to run these\n# so they are *not* required to be executables, just to conform with the\n\n# Step 1: Review /etc/cron.d\nrun-parts $run_opts --list /etc/cron.d >$temp\ncheck_results /etc/cron.d $temp \"no\"\n\n\n# Step 2: Review /etc/cron.{hourly,daily,weekly,monthly}\n\nfor interval in hourly daily weekly monthly; do\n    testdir=/etc/cron.$interval\n    run-parts $run_opts --test $testdir >$temp\n    check_results $testdir $temp \"yes\"\ndone\n\n\nexit 0\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/cron/examples/cron-tasks-review.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/sh\n(\n\tcd ../../../t\n\ttest_description='git-credential-netrc'\n\t. ./test-lib.sh\n\n\tif ! test_have_prereq PERL; then\n\t\tskip_all='skipping perl interface tests, perl not available'\n\t\ttest_done\n\tfi\n\n\tperl -MTest::More -e 0 2>/dev/null || {\n\t\tskip_all=\"Perl Test::More unavailable, skipping test\"\n\t\ttest_done\n\t}\n\n\t# set up test repository\n\n\ttest_expect_success \\\n\t\t'set up test repository' \\\n\t\t'git config --add gpg.program test.git-config-gpg'\n\n\t# The external test will outputs its own plan\n\ttest_external_has_tap=1\n\n\texport PERL5LIB=\"$GITPERLLIB\"\n\ttest_external \\\n\t\t'git-credential-netrc' \\\n\t\tperl \"$GIT_BUILD_DIR\"/contrib/credential/netrc/test.pl\n\n\ttest_done\n)\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/credential/netrc/t-git-credential-netrc.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/sh\n\nUSAGE=\"[-a] [-r] [-m] [-t] [-n] [-b <newname>] <name>\"\nLONG_USAGE=\"git-resurrect attempts to find traces of a branch tip\ncalled <name>, and tries to resurrect it.  Currently, the reflog is\nsearched for checkout messages, and with -r also merge messages.  With\n-m and -t, the history of all refs is scanned for Merge <name> into\nother/Merge <other> into <name> (respectively) commit subjects, which\nis rather slow but allows you to resurrect other people's topic\nbranches.\"\n\nOPTIONS_KEEPDASHDASH=\nOPTIONS_STUCKLONG=\nOPTIONS_SPEC=\"\\\ngit resurrect $USAGE\n--\nb,branch=            save branch as <newname> instead of <name>\na,all                same as -l -r -m -t\nk,keep-going         full rev-list scan (instead of first match)\nl,reflog             scan reflog for checkouts (enabled by default)\nr,reflog-merges      scan for merges recorded in reflog\nm,merges             scan for merges into other branches (slow)\nt,merge-targets      scan for merges of other branches into <name>\nn,dry-run            don't recreate the branch\"\n\n. git-sh-setup\n\nsearch_reflog () {\n\tsed -ne 's~^\\([^ ]*\\) .*\tcheckout: moving from '\"$1\"' .*~\\1~p' \\\n\t\t< \"$GIT_DIR\"/logs/HEAD\n}\n\nsearch_reflog_merges () {\n\tgit rev-parse $(\n\t\tsed -ne 's~^[^ ]* \\([^ ]*\\) .*\tmerge '\"$1\"':.*~\\1^2~p' \\\n\t\t\t< \"$GIT_DIR\"/logs/HEAD\n\t)\n}\n\noid_pattern=$(git hash-object --stdin </dev/null | sed -e 's/./[0-9a-f]/g')\n\nsearch_merges () {\n\tgit rev-list --all --grep=\"Merge branch '$1'\" \\\n\t\t--pretty=tformat:\"%P %s\" |\n\tsed -ne \"/^$oid_pattern \\($oid_pattern\\) Merge .*/ {s//\\1/p;$early_exit}\"\n}\n\nsearch_merge_targets () {\n\tgit rev-list --all --grep=\"Merge branch '[^']*' into $branch\\$\" \\\n\t\t--pretty=tformat:\"%H %s\" --all |\n\tsed -ne \"/^\\($oid_pattern\\) Merge .*/ {s//\\1/p;$early_exit} \"\n}\n\ndry_run=\nearly_exit=q\nscan_reflog=t\nscan_reflog_merges=\nscan_merges=\nscan_merge_targets=\nnew_name=\n\nwhile test \"$#\" != 0; do\n\tcase \"$1\" in\n\t    -b|--branch)\n\t\tshift\n\t\tnew_name=\"$1\"\n\t\t;;\n\t    -n|--dry-run)\n\t\tdry_run=t\n\t\t;;\n\t    --no-dry-run)\n\t\tdry_run=\n\t\t;;\n\t    -k|--keep-going)\n\t\tearly_exit=\n\t\t;;\n\t    --no-keep-going)\n\t\tearly_exit=q\n\t\t;;\n\t    -m|--merges)\n\t\tscan_merges=t\n\t\t;;\n\t    --no-merges)\n\t\tscan_merges=\n\t\t;;\n\t    -l|--reflog)\n\t\tscan_reflog=t\n\t\t;;\n\t    --no-reflog)\n\t\tscan_reflog=\n\t\t;;\n\t    -r|--reflog_merges)\n\t\tscan_reflog_merges=t\n\t\t;;\n\t    --no-reflog_merges)\n\t\tscan_reflog_merges=\n\t\t;;\n\t    -t|--merge-targets)\n\t\tscan_merge_targets=t\n\t\t;;\n\t    --no-merge-targets)\n\t\tscan_merge_targets=\n\t\t;;\n\t    -a|--all)\n\t\tscan_reflog=t\n\t\tscan_reflog_merges=t\n\t\tscan_merges=t\n\t\tscan_merge_targets=t\n\t\t;;\n\t    --)\n\t\tshift\n\t\tbreak\n\t\t;;\n\t    *)\n\t\tusage\n\t\t;;\n\tesac\n\tshift\ndone\n\ntest \"$#\" = 1 || usage\n\nall_strategies=\"$scan_reflog$scan_reflog_merges$scan_merges$scan_merge_targets\"\nif test -z \"$all_strategies\"; then\n\tdie \"must enable at least one of -lrmt\"\nfi\n\nbranch=\"$1\"\ntest -z \"$new_name\" && new_name=\"$branch\"\n\nif test ! -z \"$scan_reflog\"; then\n\tif test -r \"$GIT_DIR\"/logs/HEAD; then\n\t\tcandidates=\"$(search_reflog $branch)\"\n\telse\n\t\tdie 'reflog scanning requested, but' \\\n\t\t\t'$GIT_DIR/logs/HEAD not readable'\n\tfi\nfi\nif test ! -z \"$scan_reflog_merges\"; then\n\tif test -r \"$GIT_DIR\"/logs/HEAD; then\n\t\tcandidates=\"$candidates $(search_reflog_merges $branch)\"\n\telse\n\t\tdie 'reflog scanning requested, but' \\\n\t\t\t'$GIT_DIR/logs/HEAD not readable'\n\tfi\nfi\nif test ! -z \"$scan_merges\"; then\n\tcandidates=\"$candidates $(search_merges $branch)\"\nfi\nif test ! -z \"$scan_merge_targets\"; then\n\tcandidates=\"$candidates $(search_merge_targets $branch)\"\nfi\n\ncandidates=\"$(git rev-parse $candidates | sort -u)\"\n\nif test -z \"$candidates\"; then\n\thint=\n\ttest \"z$all_strategies\" != \"ztttt\" \\\n\t\t&& hint=\" (maybe try again with -a)\"\n\tdie \"no candidates for $branch found$hint\"\nfi\n\necho \"** Candidates for $branch **\"\nfor cmt in $candidates; do\n\tgit --no-pager log --pretty=tformat:\"%ct:%h [%cr] %s\" --abbrev-commit -1 $cmt\ndone \\\n| sort -n | cut -d: -f2-\n\nnewest=\"$(git rev-list -1 $candidates)\"\nif test ! -z \"$dry_run\"; then\n\tprintf \"** Most recent: \"\n\tgit --no-pager log -1 --pretty=tformat:\"%h %s\" $newest\nelif ! git rev-parse --verify --quiet $new_name >/dev/null; then\n\tprintf \"** Restoring $new_name to \"\n\tgit --no-pager log -1 --pretty=tformat:\"%h %s\" $newest\n\tgit branch $new_name $newest\nelse\n\tprintf \"Most recent: \"\n\tgit --no-pager log -1 --pretty=tformat:\"%h %s\" $newest\n\techo \"** $new_name already exists, doing nothing\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/git-resurrect.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for monitoring and alerting", "completion": "```bash\n#!/bin/sh\n\ndie () {\n\techo \"$*\" >&2\n\texit 1\n}\n\ncd \"$(dirname \"$0\")\"/../.. ||\ndie \"Could not cd to top-level directory\"\n\nmkdir -p .vscode ||\ndie \"Could not create .vscode/\"\n\n# General settings\n\ncat >.vscode/settings.json.new <<\\EOF ||\n{\n    \"C_Cpp.intelliSenseEngine\": \"Default\",\n    \"C_Cpp.intelliSenseEngineFallback\": \"Disabled\",\n    \"[git-commit]\": {\n        \"editor.wordWrap\": \"wordWrapColumn\",\n        \"editor.wordWrapColumn\": 72\n    },\n    \"[c]\": {\n        \"editor.detectIndentation\": false,\n        \"editor.insertSpaces\": false,\n        \"editor.tabSize\": 8,\n        \"editor.wordWrap\": \"wordWrapColumn\",\n        \"editor.wordWrapColumn\": 80,\n        \"files.trimTrailingWhitespace\": true\n    },\n    \"files.associations\": {\n        \"*.h\": \"c\",\n        \"*.c\": \"c\"\n    },\n    \"cSpell.ignorePaths\": [\n    ],\n    \"cSpell.words\": [\n        \"DATAW\",\n        \"DBCACHED\",\n        \"DFCHECK\",\n        \"DTYPE\",\n        \"Hamano\",\n        \"HCAST\",\n        \"HEXSZ\",\n        \"HKEY\",\n        \"HKLM\",\n        \"IFGITLINK\",\n        \"IFINVALID\",\n        \"ISBROKEN\",\n        \"ISGITLINK\",\n        \"ISSYMREF\",\n        \"Junio\",\n        \"LPDWORD\",\n        \"LPPROC\",\n        \"LPWSTR\",\n        \"MSVCRT\",\n        \"NOARG\",\n        \"NOCOMPLETE\",\n        \"NOINHERIT\",\n        \"RENORMALIZE\",\n        \"STARTF\",\n        \"STARTUPINFOEXW\",\n        \"Schindelin\",\n        \"UCRT\",\n        \"YESNO\",\n        \"argcp\",\n        \"beginthreadex\",\n        \"committish\",\n        \"contentp\",\n        \"cpath\",\n        \"cpidx\",\n        \"ctim\",\n        \"dequote\",\n        \"envw\",\n        \"ewah\",\n        \"fdata\",\n        \"fherr\",\n        \"fhin\",\n        \"fhout\",\n        \"fragp\",\n        \"fsmonitor\",\n        \"hnsec\",\n        \"idents\",\n        \"includeif\",\n        \"interpr\",\n        \"iprog\",\n        \"isexe\",\n        \"iskeychar\",\n        \"kompare\",\n        \"mksnpath\",\n        \"mktag\",\n        \"mktree\",\n        \"mmblob\",\n        \"mmbuffer\",\n        \"mmfile\",\n        \"noenv\",\n        \"nparents\",\n        \"ntpath\",\n        \"ondisk\",\n        \"ooid\",\n        \"oplen\",\n        \"osdl\",\n        \"pnew\",\n        \"pold\",\n        \"ppinfo\",\n        \"pushf\",\n        \"pushv\",\n        \"rawsz\",\n        \"rebasing\",\n        \"reencode\",\n        \"repo\",\n        \"rerere\",\n        \"scld\",\n        \"sharedrepo\",\n        \"spawnv\",\n        \"spawnve\",\n        \"spawnvpe\",\n        \"strdup'ing\",\n        \"submodule\",\n        \"submodules\",\n        \"topath\",\n        \"topo\",\n        \"tpatch\",\n        \"unexecutable\",\n        \"unhide\",\n        \"unkc\",\n        \"unkv\",\n        \"unmark\",\n        \"unmatch\",\n        \"unsets\",\n        \"unshown\",\n        \"untracked\",\n        \"untrackedcache\",\n        \"unuse\",\n        \"upos\",\n        \"uval\",\n        \"vreportf\",\n        \"wargs\",\n        \"wargv\",\n        \"wbuffer\",\n        \"wcmd\",\n        \"wcsnicmp\",\n        \"wcstoutfdup\",\n        \"wdeltaenv\",\n        \"wdir\",\n        \"wenv\",\n        \"wenvblk\",\n        \"wenvcmp\",\n        \"wenviron\",\n        \"wenvpos\",\n        \"wenvsz\",\n        \"wfile\",\n        \"wfilename\",\n        \"wfopen\",\n        \"wfreopen\",\n        \"wfullpath\",\n        \"which'll\",\n        \"wlink\",\n        \"wmain\",\n        \"wmkdir\",\n        \"wmktemp\",\n        \"wnewpath\",\n        \"wotype\",\n        \"wpath\",\n        \"wpathname\",\n        \"wpgmptr\",\n        \"wpnew\",\n        \"wpointer\",\n        \"wpold\",\n        \"wpos\",\n        \"wputenv\",\n        \"wrmdir\",\n        \"wship\",\n        \"wtarget\",\n        \"wtemplate\",\n        \"wunlink\",\n        \"xcalloc\",\n        \"xgetcwd\",\n        \"xmallocz\",\n        \"xmemdupz\",\n        \"xmmap\",\n        \"xopts\",\n        \"xrealloc\",\n        \"xsnprintf\",\n        \"xutftowcs\",\n        \"xutftowcsn\",\n        \"xwcstoutf\"\n    ],\n    \"cSpell.ignoreRegExpList\": [\n        \"\\\\\\\"(DIRC|FSMN|REUC|UNTR)\\\\\\\"\",\n        \"\\\\\\\\u[0-9a-fA-Fx]{4}\\\\b\",\n        \"\\\\b(filfre|frotz|xyzzy)\\\\b\",\n        \"\\\\bCMIT_FMT_DEFAULT\\\\b\",\n        \"\\\\bde-munge\\\\b\",\n        \"\\\\bGET_OID_DISAMBIGUATORS\\\\b\",\n        \"\\\\bHASH_RENORMALIZE\\\\b\",\n        \"\\\\bTREESAMEness\\\\b\",\n        \"\\\\bUSE_STDEV\\\\b\",\n        \"\\\\Wchar *\\\\*\\\\W*utfs\\\\W\",\n        \"cURL's\",\n        \"nedmalloc'ed\",\n        \"ntifs\\\\.h\",\n    ],\n}\nEOF\ndie \"Could not write settings.json\"\n\n# Infer some setup-specific locations/names\n\nGCCPATH=\"$(which gcc)\"\nGDBPATH=\"$(which gdb)\"\nMAKECOMMAND=\"make -j5 DEVELOPER=1\"\nOSNAME=\nX=\ncase \"$(uname -s)\" in\nMINGW*)\n\tGCCPATH=\"$(cygpath -am \"$GCCPATH\")\"\n\tGDBPATH=\"$(cygpath -am \"$GDBPATH\")\"\n\tMAKE_BASH=\"$(cygpath -am /git-cmd.exe) --command=usr\\\\\\\\bin\\\\\\\\bash.exe\"\n\tMAKECOMMAND=\"$MAKE_BASH -lc \\\\\\\"$MAKECOMMAND\\\\\\\"\"\n\tOSNAME=Win32\n\tX=.exe\n\t;;\nLinux)\n\tOSNAME=Linux\n\t;;\nDarwin)\n\tOSNAME=macOS\n\t;;\nesac\n\n# Default build task\n\ncat >.vscode/tasks.json.new <<EOF ||\n{\n    // See https://go.microsoft.com/fwlink/?LinkId=733558\n    // for the documentation about the tasks.json format\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"make\",\n            \"type\": \"shell\",\n            \"command\": \"$MAKECOMMAND\",\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        }\n    ]\n}\nEOF\ndie \"Could not install default build task\"\n\n# Debugger settings\n\ncat >.vscode/launch.json.new <<EOF ||\n{\n    // Use IntelliSense to learn about possible attributes.\n    // Hover to view descriptions of existing attributes.\n    // For more information, visit:\n    // https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"(gdb) Launch\",\n            \"type\": \"cppdbg\",\n            \"request\": \"launch\",\n            \"program\": \"\\${workspaceFolder}/git$X\",\n            \"args\": [],\n            \"stopAtEntry\": false,\n            \"cwd\": \"\\${workspaceFolder}\",\n            \"environment\": [],\n            \"externalConsole\": true,\n            \"MIMode\": \"gdb\",\n            \"miDebuggerPath\": \"$GDBPATH\",\n            \"setupCommands\": [\n                {\n                    \"description\": \"Enable pretty-printing for gdb\",\n                    \"text\": \"-enable-pretty-printing\",\n                    \"ignoreFailures\": true\n                }\n            ]\n        }\n    ]\n}\nEOF\ndie \"Could not write launch configuration\"\n\n# C/C++ extension settings\n\nmake -f - OSNAME=$OSNAME GCCPATH=\"$GCCPATH\" vscode-init \\\n\t>.vscode/c_cpp_properties.json <<\\EOF ||\ninclude Makefile\n\nvscode-init:\n\t@mkdir -p .vscode && \\\n\tincs= && defs= && \\\n\tfor e in $(ALL_CFLAGS) \\\n\t\t\t'-DGIT_EXEC_PATH=\"$(gitexecdir_SQ)\"' \\\n\t\t\t'-DGIT_LOCALE_PATH=\"$(localedir_relative_SQ)\"' \\\n\t\t\t'-DBINDIR=\"$(bindir_relative_SQ)\"' \\\n\t\t\t'-DFALLBACK_RUNTIME_PREFIX=\"$(prefix_SQ)\"' \\\n\t\t\t'-DDEFAULT_GIT_TEMPLATE_DIR=\"$(template_dir_SQ)\"' \\\n\t\t\t'-DETC_GITCONFIG=\"$(ETC_GITCONFIG_SQ)\"' \\\n\t\t\t'-DETC_GITATTRIBUTES=\"$(ETC_GITATTRIBUTES_SQ)\"' \\\n\t\t\t'-DGIT_LOCALE_PATH=\"$(localedir_relative_SQ)\"' \\\n\t\t\t'-DCURL_DISABLE_TYPECHECK', \\\n\t\t\t'-DGIT_HTML_PATH=\"$(htmldir_relative_SQ)\"' \\\n\t\t\t'-DGIT_MAN_PATH=\"$(mandir_relative_SQ)\"' \\\n\t\t\t'-DGIT_INFO_PATH=\"$(infodir_relative_SQ)\"'; do \\\n\t\tcase \"$$e\" in \\\n\t\t-I.) \\\n\t\t\tincs=\"$$(printf '% 16s\"$${workspaceRoot}\",\\n%s' \\\n\t\t\t\t\"\" \"$$incs\")\" \\\n\t\t\t;; \\\n\t\t-I/*) \\\n\t\t\tincs=\"$$(printf '% 16s\"%s\",\\n%s' \\\n\t\t\t\t\"\" \"$${e#-I}\" \"$$incs\")\" \\\n\t\t\t;; \\\n\t\t-I*) \\\n\t\t\tincs=\"$$(printf '% 16s\"$${workspaceRoot}/%s\",\\n%s' \\\n\t\t\t\t\"\" \"$${e#-I}\" \"$$incs\")\" \\\n\t\t\t;; \\\n\t\t-D*) \\\n\t\t\tdefs=\"$$(printf '% 16s\"%s\",\\n%s' \\\n\t\t\t\t\"\" \"$$(echo \"$${e#-D}\" | sed 's/\"/\\\\&/g')\" \\\n\t\t\t\t\"$$defs\")\" \\\n\t\t\t;; \\\n\t\tesac; \\\n\tdone && \\\n\techo '{' && \\\n\techo '    \"configurations\": [' && \\\n\techo '        {' && \\\n\techo '            \"name\": \"$(OSNAME)\",' && \\\n\techo '            \"intelliSenseMode\": \"clang-x64\",' && \\\n\techo '            \"includePath\": [' && \\\n\techo \"$$incs\" | sort | sed '$$s/,$$//' && \\\n\techo '            ],' && \\\n\techo '            \"defines\": [' && \\\n\techo \"$$defs\" | sort | sed '$$s/,$$//' && \\\n\techo '            ],' && \\\n\techo '            \"browse\": {' && \\\n\techo '                \"limitSymbolsToIncludedHeaders\": true,' && \\\n\techo '                \"databaseFilename\": \"\",' && \\\n\techo '                \"path\": [' && \\\n\techo '                    \"$${workspaceRoot}\"' && \\\n\techo '                ]' && \\\n\techo '            },' && \\\n\techo '            \"cStandard\": \"c11\",' && \\\n\techo '            \"cppStandard\": \"c++17\",' && \\\n\techo '            \"compilerPath\": \"$(GCCPATH)\"' && \\\n\techo '        }' && \\\n\techo '    ],' && \\\n\techo '    \"version\": 4' && \\\n\techo '}'\nEOF\ndie \"Could not write settings for the C/C++ extension\"\n\nfor file in .vscode/settings.json .vscode/tasks.json .vscode/launch.json\ndo\n\tif test -f $file\n\tthen\n\t\tif git diff --no-index --quiet --exit-code $file $file.new\n\t\tthen\n\t\t\trm $file.new\n\t\telse\n\t\t\tprintf \"The file $file.new has these changes:\\n\\n\"\n\t\t\tgit --no-pager diff --no-index $file $file.new\n\t\t\tprintf \"\\n\\nMaybe \\`mv $file.new $file\\`?\\n\\n\"\n\t\tfi\n\telse\n\t\tmv $file.new $file\n\tfi\ndone\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/vscode/init.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Create a shell script for Git workflow automation", "completion": "```bash\n#!/bin/sh\n\n# Use this tool to rewrite your .git/remotes/ files into the config.\n\n. git-sh-setup\n\nif [ -d \"$GIT_DIR\"/remotes ]; then\n\techo \"Rewriting $GIT_DIR/remotes\" >&2\n\terror=0\n\t# rewrite into config\n\t{\n\t\tcd \"$GIT_DIR\"/remotes\n\t\tls | while read f; do\n\t\t\tname=$(printf \"$f\" | tr -c \"A-Za-z0-9-\" \".\")\n\t\t\tsed -n \\\n\t\t\t-e \"s/^URL:[ \t]*\\(.*\\)$/remote.$name.url \\1 ./p\" \\\n\t\t\t-e \"s/^Pull:[ \t]*\\(.*\\)$/remote.$name.fetch \\1 ^$ /p\" \\\n\t\t\t-e \"s/^Push:[ \t]*\\(.*\\)$/remote.$name.push \\1 ^$ /p\" \\\n\t\t\t< \"$f\"\n\t\tdone\n\t\techo done\n\t} | while read key value regex; do\n\t\tcase $key in\n\t\tdone)\n\t\t\tif [ $error = 0 ]; then\n\t\t\t\tmv \"$GIT_DIR\"/remotes \"$GIT_DIR\"/remotes.old\n\t\t\tfi ;;\n\t\t*)\n\t\t\techo \"git config $key \"$value\" $regex\"\n\t\t\tgit config $key \"$value\" $regex || error=1 ;;\n\t\tesac\n\tdone\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/remotes2config.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/sh\n#See http://www.unicode.org/reports/tr44/\n#\n#Me Enclosing_Mark  an enclosing combining mark\n#Mn Nonspacing_Mark a nonspacing combining mark (zero advance width)\n#Cf Format          a format control character\n#\ncd \"$(dirname \"$0\")\"\nUNICODEWIDTH_H=$(git rev-parse --show-toplevel)/unicode-width.h\n\nwget -N http://www.unicode.org/Public/UCD/latest/ucd/UnicodeData.txt \\\n\thttp://www.unicode.org/Public/UCD/latest/ucd/EastAsianWidth.txt &&\nif ! test -d uniset; then\n\tgit clone https://github.com/depp/uniset.git &&\n\t( cd uniset && git checkout 4b186196dd )\nfi &&\n(\n\tcd uniset &&\n\tif ! test -x uniset; then\n\t\tautoreconf -i &&\n\t\t./configure --enable-warnings=-Werror CFLAGS='-O0 -ggdb'\n\tfi &&\n\tmake\n) &&\nUNICODE_DIR=. && export UNICODE_DIR &&\ncat >$UNICODEWIDTH_H <<-EOF\nstatic const struct interval zero_width[] = {\n\t$(uniset/uniset --32 cat:Me,Mn,Cf + U+1160..U+11FF - U+00AD)\n};\nstatic const struct interval double_width[] = {\n\t$(uniset/uniset --32 eaw:F,W)\n};\nEOF\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/update-unicode/update_unicode.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/sh\n# Copyright (c) 2008, Nanako Shiraishi\n# Prime rerere database from existing merge commits\n\nme=rerere-train\nUSAGE=$(cat <<-EOF\nusage: $me [--overwrite] <rev-list-args>\n\n    -h, --help            show the help\n    -o, --overwrite       overwrite any existing rerere cache\nEOF\n)\n\nSUBDIRECTORY_OK=Yes\n\noverwrite=0\n\nwhile test $# -gt 0\ndo\n\topt=\"$1\"\n\tcase \"$opt\" in\n\t-h|--help)\n\t\techo \"$USAGE\"\n\t\texit 0\n\t\t;;\n\t-o|--overwrite)\n\t\toverwrite=1\n\t\tshift\n\t\tbreak\n\t\t;;\n\t--)\n\t\tshift\n\t\tbreak\n\t\t;;\n\t*)\n\t\tbreak\n\t\t;;\n\tesac\ndone\n\n# Overwrite or help options are not valid except as first arg\nfor opt in \"$@\"\ndo\n\tcase \"$opt\" in\n\t-h|--help)\n\t\techo \"$USAGE\"\n\t\texit 0\n\t\t;;\n\t-o|--overwrite)\n\t\techo \"$USAGE\"\n\t\texit 0\n\t\t;;\n\tesac\ndone\n\n. \"$(git --exec-path)/git-sh-setup\"\nrequire_work_tree\ncd_to_toplevel\n\n# Remember original branch\nbranch=$(git symbolic-ref -q HEAD) ||\noriginal_HEAD=$(git rev-parse --verify HEAD) || {\n\techo >&2 \"Not on any branch and no commit yet?\"\n\texit 1\n}\n\nmkdir -p \"$GIT_DIR/rr-cache\" || exit\n\ngit rev-list --parents \"$@\" |\nwhile read commit parent1 other_parents\ndo\n\tif test -z \"$other_parents\"\n\tthen\n\t\t# Skip non-merges\n\t\tcontinue\n\tfi\n\tgit checkout -q \"$parent1^0\"\n\tif git merge $other_parents >/dev/null 2>&1\n\tthen\n\t\t# Cleanly merges\n\t\tcontinue\n\tfi\n\tif test $overwrite = 1\n\tthen\n\t\tgit rerere forget .\n\tfi\n\tif test -s \"$GIT_DIR/MERGE_RR\"\n\tthen\n\t\tgit show -s --pretty=format:\"Learning from %h %s\" \"$commit\"\n\t\tgit rerere\n\t\tgit checkout -q $commit -- .\n\t\tgit rerere\n\tfi\n\tgit reset -q --hard  # Might nuke untracked files...\ndone\n\nif test -z \"$branch\"\nthen\n\tgit checkout \"$original_HEAD\"\nelse\n\tgit checkout \"${branch#refs/heads/}\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/rerere-train.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/sh\n\ntest_description='Test diff-highlight'\n\nCURR_DIR=$(pwd)\nTEST_OUTPUT_DIRECTORY=$(pwd)\nTEST_DIRECTORY=\"$CURR_DIR\"/../../../t\nDIFF_HIGHLIGHT=\"$CURR_DIR\"/../diff-highlight\n\nCW=\"$(printf \"\\033[7m\")\"\t# white\nCR=\"$(printf \"\\033[27m\")\"\t# reset\n\n. \"$TEST_DIRECTORY\"/test-lib.sh\n\nif ! test_have_prereq PERL\nthen\n\tskip_all='skipping diff-highlight tests; perl not available'\n\ttest_done\nfi\n\n# dh_test is a test helper function which takes 3 file names as parameters. The\n# first 2 files are used to generate diff and commit output, which is then\n# piped through diff-highlight. The 3rd file should contain the expected output\n# of diff-highlight (minus the diff/commit header, ie. everything after and\n# including the first @@ line).\ndh_test () {\n\ta=\"$1\" b=\"$2\" &&\n\n\tcat >patch.exp &&\n\n\t{\n\t\tcat \"$a\" >file &&\n\t\tgit add file &&\n\t\tgit commit -m \"Add a file\" &&\n\n\t\tcat \"$b\" >file &&\n\t\tgit diff file >diff.raw &&\n\t\tgit commit -a -m \"Update a file\" &&\n\t\tgit show >commit.raw\n\t} >/dev/null &&\n\n\t\"$DIFF_HIGHLIGHT\" <diff.raw | test_strip_patch_header >diff.act &&\n\t\"$DIFF_HIGHLIGHT\" <commit.raw | test_strip_patch_header >commit.act &&\n\ttest_cmp patch.exp diff.act &&\n\ttest_cmp patch.exp commit.act\n}\n\ntest_strip_patch_header () {\n\tsed -n '/^@@/,$p' $*\n}\n\n# dh_test_setup_history generates a contrived graph such that we have at least\n# 1 nesting (E) and 2 nestings (F).\n#\n#\t  A---B master\n#\t /\n#\tD---E---F branch\n#\n#\tgit log --all --graph\n#\t* commit\n#\t|    B\n#\t| * commit\n#\t| |    F\n#\t* | commit\n#\t| |    A\n#\t| * commit\n#\t|/\n#\t|    E\n#\t* commit\n#\t     D\n#\ndh_test_setup_history () {\n\techo file1 >file &&\n\tgit add file &&\n\ttest_tick &&\n\tgit commit -m \"D\" &&\n\n\tgit checkout -b branch &&\n\techo file2 >file &&\n\ttest_tick &&\n\tgit commit -a -m \"E\" &&\n\n\tgit checkout master &&\n\techo file2 >file &&\n\ttest_tick &&\n\tgit commit -a -m \"A\" &&\n\n\tgit checkout branch &&\n\techo file3 >file &&\n\ttest_tick &&\n\tgit commit -a -m \"F\" &&\n\n\tgit checkout master &&\n\techo file3 >file &&\n\ttest_tick &&\n\tgit commit -a -m \"B\"\n}\n\nleft_trim () {\n\t\"$PERL_PATH\" -pe 's/^\\s+//'\n}\n\ntrim_graph () {\n\t# graphs start with * or |\n\t# followed by a space or / or \\\n\t\"$PERL_PATH\" -pe 's@^((\\*|\\|)( |/|\\\\))+@@'\n}\n\ntest_expect_success 'diff-highlight highlights the beginning of a line' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\t\tccc\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\t0bb\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-${CW}b${CR}bb\n\t\t+${CW}0${CR}bb\n\t\t ccc\n\tEOF\n'\n\ntest_expect_success 'diff-highlight highlights the end of a line' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\t\tccc\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\tbb0\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-bb${CW}b${CR}\n\t\t+bb${CW}0${CR}\n\t\t ccc\n\tEOF\n'\n\ntest_expect_success 'diff-highlight highlights the middle of a line' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\t\tccc\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\tb0b\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-b${CW}b${CR}b\n\t\t+b${CW}0${CR}b\n\t\t ccc\n\tEOF\n'\n\ntest_expect_success 'diff-highlight does not highlight whole line' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\t\tccc\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\t000\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-bbb\n\t\t+000\n\t\t ccc\n\tEOF\n'\n\ntest_expect_failure 'diff-highlight highlights mismatched hunk size' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\tb0b\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-b${CW}b${CR}b\n\t\t+b${CW}0${CR}b\n\t\t+ccc\n\tEOF\n'\n\n# These two code points share the same leading byte in UTF-8 representation;\n# a naive byte-wise diff would highlight only the second byte.\n#\n#   - U+00f3 (\"o\" with acute)\no_accent=$(printf '\\303\\263')\n#   - U+00f8 (\"o\" with stroke)\no_stroke=$(printf '\\303\\270')\n\ntest_expect_success 'diff-highlight treats multibyte utf-8 as a unit' '\n\techo \"unic${o_accent}de\" >a &&\n\techo \"unic${o_stroke}de\" >b &&\n\tdh_test a b <<-EOF\n\t\t@@ -1 +1 @@\n\t\t-unic${CW}${o_accent}${CR}de\n\t\t+unic${CW}${o_stroke}${CR}de\n\tEOF\n'\n\n# Unlike the UTF-8 above, these are combining code points which are meant\n# to modify the character preceding them:\n#\n#   - U+0301 (combining acute accent)\ncombine_accent=$(printf '\\314\\201')\n#   - U+0302 (combining circumflex)\ncombine_circum=$(printf '\\314\\202')\n\ntest_expect_failure 'diff-highlight treats combining code points as a unit' '\n\techo \"unico${combine_accent}de\" >a &&\n\techo \"unico${combine_circum}de\" >b &&\n\tdh_test a b <<-EOF\n\t\t@@ -1 +1 @@\n\t\t-unic${CW}o${combine_accent}${CR}de\n\t\t+unic${CW}o${combine_circum}${CR}de\n\tEOF\n'\n\ntest_expect_success 'diff-highlight works with the --graph option' '\n\tdh_test_setup_history &&\n\n\t# date-order so that the commits are interleaved for both\n\t# trim graph elements so we can do a diff\n\t# trim leading space because our trim_graph is not perfect\n\tgit log --branches -p --date-order |\n\t\t\"$DIFF_HIGHLIGHT\" | left_trim >graph.exp &&\n\tgit log --branches -p --date-order --graph |\n\t\t\"$DIFF_HIGHLIGHT\" | trim_graph | left_trim >graph.act &&\n\ttest_cmp graph.exp graph.act\n'\n\n# Just reuse the previous graph test, but with --color.  Our trimming\n# doesn't know about color, so just sanity check that something got\n# highlighted.\ntest_expect_success 'diff-highlight works with color graph' '\n\tgit log --branches -p --date-order --graph --color |\n\t\t\"$DIFF_HIGHLIGHT\" | trim_graph | left_trim >graph &&\n\tgrep \"\\[7m\" graph\n'\n\n# Most combined diffs won't meet diff-highlight's line-number filter. So we\n# create one here where one side drops a line and the other modifies it. That\n# should result in a diff like:\n#\n#    - modified content\n#    ++resolved content\n#\n# which naively looks like one side added \"+resolved\".\ntest_expect_success 'diff-highlight ignores combined diffs' '\n\techo \"content\" >file &&\n\tgit add file &&\n\tgit commit -m base &&\n\n\t>file &&\n\tgit commit -am master &&\n\n\tgit checkout -b other HEAD^ &&\n\techo \"modified content\" >file &&\n\tgit commit -am other &&\n\n\ttest_must_fail git merge master &&\n\techo \"resolved content\" >file &&\n\tgit commit -am resolved &&\n\n\tcat >expect <<-\\EOF &&\n\t--- a/file\n\t+++ b/file\n\t@@@ -1,1 -1,0 +1,1 @@@\n\t- modified content\n\t++resolved content\n\tEOF\n\n\tgit show -c | \"$DIFF_HIGHLIGHT\" >actual.raw &&\n\tsed -n \"/^---/,\\$p\" <actual.raw >actual &&\n\ttest_cmp expect actual\n'\n\ntest_expect_success 'diff-highlight handles --graph with leading dash' '\n\tcat >file <<-\\EOF &&\n\tbefore\n\tthe old line\n\t-leading dash\n\tEOF\n\tgit add file &&\n\tgit commit -m before &&\n\n\tsed s/old/new/ <file >file.tmp &&\n\tmv file.tmp file &&\n\tgit add file &&\n\tgit commit -m after &&\n\n\tcat >expect <<-EOF &&\n\t--- a/file\n\t+++ b/file\n\t@@ -1,3 +1,3 @@\n\t before\n\t-the ${CW}old${CR} line\n\t+the ${CW}new${CR} line\n\t -leading dash\n\tEOF\n\tgit log --graph -p -1 | \"$DIFF_HIGHLIGHT\" >actual.raw &&\n\ttrim_graph <actual.raw | sed -n \"/^---/,\\$p\" >actual &&\n\ttest_cmp expect actual\n'\n\ntest_done\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/diff-highlight/t/t9400-diff-highlight.sh", "category": "testing", "authentic": true}}
