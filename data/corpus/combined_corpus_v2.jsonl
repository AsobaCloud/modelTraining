{"prompt": "Write a shell script for deploying infrastructure and services using AWS CLI and CloudFormation.", "completion": "```bash\n#!/bin/bash\n# deploy-core-api.sh\n# Main script for deploying core API endpoints to specified AWS region\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region> [environment]\"\n    echo \"Example: $0 eu-south-1 production\"\n    exit 1\nfi\n\n# Set variables\nTARGET_REGION=\"$1\"\nENVIRONMENT=\"${2:-production}\"  # Default to production if not specified\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\n\n# Define common tags for all resources\nTAGS=\"Environment=$ENVIRONMENT \\\n      Service=OnaAPI \\\n      Component=Core \\\n      CostCenter=EnergyForecasting \\\n      Owner=PlatformTeam \\\n      UptimeSLA=99.9 \\\n      DataClassification=Internal \\\n      Compliance=ISO27001 \\\n      ManagedBy=CloudFormation \\\n      Version=1.0\"\n\n# Function to check if a CloudFormation stack exists\nstack_exists() {\n    local stack_name=$1\n    aws cloudformation describe-stacks --region \"$TARGET_REGION\" \\\n        --stack-name \"$stack_name\" \\\n        --query 'Stacks[0].StackStatus' \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\n# Function to check if a stack is in a stable state\nis_stack_stable() {\n    local stack_name=$1\n    local status\n    status=$(stack_exists \"$stack_name\")\n    [[ \"$status\" =~ ^(CREATE_COMPLETE|UPDATE_COMPLETE|UPDATE_ROLLBACK_COMPLETE)$ ]]\n}\n\n# Function to wait for a stack to be stable\nwait_for_stack() {\n    local stack_name=$1\n    local max_attempts=30\n    local attempt=1\n    \n    echo \"Waiting for stack $stack_name to be stable...\"\n    while [ $attempt -le $max_attempts ]; do\n        if is_stack_stable \"$stack_name\"; then\n            echo \"Stack $stack_name is stable\"\n            return 0\n        fi\n        echo \"Attempt $attempt/$max_attempts: Stack $stack_name is not stable yet...\"\n        sleep 30\n        ((attempt++))\n    done\n    echo \"Stack $stack_name did not become stable in time\"\n    return 1\n}\n\n# Function to check if ECR repository exists\necr_repo_exists() {\n    local repo_name=$1\n    aws ecr describe-repositories --region \"$TARGET_REGION\" \\\n        --repository-names \"$repo_name\" \\\n        --query 'repositories[0].repositoryName' \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\n# Function to check if API Gateway exists\napi_exists() {\n    local api_name=$1\n    aws apigateway get-rest-apis --region \"$TARGET_REGION\" \\\n        --query \"items[?name=='$api_name'].id\" \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\necho \"=============================================\"\necho \"Deploying Core API to region: $TARGET_REGION\"\necho \"Environment: $ENVIRONMENT\"\necho \"Account ID: $ACCOUNT_ID\"\necho \"=============================================\"\n\n# Load region-specific configuration\nCONFIG_FILE=\"$SCRIPT_DIR/config/$TARGET_REGION.env\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n    echo \"Error: Configuration file not found: $CONFIG_FILE\"\n    echo \"Please create a configuration file for this region first.\"\n    exit 1\nfi\n\nsource \"$CONFIG_FILE\"\n\n# Load environment-specific configuration (if exists)\nENV_CONFIG_FILE=\"$SCRIPT_DIR/config/$TARGET_REGION-$ENVIRONMENT.env\"\nif [ -f \"$ENV_CONFIG_FILE\" ]; then\n    source \"$ENV_CONFIG_FILE\"\n    echo \"Loaded environment-specific configuration from $ENV_CONFIG_FILE\"\nfi\n\n# Step 1: Create ECR repositories (if they don't exist)\necho \"Creating ECR repositories if they don't exist...\"\nfor repo in ingesthistoricaldata ingestnowcastdata trainforecaster generatepresignedurl \\\n            interpolatedata generateforecast returnforecastingresults marketpriceforecast \\\n            electricitydispatch weather; do\n    if [ \"$(ecr_repo_exists \"$repo/lambda\")\" = \"DOES_NOT_EXIST\" ]; then\n        echo \"Creating ECR repository: $repo/lambda\"\n        aws ecr create-repository --region \"$TARGET_REGION\" \\\n            --repository-name \"$repo/lambda\" \\\n            --tags $TAGS\n    else\n        echo \"ECR repository $repo/lambda already exists\"\n    fi\ndone\n\n# Step 2: Build and push Docker images\necho \"Building and pushing Docker images...\"\n\"$SCRIPT_DIR/scripts/build-and-push-images.sh\" \"$TARGET_REGION\"\n\n# Step 3: Deploy CloudFormation stack for S3 buckets\necho \"Deploying S3 buckets...\"\nS3_STACK_NAME=\"${REGION_PREFIX}-s3-buckets\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/s3-buckets.yaml\" \\\n    --stack-name \"$S3_STACK_NAME\" \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n    --tags $TAGS\n\n# Wait for S3 stack to be stable before proceeding\nwait_for_stack \"$S3_STACK_NAME\"\n\n# Step 4: Deploy CloudFormation stack for IAM roles\necho \"Deploying IAM roles...\"\nIAM_STACK_NAME=\"${REGION_PREFIX}-iam-roles\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/iam-roles.yaml\" \\\n    --stack-name \"$IAM_STACK_NAME\" \\\n    --capabilities CAPABILITY_NAMED_IAM \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n    --tags $TAGS\n\n# Wait for IAM stack to be stable before proceeding\nwait_for_stack \"$IAM_STACK_NAME\"\n\n# Step 5: Deploy CloudFormation stack for Lambda functions\necho \"Deploying Lambda functions...\"\nLAMBDA_STACK_NAME=\"${REGION_PREFIX}-lambda-functions\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/lambda-functions.yaml\" \\\n    --stack-name \"$LAMBDA_STACK_NAME\" \\\n    --capabilities CAPABILITY_IAM \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n        AccountId=\"$ACCOUNT_ID\" \\\n        LambdaMemory=\"$LAMBDA_MEMORY\" \\\n        IngestHistoricalDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/ingesthistoricaldata/lambda:latest\" \\\n        IngestNowcastDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/ingestnowcastdata/lambda:latest\" \\\n        TrainForecasterImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/trainforecaster/lambda:latest\" \\\n        GeneratePresignedUrlImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/generatepresignedurl/lambda:latest\" \\\n        InterpolateDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/interpolatedata/lambda:latest\" \\\n        GenerateForecastImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/generateforecast/lambda:latest\" \\\n        ReturnForecastingResultsImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/returnforecastingresults/lambda:latest\" \\\n        MarketPriceForecastImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/marketpriceforecast/lambda:latest\" \\\n        ElectricityDispatchImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/electricitydispatch/lambda:latest\" \\\n        WeatherImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/weather/lambda:latest\" \\\n    --tags $TAGS\n\n# Wait for Lambda stack to be stable before proceeding\nwait_for_stack \"$LAMBDA_STACK_NAME\"\n\n# Step 6: Deploy CloudFormation stack for API Gateway\necho \"Deploying API Gateway...\"\nAPI_STACK_NAME=\"${REGION_PREFIX}-api-gateway\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/api-gateway.yaml\" \\\n    --stack-name \"$API_STACK_NAME\" \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n        EndpointType=\"$API_ENDPOINT_TYPE\" \\\n        IngestHistoricalDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='IngestHistoricalDataFunctionArn'].OutputValue\" --output text) \\\n        IngestNowcastDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='IngestNowcastDataFunctionArn'].OutputValue\" --output text) \\\n        TrainForecasterFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='TrainForecasterFunctionArn'].OutputValue\" --output text) \\\n        GeneratePresignedUrlFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='GeneratePresignedUrlFunctionArn'].OutputValue\" --output text) \\\n        InterpolateDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='InterpolateDataFunctionArn'].OutputValue\" --output text) \\\n        GenerateForecastFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='GenerateForecastFunctionArn'].OutputValue\" --output text) \\\n        ReturnForecastingResultsFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='ReturnForecastingResultsFunctionArn'].OutputValue\" --output text) \\\n        MarketPriceForecastFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='MarketPriceForecastFunctionArn'].OutputValue\" --output text) \\\n        ElectricityDispatchFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='ElectricityDispatchFunctionArn'].OutputValue\" --output text) \\\n        WeatherFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='WeatherFunctionArn'].OutputValue\" --output text) \\\n    --tags $TAGS\n\n# Wait for API Gateway stack to be stable before proceeding\nwait_for_stack \"$API_STACK_NAME\"\n\n# Step 7: Create and configure API keys\necho \"Creating API keys...\"\n\"$SCRIPT_DIR/scripts/create-api-keys.sh\" \"$TARGET_REGION\" \"$ENVIRONMENT\"\n\n# Step 8: Deploy the API\necho \"Deploying API Gateway endpoints...\"\nAPIS=$(aws apigateway get-rest-apis --region \"$TARGET_REGION\" --query \"items[?contains(name, '${REGION_PREFIX}')].id\" --output text)\nfor API_ID in $APIS; do\n    echo \"Deploying API: $API_ID\"\n    aws apigateway create-deployment \\\n        --region \"$TARGET_REGION\" \\\n        --rest-api-id \"$API_ID\" \\\n        --stage-name \"$ENVIRONMENT\" \\\n        --description \"Deployment from deploy-core-api.sh script\" \\\n        --tags $TAGS\ndone\n\n# Step 9: Set up CloudWatch Alarms for monitoring\necho \"Setting up CloudWatch Alarms...\"\n\"$SCRIPT_DIR/scripts/setup-monitoring.sh\" \"$TARGET_REGION\" \"$ENVIRONMENT\"\n\necho \"=============================================\"\necho \"Core API deployment to $TARGET_REGION completed!\"\necho \"=============================================\"\n\n# Output API endpoints\necho \"API Endpoints:\"\nfor API_ID in $APIS; do\n    API_NAME=$(aws apigateway get-rest-api --region \"$TARGET_REGION\" --rest-api-id \"$API_ID\" --query \"name\" --output text)\n    echo \"$API_NAME: https://$API_ID.execute-api.$TARGET_REGION.amazonaws.com/$ENVIRONMENT\"\ndone\n\necho \"See CloudFormation stacks for more details:\"\necho \"<URL>\"\n```", "metadata": {"source": "/home/shingai/api/deploy/deploy-core-api.sh", "category": "deployment", "type": "complete_script"}}
{"prompt": "Get CloudFormation stack information using AWS CLI", "completion": "```bash\naws cloudformation describe-stacks --region \"$TARGET_REGION\" \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for ecr describe-repositories", "completion": "```bash\naws ecr describe-repositories --region \"$TARGET_REGION\" \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for apigateway get-rest-apis", "completion": "```bash\naws apigateway get-rest-apis --region \"$TARGET_REGION\" \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for ecr create-repository", "completion": "```bash\naws ecr create-repository --region \"$TARGET_REGION\" \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Deploy CloudFormation stack using AWS CLI", "completion": "```bash\naws cloudformation deploy \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Deploy CloudFormation stack using AWS CLI", "completion": "```bash\naws cloudformation deploy \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Deploy CloudFormation stack using AWS CLI", "completion": "```bash\naws cloudformation deploy \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Deploy CloudFormation stack using AWS CLI", "completion": "```bash\naws cloudformation deploy \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Deploy API Gateway using AWS CLI", "completion": "```bash\naws apigateway create-deployment \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Write a shell script for deploying infrastructure and services using AWS CLI and CloudFormation.", "completion": "```bash\n#!/bin/bash\n# setup-monitoring.sh\n# Sets up CloudWatch alarms for monitoring core API components\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region> [environment]\"\n    echo \"Example: $0 eu-south-1 production\"\n    exit 1\nfi\n\n# Set variables\nTARGET_REGION=\"$1\"\nENVIRONMENT=\"${2:-production}\"  # Default to production if not specified\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\nALARM_EMAIL=\"<EMAIL>\"  # Replace with actual alert email\n\n# Load region-specific configuration\nCONFIG_FILE=\"$SCRIPT_DIR/../config/$TARGET_REGION.env\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n    echo \"Error: Configuration file not found: $CONFIG_FILE\"\n    echo \"Please create a configuration file for this region first.\"\n    exit 1\nfi\n\nsource \"$CONFIG_FILE\"\n\n# Function to check if SNS topic exists\nget_sns_topic_arn() {\n    local topic_name=\"${REGION_PREFIX}-api-alarms\"\n    local topic_arn\n    \n    topic_arn=$(aws sns list-topics --region \"$TARGET_REGION\" \\\n        --query \"Topics[?contains(TopicArn, '$topic_name')].TopicArn\" \\\n        --output text)\n    \n    if [ -n \"$topic_arn\" ]; then\n        echo \"$topic_arn\"\n        return 0\n    else\n        return 1\n    fi\n}\n\n# Function to check if email is subscribed to SNS topic\nis_email_subscribed() {\n    local topic_arn=$1\n    local email=$2\n    \n    aws sns list-subscriptions-by-topic --region \"$TARGET_REGION\" \\\n        --topic-arn \"$topic_arn\" \\\n        --query \"Subscriptions[?Protocol=='email' && Endpoint=='$email'].SubscriptionArn\" \\\n        --output text | grep -q .\n}\n\n# Create or get SNS topic for alarms\necho \"Setting up SNS topic for alarms...\"\nSNS_TOPIC_ARN=$(get_sns_topic_arn) || {\n    echo \"Creating new SNS topic...\"\n    SNS_TOPIC_ARN=$(aws sns create-topic \\\n        --region \"$TARGET_REGION\" \\\n        --name \"${REGION_PREFIX}-api-alarms\" \\\n        --query 'TopicArn' \\\n        --output text)\n}\n\n# Subscribe email to SNS topic if not already subscribed\nif ! is_email_subscribed \"$SNS_TOPIC_ARN\" \"$ALARM_EMAIL\"; then\n    echo \"Subscribing email to SNS topic...\"\n    aws sns subscribe \\\n        --region \"$TARGET_REGION\" \\\n        --topic-arn \"$SNS_TOPIC_ARN\" \\\n        --protocol email \\\n        --notification-endpoint \"$ALARM_EMAIL\"\nelse\n    echo \"Email already subscribed to SNS topic\"\nfi\n\n# Function to check if alarm exists\nalarm_exists() {\n    local alarm_name=$1\n    aws cloudwatch describe-alarms --region \"$TARGET_REGION\" \\\n        --alarm-names \"$alarm_name\" \\\n        --query 'MetricAlarms[0].AlarmName' \\\n        --output text | grep -q .\n}\n\n# Function to create or update Lambda alarms\ncreate_lambda_alarms() {\n    local function_name=$1\n    local threshold=$2\n    \n    echo \"Setting up alarms for Lambda function: $function_name\"\n    \n    # Error rate alarm\n    local error_alarm_name=\"${REGION_PREFIX}-${function_name}-errors\"\n    if ! alarm_exists \"$error_alarm_name\"; then\n        echo \"Creating error rate alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name has errors\" \\\n            --metric-name Errors \\\n            --namespace AWS/Lambda \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Error rate alarm already exists\"\n    fi\n\n    # Duration alarm\n    local duration_alarm_name=\"${REGION_PREFIX}-${function_name}-duration\"\n    if ! alarm_exists \"$duration_alarm_name\"; then\n        echo \"Creating duration alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$duration_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name duration exceeds threshold\" \\\n            --metric-name Duration \\\n            --namespace AWS/Lambda \\\n            --statistic Average \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold \"$threshold\" \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Duration alarm already exists\"\n    fi\n\n    # Throttles alarm\n    local throttle_alarm_name=\"${REGION_PREFIX}-${function_name}-throttles\"\n    if ! alarm_exists \"$throttle_alarm_name\"; then\n        echo \"Creating throttles alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$throttle_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name is throttled\" \\\n            --metric-name Throttles \\\n            --namespace AWS/Lambda \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Throttles alarm already exists\"\n    fi\n}\n\n# Function to create or update API Gateway alarms\ncreate_api_alarms() {\n    local api_id=$1\n    local api_name=$2\n    \n    echo \"Setting up alarms for API Gateway: $api_name\"\n    \n    # 4XX errors alarm\n    local error_4xx_alarm_name=\"${REGION_PREFIX}-${api_name}-4xx-errors\"\n    if ! alarm_exists \"$error_4xx_alarm_name\"; then\n        echo \"Creating 4XX errors alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_4xx_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name has 4XX errors\" \\\n            --metric-name 4XXError \\\n            --namespace AWS/ApiGateway \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 10 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"4XX errors alarm already exists\"\n    fi\n\n    # 5XX errors alarm\n    local error_5xx_alarm_name=\"${REGION_PREFIX}-${api_name}-5xx-errors\"\n    if ! alarm_exists \"$error_5xx_alarm_name\"; then\n        echo \"Creating 5XX errors alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_5xx_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name has 5XX errors\" \\\n            --metric-name 5XXError \\\n            --namespace AWS/ApiGateway \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"5XX errors alarm already exists\"\n    fi\n\n    # Latency alarm\n    local latency_alarm_name=\"${REGION_PREFIX}-${api_name}-latency\"\n    if ! alarm_exists \"$latency_alarm_name\"; then\n        echo \"Creating latency alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$latency_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name latency is high\" \\\n            --metric-name Latency \\\n            --namespace AWS/ApiGateway \\\n            --statistic Average \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1000 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Latency alarm already exists\"\n    fi\n}\n\n# Function to create or update S3 bucket alarms\ncreate_s3_alarms() {\n    local bucket_name=$1\n    \n    echo \"Setting up alarms for S3 bucket: $bucket_name\"\n    \n    # Bucket size alarm\n    local size_alarm_name=\"${REGION_PREFIX}-${bucket_name}-size\"\n    if ! alarm_exists \"$size_alarm_name\"; then\n        echo \"Creating bucket size alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$size_alarm_name\" \\\n            --alarm-description \"Alarm when S3 bucket $bucket_name size is high\" \\\n            --metric-name BucketSizeBytes \\\n            --namespace AWS/S3 \\\n            --statistic Average \\\n            --period 86400 \\\n            --evaluation-periods 1 \\\n            --threshold 10737418240 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=BucketName,Value=\"$bucket_name\" Name=StorageType,Value=StandardStorage \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Bucket size alarm already exists\"\n    fi\n\n    # Number of objects alarm\n    local objects_alarm_name=\"${REGION_PREFIX}-${bucket_name}-objects\"\n    if ! alarm_exists \"$objects_alarm_name\"; then\n        echo \"Creating objects count alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$objects_alarm_name\" \\\n            --alarm-description \"Alarm when S3 bucket $bucket_name has too many objects\" \\\n            --metric-name NumberOfObjects \\\n            --namespace AWS/S3 \\\n            --statistic Average \\\n            --period 86400 \\\n            --evaluation-periods 1 \\\n            --threshold 1000000 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=BucketName,Value=\"$bucket_name\" Name=StorageType,Value=AllStorageTypes \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Objects count alarm already exists\"\n    fi\n}\n\n# Create alarms for all Lambda functions\necho \"Setting up Lambda function alarms...\"\ncreate_lambda_alarms \"ingestHistoricalData\" 300000  # 5 minutes\ncreate_lambda_alarms \"ingestNowcastData\" 300000\ncreate_lambda_alarms \"trainForecaster\" 900000  # 15 minutes\ncreate_lambda_alarms \"generatePresignedUrl\" 30000  # 30 seconds\ncreate_lambda_alarms \"interpolateData\" 300000\ncreate_lambda_alarms \"generateForecast\" 300000\ncreate_lambda_alarms \"returnForecastingResults\" 300000\ncreate_lambda_alarms \"marketPriceForecast\" 300000\ncreate_lambda_alarms \"electricityDispatch\" 300000\ncreate_lambda_alarms \"weather\" 300000\n\n# Create alarms for all API Gateways\necho \"Setting up API Gateway alarms...\"\nAPIS=$(aws apigateway get-rest-apis --region \"$TARGET_REGION\" --query \"items[?contains(name, '${REGION_PREFIX}')].[id,name]\" --output text)\nwhile read -r API_ID API_NAME; do\n    create_api_alarms \"$API_ID\" \"$API_NAME\"\ndone <<< \"$APIS\"\n\n# Create alarms for all S3 buckets\necho \"Setting up S3 bucket alarms...\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-input\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-output\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-facing\"\n\necho \"=============================================\"\necho \"CloudWatch alarms setup completed!\"\necho \"Alarm notifications will be sent to: $ALARM_EMAIL\"\necho \"=============================================\"\n```", "metadata": {"source": "/home/shingai/api/deploy/scripts/setup-monitoring.sh", "category": "deployment", "type": "complete_script"}}
{"prompt": "Use AWS CLI for sns list-subscriptions-by-topic", "completion": "```bash\naws sns list-subscriptions-by-topic --region \"$TARGET_REGION\" \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for sns subscribe", "completion": "```bash\naws sns subscribe \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for cloudwatch describe-alarms", "completion": "```bash\naws cloudwatch describe-alarms --region \"$TARGET_REGION\" \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Write a shell script that orchestrates multiple deployment steps using AWS CLI and CloudFormation.", "completion": "```bash\n#!/bin/bash\nset -e\necho \"Starting orchestration...\"\necho \"Running redeploy2.sh...\"\nREDEPLOY2_OUTPUT=$(./redeploy2.sh)\necho \"redeploy2.sh output:\"\necho \"$REDEPLOY2_OUTPUT\"\nJOB_RUN_ID=$(echo \"$REDEPLOY2_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID\" ] || [ \"$JOB_RUN_ID\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy2.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETLJob JobRunId: $JOB_RUN_ID\"\necho \"Waiting for KnowledgeBaseETLJob to complete...\"\nwhile true; do\n  STATUS=$(aws glue get-job-run --job-name KnowledgeBaseETLJob --run-id \"$JOB_RUN_ID\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS\"\n  if [ \"$STATUS\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETLJob succeeded.\"\n    break\n  elif [[ \"$STATUS\" == \"FAILED\" || \"$STATUS\" == \"TIMEOUT\" || \"$STATUS\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETLJob ended with terminal state: $STATUS\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy3.sh...\"\nREDEPLOY3_OUTPUT=$(./redeploy3.sh)\necho \"redeploy3.sh output:\"\necho \"$REDEPLOY3_OUTPUT\"\nJOB_RUN_ID2=$(echo \"$REDEPLOY3_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID2\" ] || [ \"$JOB_RUN_ID2\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy3.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETL2ndChanceJob JobRunId: $JOB_RUN_ID2\"\necho \"Waiting for KnowledgeBaseETL2ndChanceJob to complete...\"\nwhile true; do\n  STATUS2=$(aws glue get-job-run --job-name KnowledgeBaseETL2ndChanceJob --run-id \"$JOB_RUN_ID2\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS2\"\n  if [ \"$STATUS2\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETL2ndChanceJob succeeded.\"\n    break\n  elif [[ \"$STATUS2\" == \"FAILED\" || \"$STATUS2\" == \"TIMEOUT\" || \"$STATUS2\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETL2ndChanceJob ended with terminal state: $STATUS2\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy4.sh...\"\n./redeploy4.sh\necho \"Orchestration complete.\"\necho \"Shutting down the instance now...\"\nsudo shutdown -h now\n```", "metadata": {"source": "/home/shingai/api/RAG/ETL/scripts/orchestrator.sh", "category": "orchestration", "type": "complete_script"}}
{"prompt": "Write a shell script for deploying infrastructure and services using AWS CLI and CloudFormation.", "completion": "```bash\n#!/bin/bash\n# deploy.sh\n# Comprehensive deployment script for Knowledge Base ETL system\n#\n# This script handles deployment of all components:\n#   1. Lambda Function (etl-google-alerts)\n#   2. Primary Glue Job (KnowledgeBaseETLJob) - etl-s3.py\n#   3. Second Chance Glue Job (KnowledgeBaseETL2ndChanceJob) - etl-s3-failed.py\n#   4. Rehoming Glue Job (KnowledgeBaseETLRehomeJob) - rehoming_etl.py\n#\n# Usage:\n#   ./deploy.sh [--all] [--lambda] [--primary] [--second-chance] [--rehome]\n#\n# Options:\n#   --all            Deploy all components (default if no flag is provided)\n#   --lambda         Deploy only the Lambda function (etl-google-alerts)\n#   --primary        Deploy only the primary ETL job\n#   --second-chance  Deploy only the second chance ETL job\n#   --rehome         Deploy only the rehoming ETL job\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - Script files must be present in the respective directories.\n# - IAM role with necessary permissions must exist.\n\nset -e  # Exit immediately if any command fails\n\n# Common variables\nREGION=\"us-east-1\"\nS3_BUCKET=\"policy-database\"\nTEMP_DIR=\"s3://$S3_BUCKET/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nROLE_NAME=\"AWSGluePolicyDatabaseRole\"  # Extracted from the ARN\nGLUE_VERSION=\"2.0\"\nMAX_CAPACITY=\"2.0\"\nTIMEOUT=\"2880\"\n\n# Lambda variables\nLAMBDA_FUNCTION_NAME=\"etl-google-alerts\"\nLAMBDA_ZIP_FILE=\"../lambda/etl-lambda.zip\"\nLAMBDA_HANDLER_FILE=\"../lambda/etl-google-alerts-lambda.js\"\nNODE_MODULES_DIR=\"../node_modules\"\n\n# Glue job variables\nPRIMARY_JOB_NAME=\"KnowledgeBaseETLJob\"\nPRIMARY_SCRIPT_LOCAL=\"../glue/etl-s3.py\"\nPRIMARY_SCRIPT_S3=\"s3://$S3_BUCKET/etl/etl-s3.py\"\nPRIMARY_MODULES=\"PyPDF2==3.0.1,pycryptodome\"\n\nSECOND_CHANCE_JOB_NAME=\"KnowledgeBaseETL2ndChanceJob\"\nSECOND_CHANCE_SCRIPT_LOCAL=\"../glue/etl-s3-failed.py\"\nSECOND_CHANCE_SCRIPT_S3=\"s3://$S3_BUCKET/etl/etl-s3-failed.py\"\nSECOND_CHANCE_MODULES=\"PyPDF2==3.0.1,pycryptodome\"\n\nREHOME_JOB_NAME=\"KnowledgeBaseETLRehomeJob\"\nREHOME_SCRIPT_LOCAL=\"../glue/rehoming_etl.py\"\nREHOME_SCRIPT_S3=\"s3://$S3_BUCKET/etl/rehoming_etl.py\"\nREHOME_MODULES=\"PyPDF2==3.0.1\"\n\n# CloudWatch logs inline policy document for rehoming job\nINLINE_POLICY_NAME=\"GlueCloudWatchLogAccessPolicy\"\nINLINE_POLICY_DOCUMENT=$(cat <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n          \"logs:FilterLogEvents\",\n          \"logs:DescribeLogStreams\",\n          \"logs:GetLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:$REGION:<ACCOUNT_ID>:log-group:/aws-glue/jobs/output:*\"\n    }\n  ]\n}\nEOF\n)\n\n# Function to deploy a Glue job\ndeploy_glue_job() {\n    local job_name=$1\n    local script_local=$2\n    local script_s3=$3\n    local additional_modules=$4\n    local extra_setup=$5\n\n    echo \"Uploading script $script_local to $script_s3...\"\n    aws s3 cp \"$script_local\" \"$script_s3\" --region \"$REGION\"\n\n    # Run any extra setup if provided (e.g., for rehome job IAM policy)\n    if [ -n \"$extra_setup\" ]; then\n        eval \"$extra_setup\"\n    fi\n\n    echo \"Checking if Glue job $job_name exists...\"\n    if aws glue get-job --job-name \"$job_name\" --region \"$REGION\" >/dev/null 2>&1; then\n        echo \"Job exists. Updating job configuration...\"\n        aws glue update-job \\\n          --job-name \"$job_name\" \\\n          --job-update '{\n            \"Role\": \"'\"$ROLE\"'\",\n            \"Command\": {\n              \"Name\": \"glueetl\",\n              \"ScriptLocation\": \"'\"$script_s3\"'\",\n              \"PythonVersion\": \"3\"\n            },\n            \"DefaultArguments\": {\n              \"--TempDir\": \"'\"$TEMP_DIR\"'\",\n              \"--job-language\": \"python\",\n              \"--additional-python-modules\": \"'\"$additional_modules\"'\"\n            },\n            \"MaxRetries\": 0,\n            \"Timeout\": '\"$TIMEOUT\"',\n            \"MaxCapacity\": '\"$MAX_CAPACITY\"',\n            \"GlueVersion\": \"'\"$GLUE_VERSION\"'\"\n          }' \\\n          --region \"$REGION\"\n    else\n        echo \"Job does not exist. Creating Glue job $job_name...\"\n        aws glue create-job \\\n          --name \"$job_name\" \\\n          --role \"$ROLE\" \\\n          --command \"Name=glueetl,ScriptLocation=$script_s3,PythonVersion=3\" \\\n          --default-arguments \"{\\\"--TempDir\\\":\\\"$TEMP_DIR\\\",\\\"--job-language\\\":\\\"python\\\",\\\"--additional-python-modules\\\":\\\"$additional_modules\\\"}\" \\\n          --max-retries 0 \\\n          --timeout \"$TIMEOUT\" \\\n          --max-capacity \"$MAX_CAPACITY\" \\\n          --glue-version \"$GLUE_VERSION\" \\\n          --region \"$REGION\"\n    fi\n\n    echo \"Starting a new run of the Glue job $job_name...\"\n    JOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$job_name\" --region \"$REGION\")\n    echo \"Job run started:\"\n    echo \"$JOB_RUN_OUTPUT\"\n    echo \"---------------------------------------------\"\n}\n\n# Function to deploy Lambda\ndeploy_lambda() {\n    echo \"Starting deployment of Lambda function: $LAMBDA_FUNCTION_NAME\"\n    \n    # 1. Install production dependencies\n    echo \"Installing production dependencies...\"\n    (cd .. && npm install --production)\n    \n    # 2. Create the deployment package zip file\n    echo \"Creating deployment package: $LAMBDA_ZIP_FILE\"\n    (cd .. && zip -r \"lambda/etl-lambda.zip\" \"lambda/etl-google-alerts-lambda.js\" \"node_modules\")\n    \n    # 3. Upload the ZIP file to the same S3 location where Glue scripts are stored\n    echo \"Uploading Lambda package to S3...\"\n    aws s3 cp \"$LAMBDA_ZIP_FILE\" \"s3://$S3_BUCKET/etl/etl-lambda.zip\" --region \"$REGION\"\n    \n    # 4. Update the Lambda function code using the S3 reference\n    echo \"Updating Lambda function code from S3 in region $REGION...\"\n    aws lambda update-function-code \\\n      --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n      --s3-bucket \"$S3_BUCKET\" \\\n      --s3-key \"etl/etl-lambda.zip\" \\\n      --region \"$REGION\"\n    \n    echo \"Lambda deployment complete.\"\n    echo \"---------------------------------------------\"\n}\n\n# Process command-line arguments\nDEPLOY_LAMBDA=false\nDEPLOY_PRIMARY=false\nDEPLOY_SECOND_CHANCE=false\nDEPLOY_REHOME=false\n\n# Default to deploying all if no arguments provided\nif [ $# -eq 0 ]; then\n    DEPLOY_LAMBDA=true\n    DEPLOY_PRIMARY=true\n    DEPLOY_SECOND_CHANCE=true\n    DEPLOY_REHOME=true\nelse\n    while [ $# -gt 0 ]; do\n        case \"$1\" in\n            --all)\n                DEPLOY_LAMBDA=true\n                DEPLOY_PRIMARY=true\n                DEPLOY_SECOND_CHANCE=true\n                DEPLOY_REHOME=true\n                ;;\n            --lambda)\n                DEPLOY_LAMBDA=true\n                ;;\n            --primary)\n                DEPLOY_PRIMARY=true\n                ;;\n            --second-chance)\n                DEPLOY_SECOND_CHANCE=true\n                ;;\n            --rehome)\n                DEPLOY_REHOME=true\n                ;;\n            *)\n                echo \"Unknown option: $1\"\n                echo \"Usage: ./deploy.sh [--all] [--lambda] [--primary] [--second-chance] [--rehome]\"\n                exit 1\n                ;;\n        esac\n        shift\n    done\nfi\n\n# Extra setup command for rehome job (IAM policy update)\nREHOME_EXTRA_SETUP='echo \"Updating IAM role ($ROLE_NAME) to allow CloudWatch Logs access...\"; aws iam put-role-policy --role-name \"$ROLE_NAME\" --policy-name \"$INLINE_POLICY_NAME\" --policy-document \"$INLINE_POLICY_DOCUMENT\" --region \"$REGION\"'\n\n# Deploy selected components\nif [ \"$DEPLOY_LAMBDA\" = true ]; then\n    echo \"Deploying Lambda Function ($LAMBDA_FUNCTION_NAME)...\"\n    deploy_lambda\nfi\n\nif [ \"$DEPLOY_PRIMARY\" = true ]; then\n    echo \"Deploying Primary ETL Job ($PRIMARY_JOB_NAME)...\"\n    deploy_glue_job \"$PRIMARY_JOB_NAME\" \"$PRIMARY_SCRIPT_LOCAL\" \"$PRIMARY_SCRIPT_S3\" \"$PRIMARY_MODULES\"\nfi\n\nif [ \"$DEPLOY_SECOND_CHANCE\" = true ]; then\n    echo \"Deploying Second Chance ETL Job ($SECOND_CHANCE_JOB_NAME)...\"\n    deploy_glue_job \"$SECOND_CHANCE_JOB_NAME\" \"$SECOND_CHANCE_SCRIPT_LOCAL\" \"$SECOND_CHANCE_SCRIPT_S3\" \"$SECOND_CHANCE_MODULES\"\nfi\n\nif [ \"$DEPLOY_REHOME\" = true ]; then\n    echo \"Deploying Rehoming ETL Job ($REHOME_JOB_NAME)...\"\n    deploy_glue_job \"$REHOME_JOB_NAME\" \"$REHOME_SCRIPT_LOCAL\" \"$REHOME_SCRIPT_S3\" \"$REHOME_MODULES\" \"$REHOME_EXTRA_SETUP\"\nfi\n\necho \"Deployment completed successfully!\"\n```", "metadata": {"source": "/home/shingai/api/RAG/ETL/scripts/deploy.sh", "category": "deployment", "type": "complete_script"}}
{"prompt": "Use AWS CLI for s3 cp", "completion": "```bash\naws s3 cp \"$script_local\" \"$script_s3\" --region \"$REGION\"\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for glue update-job", "completion": "```bash\naws glue update-job \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for glue create-job", "completion": "```bash\naws glue create-job \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for s3 cp", "completion": "```bash\naws s3 cp \"$LAMBDA_ZIP_FILE\" \"s3://$S3_BUCKET/etl/etl-lambda.zip\" --region \"$REGION\"\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Update Lambda function code using AWS CLI", "completion": "```bash\naws lambda update-function-code \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Write a shell script for deploying infrastructure and services using AWS CLI and CloudFormation.", "completion": "```bash\n#!/bin/bash\n# Deploy script for the Visual Crossing weather data fetching Lambda functions\n# Sets up S3 bucket and Lambda functions to fetch and store weather data for various cities\n# Deployment region: af-south-1 (Cape Town)\n\n# Exit on error\nset -e\n\n# Check if .env file exists and load it\nif [ -f .env ]; then\n    export $(grep -v '^#' .env | xargs)\n    echo \"Loaded environment variables from .env file\"\nelse\n    echo \"No .env file found. Make sure you have set the VISUALCROSSING_API_KEY environment variable.\"\nfi\n\n# Check if API key is set\nif [ -z \"$VISUALCROSSING_API_KEY\" ]; then\n    echo \"VISUALCROSSING_API_KEY environment variable is not set.\"\n    echo \"Please set it using 'export VISUALCROSSING_API_KEY=your_api_key_here'\"\n    exit 1\nfi\n\n# Configuration\nREGION=\"us-east-1\"\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nLAMBDA_ROLE_NAME=\"lambda-weather-execution-role\"\nS3_BUCKET=\"visualcrossing-city-database\"\nLAMBDA_RUNTIME=\"python3.9\"\nLAMBDA_MEMORY=256\nLAMBDA_TIMEOUT=120\nLAMBDA_DAILY_WEATHER_NAME=\"daily_weather_fetch\"\n\n# Check if virtual environment exists, if not create one\nif [ ! -d \"venv\" ]; then\n    echo \"Creating virtual environment...\"\n    python3 -m venv venv\nfi\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Install dependencies\necho \"Installing dependencies...\"\npip install boto3 requests\n\n# Create output directory for packages\nmkdir -p build\n\necho \"Creating S3 bucket if it doesn't exist...\"\nif ! aws s3api head-bucket --bucket $S3_BUCKET --region $REGION 2>/dev/null; then\n    echo \"Creating S3 bucket: $S3_BUCKET\"\n    aws s3api create-bucket \\\n        --bucket $S3_BUCKET \\\n        --region $REGION \\\n        --create-bucket-configuration LocationConstraint=$REGION\n    \n    # Wait for bucket to be available\n    echo \"Waiting for bucket to become available...\"\n    sleep 5\nelse\n    echo \"S3 bucket already exists: $S3_BUCKET\"\nfi\n\n# Create IAM role for Lambda if it doesn't exist\necho \"Setting up IAM role for Lambda...\"\nif ! aws iam get-role --role-name $LAMBDA_ROLE_NAME 2>/dev/null; then\n    echo \"Creating IAM role: $LAMBDA_ROLE_NAME\"\n    \n    # Create a trust policy document for Lambda\n    cat > /tmp/trust-policy.json << EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n    \n    # Create the role\n    aws iam create-role \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --assume-role-policy-document file:///tmp/trust-policy.json\n    \n    # Attach policies\n    echo \"Attaching policies to IAM role...\"\n    \n    # Basic execution role for CloudWatch Logs\n    aws iam attach-role-policy \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n    \n    # S3 access for storing weather data\n    aws iam attach-role-policy \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess\n    \n    # Wait for role to be ready\n    echo \"Waiting for IAM role to be ready...\"\n    sleep 10\nelse\n    echo \"IAM role already exists: $LAMBDA_ROLE_NAME\"\nfi\n\n# Get the IAM role ARN\nLAMBDA_ROLE_ARN=\"arn:aws:iam::$ACCOUNT_ID:role/$LAMBDA_ROLE_NAME\"\necho \"Using IAM role ARN: $LAMBDA_ROLE_ARN\"\n\n# Deploy daily weather fetch Lambda\necho \"Deploying daily weather fetch Lambda...\"\n\n# Package the code\necho \"Packaging daily_weather_fetch.py...\"\nmkdir -p build/daily_weather\ncp daily_weather_fetch.py build/daily_weather/\ncd build/daily_weather\nzip -r ../daily_weather_function.zip .\ncd ../..\n\n# Check if the Lambda function exists\nif aws lambda get-function --function-name $LAMBDA_DAILY_WEATHER_NAME --region $REGION 2>/dev/null; then\n    echo \"Updating existing Lambda function: $LAMBDA_DAILY_WEATHER_NAME\"\n    \n    # FIRST: Update the Lambda function configuration\n    echo \"Updating Lambda configuration...\"\n    aws lambda update-function-configuration \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --timeout $LAMBDA_TIMEOUT \\\n        --memory-size $LAMBDA_MEMORY \\\n        --environment \"Variables={VISUALCROSSING_API_KEY=$VISUALCROSSING_API_KEY,S3_BUCKET=$S3_BUCKET}\" \\\n        --region $REGION\n    \n    # Wait for configuration update to complete\n    echo \"Waiting for configuration update to complete...\"\n    sleep 10\n    \n    # Verify environment variables\n    CURRENT_ENV=$(aws lambda get-function --function-name $LAMBDA_DAILY_WEATHER_NAME --region $REGION --query 'Configuration.Environment.Variables' --output json)\n    echo \"Updated environment variables: $CURRENT_ENV\"\n    \n    # SECOND: Update the Lambda function code\n    echo \"Updating Lambda code...\"\n    aws lambda update-function-code \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --zip-file fileb://build/daily_weather_function.zip \\\n        --region $REGION\nelse\n    echo \"Creating new Lambda function: $LAMBDA_DAILY_WEATHER_NAME\"\n    \n    # Create the Lambda function\n    aws lambda create-function \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --runtime $LAMBDA_RUNTIME \\\n        --role $LAMBDA_ROLE_ARN \\\n        --handler daily_weather_fetch.lambda_handler \\\n        --zip-file fileb://build/daily_weather_function.zip \\\n        --timeout $LAMBDA_TIMEOUT \\\n        --memory-size $LAMBDA_MEMORY \\\n        --environment \"Variables={VISUALCROSSING_API_KEY=$VISUALCROSSING_API_KEY,S3_BUCKET=$S3_BUCKET}\" \\\n        --region $REGION\nfi\n\n# Create or update EventBridge rule to trigger the Lambda daily at midnight UTC\nRULE_NAME=\"daily-weather-fetch-trigger\"\necho \"Setting up EventBridge rule: $RULE_NAME\"\n\naws events put-rule \\\n    --name $RULE_NAME \\\n    --schedule-expression \"cron(0 0 * * ? *)\" \\\n    --state ENABLED \\\n    --region $REGION\n\n# Add the daily weather Lambda as target\naws events put-targets \\\n    --rule $RULE_NAME \\\n    --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:$REGION:$ACCOUNT_ID:function:$LAMBDA_DAILY_WEATHER_NAME\" \\\n    --region $REGION\n\n# Add permission for EventBridge to invoke the Lambda\necho \"Adding permission for EventBridge to invoke Lambda...\"\naws lambda add-permission \\\n    --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n    --statement-id \"AllowExecutionFromEventBridge\" \\\n    --action \"lambda:InvokeFunction\" \\\n    --principal \"events.amazonaws.com\" \\\n    --source-arn \"arn:aws:events:$REGION:$ACCOUNT_ID:rule/$RULE_NAME\" \\\n    --region $REGION || true  # Ignore error if permission already exists\n\necho \"Deployment completed successfully!\"\necho \"The daily weather fetch Lambda will run every day at midnight UTC.\"\necho \"Weather data will be stored in s3://$S3_BUCKET/<city_name>/daily/ directories.\"\necho \"Historical data: s3://$S3_BUCKET/<city_name>/daily/YYYY-MM-DD.json\"\necho \"Forecast data: s3://$S3_BUCKET/<city_name>/daily/forecast_YYYY-MM-DD.json\"\n\n# Deactivate virtual environment\ndeactivate\n\necho \"You can test the Lambda function by running:\"\necho \"aws lambda invoke --function-name $LAMBDA_DAILY_WEATHER_NAME --payload '{}' --region $REGION output.json\"\n```", "metadata": {"source": "/home/shingai/api/core/weather/deploy.sh", "category": "deployment", "type": "complete_script"}}
{"prompt": "Use AWS CLI for s3api create-bucket", "completion": "```bash\naws s3api create-bucket \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create IAM role using AWS CLI", "completion": "```bash\naws iam create-role \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for iam attach-role-policy", "completion": "```bash\naws iam attach-role-policy \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for iam attach-role-policy", "completion": "```bash\naws iam attach-role-policy \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for lambda update-function-configuration", "completion": "```bash\naws lambda update-function-configuration \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Update Lambda function code using AWS CLI", "completion": "```bash\naws lambda update-function-code \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Create Lambda function using AWS CLI", "completion": "```bash\naws lambda create-function \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for events put-rule", "completion": "```bash\naws events put-rule \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for events put-targets", "completion": "```bash\naws events put-targets \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for lambda add-permission", "completion": "```bash\naws lambda add-permission \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Write a shell script for deploying infrastructure and services using AWS CLI and CloudFormation.", "completion": "```bash\n#!/bin/bash\n# create-ecr-repos.sh\n# Script to create ECR repositories for core API components\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region>\"\n    echo \"Example: $0 eu-south-1\"\n    exit 1\nfi\n\nTARGET_REGION=\"$1\"\n\necho \"Creating ECR repositories in region: $TARGET_REGION\"\n\n# List of repository names to create\nREPO_NAMES=(\n    \"ingesthistoricaldata/lambda\"\n    \"ingestnowcastdata/lambda\"\n    \"trainforecaster/lambda\"\n    \"generatepresignedurl/lambda\"\n)\n\n# Create each repository if it doesn't exist\nfor REPO_NAME in \"${REPO_NAMES[@]}\"; do\n    echo \"Checking repository: $REPO_NAME\"\n    \n    # Check if repository exists\n    if aws ecr describe-repositories --region \"$TARGET_REGION\" --repository-names \"$REPO_NAME\" >/dev/null 2>&1; then\n        echo \"Repository $REPO_NAME already exists\"\n    else\n        echo \"Creating repository: $REPO_NAME\"\n        aws ecr create-repository \\\n            --region \"$TARGET_REGION\" \\\n            --repository-name \"$REPO_NAME\" \\\n            --image-scanning-configuration scanOnPush=true\n        \n        # Set lifecycle policy to keep only the last 5 images\n        echo \"Setting lifecycle policy for $REPO_NAME\"\n        aws ecr put-lifecycle-policy \\\n            --region \"$TARGET_REGION\" \\\n            --repository-name \"$REPO_NAME\" \\\n            --lifecycle-policy-text '{\n                \"rules\": [\n                    {\n                        \"rulePriority\": 1,\n                        \"description\": \"Keep only the last 5 images\",\n                        \"selection\": {\n                            \"tagStatus\": \"any\",\n                            \"countType\": \"imageCountMoreThan\",\n                            \"countNumber\": 5\n                        },\n                        \"action\": {\n                            \"type\": \"expire\"\n                        }\n                    }\n                ]\n            }'\n        \n        echo \"Repository $REPO_NAME created successfully\"\n    fi\ndone\n\necho \"ECR repository setup complete\"\n```", "metadata": {"source": "/home/shingai/api/deploy/scripts/create-ecr-repos.sh", "category": "deployment", "type": "complete_script"}}
{"prompt": "Use AWS CLI for ecr create-repository", "completion": "```bash\naws ecr create-repository \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Use AWS CLI for ecr put-lifecycle-policy", "completion": "```bash\naws ecr put-lifecycle-policy \\\n```", "metadata": {"category": "deployment", "type": "aws_command"}}
{"prompt": "Write a shell script for deploying infrastructure and services using AWS CLI and CloudFormation.", "completion": "```bash\n#!/bin/bash\nset -euo pipefail\n\n# Comprehensive monitoring setup for Flux model loading\necho \"Setting up monitoring infrastructure...\"\n\n# Install monitoring tools\nsudo apt update\nsudo apt install -y htop iotop sysstat nethogs\n\n# Create monitoring directories\nsudo mkdir -p /var/log/flux-monitoring\nsudo chown ubuntu:ubuntu /var/log/flux-monitoring\n\n# System resource monitoring script\ncat > /tmp/system_monitor.py << 'EOF'\n#!/usr/bin/env python3\nimport psutil\nimport subprocess\nimport time\nimport json\nimport sys\nfrom datetime import datetime\n\ndef get_gpu_info():\n    try:\n        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total,utilization.gpu,temperature.gpu'], \n                              capture_output=True, text=True, check=True)\n        lines = result.stdout.strip().split('\\n')[1:]  # Skip header\n        if lines:\n            memory_used, memory_total, gpu_util, temp = lines[0].split(', ')\n            return {\n                'memory_used_mb': int(memory_used.split()[0]),\n                'memory_total_mb': int(memory_total.split()[0]),\n                'utilization_percent': int(gpu_util.split()[0]),\n                'temperature_c': int(temp.split()[0])\n            }\n    except:\n        pass\n    return {'error': 'GPU info unavailable'}\n\ndef get_process_info(process_name):\n    processes = []\n    for proc in psutil.process_iter(['pid', 'name', 'memory_info', 'cpu_percent', 'status']):\n        try:\n            if process_name.lower() in proc.info['name'].lower():\n                processes.append({\n                    'pid': proc.info['pid'],\n                    'memory_mb': proc.info['memory_info'].rss / 1024 / 1024,\n                    'cpu_percent': proc.info['cpu_percent'],\n                    'status': proc.info['status']\n                })\n        except:\n            continue\n    return processes\n\ndef monitor_system():\n    timestamp = datetime.now().isoformat()\n    \n    # System metrics\n    memory = psutil.virtual_memory()\n    cpu = psutil.cpu_percent(interval=1)\n    disk = psutil.disk_usage('/')\n    \n    # Network stats\n    net = psutil.net_io_counters()\n    \n    data = {\n        'timestamp': timestamp,\n        'memory': {\n            'total_gb': memory.total / 1024**3,\n            'used_gb': memory.used / 1024**3,\n            'available_gb': memory.available / 1024**3,\n            'percent': memory.percent\n        },\n        'cpu_percent': cpu,\n        'disk': {\n            'total_gb': disk.total / 1024**3,\n            'used_gb': disk.used / 1024**3,\n            'free_gb': disk.free / 1024**3\n        },\n        'network': {\n            'bytes_sent': net.bytes_sent,\n            'bytes_recv': net.bytes_recv\n        },\n        'gpu': get_gpu_info(),\n        'python_processes': get_process_info('python')\n    }\n    \n    return data\n\nif __name__ == '__main__':\n    if len(sys.argv) > 1 and sys.argv[1] == '--continuous':\n        # Continuous monitoring mode\n        log_file = '/var/log/flux-monitoring/system_metrics.log'\n        while True:\n            try:\n                data = monitor_system()\n                with open(log_file, 'a') as f:\n                    f.write(json.dumps(data) + '\\n')\n                time.sleep(5)\n            except KeyboardInterrupt:\n                break\n            except Exception as e:\n                print(f\"Monitoring error: {e}\")\n    else:\n        # Single measurement\n        data = monitor_system()\n        print(json.dumps(data, indent=2))\nEOF\n\nchmod +x /tmp/system_monitor.py\n\n# Process monitoring script\ncat > /tmp/process_monitor.sh << 'EOF'\n#!/bin/bash\nset -euo pipefail\n\nLOG_FILE=\"/var/log/flux-monitoring/process.log\"\n\nmonitor_process() {\n    local pid=$1\n    local name=$2\n    \n    echo \"$(date): Monitoring process $name (PID: $pid)\" >> \"$LOG_FILE\"\n    \n    while kill -0 \"$pid\" 2>/dev/null; do\n        # Get process stats\n        ps -o pid,ppid,rss,vsz,pcpu,time,cmd -p \"$pid\" >> \"$LOG_FILE\" 2>/dev/null || break\n        \n        # Check if process is responding\n        if [ -d \"/proc/$pid\" ]; then\n            echo \"$(date): Process $pid still alive\" >> \"$LOG_FILE\"\n        else\n            echo \"$(date): Process $pid disappeared\" >> \"$LOG_FILE\"\n            break\n        fi\n        \n        sleep 10\n    done\n    \n    echo \"$(date): Process $name (PID: $pid) monitoring ended\" >> \"$LOG_FILE\"\n}\n\n# Export function for external use\nexport -f monitor_process\nEOF\n\nchmod +x /tmp/process_monitor.sh\n\n# Kernel message monitoring\ncat > /tmp/kernel_monitor.sh << 'EOF'\n#!/bin/bash\nset -euo pipefail\n\nLOG_FILE=\"/var/log/flux-monitoring/kernel.log\"\n\necho \"$(date): Starting kernel message monitoring\" >> \"$LOG_FILE\"\n\n# Monitor dmesg for OOM, GPU, and other critical messages\nsudo dmesg -w | while read line; do\n    echo \"$(date): $line\" >> \"$LOG_FILE\"\n    \n    # Alert on critical messages\n    if echo \"$line\" | grep -i -E \"(oom|killed|cuda|nvidia|memory|hung|panic)\"; then\n        echo \"$(date): CRITICAL: $line\" >> \"$LOG_FILE\"\n    fi\ndone &\n\necho $! > /tmp/kernel_monitor_pid\nEOF\n\nchmod +x /tmp/kernel_monitor.sh\n\necho \"Monitoring infrastructure installed\"\necho \"Available commands:\"\necho \"  - /tmp/system_monitor.py                 # Single system snapshot\"\necho \"  - /tmp/system_monitor.py --continuous    # Continuous monitoring\"\necho \"  - /tmp/process_monitor.sh                # Process monitoring functions\"\necho \"  - /tmp/kernel_monitor.sh                 # Kernel message monitoring\"\necho \"\"\necho \"Logs will be written to /var/log/flux-monitoring/\"\nEOF\n```", "metadata": {"source": "/home/shingai/sort/deployments/monitoring/setup_monitoring.sh", "category": "deployment", "type": "complete_script"}}
{"prompt": "List all EC2 instances using AWS CLI", "completion": "```bash\naws ec2 describe-instances --query \"Reservations[].Instances[].{ID:InstanceId,State:State.Name}\" --output table\n```", "metadata": {"source": "generated_pattern", "service": "ec2", "operation": "describe-instances", "type": "common_pattern"}}
{"prompt": "Launch an EC2 instance using AWS CLI", "completion": "```bash\naws ec2 run-instances --image-id ami-12345678 --count 1 --instance-type t3.micro --key-name <KEY_NAME> --security-group-ids sg-12345678\n```", "metadata": {"source": "generated_pattern", "service": "ec2", "operation": "run-instances", "type": "common_pattern"}}
{"prompt": "Terminate EC2 instances using AWS CLI", "completion": "```bash\naws ec2 terminate-instances --instance-ids <INSTANCE_ID>\n```", "metadata": {"source": "generated_pattern", "service": "ec2", "operation": "terminate-instances", "type": "common_pattern"}}
{"prompt": "List EC2 security groups using AWS CLI", "completion": "```bash\naws ec2 describe-security-groups --help\n```", "metadata": {"source": "generated_pattern", "service": "ec2", "operation": "describe-security-groups", "type": "common_pattern"}}
{"prompt": "Create EC2 security group using AWS CLI", "completion": "```bash\naws ec2 create-security-group --group-name <SECURITY_GROUP_NAME> --description \"Security group for web servers\"\n```", "metadata": {"source": "generated_pattern", "service": "ec2", "operation": "create-security-group", "type": "common_pattern"}}
{"prompt": "Deploy CloudFormation stack using AWS CLI", "completion": "```bash\naws cloudformation deploy --template-file template.yaml --stack-name <STACK_NAME> --capabilities CAPABILITY_IAM\n```", "metadata": {"source": "generated_pattern", "service": "cloudformation", "operation": "deploy", "type": "common_pattern"}}
{"prompt": "Get CloudFormation stack information using AWS CLI", "completion": "```bash\naws cloudformation describe-stacks --stack-name <STACK_NAME> --query \"Stacks[0].StackStatus\" --output text\n```", "metadata": {"source": "generated_pattern", "service": "cloudformation", "operation": "describe-stacks", "type": "common_pattern"}}
{"prompt": "List CloudFormation stacks using AWS CLI", "completion": "```bash\naws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE --query \"StackSummaries[].{Name:StackName,Status:StackStatus}\"\n```", "metadata": {"source": "generated_pattern", "service": "cloudformation", "operation": "list-stacks", "type": "common_pattern"}}
{"prompt": "Delete CloudFormation stack using AWS CLI", "completion": "```bash\naws cloudformation delete-stack --stack-name <STACK_NAME>\n```", "metadata": {"source": "generated_pattern", "service": "cloudformation", "operation": "delete-stack", "type": "common_pattern"}}
{"prompt": "Validate CloudFormation template using AWS CLI", "completion": "```bash\naws cloudformation validate-template --template-body file://template.yaml\n```", "metadata": {"source": "generated_pattern", "service": "cloudformation", "operation": "validate-template", "type": "common_pattern"}}
{"prompt": "Copy files to S3 bucket using AWS CLI", "completion": "```bash\naws s3 cp <FILE_PATH> s3://<BUCKET_NAME>/<KEY>\n```", "metadata": {"source": "generated_pattern", "service": "s3", "operation": "cp", "type": "common_pattern"}}
{"prompt": "Sync directory with S3 bucket using AWS CLI", "completion": "```bash\naws s3 sync <LOCAL_DIR> s3://<BUCKET_NAME>/ --delete\n```", "metadata": {"source": "generated_pattern", "service": "s3", "operation": "sync", "type": "common_pattern"}}
{"prompt": "List S3 bucket contents using AWS CLI", "completion": "```bash\naws s3 ls s3://<BUCKET_NAME>/ --recursive\n```", "metadata": {"source": "generated_pattern", "service": "s3", "operation": "ls", "type": "common_pattern"}}
{"prompt": "Create S3 bucket using AWS CLI", "completion": "```bash\naws s3 mb s3://<BUCKET_NAME>\n```", "metadata": {"source": "generated_pattern", "service": "s3", "operation": "mb", "type": "common_pattern"}}
{"prompt": "Delete S3 bucket using AWS CLI", "completion": "```bash\naws s3 rb s3://<BUCKET_NAME> --force\n```", "metadata": {"source": "generated_pattern", "service": "s3", "operation": "rb", "type": "common_pattern"}}
{"prompt": "Create IAM role using AWS CLI", "completion": "```bash\naws iam create-role --role-name <ROLE_NAME> --assume-role-policy-document file://trust-policy.json\n```", "metadata": {"source": "generated_pattern", "service": "iam", "operation": "create-role", "type": "common_pattern"}}
{"prompt": "Attach policy to IAM role using AWS CLI", "completion": "```bash\naws iam attach-role-policy --role-name <ROLE_NAME> --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\n```", "metadata": {"source": "generated_pattern", "service": "iam", "operation": "attach-role-policy", "type": "common_pattern"}}
{"prompt": "Create IAM user using AWS CLI", "completion": "```bash\naws iam create-user --user-name <USER_NAME>\n```", "metadata": {"source": "generated_pattern", "service": "iam", "operation": "create-user", "type": "common_pattern"}}
{"prompt": "List IAM roles using AWS CLI", "completion": "```bash\naws iam list-roles --query \"Roles[].{Name:RoleName,Created:CreateDate}\" --output table\n```", "metadata": {"source": "generated_pattern", "service": "iam", "operation": "list-roles", "type": "common_pattern"}}
{"prompt": "Get IAM role details using AWS CLI", "completion": "```bash\naws iam get-role --role-name <ROLE_NAME>\n```", "metadata": {"source": "generated_pattern", "service": "iam", "operation": "get-role", "type": "common_pattern"}}
{"prompt": "Create Lambda function using AWS CLI", "completion": "```bash\naws lambda create-function --function-name <FUNCTION_NAME> --runtime python3.9 --role arn:aws:iam::<ACCOUNT_ID>:role/<ROLE_NAME> --handler lambda_function.lambda_handler --zip-file fileb://function.zip\n```", "metadata": {"source": "generated_pattern", "service": "lambda", "operation": "create-function", "type": "common_pattern"}}
{"prompt": "Update Lambda function code using AWS CLI", "completion": "```bash\naws lambda update-function-code --function-name <FUNCTION_NAME> --zip-file fileb://function.zip\n```", "metadata": {"source": "generated_pattern", "service": "lambda", "operation": "update-function-code", "type": "common_pattern"}}
{"prompt": "Invoke Lambda function using AWS CLI", "completion": "```bash\naws lambda invoke --function-name <FUNCTION_NAME> --payload '{\"key\": \"value\"}' response.json\n```", "metadata": {"source": "generated_pattern", "service": "lambda", "operation": "invoke", "type": "common_pattern"}}
{"prompt": "List Lambda functions using AWS CLI", "completion": "```bash\naws lambda list-functions --query \"Functions[].{Name:FunctionName,Runtime:Runtime}\" --output table\n```", "metadata": {"source": "generated_pattern", "service": "lambda", "operation": "list-functions", "type": "common_pattern"}}
{"prompt": "Delete Lambda function using AWS CLI", "completion": "```bash\naws lambda delete-function --function-name <FUNCTION_NAME>\n```", "metadata": {"source": "generated_pattern", "service": "lambda", "operation": "delete-function", "type": "common_pattern"}}
{"prompt": "Create SNS topic using AWS CLI", "completion": "```bash\naws sns create-topic --name <TOPIC_NAME>\n```", "metadata": {"source": "generated_pattern", "service": "sns", "operation": "create-topic", "type": "common_pattern"}}
{"prompt": "Publish message to SNS topic using AWS CLI", "completion": "```bash\naws sns publish --topic-arn <TOPIC_ARN> --message \"Hello World\"\n```", "metadata": {"source": "generated_pattern", "service": "sns", "operation": "publish", "type": "common_pattern"}}
{"prompt": "Subscribe to SNS topic using AWS CLI", "completion": "```bash\naws sns subscribe --topic-arn <TOPIC_ARN> --protocol email --notification-endpoint <EMAIL>\n```", "metadata": {"source": "generated_pattern", "service": "sns", "operation": "subscribe", "type": "common_pattern"}}
{"prompt": "List SNS topics using AWS CLI", "completion": "```bash\naws sns list-topics --query \"Topics[].TopicArn\" --output table\n```", "metadata": {"source": "generated_pattern", "service": "sns", "operation": "list-topics", "type": "common_pattern"}}
{"prompt": "Delete SNS topic using AWS CLI", "completion": "```bash\naws sns delete-topic --topic-arn <TOPIC_ARN>\n```", "metadata": {"source": "generated_pattern", "service": "sns", "operation": "delete-topic", "type": "common_pattern"}}
{"prompt": "Create CloudWatch alarm using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-alarm --alarm-name <ALARM_NAME> --alarm-description \"CPU utilization\" --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold 80 --comparison-operator GreaterThanThreshold --evaluation-periods 2\n```", "metadata": {"source": "generated_pattern", "service": "cloudwatch", "operation": "put-metric-alarm", "type": "common_pattern"}}
{"prompt": "List CloudWatch alarms using AWS CLI", "completion": "```bash\naws cloudwatch describe-alarms --query \"MetricAlarms[].{Name:AlarmName,State:StateValue}\" --output table\n```", "metadata": {"source": "generated_pattern", "service": "cloudwatch", "operation": "describe-alarms", "type": "common_pattern"}}
{"prompt": "Send custom metrics to CloudWatch using AWS CLI", "completion": "```bash\naws cloudwatch put-metric-data --namespace \"Custom/Application\" --metric-data MetricName=PageViews,Value=100,Unit=Count\n```", "metadata": {"source": "generated_pattern", "service": "cloudwatch", "operation": "put-metric-data", "type": "common_pattern"}}
{"prompt": "Get CloudWatch metrics using AWS CLI", "completion": "```bash\naws cloudwatch get-metric-statistics --namespace AWS/EC2 --metric-name CPUUtilization --start-time 2023-01-01T00:00:00Z --end-time 2023-01-01T23:59:59Z --period 3600 --statistics Average\n```", "metadata": {"source": "generated_pattern", "service": "cloudwatch", "operation": "get-metric-statistics", "type": "common_pattern"}}
{"prompt": "Delete CloudWatch alarms using AWS CLI", "completion": "```bash\naws cloudwatch delete-alarms --alarm-names <ALARM_NAME>\n```", "metadata": {"source": "generated_pattern", "service": "cloudwatch", "operation": "delete-alarms", "type": "common_pattern"}}
{"prompt": "Create AWS CLI script to launch EC2 instance with security group", "completion": "```bash\n#!/bin/bash\n# Launch EC2 instance with custom security group\n\n# Create security group\naws ec2 create-security-group \\\n    --group-name web-servers \\\n    --description \"Security group for web servers\"\n\n# Add SSH access rule\naws ec2 authorize-security-group-ingress \\\n    --group-name web-servers \\\n    --protocol tcp \\\n    --port 22 \\\n    --cidr 0.0.0.0/0\n\n# Add HTTP access rule  \naws ec2 authorize-security-group-ingress \\\n    --group-name web-servers \\\n    --protocol tcp \\\n    --port 80 \\\n    --cidr 0.0.0.0/0\n\n# Launch instance\naws ec2 run-instances \\\n    --image-id ami-12345678 \\\n    --count 1 \\\n    --instance-type t3.micro \\\n    --key-name <KEY_NAME> \\\n    --security-groups web-servers \\\n    --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=WebServer}]'\n```", "metadata": {"source": "common_pattern", "type": "multi_step_deployment"}}
{"prompt": "Create AWS CLI script to deploy and monitor CloudFormation stack", "completion": "```bash\n#!/bin/bash\n# Deploy CloudFormation stack with monitoring\n\nSTACK_NAME=\"<STACK_NAME>\"\nTEMPLATE_FILE=\"infrastructure.yaml\"\n\n# Validate template\necho \"Validating CloudFormation template...\"\naws cloudformation validate-template --template-body file://$TEMPLATE_FILE\n\n# Deploy stack\necho \"Deploying CloudFormation stack...\"\naws cloudformation deploy \\\n    --template-file $TEMPLATE_FILE \\\n    --stack-name $STACK_NAME \\\n    --capabilities CAPABILITY_IAM \\\n    --parameter-overrides Environment=production\n\n# Wait for completion\necho \"Waiting for stack deployment to complete...\"\naws cloudformation wait stack-deploy-complete --stack-name $STACK_NAME\n\n# Get stack outputs\necho \"Stack deployment completed. Outputs:\"\naws cloudformation describe-stacks \\\n    --stack-name $STACK_NAME \\\n    --query \"Stacks[0].Outputs[].{Key:OutputKey,Value:OutputValue}\" \\\n    --output table\n```", "metadata": {"source": "common_pattern", "type": "cloudformation_deployment"}}
{"prompt": "Create AWS CLI script for S3 backup with lifecycle management", "completion": "```bash\n#!/bin/bash\n# S3 backup script with lifecycle management\n\nBUCKET_NAME=\"<BUCKET_NAME>\"\nLOCAL_DIR=\"<LOCAL_DIR>\"\n\n# Create S3 bucket\naws s3 mb s3://$BUCKET_NAME\n\n# Enable versioning\naws s3api put-bucket-versioning \\\n    --bucket $BUCKET_NAME \\\n    --versioning-configuration Status=Enabled\n\n# Sync local directory to S3\naws s3 sync $LOCAL_DIR s3://$BUCKET_NAME/ \\\n    --delete \\\n    --exclude \"*.tmp\" \\\n    --exclude \".DS_Store\"\n\n# Set lifecycle policy\naws s3api put-bucket-lifecycle-configuration \\\n    --bucket $BUCKET_NAME \\\n    --lifecycle-configuration file://lifecycle-policy.json\n\necho \"Backup completed to s3://$BUCKET_NAME\"\n```", "metadata": {"source": "common_pattern", "type": "s3_backup"}}
{"prompt": "Write a shell script to install Docker on Ubuntu", "completion": "```bash\n#!/bin/bash\n# Install Docker on Ubuntu\n\nset -e\n\n# Update package index\nsudo apt-get update\n\n# Install dependencies\nsudo apt-get install -y \\\n    apt-transport-https \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n\n# Add Docker GPG key\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\n# Add Docker repository\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\n# Update package index again\nsudo apt-get update\n\n# Install Docker\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io\n\n# Start and enable Docker\nsudo systemctl start docker\nsudo systemctl enable docker\n\n# Add current user to docker group\nsudo usermod -aG docker $USER\n\necho \"Docker installation completed. Please log out and back in to use Docker without sudo.\"\n```", "metadata": {"source": "opensource_pattern", "project": "docker/docker-ce", "project_type": "container", "tool": "docker"}}
{"prompt": "Create a shell script to deploy Kubernetes cluster with kubeadm", "completion": "```bash\n#!/bin/bash\n# Deploy Kubernetes cluster with kubeadm\n\nset -e\n\nNODE_TYPE=\"${1:-master}\"\n\n# Install dependencies\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates curl\n\n# Add Kubernetes GPG key\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n\n# Add Kubernetes repository\necho \"deb https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list\n\n# Install kubelet, kubeadm, kubectl\nsudo apt-get update\nsudo apt-get install -y kubelet kubeadm kubectl\nsudo apt-mark hold kubelet kubeadm kubectl\n\nif [ \"$NODE_TYPE\" = \"master\" ]; then\n    # Initialize master node\n    sudo kubeadm init --pod-network-cidr=10.244.0.0/16\n    \n    # Setup kubectl for current user\n    mkdir -p $HOME/.kube\n    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n    sudo chown $(id -u):$(id -g) $HOME/.kube/config\n    \n    # Install Flannel network plugin\n    kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n    \n    echo \"Kubernetes master node setup completed\"\nelse\n    echo \"Worker node ready. Run kubeadm join command from master node.\"\nfi\n```", "metadata": {"source": "opensource_pattern", "project": "kubernetes/kubernetes", "project_type": "orchestration", "tool": "kubernetes"}}
{"prompt": "Write a shell script to deploy Prometheus monitoring stack", "completion": "```bash\n#!/bin/bash\n# Deploy Prometheus monitoring stack\n\nset -e\n\nNAMESPACE=\"${1:-monitoring}\"\n\n# Create monitoring namespace\nkubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -\n\n# Add Prometheus Helm repository\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n\n# Install Prometheus stack\nhelm upgrade --install prometheus prometheus-community/kube-prometheus-stack \\\n    --namespace $NAMESPACE \\\n    --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName=gp2 \\\n    --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=20Gi \\\n    --set grafana.persistence.enabled=true \\\n    --set grafana.persistence.storageClassName=gp2 \\\n    --set grafana.persistence.size=10Gi\n\n# Wait for deployment\nkubectl rollout status deployment/prometheus-grafana -n $NAMESPACE\nkubectl rollout status statefulset/prometheus-prometheus-kube-prometheus-prometheus -n $NAMESPACE\n\n# Get Grafana admin password\necho \"Grafana admin password:\"\nkubectl get secret prometheus-grafana -n $NAMESPACE -o jsonpath=\"{.data.admin-password}\" | base64 --decode\necho\n\necho \"Prometheus monitoring stack deployed successfully in namespace: $NAMESPACE\"\n```", "metadata": {"source": "opensource_pattern", "project": "prometheus/prometheus", "project_type": "monitoring", "tool": "prometheus"}}
{"prompt": "Write a shell script to deploy Prometheus monitoring stack", "completion": "```bash\n#!/bin/bash\n# Deploy Prometheus monitoring stack\n\nset -e\n\nNAMESPACE=\"${1:-monitoring}\"\n\n# Create monitoring namespace\nkubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -\n\n# Add Prometheus Helm repository\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n\n# Install Prometheus stack\nhelm upgrade --install prometheus prometheus-community/kube-prometheus-stack \\\n    --namespace $NAMESPACE \\\n    --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName=gp2 \\\n    --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=20Gi \\\n    --set grafana.persistence.enabled=true \\\n    --set grafana.persistence.storageClassName=gp2 \\\n    --set grafana.persistence.size=10Gi\n\n# Wait for deployment\nkubectl rollout status deployment/prometheus-grafana -n $NAMESPACE\nkubectl rollout status statefulset/prometheus-prometheus-kube-prometheus-prometheus -n $NAMESPACE\n\n# Get Grafana admin password\necho \"Grafana admin password:\"\nkubectl get secret prometheus-grafana -n $NAMESPACE -o jsonpath=\"{.data.admin-password}\" | base64 --decode\necho\n\necho \"Prometheus monitoring stack deployed successfully in namespace: $NAMESPACE\"\n```", "metadata": {"source": "opensource_pattern", "project": "grafana/grafana", "project_type": "monitoring", "tool": "prometheus"}}
{"prompt": "Write a shell script to deploy Prometheus monitoring stack", "completion": "```bash\n#!/bin/bash\n# Deploy Prometheus monitoring stack\n\nset -e\n\nNAMESPACE=\"${1:-monitoring}\"\n\n# Create monitoring namespace\nkubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -\n\n# Add Prometheus Helm repository\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n\n# Install Prometheus stack\nhelm upgrade --install prometheus prometheus-community/kube-prometheus-stack \\\n    --namespace $NAMESPACE \\\n    --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName=gp2 \\\n    --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=20Gi \\\n    --set grafana.persistence.enabled=true \\\n    --set grafana.persistence.storageClassName=gp2 \\\n    --set grafana.persistence.size=10Gi\n\n# Wait for deployment\nkubectl rollout status deployment/prometheus-grafana -n $NAMESPACE\nkubectl rollout status statefulset/prometheus-prometheus-kube-prometheus-prometheus -n $NAMESPACE\n\n# Get Grafana admin password\necho \"Grafana admin password:\"\nkubectl get secret prometheus-grafana -n $NAMESPACE -o jsonpath=\"{.data.admin-password}\" | base64 --decode\necho\n\necho \"Prometheus monitoring stack deployed successfully in namespace: $NAMESPACE\"\n```", "metadata": {"source": "opensource_pattern", "project": "jaegertracing/jaeger", "project_type": "monitoring", "tool": "prometheus"}}
{"prompt": "Create a shell script to setup Kubernetes monitoring with Prometheus and Grafana", "completion": "```bash\n#!/bin/bash\n# Setup Kubernetes monitoring with Prometheus and Grafana\n\nset -e\n\nNAMESPACE=\"monitoring\"\n\necho \"Setting up Kubernetes monitoring stack...\"\n\n# Create monitoring namespace\nkubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -\n\n# Add Helm repositories\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n\n# Install Prometheus\necho \"Installing Prometheus...\"\nhelm upgrade --install prometheus prometheus-community/prometheus \\\n    --namespace $NAMESPACE \\\n    --set server.persistentVolume.size=20Gi \\\n    --set alertmanager.persistentVolume.size=5Gi\n\n# Install Grafana\necho \"Installing Grafana...\"\nhelm upgrade --install grafana grafana/grafana \\\n    --namespace $NAMESPACE \\\n    --set persistence.enabled=true \\\n    --set persistence.size=10Gi \\\n    --set adminPassword=admin123\n\n# Wait for deployments\nkubectl rollout status deployment/prometheus-server -n $NAMESPACE\nkubectl rollout status deployment/grafana -n $NAMESPACE\n\n# Port forward for access\necho \"Monitoring stack deployed. Access via:\"\necho \"Prometheus: kubectl port-forward -n $NAMESPACE svc/prometheus-server 9090:80\"\necho \"Grafana: kubectl port-forward -n $NAMESPACE svc/grafana 3000:80\"\n```", "metadata": {"source": "curated_example", "category": "monitoring", "type": "kubernetes_monitoring"}}
{"prompt": "Write a shell script to deploy microservices with Istio service mesh", "completion": "```bash\n#!/bin/bash\n# Deploy microservices with Istio service mesh\n\nset -e\n\nNAMESPACE=\"${1:-default}\"\n\necho \"Deploying microservices with Istio...\"\n\n# Install Istio\necho \"Installing Istio...\"\ncurl -L https://istio.io/downloadIstio | sh -\nexport PATH=$PWD/istio-*/bin:$PATH\n\n# Install Istio on cluster\nistioctl install --set values.defaultRevision=default -y\n\n# Enable sidecar injection\nkubectl label namespace $NAMESPACE istio-injection=enabled --overwrite\n\n# Deploy sample microservices\necho \"Deploying sample application...\"\nkubectl apply -f - <<EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  namespace: $NAMESPACE\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: frontend\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\n  namespace: $NAMESPACE\nspec:\n  selector:\n    app: frontend\n  ports:\n  - port: 80\n    targetPort: 80\nEOF\n\n# Create Istio Gateway\nkubectl apply -f - <<EOF\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: frontend-gateway\n  namespace: $NAMESPACE\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n  - port:\n      number: 80\n      name: http\n      protocol: HTTP\n    hosts:\n    - \"*\"\n---\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: frontend\n  namespace: $NAMESPACE\nspec:\n  hosts:\n  - \"*\"\n  gateways:\n  - frontend-gateway\n  http:\n  - route:\n    - destination:\n        host: frontend\n        port:\n          number: 80\nEOF\n\necho \"Microservices deployed with Istio service mesh\"\necho \"Access via: kubectl get svc istio-ingressgateway -n istio-system\"\n```", "metadata": {"source": "curated_example", "category": "service_mesh", "type": "istio_deployment"}}
{"prompt": "Create a shell script for automated GitOps deployment with ArgoCD", "completion": "```bash\n#!/bin/bash\n# Automated GitOps deployment with ArgoCD\n\nset -e\n\nNAMESPACE=\"argocd\"\nREPO_URL=\"${1:-https://github.com/example/k8s-manifests}\"\nAPP_NAME=\"${2:-sample-app}\"\n\necho \"Setting up GitOps with ArgoCD...\"\n\n# Create ArgoCD namespace\nkubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -\n\n# Install ArgoCD\necho \"Installing ArgoCD...\"\nkubectl apply -n $NAMESPACE -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Wait for ArgoCD to be ready\necho \"Waiting for ArgoCD to be ready...\"\nkubectl rollout status deployment/argocd-server -n $NAMESPACE\n\n# Get ArgoCD admin password\nARGOCD_PASSWORD=$(kubectl -n $NAMESPACE get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d)\n\n# Install ArgoCD CLI\ncurl -sSL -o /tmp/argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64\nchmod +x /tmp/argocd\nsudo mv /tmp/argocd /usr/local/bin/argocd\n\n# Port forward ArgoCD server\nkubectl port-forward svc/argocd-server -n $NAMESPACE 8080:443 &\nPORTFORWARD_PID=$!\n\n# Wait for port forward\nsleep 5\n\n# Login to ArgoCD\necho \"Logging into ArgoCD...\"\nargocd login localhost:8080 --username admin --password $ARGOCD_PASSWORD --insecure\n\n# Create application\necho \"Creating ArgoCD application...\"\nargocd app create $APP_NAME \\\n    --repo $REPO_URL \\\n    --path manifests \\\n    --dest-server https://kubernetes.default.svc \\\n    --dest-namespace default \\\n    --sync-policy automated \\\n    --auto-prune \\\n    --self-heal\n\n# Sync application\nargocd app sync $APP_NAME\n\n# Kill port forward\nkill $PORTFORWARD_PID\n\necho \"GitOps deployment with ArgoCD completed\"\necho \"ArgoCD admin password: $ARGOCD_PASSWORD\"\necho \"Access ArgoCD: kubectl port-forward svc/argocd-server -n $NAMESPACE 8080:443\"\n```", "metadata": {"source": "curated_example", "category": "gitops", "type": "argocd_setup"}}
{"prompt": "Write a shell script to launch ec2 instance with security group and tags using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Launch EC2 instance with security group and tags\n\nset -euo pipefail\n\nINSTANCE_TYPE=\"${1:-t3.micro}\"\nKEY_NAME=\"${2:-<KEY_NAME>}\"\nSUBNET_ID=\"${3:-<SUBNET_ID>}\"\n\n# Create security group\nSG_ID=$(aws ec2 create-security-group \\\n    --group-name \"web-server-sg-$(date +%s)\" \\\n    --description \"Security group for web server\" \\\n    --vpc-id <VPC_ID> \\\n    --query 'GroupId' --output text)\n\n# Add SSH rule\naws ec2 authorize-security-group-ingress \\\n    --group-id $SG_ID \\\n    --protocol tcp \\\n    --port 22 \\\n    --cidr 0.0.0.0/0\n\n# Add HTTP rule\naws ec2 authorize-security-group-ingress \\\n    --group-id $SG_ID \\\n    --protocol tcp \\\n    --port 80 \\\n    --cidr 0.0.0.0/0\n\n# Launch instance\nINSTANCE_ID=$(aws ec2 run-instances \\\n    --image-id ami-0abcdef1234567890 \\\n    --count 1 \\\n    --instance-type $INSTANCE_TYPE \\\n    --key-name $KEY_NAME \\\n    --security-group-ids $SG_ID \\\n    --subnet-id $SUBNET_ID \\\n    --tag-specifications \\\n        'ResourceType=instance,Tags=[{Key=Name,Value=WebServer},{Key=Environment,Value=Production}]' \\\n    --query 'Instances[0].InstanceId' --output text)\n\necho \"Instance launched: $INSTANCE_ID\"\necho \"Security Group: $SG_ID\"\n\n# Wait for instance to be running\naws ec2 wait instance-running --instance-ids $INSTANCE_ID\necho \"Instance is now running\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ec2", "pattern": "launch_instance", "category": "aws_operations"}}
{"prompt": "Write a shell script to create and configure ec2 security group using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Create and configure EC2 security group\n\nset -euo pipefail\n\necho \"Configuring ec2 create_security_group...\"\naws ec2 help\n\necho \"Create and configure EC2 security group completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ec2", "pattern": "create_security_group", "category": "aws_operations"}}
{"prompt": "Write a shell script to start, stop, and manage ec2 instances using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Start, stop, and manage EC2 instances\n\nset -euo pipefail\n\necho \"Configuring ec2 manage_instances...\"\naws ec2 help\n\necho \"Start, stop, and manage EC2 instances completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ec2", "pattern": "manage_instances", "category": "aws_operations"}}
{"prompt": "Write a shell script to create and configure application load balancer using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Create and configure Application Load Balancer\n\nset -euo pipefail\n\necho \"Configuring ec2 setup_load_balancer...\"\naws ec2 help\n\necho \"Create and configure Application Load Balancer completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ec2", "pattern": "setup_load_balancer", "category": "aws_operations"}}
{"prompt": "Write a shell script to setup auto scaling group with launch template using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Setup Auto Scaling Group with launch template\n\nset -euo pipefail\n\necho \"Configuring ec2 auto_scaling...\"\naws ec2 help\n\necho \"Setup Auto Scaling Group with launch template completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ec2", "pattern": "auto_scaling", "category": "aws_operations"}}
{"prompt": "Write a shell script to create s3 bucket with lifecycle management using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Create S3 bucket with lifecycle management\n\nset -euo pipefail\n\nBUCKET_NAME=\"${1:-<BUCKET_NAME>}\"\nREGION=\"${2:-us-east-1}\"\n\n# Create bucket\naws s3 mb s3://$BUCKET_NAME --region $REGION\n\n# Enable versioning\naws s3api put-bucket-versioning \\\n    --bucket $BUCKET_NAME \\\n    --versioning-configuration Status=Enabled\n\n# Create lifecycle policy\ncat > lifecycle-policy.json <<EOF\n{\n    \"Rules\": [\n        {\n            \"ID\": \"ArchiveOldVersions\",\n            \"Status\": \"Enabled\",\n            \"Filter\": {\"Prefix\": \"\"},\n            \"Transitions\": [\n                {\n                    \"Days\": 30,\n                    \"StorageClass\": \"STANDARD_IA\"\n                },\n                {\n                    \"Days\": 90,\n                    \"StorageClass\": \"GLACIER\"\n                },\n                {\n                    \"Days\": 365,\n                    \"StorageClass\": \"DEEP_ARCHIVE\"\n                }\n            ],\n            \"NoncurrentVersionTransitions\": [\n                {\n                    \"NoncurrentDays\": 30,\n                    \"StorageClass\": \"STANDARD_IA\"\n                }\n            ],\n            \"NoncurrentVersionExpiration\": {\n                \"NoncurrentDays\": 365\n            }\n        }\n    ]\n}\nEOF\n\n# Apply lifecycle policy\naws s3api put-bucket-lifecycle-configuration \\\n    --bucket $BUCKET_NAME \\\n    --lifecycle-configuration file://lifecycle-policy.json\n\n# Enable server-side encryption\naws s3api put-bucket-encryption \\\n    --bucket $BUCKET_NAME \\\n    --server-side-encryption-configuration \\\n    '{\"Rules\":[{\"ApplyServerSideEncryptionByDefault\":{\"SSEAlgorithm\":\"AES256\"}}]}'\n\necho \"S3 bucket $BUCKET_NAME created with lifecycle management\"\nrm lifecycle-policy.json\n```", "metadata": {"source": "generated_aws_pattern", "service": "s3", "pattern": "bucket_lifecycle", "category": "aws_operations"}}
{"prompt": "Write a shell script to setup s3 static website hosting using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Setup S3 static website hosting\n\nset -euo pipefail\n\necho \"Configuring s3 static_website...\"\naws s3 help\n\necho \"Setup S3 static website hosting completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "s3", "pattern": "static_website", "category": "aws_operations"}}
{"prompt": "Write a shell script to automated s3 backup and sync script using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Automated S3 backup and sync script\n\nset -euo pipefail\n\necho \"Configuring s3 backup_sync...\"\naws s3 help\n\necho \"Automated S3 backup and sync script completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "s3", "pattern": "backup_sync", "category": "aws_operations"}}
{"prompt": "Write a shell script to configure s3 cross-region replication using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Configure S3 cross-region replication\n\nset -euo pipefail\n\necho \"Configuring s3 cross_region_replication...\"\naws s3 help\n\necho \"Configure S3 cross-region replication completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "s3", "pattern": "cross_region_replication", "category": "aws_operations"}}
{"prompt": "Write a shell script to large-scale s3 data migration script using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Large-scale S3 data migration script\n\nset -euo pipefail\n\necho \"Configuring s3 data_migration...\"\naws s3 help\n\necho \"Large-scale S3 data migration script completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "s3", "pattern": "data_migration", "category": "aws_operations"}}
{"prompt": "Write a shell script to deploy cloudformation stack with parameters using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Deploy CloudFormation stack with parameters\n\nset -euo pipefail\n\nSTACK_NAME=\"${1:-<STACK_NAME>}\"\nTEMPLATE_FILE=\"${2:-infrastructure.yaml}\"\nENVIRONMENT=\"${3:-production}\"\n\n# Validate template\necho \"Validating CloudFormation template...\"\naws cloudformation validate-template \\\n    --template-body file://$TEMPLATE_FILE\n\n# Deploy stack\necho \"Deploying CloudFormation stack: $STACK_NAME\"\naws cloudformation deploy \\\n    --template-file $TEMPLATE_FILE \\\n    --stack-name $STACK_NAME \\\n    --parameter-overrides \\\n        Environment=$ENVIRONMENT \\\n        InstanceType=t3.micro \\\n        KeyName=<KEY_NAME> \\\n    --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \\\n    --tags \\\n        Environment=$ENVIRONMENT \\\n        Project=Infrastructure \\\n        ManagedBy=CloudFormation\n\n# Wait for deployment to complete\necho \"Waiting for stack deployment to complete...\"\naws cloudformation wait stack-deploy-complete \\\n    --stack-name $STACK_NAME\n\n# Get stack outputs\necho \"Stack deployment completed. Outputs:\"\naws cloudformation describe-stacks \\\n    --stack-name $STACK_NAME \\\n    --query 'Stacks[0].Outputs[].{Key:OutputKey,Value:OutputValue,Description:Description}' \\\n    --output table\n\necho \"Stack $STACK_NAME deployed successfully\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "cloudformation", "pattern": "stack_deployment", "category": "aws_operations"}}
{"prompt": "Write a shell script to monitor cloudformation stack status using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Monitor CloudFormation stack status\n\nset -euo pipefail\n\necho \"Configuring cloudformation stack_monitoring...\"\naws cloudformation help\n\necho \"Monitor CloudFormation stack status completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "cloudformation", "pattern": "stack_monitoring", "category": "aws_operations"}}
{"prompt": "Write a shell script to deploy to multiple aws regions using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Deploy to multiple AWS regions\n\nset -euo pipefail\n\necho \"Configuring cloudformation multi_region_deploy...\"\naws cloudformation help\n\necho \"Deploy to multiple AWS regions completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "cloudformation", "pattern": "multi_region_deploy", "category": "aws_operations"}}
{"prompt": "Write a shell script to implement stack rollback on failure using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Implement stack rollback on failure\n\nset -euo pipefail\n\necho \"Configuring cloudformation rollback_strategy...\"\naws cloudformation help\n\necho \"Implement stack rollback on failure completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "cloudformation", "pattern": "rollback_strategy", "category": "aws_operations"}}
{"prompt": "Write a shell script to deploy nested cloudformation stacks using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Deploy nested CloudFormation stacks\n\nset -euo pipefail\n\necho \"Configuring cloudformation nested_stacks...\"\naws cloudformation help\n\necho \"Deploy nested CloudFormation stacks completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "cloudformation", "pattern": "nested_stacks", "category": "aws_operations"}}
{"prompt": "Write a shell script to deploy lambda function with dependencies using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Deploy Lambda function with dependencies\n\nset -euo pipefail\n\nFUNCTION_NAME=\"${1:-<FUNCTION_NAME>}\"\nRUNTIME=\"${2:-python3.9}\"\nHANDLER=\"${3:-lambda_function.lambda_handler}\"\n\n# Create deployment package\necho \"Creating deployment package...\"\nrm -f function.zip\nzip -r function.zip . -x \"*.git*\" \"*.DS_Store*\" \"__pycache__/*\"\n\n# Create IAM role for Lambda\nROLE_NAME=\"${FUNCTION_NAME}-execution-role\"\nASSUME_ROLE_POLICY=$(cat <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"lambda.amazonaws.com\"\n            },\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\nEOF\n)\n\n# Create role\naws iam create-role \\\n    --role-name $ROLE_NAME \\\n    --assume-role-policy-document \"$ASSUME_ROLE_POLICY\" || true\n\n# Attach basic execution policy\naws iam attach-role-policy \\\n    --role-name $ROLE_NAME \\\n    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n\n# Wait for role propagation\nsleep 10\n\n# Get account ID for role ARN\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nROLE_ARN=\"arn:aws:iam::${ACCOUNT_ID}:role/${ROLE_NAME}\"\n\n# Create or update function\nif aws lambda get-function --function-name $FUNCTION_NAME >/dev/null 2>&1; then\n    echo \"Updating existing Lambda function...\"\n    aws lambda update-function-code \\\n        --function-name $FUNCTION_NAME \\\n        --zip-file fileb://function.zip\nelse\n    echo \"Creating new Lambda function...\"\n    aws lambda create-function \\\n        --function-name $FUNCTION_NAME \\\n        --runtime $RUNTIME \\\n        --role $ROLE_ARN \\\n        --handler $HANDLER \\\n        --zip-file fileb://function.zip \\\n        --timeout 30 \\\n        --memory-size 256 \\\n        --environment Variables='{ENV=production}' \\\n        --tags Environment=production,Project=Lambda\nfi\n\necho \"Lambda function $FUNCTION_NAME deployed successfully\"\nrm function.zip\n```", "metadata": {"source": "generated_aws_pattern", "service": "lambda", "pattern": "function_deployment", "category": "aws_operations"}}
{"prompt": "Write a shell script to connect lambda to api gateway using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Connect Lambda to API Gateway\n\nset -euo pipefail\n\necho \"Configuring lambda api_gateway_integration...\"\naws lambda help\n\necho \"Connect Lambda to API Gateway completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "lambda", "pattern": "api_gateway_integration", "category": "aws_operations"}}
{"prompt": "Write a shell script to setup event-driven lambda processing using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Setup event-driven Lambda processing\n\nset -euo pipefail\n\necho \"Configuring lambda event_driven_processing...\"\naws lambda help\n\necho \"Setup event-driven Lambda processing completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "lambda", "pattern": "event_driven_processing", "category": "aws_operations"}}
{"prompt": "Write a shell script to deploy scheduled lambda functions using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Deploy scheduled Lambda functions\n\nset -euo pipefail\n\necho \"Configuring lambda scheduled_functions...\"\naws lambda help\n\necho \"Deploy scheduled Lambda functions completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "lambda", "pattern": "scheduled_functions", "category": "aws_operations"}}
{"prompt": "Write a shell script to manage lambda layers and dependencies using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Manage Lambda layers and dependencies\n\nset -euo pipefail\n\necho \"Configuring lambda layer_management...\"\naws lambda help\n\necho \"Manage Lambda layers and dependencies completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "lambda", "pattern": "layer_management", "category": "aws_operations"}}
{"prompt": "Write a shell script to create rds database with backup using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Create RDS database with backup\n\nset -euo pipefail\n\necho \"Configuring rds database_setup...\"\naws rds help\n\necho \"Create RDS database with backup completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "rds", "pattern": "database_setup", "category": "aws_operations"}}
{"prompt": "Write a shell script to setup rds read replicas using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Setup RDS read replicas\n\nset -euo pipefail\n\necho \"Configuring rds read_replica...\"\naws rds help\n\necho \"Setup RDS read replicas completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "rds", "pattern": "read_replica", "category": "aws_operations"}}
{"prompt": "Write a shell script to configure rds parameter groups using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Configure RDS parameter groups\n\nset -euo pipefail\n\necho \"Configuring rds parameter_groups...\"\naws rds help\n\necho \"Configure RDS parameter groups completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "rds", "pattern": "parameter_groups", "category": "aws_operations"}}
{"prompt": "Write a shell script to automated rds snapshot management using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Automated RDS snapshot management\n\nset -euo pipefail\n\necho \"Configuring rds snapshot_automation...\"\naws rds help\n\necho \"Automated RDS snapshot management completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "rds", "pattern": "snapshot_automation", "category": "aws_operations"}}
{"prompt": "Write a shell script to deploy rds with multi-az configuration using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Deploy RDS with Multi-AZ configuration\n\nset -euo pipefail\n\necho \"Configuring rds multi_az_deployment...\"\naws rds help\n\necho \"Deploy RDS with Multi-AZ configuration completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "rds", "pattern": "multi_az_deployment", "category": "aws_operations"}}
{"prompt": "Write a shell script to create ecs cluster with auto scaling using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Create ECS cluster with auto scaling\n\nset -euo pipefail\n\necho \"Configuring ecs cluster_setup...\"\naws ecs help\n\necho \"Create ECS cluster with auto scaling completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ecs", "pattern": "cluster_setup", "category": "aws_operations"}}
{"prompt": "Write a shell script to deploy containerized service to ecs using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Deploy containerized service to ECS\n\nset -euo pipefail\n\necho \"Configuring ecs service_deployment...\"\naws ecs help\n\necho \"Deploy containerized service to ECS completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ecs", "pattern": "service_deployment", "category": "aws_operations"}}
{"prompt": "Write a shell script to create and update ecs task definitions using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Create and update ECS task definitions\n\nset -euo pipefail\n\necho \"Configuring ecs task_definition...\"\naws ecs help\n\necho \"Create and update ECS task definitions completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ecs", "pattern": "task_definition", "category": "aws_operations"}}
{"prompt": "Write a shell script to integrate ecs with load balancer using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Integrate ECS with load balancer\n\nset -euo pipefail\n\necho \"Configuring ecs load_balancer_integration...\"\naws ecs help\n\necho \"Integrate ECS with load balancer completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ecs", "pattern": "load_balancer_integration", "category": "aws_operations"}}
{"prompt": "Write a shell script to implement blue-green deployment with ecs using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Implement blue-green deployment with ECS\n\nset -euo pipefail\n\necho \"Configuring ecs blue_green_deployment...\"\naws ecs help\n\necho \"Implement blue-green deployment with ECS completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "ecs", "pattern": "blue_green_deployment", "category": "aws_operations"}}
{"prompt": "Write a shell script to create eks cluster with node groups using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Create EKS cluster with node groups\n\nset -euo pipefail\n\necho \"Configuring eks cluster_creation...\"\naws eks help\n\necho \"Create EKS cluster with node groups completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "eks", "pattern": "cluster_creation", "category": "aws_operations"}}
{"prompt": "Write a shell script to install eks add-ons and controllers using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Install EKS add-ons and controllers\n\nset -euo pipefail\n\necho \"Configuring eks addon_installation...\"\naws eks help\n\necho \"Install EKS add-ons and controllers completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "eks", "pattern": "addon_installation", "category": "aws_operations"}}
{"prompt": "Write a shell script to deploy applications to eks cluster using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Deploy applications to EKS cluster\n\nset -euo pipefail\n\necho \"Configuring eks workload_deployment...\"\naws eks help\n\necho \"Deploy applications to EKS cluster completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "eks", "pattern": "workload_deployment", "category": "aws_operations"}}
{"prompt": "Write a shell script to setup ingress controller on eks using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Setup ingress controller on EKS\n\nset -euo pipefail\n\necho \"Configuring eks ingress_setup...\"\naws eks help\n\necho \"Setup ingress controller on EKS completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "eks", "pattern": "ingress_setup", "category": "aws_operations"}}
{"prompt": "Write a shell script to integrate monitoring with eks cluster using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Integrate monitoring with EKS cluster\n\nset -euo pipefail\n\necho \"Configuring eks monitoring_integration...\"\naws eks help\n\necho \"Integrate monitoring with EKS cluster completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "eks", "pattern": "monitoring_integration", "category": "aws_operations"}}
{"prompt": "Write a shell script to create vpc with subnets and route tables using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Create VPC with subnets and route tables\n\nset -euo pipefail\n\necho \"Configuring vpc network_setup...\"\naws vpc help\n\necho \"Create VPC with subnets and route tables completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "vpc", "pattern": "network_setup", "category": "aws_operations"}}
{"prompt": "Write a shell script to setup vpc peering connections using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Setup VPC peering connections\n\nset -euo pipefail\n\necho \"Configuring vpc peering_connection...\"\naws vpc help\n\necho \"Setup VPC peering connections completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "vpc", "pattern": "peering_connection", "category": "aws_operations"}}
{"prompt": "Write a shell script to configure nat gateway for private subnets using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Configure NAT Gateway for private subnets\n\nset -euo pipefail\n\necho \"Configuring vpc nat_gateway...\"\naws vpc help\n\necho \"Configure NAT Gateway for private subnets completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "vpc", "pattern": "nat_gateway", "category": "aws_operations"}}
{"prompt": "Write a shell script to establish vpn connection to on-premises using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Establish VPN connection to on-premises\n\nset -euo pipefail\n\necho \"Configuring vpc vpn_connection...\"\naws vpc help\n\necho \"Establish VPN connection to on-premises completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "vpc", "pattern": "vpn_connection", "category": "aws_operations"}}
{"prompt": "Write a shell script to setup aws transit gateway using AWS CLI", "completion": "```bash\n#!/bin/bash\n# Setup AWS Transit Gateway\n\nset -euo pipefail\n\necho \"Configuring vpc transit_gateway...\"\naws vpc help\n\necho \"Setup AWS Transit Gateway completed\"\n```", "metadata": {"source": "generated_aws_pattern", "service": "vpc", "pattern": "transit_gateway", "category": "aws_operations"}}
{"prompt": "Create a shell script to initialize terraform and create execution plan using Terraform", "completion": "```bash\n#!/bin/bash\n# Initialize Terraform and create execution plan\n\nset -euo pipefail\n\nENVIRONMENT=\"${1:-development}\"\nTF_VAR_FILE=\"${2:-terraform.tfvars}\"\n\necho \"Initializing Terraform for environment: $ENVIRONMENT\"\n\n# Initialize Terraform\nterraform init -backend-config=\"key=$ENVIRONMENT/terraform.tfstate\"\n\n# Validate configuration\nterraform validate\n\n# Format code\nterraform fmt -recursive\n\n# Create plan\nterraform plan \\\n    -var-file=\"$TF_VAR_FILE\" \\\n    -var=\"environment=$ENVIRONMENT\" \\\n    -out=\"$ENVIRONMENT.tfplan\"\n\necho \"Terraform plan created: $ENVIRONMENT.tfplan\"\necho \"Review the plan and run: terraform apply $ENVIRONMENT.tfplan\"\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "init_and_plan", "category": "infrastructure"}}
{"prompt": "Create a shell script to apply terraform configuration with approval workflow using Terraform", "completion": "```bash\n#!/bin/bash\n# Apply Terraform configuration with approval workflow\n\nset -euo pipefail\n\nPLAN_FILE=\"${1:-terraform.tfplan}\"\nENVIRONMENT=\"${2:-development}\"\n\nif [ ! -f \"$PLAN_FILE\" ]; then\n    echo \"Error: Plan file $PLAN_FILE not found\"\n    echo \"Run terraform plan first\"\n    exit 1\nfi\n\n# Show plan summary\necho \"Terraform plan summary for $ENVIRONMENT:\"\nterraform show -no-color \"$PLAN_FILE\" | head -50\n\necho\necho \"This will apply the above changes to $ENVIRONMENT environment.\"\nread -p \"Do you want to continue? (yes/no): \" -r\necho\n\nif [[ $REPLY =~ ^[Yy][Ee][Ss]$ ]]; then\n    echo \"Applying Terraform plan...\"\n    \n    # Apply with automatic approval\n    terraform apply \"$PLAN_FILE\"\n    \n    # Save outputs\n    terraform output -json > \"outputs-$ENVIRONMENT.json\"\n    \n    echo \"Terraform apply completed successfully\"\n    echo \"Outputs saved to: outputs-$ENVIRONMENT.json\"\nelse\n    echo \"Terraform apply cancelled\"\n    exit 1\nfi\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "apply_with_approval", "category": "infrastructure"}}
{"prompt": "Create a shell script to destroy terraform infrastructure with confirmation using Terraform", "completion": "```bash\n#!/bin/bash\n# Destroy Terraform infrastructure with confirmation\n\nset -euo pipefail\n\necho \"Terraform destroy_with_confirmation operation\"\nterraform --version\n\necho \"Destroy Terraform infrastructure with confirmation completed\"\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "destroy_with_confirmation", "category": "infrastructure"}}
{"prompt": "Create a shell script to manage terraform workspaces for different environments using Terraform", "completion": "```bash\n#!/bin/bash\n# Manage Terraform workspaces for different environments\n\nset -euo pipefail\n\nACTION=\"${1:-list}\"\nWORKSPACE=\"${2:-}\"\n\ncase $ACTION in\n    \"list\")\n        echo \"Available Terraform workspaces:\"\n        terraform workspace list\n        ;;\n    \"create\")\n        if [ -z \"$WORKSPACE\" ]; then\n            echo \"Error: Workspace name required for create action\"\n            exit 1\n        fi\n        echo \"Creating workspace: $WORKSPACE\"\n        terraform workspace new \"$WORKSPACE\"\n        ;;\n    \"select\")\n        if [ -z \"$WORKSPACE\" ]; then\n            echo \"Error: Workspace name required for select action\"\n            exit 1\n        fi\n        echo \"Selecting workspace: $WORKSPACE\"\n        terraform workspace select \"$WORKSPACE\"\n        ;;\n    \"delete\")\n        if [ -z \"$WORKSPACE\" ]; then\n            echo \"Error: Workspace name required for delete action\"\n            exit 1\n        fi\n        echo \"Deleting workspace: $WORKSPACE\"\n        terraform workspace select default\n        terraform workspace delete \"$WORKSPACE\"\n        ;;\n    \"show\")\n        echo \"Current workspace: $(terraform workspace show)\"\n        ;;\n    *)\n        echo \"Usage: $0 {list|create|select|delete|show} [workspace_name]\"\n        exit 1\n        ;;\nesac\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "workspace_management", "category": "infrastructure"}}
{"prompt": "Create a shell script to backup and manage terraform state files using Terraform", "completion": "```bash\n#!/bin/bash\n# Backup and manage Terraform state files\n\nset -euo pipefail\n\necho \"Terraform state_management operation\"\nterraform --version\n\necho \"Backup and manage Terraform state files completed\"\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "state_management", "category": "infrastructure"}}
{"prompt": "Create a shell script to validate terraform modules and configurations using Terraform", "completion": "```bash\n#!/bin/bash\n# Validate Terraform modules and configurations\n\nset -euo pipefail\n\necho \"Terraform module_validation operation\"\nterraform --version\n\necho \"Validate Terraform modules and configurations completed\"\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "module_validation", "category": "infrastructure"}}
{"prompt": "Create a shell script to deploy to multiple environments with terraform using Terraform", "completion": "```bash\n#!/bin/bash\n# Deploy to multiple environments with Terraform\n\nset -euo pipefail\n\necho \"Terraform multi_environment_deploy operation\"\nterraform --version\n\necho \"Deploy to multiple environments with Terraform completed\"\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "multi_environment_deploy", "category": "infrastructure"}}
{"prompt": "Create a shell script to detect and report infrastructure drift using Terraform", "completion": "```bash\n#!/bin/bash\n# Detect and report infrastructure drift\n\nset -euo pipefail\n\necho \"Terraform drift_detection operation\"\nterraform --version\n\necho \"Detect and report infrastructure drift completed\"\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "drift_detection", "category": "infrastructure"}}
{"prompt": "Create a shell script to generate cost estimates for terraform changes using Terraform", "completion": "```bash\n#!/bin/bash\n# Generate cost estimates for Terraform changes\n\nset -euo pipefail\n\necho \"Terraform cost_estimation operation\"\nterraform --version\n\necho \"Generate cost estimates for Terraform changes completed\"\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "cost_estimation", "category": "infrastructure"}}
{"prompt": "Create a shell script to generate documentation from terraform code using Terraform", "completion": "```bash\n#!/bin/bash\n# Generate documentation from Terraform code\n\nset -euo pipefail\n\necho \"Terraform documentation_generation operation\"\nterraform --version\n\necho \"Generate documentation from Terraform code completed\"\n```", "metadata": {"source": "generated_terraform_pattern", "pattern": "documentation_generation", "category": "infrastructure"}}
{"prompt": "Create a shell script to setup kubernetes cluster with essential components in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Setup Kubernetes cluster with essential components\n\nset -euo pipefail\n\nCLUSTER_NAME=\"${1:-<CLUSTER_NAME>}\"\nNODE_COUNT=\"${2:-3}\"\n\necho \"Setting up Kubernetes cluster: $CLUSTER_NAME\"\n\n# Create cluster (example for kind/minikube)\nkind create cluster --name \"$CLUSTER_NAME\" --config - <<EOF\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n  kubeadmConfigPatches:\n  - |\n    kind: InitConfiguration\n    nodeRegistration:\n      kubeletExtraArgs:\n        node-labels: \"ingress-ready=true\"\n  extraPortMappings:\n  - containerPort: 80\n    hostPort: 80\n    protocol: TCP\n  - containerPort: 443\n    hostPort: 443\n    protocol: TCP\n$(for i in $(seq 1 $((NODE_COUNT-1))); do echo \"- role: worker\"; done)\nEOF\n\n# Wait for cluster to be ready\nkubectl wait --for=condition=Ready nodes --all --timeout=300s\n\n# Install essential components\necho \"Installing essential cluster components...\"\n\n# Install metrics server\nkubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n\n# Install ingress controller\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml\n\n# Wait for ingress controller\nkubectl wait --namespace ingress-nginx \\\n  --for=condition=ready pod \\\n  --selector=app.kubernetes.io/component=controller \\\n  --timeout=90s\n\necho \"Kubernetes cluster $CLUSTER_NAME setup completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "cluster_setup", "category": "orchestration"}}
{"prompt": "Create a shell script to deploy application with rolling updates in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Deploy application with rolling updates\n\nset -euo pipefail\n\nAPP_NAME=\"${1:-<APP_NAME>}\"\nIMAGE=\"${2:-nginx:latest}\"\nREPLICAS=\"${3:-3}\"\nNAMESPACE=\"${4:-default}\"\n\necho \"Deploying application: $APP_NAME\"\n\n# Create namespace if it doesn't exist\nkubectl create namespace \"$NAMESPACE\" --dry-run=client -o yaml | kubectl apply -f -\n\n# Create deployment\nkubectl create deployment \"$APP_NAME\" \\\n    --image=\"$IMAGE\" \\\n    --replicas=\"$REPLICAS\" \\\n    --namespace=\"$NAMESPACE\" \\\n    --dry-run=client -o yaml | kubectl apply -f -\n\n# Configure rolling update strategy\nkubectl patch deployment \"$APP_NAME\" -n \"$NAMESPACE\" -p '{\n    \"spec\": {\n        \"strategy\": {\n            \"type\": \"RollingUpdate\",\n            \"rollingUpdate\": {\n                \"maxUnavailable\": \"25%\",\n                \"maxSurge\": \"25%\"\n            }\n        }\n    }\n}'\n\n# Expose as service\nkubectl expose deployment \"$APP_NAME\" \\\n    --port=80 \\\n    --target-port=80 \\\n    --type=ClusterIP \\\n    --namespace=\"$NAMESPACE\"\n\n# Create ingress\ncat <<EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: $APP_NAME-ingress\n  namespace: $NAMESPACE\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: $APP_NAME.local\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: $APP_NAME\n            port:\n              number: 80\nEOF\n\n# Wait for deployment\nkubectl rollout status deployment \"$APP_NAME\" -n \"$NAMESPACE\"\n\necho \"Application $APP_NAME deployed successfully\"\necho \"Access via: http://$APP_NAME.local\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "application_deployment", "category": "orchestration"}}
{"prompt": "Create a shell script to configure ingress controller and tls in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Configure ingress controller and TLS\n\nset -euo pipefail\n\necho \"Kubernetes ingress_configuration operation\"\nkubectl version --client\n\necho \"Configure ingress controller and TLS completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "ingress_configuration", "category": "orchestration"}}
{"prompt": "Create a shell script to deploy monitoring with prometheus and grafana in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Deploy monitoring with Prometheus and Grafana\n\nset -euo pipefail\n\necho \"Kubernetes monitoring_stack operation\"\nkubectl version --client\n\necho \"Deploy monitoring with Prometheus and Grafana completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "monitoring_stack", "category": "orchestration"}}
{"prompt": "Create a shell script to manage secrets and configmaps in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Manage secrets and ConfigMaps\n\nset -euo pipefail\n\necho \"Kubernetes secret_management operation\"\nkubectl version --client\n\necho \"Manage secrets and ConfigMaps completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "secret_management", "category": "orchestration"}}
{"prompt": "Create a shell script to automate cluster backup and restore in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Automate cluster backup and restore\n\nset -euo pipefail\n\necho \"Kubernetes backup_automation operation\"\nkubectl version --client\n\necho \"Automate cluster backup and restore completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "backup_automation", "category": "orchestration"}}
{"prompt": "Create a shell script to implement network security policies in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Implement network security policies\n\nset -euo pipefail\n\necho \"Kubernetes network_policies operation\"\nkubectl version --client\n\necho \"Implement network security policies completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "network_policies", "category": "orchestration"}}
{"prompt": "Create a shell script to configure role-based access control in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Configure Role-Based Access Control\n\nset -euo pipefail\n\necho \"Kubernetes rbac_configuration operation\"\nkubectl version --client\n\necho \"Configure Role-Based Access Control completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "rbac_configuration", "category": "orchestration"}}
{"prompt": "Create a shell script to setup persistent storage with storageclasses in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Setup persistent storage with StorageClasses\n\nset -euo pipefail\n\necho \"Kubernetes persistent_storage operation\"\nkubectl version --client\n\necho \"Setup persistent storage with StorageClasses completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "persistent_storage", "category": "orchestration"}}
{"prompt": "Create a shell script to deploy and configure service mesh in Kubernetes", "completion": "```bash\n#!/bin/bash\n# Deploy and configure service mesh\n\nset -euo pipefail\n\necho \"Kubernetes service_mesh_deployment operation\"\nkubectl version --client\n\necho \"Deploy and configure service mesh completed\"\n```", "metadata": {"source": "generated_k8s_pattern", "pattern": "service_mesh_deployment", "category": "orchestration"}}
{"prompt": "Write a shell script to create optimized multi-stage docker build with Docker", "completion": "```bash\n#!/bin/bash\n# Create optimized multi-stage Docker build\n\nset -euo pipefail\n\necho \"Docker multi_stage_build automation\"\ndocker --version\n\n# Implementation would go here\necho \"Create optimized multi-stage Docker build completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "multi_stage_build", "category": "containerization"}}
{"prompt": "Write a shell script to orchestrate multiple containers with docker compose with Docker", "completion": "```bash\n#!/bin/bash\n# Orchestrate multiple containers with Docker Compose\n\nset -euo pipefail\n\necho \"Docker container_orchestration automation\"\ndocker --version\n\n# Implementation would go here\necho \"Orchestrate multiple containers with Docker Compose completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "container_orchestration", "category": "containerization"}}
{"prompt": "Write a shell script to security scan docker images before deployment with Docker", "completion": "```bash\n#!/bin/bash\n# Security scan Docker images before deployment\n\nset -euo pipefail\n\necho \"Docker image_security_scan automation\"\ndocker --version\n\n# Implementation would go here\necho \"Security scan Docker images before deployment completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "image_security_scan", "category": "containerization"}}
{"prompt": "Write a shell script to push and manage images in docker registry with Docker", "completion": "```bash\n#!/bin/bash\n# Push and manage images in Docker registry\n\nset -euo pipefail\n\necho \"Docker registry_management automation\"\ndocker --version\n\n# Implementation would go here\necho \"Push and manage images in Docker registry completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "registry_management", "category": "containerization"}}
{"prompt": "Write a shell script to monitor container health and performance with Docker", "completion": "```bash\n#!/bin/bash\n# Monitor container health and performance\n\nset -euo pipefail\n\necho \"Docker container_monitoring automation\"\ndocker --version\n\n# Implementation would go here\necho \"Monitor container health and performance completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "container_monitoring", "category": "containerization"}}
{"prompt": "Write a shell script to backup and restore docker volumes with Docker", "completion": "```bash\n#!/bin/bash\n# Backup and restore Docker volumes\n\nset -euo pipefail\n\necho \"Docker backup_volumes automation\"\ndocker --version\n\n# Implementation would go here\necho \"Backup and restore Docker volumes completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "backup_volumes", "category": "containerization"}}
{"prompt": "Write a shell script to configure docker networks and connectivity with Docker", "completion": "```bash\n#!/bin/bash\n# Configure Docker networks and connectivity\n\nset -euo pipefail\n\necho \"Docker network_configuration automation\"\ndocker --version\n\n# Implementation would go here\necho \"Configure Docker networks and connectivity completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "network_configuration", "category": "containerization"}}
{"prompt": "Write a shell script to set container resource limits and constraints with Docker", "completion": "```bash\n#!/bin/bash\n# Set container resource limits and constraints\n\nset -euo pipefail\n\necho \"Docker resource_limits automation\"\ndocker --version\n\n# Implementation would go here\necho \"Set container resource limits and constraints completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "resource_limits", "category": "containerization"}}
{"prompt": "Write a shell script to aggregate and manage container logs with Docker", "completion": "```bash\n#!/bin/bash\n# Aggregate and manage container logs\n\nset -euo pipefail\n\necho \"Docker log_aggregation automation\"\ndocker --version\n\n# Implementation would go here\necho \"Aggregate and manage container logs completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "log_aggregation", "category": "containerization"}}
{"prompt": "Write a shell script to setup consistent development environment with Docker", "completion": "```bash\n#!/bin/bash\n# Setup consistent development environment\n\nset -euo pipefail\n\necho \"Docker development_environment automation\"\ndocker --version\n\n# Implementation would go here\necho \"Setup consistent development environment completed successfully\"\n```", "metadata": {"source": "generated_docker_pattern", "pattern": "development_environment", "category": "containerization"}}
{"prompt": "Create a shell script to setup prometheus monitoring stack", "completion": "```bash\n#!/bin/bash\n# Setup Prometheus monitoring stack\n\nset -euo pipefail\n\necho \"Setting up prometheus_setup\"\n\n# Implementation would be here\necho \"Setup Prometheus monitoring stack setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "prometheus_setup", "category": "monitoring"}}
{"prompt": "Create a shell script to configure grafana dashboards and alerts", "completion": "```bash\n#!/bin/bash\n# Configure Grafana dashboards and alerts\n\nset -euo pipefail\n\necho \"Setting up grafana_dashboards\"\n\n# Implementation would be here\necho \"Configure Grafana dashboards and alerts setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "grafana_dashboards", "category": "monitoring"}}
{"prompt": "Create a shell script to setup centralized log aggregation", "completion": "```bash\n#!/bin/bash\n# Setup centralized log aggregation\n\nset -euo pipefail\n\necho \"Setting up log_aggregation\"\n\n# Implementation would be here\necho \"Setup centralized log aggregation setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "log_aggregation", "category": "monitoring"}}
{"prompt": "Create a shell script to collect custom application metrics", "completion": "```bash\n#!/bin/bash\n# Collect custom application metrics\n\nset -euo pipefail\n\necho \"Setting up metrics_collection\"\n\n# Implementation would be here\necho \"Collect custom application metrics setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "metrics_collection", "category": "monitoring"}}
{"prompt": "Create a shell script to configure alerting rules and notifications", "completion": "```bash\n#!/bin/bash\n# Configure alerting rules and notifications\n\nset -euo pipefail\n\necho \"Setting up alert_management\"\n\n# Implementation would be here\necho \"Configure alerting rules and notifications setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "alert_management", "category": "monitoring"}}
{"prompt": "Create a shell script to monitor system and application performance", "completion": "```bash\n#!/bin/bash\n# Monitor system and application performance\n\nset -euo pipefail\n\necho \"Setting up performance_monitoring\"\n\n# Implementation would be here\necho \"Monitor system and application performance setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "performance_monitoring", "category": "monitoring"}}
{"prompt": "Create a shell script to implement comprehensive health checks", "completion": "```bash\n#!/bin/bash\n# Implement comprehensive health checks\n\nset -euo pipefail\n\necho \"Setting up health_checks\"\n\n# Implementation would be here\necho \"Implement comprehensive health checks setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "health_checks", "category": "monitoring"}}
{"prompt": "Create a shell script to setup uptime and availability monitoring", "completion": "```bash\n#!/bin/bash\n# Setup uptime and availability monitoring\n\nset -euo pipefail\n\necho \"Setting up uptime_monitoring\"\n\n# Implementation would be here\necho \"Setup uptime and availability monitoring setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "uptime_monitoring", "category": "monitoring"}}
{"prompt": "Create a shell script to monitor cloud infrastructure costs", "completion": "```bash\n#!/bin/bash\n# Monitor cloud infrastructure costs\n\nset -euo pipefail\n\necho \"Setting up cost_monitoring\"\n\n# Implementation would be here\necho \"Monitor cloud infrastructure costs setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "cost_monitoring", "category": "monitoring"}}
{"prompt": "Create a shell script to implement security monitoring and siem", "completion": "```bash\n#!/bin/bash\n# Implement security monitoring and SIEM\n\nset -euo pipefail\n\necho \"Setting up security_monitoring\"\n\n# Implementation would be here\necho \"Implement security monitoring and SIEM setup completed\"\n```", "metadata": {"source": "generated_monitoring_pattern", "pattern": "security_monitoring", "category": "monitoring"}}
{"prompt": "Write a shell script to setup gitlab ci/cd pipeline", "completion": "```bash\n#!/bin/bash\n# Setup GitLab CI/CD pipeline\n\nset -euo pipefail\n\necho \"Configuring gitlab_pipeline\"\n\n# Implementation would be here\necho \"Setup GitLab CI/CD pipeline configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "gitlab_pipeline", "category": "deployment"}}
{"prompt": "Write a shell script to configure github actions workflow", "completion": "```bash\n#!/bin/bash\n# Configure GitHub Actions workflow\n\nset -euo pipefail\n\necho \"Configuring github_actions\"\n\n# Implementation would be here\necho \"Configure GitHub Actions workflow configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "github_actions", "category": "deployment"}}
{"prompt": "Write a shell script to create jenkins pipeline script", "completion": "```bash\n#!/bin/bash\n# Create Jenkins pipeline script\n\nset -euo pipefail\n\necho \"Configuring jenkins_pipeline\"\n\n# Implementation would be here\necho \"Create Jenkins pipeline script configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "jenkins_pipeline", "category": "deployment"}}
{"prompt": "Write a shell script to setup automated testing pipeline", "completion": "```bash\n#!/bin/bash\n# Setup automated testing pipeline\n\nset -euo pipefail\n\necho \"Configuring automated_testing\"\n\n# Implementation would be here\necho \"Setup automated testing pipeline configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "automated_testing", "category": "deployment"}}
{"prompt": "Write a shell script to automate application deployment", "completion": "```bash\n#!/bin/bash\n# Automate application deployment\n\nset -euo pipefail\n\necho \"Configuring deployment_automation\"\n\n# Implementation would be here\necho \"Automate application deployment configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "deployment_automation", "category": "deployment"}}
{"prompt": "Write a shell script to implement code quality gates", "completion": "```bash\n#!/bin/bash\n# Implement code quality gates\n\nset -euo pipefail\n\necho \"Configuring quality_gates\"\n\n# Implementation would be here\necho \"Implement code quality gates configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "quality_gates", "category": "deployment"}}
{"prompt": "Write a shell script to integrate security scanning in pipeline", "completion": "```bash\n#!/bin/bash\n# Integrate security scanning in pipeline\n\nset -euo pipefail\n\necho \"Configuring security_scanning\"\n\n# Implementation would be here\necho \"Integrate security scanning in pipeline configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "security_scanning", "category": "deployment"}}
{"prompt": "Write a shell script to manage build artifacts and dependencies", "completion": "```bash\n#!/bin/bash\n# Manage build artifacts and dependencies\n\nset -euo pipefail\n\necho \"Configuring artifact_management\"\n\n# Implementation would be here\necho \"Manage build artifacts and dependencies configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "artifact_management", "category": "deployment"}}
{"prompt": "Write a shell script to promote releases across environments", "completion": "```bash\n#!/bin/bash\n# Promote releases across environments\n\nset -euo pipefail\n\necho \"Configuring environment_promotion\"\n\n# Implementation would be here\necho \"Promote releases across environments configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "environment_promotion", "category": "deployment"}}
{"prompt": "Write a shell script to automate rollback procedures", "completion": "```bash\n#!/bin/bash\n# Automate rollback procedures\n\nset -euo pipefail\n\necho \"Configuring rollback_automation\"\n\n# Implementation would be here\necho \"Automate rollback procedures configuration completed\"\n```", "metadata": {"source": "generated_cicd_pattern", "pattern": "rollback_automation", "category": "deployment"}}
