{"prompt": "Create a shell script for application deployment", "completion": "```bash\n# Step 1: Create a directory for packaging and copy your Python script\nmkdir -p package_daily\ncp historical_weather_fetch.py package_daily/\n\n# Step 2: Install the 'requests' dependency along with a compatible version of urllib3 into the package directory.\n# This forces urllib3 to remain in the 1.x series (e.g., 1.26.x) which works with Python 3.8.\npip install requests \"urllib3<2\" -t package_daily/ --quiet\n\n# Step 3: Create the deployment package as a zip file\ncd package_daily\nzip -r ../historical_weather_fetch.zip .\ncd ..\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/core/weather/fix2.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# Deploy script for the Visual Crossing weather data fetching Lambda functions\n# Sets up S3 bucket and Lambda functions to fetch and store weather data for various cities\n# Deployment region: af-south-1 (Cape Town)\n\n# Exit on error\nset -e\n\n# Check if .env file exists and load it\nif [ -f .env ]; then\n    export $(grep -v '^#' .env | xargs)\n    echo \"Loaded environment variables from .env file\"\nelse\n    echo \"No .env file found. Make sure you have set the VISUALCROSSING_API_KEY environment variable.\"\nfi\n\n# Check if API key is set\nif [ -z \"$VISUALCROSSING_API_KEY\" ]; then\n    echo \"VISUALCROSSING_API_KEY environment variable is not set.\"\n    echo \"Please set it using 'export VISUALCROSSING_API_KEY=your_api_key_here'\"\n    exit 1\nfi\n\n# Configuration\nREGION=\"us-east-1\"\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nLAMBDA_ROLE_NAME=\"lambda-weather-execution-role\"\nS3_BUCKET=\"visualcrossing-city-database\"\nLAMBDA_RUNTIME=\"python3.9\"\nLAMBDA_MEMORY=256\nLAMBDA_TIMEOUT=120\nLAMBDA_DAILY_WEATHER_NAME=\"daily_weather_fetch\"\n\n# Check if virtual environment exists, if not create one\nif [ ! -d \"venv\" ]; then\n    echo \"Creating virtual environment...\"\n    python3 -m venv venv\nfi\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Install dependencies\necho \"Installing dependencies...\"\npip install boto3 requests\n\n# Create output directory for packages\nmkdir -p build\n\necho \"Creating S3 bucket if it doesn't exist...\"\nif ! aws s3api head-bucket --bucket $S3_BUCKET --region $REGION 2>/dev/null; then\n    echo \"Creating S3 bucket: $S3_BUCKET\"\n    aws s3api create-bucket \\\n        --bucket $S3_BUCKET \\\n        --region $REGION \\\n        --create-bucket-configuration LocationConstraint=$REGION\n\n    # Wait for bucket to be available\n    echo \"Waiting for bucket to become available...\"\n    sleep 5\nelse\n    echo \"S3 bucket already exists: $S3_BUCKET\"\nfi\n\n# Create IAM role for Lambda if it doesn't exist\necho \"Setting up IAM role for Lambda...\"\nif ! aws iam get-role --role-name $LAMBDA_ROLE_NAME 2>/dev/null; then\n    echo \"Creating IAM role: $LAMBDA_ROLE_NAME\"\n\n    # Create a trust policy document for Lambda\n    cat > /tmp/trust-policy.json << EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n    # Create the role\n    aws iam create-role \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --assume-role-policy-document file:///tmp/trust-policy.json\n\n    # Attach policies\n    echo \"Attaching policies to IAM role...\"\n\n    # Basic execution role for CloudWatch Logs\n    aws iam attach-role-policy \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n\n    # S3 access for storing weather data\n    aws iam attach-role-policy \\\n        --role-name $LAMBDA_ROLE_NAME \\\n        --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess\n\n    # Wait for role to be ready\n    echo \"Waiting for IAM role to be ready...\"\n    sleep 10\nelse\n    echo \"IAM role already exists: $LAMBDA_ROLE_NAME\"\nfi\n\n# Get the IAM role ARN\nLAMBDA_ROLE_ARN=\"arn:aws:iam::$ACCOUNT_ID:role/$LAMBDA_ROLE_NAME\"\necho \"Using IAM role ARN: $LAMBDA_ROLE_ARN\"\n\n# Deploy daily weather fetch Lambda\necho \"Deploying daily weather fetch Lambda...\"\n\n# Package the code\necho \"Packaging daily_weather_fetch.py...\"\nmkdir -p build/daily_weather\ncp daily_weather_fetch.py build/daily_weather/\ncd build/daily_weather\nzip -r ../daily_weather_function.zip .\ncd ../..\n\n# Check if the Lambda function exists\nif aws lambda get-function --function-name $LAMBDA_DAILY_WEATHER_NAME --region $REGION 2>/dev/null; then\n    echo \"Updating existing Lambda function: $LAMBDA_DAILY_WEATHER_NAME\"\n\n    # FIRST: Update the Lambda function configuration\n    echo \"Updating Lambda configuration...\"\n    aws lambda update-function-configuration \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --timeout $LAMBDA_TIMEOUT \\\n        --memory-size $LAMBDA_MEMORY \\\n        --environment \"Variables={VISUALCROSSING_API_KEY=$VISUALCROSSING_API_KEY,S3_BUCKET=$S3_BUCKET}\" \\\n        --region $REGION\n\n    # Wait for configuration update to complete\n    echo \"Waiting for configuration update to complete...\"\n    sleep 10\n\n    # Verify environment variables\n    CURRENT_ENV=$(aws lambda get-function --function-name $LAMBDA_DAILY_WEATHER_NAME --region $REGION --query 'Configuration.Environment.Variables' --output json)\n    echo \"Updated environment variables: $CURRENT_ENV\"\n\n    # SECOND: Update the Lambda function code\n    echo \"Updating Lambda code...\"\n    aws lambda update-function-code \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --zip-file fileb://build/daily_weather_function.zip \\\n        --region $REGION\nelse\n    echo \"Creating new Lambda function: $LAMBDA_DAILY_WEATHER_NAME\"\n\n    # Create the Lambda function\n    aws lambda create-function \\\n        --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n        --runtime $LAMBDA_RUNTIME \\\n        --role $LAMBDA_ROLE_ARN \\\n        --handler daily_weather_fetch.lambda_handler \\\n        --zip-file fileb://build/daily_weather_function.zip \\\n        --timeout $LAMBDA_TIMEOUT \\\n        --memory-size $LAMBDA_MEMORY \\\n        --environment \"Variables={VISUALCROSSING_API_KEY=$VISUALCROSSING_API_KEY,S3_BUCKET=$S3_BUCKET}\" \\\n        --region $REGION\nfi\n\n# Create or update EventBridge rule to trigger the Lambda daily at midnight UTC\nRULE_NAME=\"daily-weather-fetch-trigger\"\necho \"Setting up EventBridge rule: $RULE_NAME\"\n\naws events put-rule \\\n    --name $RULE_NAME \\\n    --schedule-expression \"cron(0 0 * * ? *)\" \\\n    --state ENABLED \\\n    --region $REGION\n\n# Add the daily weather Lambda as target\naws events put-targets \\\n    --rule $RULE_NAME \\\n    --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:$REGION:$ACCOUNT_ID:function:$LAMBDA_DAILY_WEATHER_NAME\" \\\n    --region $REGION\n\n# Add permission for EventBridge to invoke the Lambda\necho \"Adding permission for EventBridge to invoke Lambda...\"\naws lambda add-permission \\\n    --function-name $LAMBDA_DAILY_WEATHER_NAME \\\n    --statement-id \"AllowExecutionFromEventBridge\" \\\n    --action \"lambda:InvokeFunction\" \\\n    --principal \"events.amazonaws.com\" \\\n    --source-arn \"arn:aws:events:$REGION:$ACCOUNT_ID:rule/$RULE_NAME\" \\\n    --region $REGION || true  # Ignore error if permission already exists\n\necho \"Deployment completed successfully!\"\necho \"The daily weather fetch Lambda will run every day at midnight UTC.\"\necho \"Weather data will be stored in s3://$S3_BUCKET/<city_name>/daily/ directories.\"\necho \"Historical data: s3://$S3_BUCKET/<city_name>/daily/YYYY-MM-DD.json\"\necho \"Forecast data: s3://$S3_BUCKET/<city_name>/daily/forecast_YYYY-MM-DD.json\"\n\n# Deactivate virtual environment\ndeactivate\n\necho \"You can test the Lambda function by running:\"\necho \"aws lambda invoke --function-name $LAMBDA_DAILY_WEATHER_NAME --payload '{}' --region $REGION output.json\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/core/weather/deploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#!/bin/bash\n# setup-monitoring.sh\n# Sets up CloudWatch alarms for monitoring core API components\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region> [environment]\"\n    echo \"Example: $0 eu-south-1 production\"\n    exit 1\nfi\n\n# Set variables\nTARGET_REGION=\"$1\"\nENVIRONMENT=\"${2:-production}\"  # Default to production if not specified\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\nALARM_EMAIL=\"<EMAIL>\"  # Replace with actual alert email\n\n# Load region-specific configuration\nCONFIG_FILE=\"$SCRIPT_DIR/../config/$TARGET_REGION.env\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n    echo \"Error: Configuration file not found: $CONFIG_FILE\"\n    echo \"Please create a configuration file for this region first.\"\n    exit 1\nfi\n\nsource \"$CONFIG_FILE\"\n\n# Function to check if SNS topic exists\nget_sns_topic_arn() {\n    local topic_name=\"${REGION_PREFIX}-api-alarms\"\n    local topic_arn\n\n    topic_arn=$(aws sns list-topics --region \"$TARGET_REGION\" \\\n        --query \"Topics[?contains(TopicArn, '$topic_name')].TopicArn\" \\\n        --output text)\n\n    if [ -n \"$topic_arn\" ]; then\n        echo \"$topic_arn\"\n        return 0\n    else\n        return 1\n    fi\n}\n\n# Function to check if email is subscribed to SNS topic\nis_email_subscribed() {\n    local topic_arn=$1\n    local email=$2\n\n    aws sns list-subscriptions-by-topic --region \"$TARGET_REGION\" \\\n        --topic-arn \"$topic_arn\" \\\n        --query \"Subscriptions[?Protocol=='email' && Endpoint=='$email'].SubscriptionArn\" \\\n        --output text | grep -q .\n}\n\n# Create or get SNS topic for alarms\necho \"Setting up SNS topic for alarms...\"\nSNS_TOPIC_ARN=$(get_sns_topic_arn) || {\n    echo \"Creating new SNS topic...\"\n    SNS_TOPIC_ARN=$(aws sns create-topic \\\n        --region \"$TARGET_REGION\" \\\n        --name \"${REGION_PREFIX}-api-alarms\" \\\n        --query 'TopicArn' \\\n        --output text)\n}\n\n# Subscribe email to SNS topic if not already subscribed\nif ! is_email_subscribed \"$SNS_TOPIC_ARN\" \"$ALARM_EMAIL\"; then\n    echo \"Subscribing email to SNS topic...\"\n    aws sns subscribe \\\n        --region \"$TARGET_REGION\" \\\n        --topic-arn \"$SNS_TOPIC_ARN\" \\\n        --protocol email \\\n        --notification-endpoint \"$ALARM_EMAIL\"\nelse\n    echo \"Email already subscribed to SNS topic\"\nfi\n\n# Function to check if alarm exists\nalarm_exists() {\n    local alarm_name=$1\n    aws cloudwatch describe-alarms --region \"$TARGET_REGION\" \\\n        --alarm-names \"$alarm_name\" \\\n        --query 'MetricAlarms[0].AlarmName' \\\n        --output text | grep -q .\n}\n\n# Function to create or update Lambda alarms\ncreate_lambda_alarms() {\n    local function_name=$1\n    local threshold=$2\n\n    echo \"Setting up alarms for Lambda function: $function_name\"\n\n    # Error rate alarm\n    local error_alarm_name=\"${REGION_PREFIX}-${function_name}-errors\"\n    if ! alarm_exists \"$error_alarm_name\"; then\n        echo \"Creating error rate alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name has errors\" \\\n            --metric-name Errors \\\n            --namespace AWS/Lambda \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Error rate alarm already exists\"\n    fi\n\n    # Duration alarm\n    local duration_alarm_name=\"${REGION_PREFIX}-${function_name}-duration\"\n    if ! alarm_exists \"$duration_alarm_name\"; then\n        echo \"Creating duration alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$duration_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name duration exceeds threshold\" \\\n            --metric-name Duration \\\n            --namespace AWS/Lambda \\\n            --statistic Average \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold \"$threshold\" \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Duration alarm already exists\"\n    fi\n\n    # Throttles alarm\n    local throttle_alarm_name=\"${REGION_PREFIX}-${function_name}-throttles\"\n    if ! alarm_exists \"$throttle_alarm_name\"; then\n        echo \"Creating throttles alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$throttle_alarm_name\" \\\n            --alarm-description \"Alarm when Lambda function $function_name is throttled\" \\\n            --metric-name Throttles \\\n            --namespace AWS/Lambda \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=FunctionName,Value=\"$function_name\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Throttles alarm already exists\"\n    fi\n}\n\n# Function to create or update API Gateway alarms\ncreate_api_alarms() {\n    local api_id=$1\n    local api_name=$2\n\n    echo \"Setting up alarms for API Gateway: $api_name\"\n\n    # 4XX errors alarm\n    local error_4xx_alarm_name=\"${REGION_PREFIX}-${api_name}-4xx-errors\"\n    if ! alarm_exists \"$error_4xx_alarm_name\"; then\n        echo \"Creating 4XX errors alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_4xx_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name has 4XX errors\" \\\n            --metric-name 4XXError \\\n            --namespace AWS/ApiGateway \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 10 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"4XX errors alarm already exists\"\n    fi\n\n    # 5XX errors alarm\n    local error_5xx_alarm_name=\"${REGION_PREFIX}-${api_name}-5xx-errors\"\n    if ! alarm_exists \"$error_5xx_alarm_name\"; then\n        echo \"Creating 5XX errors alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$error_5xx_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name has 5XX errors\" \\\n            --metric-name 5XXError \\\n            --namespace AWS/ApiGateway \\\n            --statistic Sum \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"5XX errors alarm already exists\"\n    fi\n\n    # Latency alarm\n    local latency_alarm_name=\"${REGION_PREFIX}-${api_name}-latency\"\n    if ! alarm_exists \"$latency_alarm_name\"; then\n        echo \"Creating latency alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$latency_alarm_name\" \\\n            --alarm-description \"Alarm when API Gateway $api_name latency is high\" \\\n            --metric-name Latency \\\n            --namespace AWS/ApiGateway \\\n            --statistic Average \\\n            --period 300 \\\n            --evaluation-periods 2 \\\n            --threshold 1000 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=ApiId,Value=\"$api_id\" \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Latency alarm already exists\"\n    fi\n}\n\n# Function to create or update S3 bucket alarms\ncreate_s3_alarms() {\n    local bucket_name=$1\n\n    echo \"Setting up alarms for S3 bucket: $bucket_name\"\n\n    # Bucket size alarm\n    local size_alarm_name=\"${REGION_PREFIX}-${bucket_name}-size\"\n    if ! alarm_exists \"$size_alarm_name\"; then\n        echo \"Creating bucket size alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$size_alarm_name\" \\\n            --alarm-description \"Alarm when S3 bucket $bucket_name size is high\" \\\n            --metric-name BucketSizeBytes \\\n            --namespace AWS/S3 \\\n            --statistic Average \\\n            --period 86400 \\\n            --evaluation-periods 1 \\\n            --threshold 10737418240 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=BucketName,Value=\"$bucket_name\" Name=StorageType,Value=StandardStorage \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Bucket size alarm already exists\"\n    fi\n\n    # Number of objects alarm\n    local objects_alarm_name=\"${REGION_PREFIX}-${bucket_name}-objects\"\n    if ! alarm_exists \"$objects_alarm_name\"; then\n        echo \"Creating objects count alarm...\"\n        aws cloudwatch put-metric-alarm \\\n            --region \"$TARGET_REGION\" \\\n            --alarm-name \"$objects_alarm_name\" \\\n            --alarm-description \"Alarm when S3 bucket $bucket_name has too many objects\" \\\n            --metric-name NumberOfObjects \\\n            --namespace AWS/S3 \\\n            --statistic Average \\\n            --period 86400 \\\n            --evaluation-periods 1 \\\n            --threshold 1000000 \\\n            --comparison-operator GreaterThanThreshold \\\n            --dimensions Name=BucketName,Value=\"$bucket_name\" Name=StorageType,Value=AllStorageTypes \\\n            --alarm-actions \"$SNS_TOPIC_ARN\" \\\n            --ok-actions \"$SNS_TOPIC_ARN\"\n    else\n        echo \"Objects count alarm already exists\"\n    fi\n}\n\n# Create alarms for all Lambda functions\necho \"Setting up Lambda function alarms...\"\ncreate_lambda_alarms \"ingestHistoricalData\" 300000  # 5 minutes\ncreate_lambda_alarms \"ingestNowcastData\" 300000\ncreate_lambda_alarms \"trainForecaster\" 900000  # 15 minutes\ncreate_lambda_alarms \"generatePresignedUrl\" 30000  # 30 seconds\ncreate_lambda_alarms \"interpolateData\" 300000\ncreate_lambda_alarms \"generateForecast\" 300000\ncreate_lambda_alarms \"returnForecastingResults\" 300000\ncreate_lambda_alarms \"marketPriceForecast\" 300000\ncreate_lambda_alarms \"electricityDispatch\" 300000\ncreate_lambda_alarms \"weather\" 300000\n\n# Create alarms for all API Gateways\necho \"Setting up API Gateway alarms...\"\nAPIS=$(aws apigateway get-rest-apis --region \"$TARGET_REGION\" --query \"items[?contains(name, '${REGION_PREFIX}')].[id,name]\" --output text)\nwhile read -r API_ID API_NAME; do\n    create_api_alarms \"$API_ID\" \"$API_NAME\"\ndone <<< \"$APIS\"\n\n# Create alarms for all S3 buckets\necho \"Setting up S3 bucket alarms...\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-input\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-output\"\ncreate_s3_alarms \"${REGION_PREFIX}-api-client-facing\"\n\necho \"=============================================\"\necho \"CloudWatch alarms setup completed!\"\necho \"Alarm notifications will be sent to: $ALARM_EMAIL\"\necho \"=============================================\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/setup-monitoring.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Create a shell script for application deployment", "completion": "```bash\n#!/bin/bash\n\n# Automated Testing Framework Implementation\n# Location: /deploy/scripts/implement-testing.sh\n# Usage from repo root: deploy/scripts/implement-testing.sh [phase_number]\n# Usage from scripts dir: ./implement-testing.sh [phase_number]\n#\n# Examples:\n#   deploy/scripts/implement-testing.sh        # Run all phases\n#   deploy/scripts/implement-testing.sh 2      # Run only phase 2\n#   deploy/scripts/implement-testing.sh status # Check completion status\n\nset -e  # Exit on any error\n\n# Determine repo root from script location\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nREPO_ROOT=\"$(cd \"$SCRIPT_DIR/../..\" && pwd)\"\nLOG_FILE=\"$REPO_ROOT/testing-implementation.log\"\nVALIDATION_ERRORS=0\n\n# Change to repo root for all operations\ncd \"$REPO_ROOT\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\nlog() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nsuccess() {\n    echo -e \"${GREEN}✅ $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nwarning() {\n    echo -e \"${YELLOW}⚠️  $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nerror() {\n    echo -e \"${RED}❌ $1${NC}\" | tee -a \"$LOG_FILE\"\n    ((VALIDATION_ERRORS++))\n}\n\ninfo() {\n    echo -e \"${BLUE}ℹ️  $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nvalidate_environment() {\n    info \"Validating environment...\"\n    info \"Script location: $SCRIPT_DIR\"\n    info \"Repository root: $REPO_ROOT\"\n\n    # Check if we're in a git repo\n    if ! git rev-parse --git-dir > /dev/null 2>&1; then\n        error \"Not in a git repository\"\n        exit 1\n    fi\n\n    # Check for Python\n    if ! command -v python3 &> /dev/null; then\n        error \"Python3 not found\"\n        exit 1\n    fi\n\n    # Check for core directory\n    if [ ! -d \"$REPO_ROOT/core\" ]; then\n        error \"core/ directory not found in repository root: $REPO_ROOT\"\n        info \"Expected structure: $REPO_ROOT/core/\"\n        exit 1\n    fi\n\n    success \"Environment validation passed\"\n}\n\nphase1_foundation() {\n    info \"Phase 1: Setting up foundation...\"\n    info \"Working in repository root: $REPO_ROOT\"\n\n    # Check if already completed\n    if [ -f \".testing-framework-phase1\" ]; then\n        success \"Phase 1 already completed - skipping\"\n        return 0\n    fi\n\n    # Create test directory structure\n    info \"Creating test directory structure...\"\n    mkdir -p tests/{test_functionality,test_data_processing,test_error_handling,test_integration,test_performance,test_business_logic}\n    mkdir -p tests/fixtures/{sample_data,test_models,mock_responses}\n    mkdir -p tests/utils\n\n    # Create conftest.py (backup existing if present)\n    if [ -f \"tests/conftest.py\" ]; then\n        warning \"tests/conftest.py exists - backing up to tests/conftest.py.bak\"\n        cp tests/conftest.py tests/conftest.py.bak\n    fi\n\n    info \"Creating pytest configuration...\"\n    cat > tests/conftest.py << 'EOF'\nimport pytest\nimport sys\nimport os\nfrom unittest.mock import Mock, patch\nimport pandas as pd\nimport numpy as np\n\n# Add core package to path\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\n\n@pytest.fixture\ndef sample_weather_data():\n    return {\n        \"temperature\": [20, 22, 24, 26, 25, 23, 21],\n        \"solar_irradiance\": [0, 200, 400, 600, 400, 200, 0],\n        \"wind_speed\": [5, 7, 6, 8, 9, 6, 4]\n    }\n\n@pytest.fixture\ndef sample_load_data():\n    return pd.DataFrame({\n        \"timestamp\": pd.date_range(\"2024-01-01\", periods=24, freq=\"H\"),\n        \"load\": np.random.normal(100, 20, 24).clip(50, 200)\n    })\n\n@pytest.fixture\ndef mock_dispatch_config():\n    return {\n        \"battery_capacity\": 100.0,\n        \"battery_min_soc\": 0.2,\n        \"battery_max_soc\": 0.8,\n        \"solar_capacity\": 50.0,\n        \"grid_connection\": True\n    }\nEOF\n\n    # Create pytest.ini (backup existing if present)\n    if [ -f \"pytest.ini\" ]; then\n        warning \"pytest.ini exists - backing up to pytest.ini.bak\"\n        cp pytest.ini pytest.ini.bak\n    fi\n\n    info \"Creating pytest configuration...\"\n    cat > pytest.ini << 'EOF'\n[tool:pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts =\n    --verbose\n    --tb=short\n    --cov=core\n    --cov-report=term-missing\n    --cov-report=html\n    --timeout=300\nmarkers =\n    slow: marks tests as slow (deselect with '-m \"not slow\"')\n    integration: marks tests as integration tests\n    performance: marks tests as performance tests\nEOF\n\n    # Create GitHub Actions workflow (backup existing if present)\n    mkdir -p .github/workflows\n    if [ -f \".github/workflows/test.yml\" ]; then\n        warning \"GitHub Actions workflow exists - backing up to .github/workflows/test.yml.bak\"\n        cp .github/workflows/test.yml .github/workflows/test.yml.bak\n    fi\n\n    info \"Creating GitHub Actions workflow...\"\n    cat > .github/workflows/test.yml << 'EOF'\nname: Automated Testing Pipeline\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.8, 3.9, '3.10']\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v4\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install pytest pytest-cov pytest-timeout pytest-mock\n\n    - name: Install package\n      run: pip install -e .\n\n    - name: Run tests\n      run: pytest tests/ --cov=core --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\nEOF\n\n    # Validate Phase 1\n    if [ -d \"tests/test_functionality\" ] && [ -f \"tests/conftest.py\" ] && [ -f \".github/workflows/test.yml\" ]; then\n        # Mark phase as completed\n        echo \"$(date)\" > .testing-framework-phase1\n        success \"Phase 1 completed - Foundation setup complete\"\n        return 0\n    else\n        error \"Phase 1 validation failed\"\n        return 1\n    fi\n}\n\nphase2_core_testing() {\n    info \"Phase 2: Generating core tests...\"\n\n    # Check if already completed\n    if [ -f \".testing-framework-phase2\" ]; then\n        success \"Phase 2 already completed - skipping\"\n        return 0\n    fi\n\n    # Check if Phase 1 was completed\n    if [ ! -f \".testing-framework-phase1\" ]; then\n        error \"Phase 1 not completed - run Phase 1 first\"\n        return 1\n    fi\n\n    # Auto-generate basic functionality tests\n    info \"Auto-discovering modules and generating tests...\"\n    python3 << 'EOF'\nimport os\nimport sys\n\n# Ensure we're working from repo root\nrepo_root = os.getcwd()\ncore_path = os.path.join(repo_root, \"core\")\n\ndef discover_modules():\n    modules = []\n    if not os.path.exists(core_path):\n        print(f\"Error: core directory not found at {core_path}\")\n        return modules\n\n    for root, dirs, files in os.walk(core_path):\n        for file in files:\n            if file.endswith('.py') and not file.startswith('__'):\n                module_path = os.path.join(root, file)\n                # Convert to module name relative to repo root\n                rel_path = os.path.relpath(module_path, repo_root)\n                module_name = rel_path.replace('/', '.').replace('.py', '')\n                modules.append((module_name, module_path))\n    return modules\n\ndef generate_basic_test(module_name, module_path):\n    test_name = module_name.replace('.', '_')\n    return f'''\nimport pytest\nimport sys\nimport os\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))\n\ndef test_{test_name}_imports():\n    \"\"\"Test that {module_name} can be imported without errors.\"\"\"\n    try:\n        import {module_name}\n        assert True\n    except ImportError as e:\n        pytest.fail(f\"Failed to import {module_name}: {{e}}\")\n\ndef test_{test_name}_basic_functionality():\n    \"\"\"Test basic functionality of {module_name}.\"\"\"\n    try:\n        import {module_name}\n        # Add module-specific tests here\n        assert hasattr({module_name}, '__file__')\n    except Exception as e:\n        pytest.fail(f\"Basic functionality test failed for {module_name}: {{e}}\")\n'''\n\n# Generate tests for discovered modules\nmodules = discover_modules()\nfor module_name, module_path in modules:\n    if 'core.' in module_name:\n        test_content = generate_basic_test(module_name, module_path)\n        test_file = f\"tests/test_functionality/test_{module_name.replace('.', '_')}.py\"\n        os.makedirs(os.path.dirname(test_file), exist_ok=True)\n        with open(test_file, 'w') as f:\n            f.write(test_content)\n\nprint(f\"Generated {len(modules)} test files\")\nEOF\n\n    # Create data processing tests\n    cat > tests/test_data_processing/test_data_validation.py << 'EOF'\nimport pytest\nimport pandas as pd\nimport numpy as np\n\ndef test_data_frame_validation():\n    \"\"\"Test basic DataFrame validation.\"\"\"\n    df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n    assert len(df) == 3\n    assert list(df.columns) == ['a', 'b']\n\ndef test_time_series_validation():\n    \"\"\"Test time series data validation.\"\"\"\n    dates = pd.date_range('2024-01-01', periods=24, freq='H')\n    ts = pd.Series(range(24), index=dates)\n    assert len(ts) == 24\n    assert ts.index.freq == 'H'\n\ndef test_missing_data_handling():\n    \"\"\"Test handling of missing data.\"\"\"\n    data = [1, 2, None, 4, 5]\n    series = pd.Series(data)\n    assert series.isnull().sum() == 1\n    filled = series.fillna(series.mean())\n    assert filled.isnull().sum() == 0\nEOF\n\n    # Run tests to validate\n    if python3 -m pytest tests/test_functionality/ -v --tb=short; then\n        # Mark phase as completed\n        echo \"$(date)\" > .testing-framework-phase2\n        success \"Phase 2 completed - Core tests generated and passing\"\n        return 0\n    else\n        warning \"Phase 2 completed but some tests are failing\"\n        echo \"$(date)\" > .testing-framework-phase2\n        return 0  # Don't fail the phase for test failures\n    fi\n}\n\ncheck_status() {\n    info \"Checking implementation status...\"\n\n    for phase in 1 2 3 4; do\n        if [ -f \".testing-framework-phase${phase}\" ]; then\n            local date=$(cat .testing-framework-phase${phase})\n            success \"Phase ${phase}: Completed on ${date}\"\n        else\n            warning \"Phase ${phase}: Not completed\"\n        fi\n    done\n\n    echo \"\"\n    info \"To run missing phases:\"\n    echo \"  ./implement-testing.sh 1   # Run Phase 1 only\"\n    echo \"  ./implement-testing.sh 2   # Run Phase 2 only\"\n    echo \"  ./implement-testing.sh     # Run all incomplete phases\"\n}\n\nphase3_integration() {\n    info \"Phase 3: Creating integration tests...\"\n\n    # Check if already completed\n    if [ -f \".testing-framework-phase3\" ]; then\n        success \"Phase 3 already completed - skipping\"\n        return 0\n    fi\n\n    # Check if Phase 2 was completed\n    if [ ! -f \".testing-framework-phase2\" ]; then\n        error \"Phase 2 not completed - run Phase 2 first\"\n        return 1\n    fi\n\n    # Create integration test\n    cat > tests/test_integration/test_end_to_end.py << 'EOF'\nimport pytest\nimport sys\nimport os\n\ndef test_module_imports():\n    \"\"\"Test that core modules can be imported together.\"\"\"\n    try:\n        # Test importing main modules\n        modules_to_test = [\n            'core.electricityDispatch',\n            'core.marketPriceForecast',\n            'core.generateForecast',\n            'core.weather',\n            'core.interpolateData'\n        ]\n\n        imported = []\n        for module in modules_to_test:\n            try:\n                __import__(module)\n                imported.append(module)\n            except ImportError:\n                pass  # Module might not exist\n\n        assert len(imported) > 0, \"No core modules could be imported\"\n\n    except Exception as e:\n        pytest.fail(f\"Integration import test failed: {e}\")\n\ndef test_basic_workflow():\n    \"\"\"Test a basic workflow if modules are available.\"\"\"\n    try:\n        # This is a placeholder for actual workflow testing\n        # Would need to be customized based on available modules\n        assert True, \"Basic workflow placeholder test\"\n    except Exception as e:\n        pytest.fail(f\"Basic workflow test failed: {e}\")\nEOF\n\n    # Create business logic tests\n    cat > tests/test_business_logic/test_energy_constraints.py << 'EOF'\nimport pytest\nimport numpy as np\n\ndef test_energy_balance_logic():\n    \"\"\"Test energy balance constraint logic.\"\"\"\n    # Mock energy balance calculation\n    generation = np.array([10, 20, 30, 25, 15])\n    load = np.array([12, 18, 28, 22, 17])\n\n    # Simple energy balance check\n    net_energy = generation - load\n\n    # Test that we can calculate net energy\n    assert len(net_energy) == 5\n    assert isinstance(net_energy[0], (int, float, np.number))\n\ndef test_capacity_constraints():\n    \"\"\"Test capacity constraint validation.\"\"\"\n    battery_capacity = 100.0\n    current_soc = 0.5\n    charge_rate = 20.0\n\n    # Test charge limits\n    max_charge = min(charge_rate, (1.0 - current_soc) * battery_capacity)\n    assert max_charge >= 0\n    assert max_charge <= battery_capacity\n\n    # Test discharge limits\n    max_discharge = min(charge_rate, current_soc * battery_capacity)\n    assert max_discharge >= 0\n    assert max_discharge <= battery_capacity\nEOF\n\n    echo \"$(date)\" > .testing-framework-phase3\n    success \"Phase 3 completed - Integration and business logic tests created\"\n    return 0\n}\n\nphase4_monitoring() {\n    info \"Phase 4: Setting up monitoring and maintenance...\"\n\n    # Check if already completed\n    if [ -f \".testing-framework-phase4\" ]; then\n        success \"Phase 4 already completed - skipping\"\n        return 0\n    fi\n\n    # Check if Phase 3 was completed\n    if [ ! -f \".testing-framework-phase3\" ]; then\n        error \"Phase 3 not completed - run Phase 3 first\"\n        return 1\n    fi\n\n    # Create test monitoring script\n    cat > tests/utils/test_monitor.py << 'EOF'\n#!/usr/bin/env python3\nimport subprocess\nimport json\nimport sys\n\ndef run_tests_with_metrics():\n    \"\"\"Run tests and collect metrics.\"\"\"\n    try:\n        result = subprocess.run([\n            'python', '-m', 'pytest',\n            'tests/',\n            '--cov=core',\n            '--cov-report=json',\n            '--tb=short'\n        ], capture_output=True, text=True, timeout=900)\n\n        metrics = {\n            'exit_code': result.returncode,\n            'tests_passed': result.returncode == 0,\n            'stdout_lines': len(result.stdout.split('\\n')),\n            'stderr_lines': len(result.stderr.split('\\n'))\n        }\n\n        # Try to parse coverage\n        try:\n            with open('coverage.json', 'r') as f:\n                coverage_data = json.load(f)\n                metrics['coverage_percent'] = coverage_data['totals']['percent_covered']\n        except:\n            metrics['coverage_percent'] = 0\n\n        return metrics\n\n    except subprocess.TimeoutExpired:\n        return {'error': 'Tests timed out after 15 minutes'}\n\nif __name__ == '__main__':\n    metrics = run_tests_with_metrics()\n    print(json.dumps(metrics, indent=2))\nEOF\n\n    chmod +x tests/utils/test_monitor.py\n\n    # Create maintenance checklist\n    cat > TESTING_MAINTENANCE.md << 'EOF'\n# Testing Framework Maintenance\n\n## Daily Checks\n- [ ] All GitHub Actions workflows passing\n- [ ] Test coverage above 80%\n- [ ] No flaky tests (>2% failure rate)\n\n## Weekly Checks\n- [ ] Review test execution time (<15 minutes)\n- [ ] Update test data if needed\n- [ ] Review and fix any skipped tests\n\n## Monthly Checks\n- [ ] Update test dependencies\n- [ ] Review and refactor slow tests\n- [ ] Add tests for new features\n- [ ] Archive obsolete tests\n\n## Monitoring Commands\n```bash\n# Run all tests with coverage\npython -m pytest tests/ --cov=core --cov-report=html\n\n# Run only fast tests\npython -m pytest tests/ -m \"not slow\"\n\n# Run performance tests\npython -m pytest tests/test_performance/ --benchmark-only\n\n# Get test metrics\npython tests/utils/test_monitor.py\n```\nEOF\n\n    echo \"$(date)\" > .testing-framework-phase4\n    success \"Phase 4 completed - Monitoring and maintenance setup complete\"\n    return 0\n}\n\nrun_final_validation() {\n    info \"Running final validation...\"\n\n    local errors=0\n\n    # Check directory structure\n    if [ ! -d \"$REPO_ROOT/tests\" ]; then\n        error \"tests/ directory missing in $REPO_ROOT\"\n        ((errors++))\n    fi\n\n    # Check key files\n    for file in \"tests/conftest.py\" \"pytest.ini\" \".github/workflows/test.yml\"; do\n        if [ ! -f \"$REPO_ROOT/$file\" ]; then\n            error \"Required file missing: $REPO_ROOT/$file\"\n            ((errors++))\n        fi\n    done\n\n    # Try to run a basic test\n    if ! python3 -c \"import pytest; pytest.main(['--version'])\" > /dev/null 2>&1; then\n        warning \"pytest not available - install with: pip install pytest pytest-cov\"\n    else\n        info \"Running basic import tests...\"\n        if python3 -m pytest tests/ --collect-only > /dev/null 2>&1; then\n            success \"Test collection successful\"\n        else\n            warning \"Some tests may have collection issues\"\n        fi\n    fi\n\n    if [ $errors -eq 0 ]; then\n        success \"Final validation passed - Testing framework ready!\"\n        success \"Working directory: $REPO_ROOT\"\n        success \"Script location: $SCRIPT_DIR\"\n        return 0\n    else\n        error \"Final validation failed with $errors errors\"\n        return 1\n    fi\n}\n\n# Main execution\nmain() {\n    # Handle status check\n    if [ \"$1\" = \"status\" ]; then\n        check_status\n        exit 0\n    fi\n\n    local start_phase=1\n    local end_phase=4\n\n    if [ $# -eq 1 ]; then\n        start_phase=$1\n        end_phase=$1\n        info \"Running only Phase $1\"\n    else\n        info \"Running phases 1-4 (skipping completed phases)\"\n        # Auto-detect which phases need to be run\n        for phase in 1 2 3 4; do\n            if [ -f \".testing-framework-phase${phase}\" ]; then\n                info \"Phase ${phase} already completed - will skip\"\n            fi\n        done\n    fi\n\n    log \"Starting testing framework implementation...\"\n    log \"Script executed from: $SCRIPT_DIR\"\n    log \"Operating on repository: $REPO_ROOT\"\n\n    validate_environment\n\n    for phase in $(seq $start_phase $end_phase); do\n        case $phase in\n            1) phase1_foundation || exit 1 ;;\n            2) phase2_core_testing || exit 1 ;;\n            3) phase3_integration || exit 1 ;;\n            4) phase4_monitoring || exit 1 ;;\n            *) error \"Invalid phase: $phase\" && exit 1 ;;\n        esac\n    done\n\n    if [ $start_phase -eq 1 ] && [ $end_phase -eq 4 ]; then\n        run_final_validation\n    fi\n\n    success \"Implementation complete! Check $LOG_FILE for details.\"\n\n    if [ $VALIDATION_ERRORS -gt 0 ]; then\n        warning \"$VALIDATION_ERRORS validation warnings encountered\"\n    fi\n\n    info \"Next steps:\"\n    echo \"  1. Install test dependencies: pip install pytest pytest-cov pytest-timeout\"\n    echo \"  2. Run tests: python -m pytest tests/\"\n    echo \"  3. Check coverage: open htmlcov/index.html\"\n    echo \"  4. Commit changes: git add . && git commit -m 'Add automated testing framework'\"\n    echo \"\"\n    info \"Useful commands (from $REPO_ROOT):\"\n    echo \"  deploy/scripts/implement-testing.sh status    # Check which phases are completed\"\n    echo \"  deploy/scripts/implement-testing.sh 2         # Run only Phase 2\"\n    echo \"  deploy/scripts/implement-testing.sh           # Run all incomplete phases\"\n}\n\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/implement_testing.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/bash\n# build-and-push-images.sh\n# Script to build and push Docker images for core API components\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region>\"\n    echo \"Example: $0 eu-south-1\"\n    exit 1\nfi\n\nTARGET_REGION=\"$1\"\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\nPROJECT_ROOT=\"$(cd \"$SCRIPT_DIR/../../\" &> /dev/null && pwd)\"\n\necho \"Building and pushing Docker images to region: $TARGET_REGION\"\necho \"Account ID: $ACCOUNT_ID\"\necho \"Project root: $PROJECT_ROOT\"\n\n# Login to ECR\necho \"Logging in to ECR...\"\naws ecr get-login-password --region \"$TARGET_REGION\" | docker login --username AWS --password-stdin \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com\"\n\n# Components to build\nCOMPONENTS=(\n    \"ingestHistoricalLoadData:ingesthistoricaldata\"\n    \"ingestNowcastLoadData:ingestnowcastdata\"\n    \"trainForecaster:trainforecaster\"\n)\n\n# Build and push GeneratePresignedUrlLambda\necho \"Building and pushing GeneratePresignedUrlLambda...\"\ncd \"$PROJECT_ROOT/core/ingestHistoricalLoadData\"\n\n# Create a temporary Dockerfile for GeneratePresignedUrlLambda\ncat > Dockerfile.presignedurl << 'EOF'\nFROM public.ecr.aws/lambda/python:3.9\n\n# Copy GeneratePresignedUrlLambda.py\nCOPY GeneratePresignedUrlLambda.py ${LAMBDA_TASK_ROOT}\n\n# Install requirements\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Set the CMD to your handler\nCMD [\"GeneratePresignedUrlLambda.lambda_handler\"]\nEOF\n\n# Build and push the image\ndocker build -f Dockerfile.presignedurl -t \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com/generatepresignedurl/lambda:latest\" .\ndocker push \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com/generatepresignedurl/lambda:latest\"\n\n# Clean up temporary Dockerfile\nrm Dockerfile.presignedurl\n\n# Build and push other components\nfor COMPONENT in \"${COMPONENTS[@]}\"; do\n    # Split component name and repo name\n    COMPONENT_NAME=$(echo \"$COMPONENT\" | cut -d':' -f1)\n    REPO_NAME=$(echo \"$COMPONENT\" | cut -d':' -f2)\n\n    echo \"Building and pushing $COMPONENT_NAME...\"\n\n    # Change to component directory\n    cd \"$PROJECT_ROOT/core/$COMPONENT_NAME\"\n\n    # Build Docker image\n    docker build -t \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com/$REPO_NAME/lambda:latest\" .\n\n    # Push Docker image to ECR\n    docker push \"$ACCOUNT_ID.dkr.ecr.$TARGET_REGION.amazonaws.com/$REPO_NAME/lambda:latest\"\n\n    echo \"$COMPONENT_NAME built and pushed successfully\"\ndone\n\necho \"All images built and pushed successfully\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/build-and-push-images.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n#!/bin/bash\n# create-api-keys.sh\n# Script to create the admin (superuser) API key for a new environment and store it securely\n\nset -e  # Exit on error\n\nif [ $# -lt 2 ]; then\n    echo \"Usage: $0 <region> <environment>\"\n    echo \"Example: $0 eu-south-1 production\"\n    exit 1\nfi\n\nTARGET_REGION=\"$1\"\nENVIRONMENT=\"$2\"\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\n\nCONFIG_FILE=\"$SCRIPT_DIR/../config/$TARGET_REGION.env\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n    echo \"Error: Configuration file not found: $CONFIG_FILE\"\n    exit 1\nfi\n\nsource \"$CONFIG_FILE\"\n\nDYNAMO_TABLE=\"clients\"\nADMIN_CLIENT_ID=1\nADMIN_NAME=\"Admin\"\nADMIN_ROLE=\"superuser\"\nADMIN_EMAIL=\"<EMAIL>\"\nSECRET_NAME=\"ona-admin-api-key-$TARGET_REGION-$ENVIRONMENT\"\n\n# Check if admin client exists\nADMIN_EXISTS=$(aws dynamodb get-item \\\n    --region us-east-1 \\\n    --table-name \"$DYNAMO_TABLE\" \\\n    --key \"{\\\"client_id\\\":{\\\"N\\\":\\\"$ADMIN_CLIENT_ID\\\"}}\" \\\n    --query 'Item.client_id.N' \\\n    --output text 2>/dev/null || echo \"DOES_NOT_EXIST\")\n\nif [ \"$ADMIN_EXISTS\" = \"DOES_NOT_EXIST\" ]; then\n    echo \"Creating admin (superuser) client...\"\n    aws dynamodb put-item \\\n        --region us-east-1 \\\n        --table-name \"$DYNAMO_TABLE\" \\\n        --item \"{\\\"client_id\\\":{\\\"N\\\":\\\"$ADMIN_CLIENT_ID\\\"},\\\"name\\\":{\\\"S\\\":\\\"$ADMIN_NAME\\\"},\\\"role\\\":{\\\"S\\\":\\\"$ADMIN_ROLE\\\"},\\\"contact_email\\\":{\\\"S\\\":\\\"$ADMIN_EMAIL\\\"}}\"\n    echo \"Admin client created.\"\nelse\n    echo \"Admin client already exists.\"\nfi\n\n# Create API key for admin client\nPYTHON_CODE=\"\"\"\nfrom core.manageUsers.create_api_key import create_api_key\nimport boto3\nimport sys\nregion = '$TARGET_REGION'\nenvironment = '$ENVIRONMENT'\nclient_id = $ADMIN_CLIENT_ID\nkey = create_api_key(region, environment, client_id)\nif not key:\n    print('Failed to create or retrieve admin API key', file=sys.stderr)\n    sys.exit(1)\n# Store in AWS Secrets Manager\ndescription = f'Ona admin API key for {region} {environment}'\nsecrets = boto3.client('secretsmanager', region_name=region)\ntry:\n    secrets.create_secret(Name='$SECRET_NAME', SecretString=key, Description=description)\n    print(f'Stored admin API key in Secrets Manager: $SECRET_NAME')\nexcept secrets.exceptions.ResourceExistsException:\n    secrets.put_secret_value(SecretId='$SECRET_NAME', SecretString=key)\n    print(f'Updated admin API key in Secrets Manager: $SECRET_NAME')\n\"\"\"\n\npython3 -c \"$PYTHON_CODE\"\n\necho \"Admin API key setup complete.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/create-api-keys.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n#!/bin/bash\n# create-ecr-repos.sh\n# Script to create ECR repositories for core API components\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region>\"\n    echo \"Example: $0 eu-south-1\"\n    exit 1\nfi\n\nTARGET_REGION=\"$1\"\n\necho \"Creating ECR repositories in region: $TARGET_REGION\"\n\n# List of repository names to create\nREPO_NAMES=(\n    \"ingesthistoricaldata/lambda\"\n    \"ingestnowcastdata/lambda\"\n    \"trainforecaster/lambda\"\n    \"generatepresignedurl/lambda\"\n)\n\n# Create each repository if it doesn't exist\nfor REPO_NAME in \"${REPO_NAMES[@]}\"; do\n    echo \"Checking repository: $REPO_NAME\"\n\n    # Check if repository exists\n    if aws ecr describe-repositories --region \"$TARGET_REGION\" --repository-names \"$REPO_NAME\" >/dev/null 2>&1; then\n        echo \"Repository $REPO_NAME already exists\"\n    else\n        echo \"Creating repository: $REPO_NAME\"\n        aws ecr create-repository \\\n            --region \"$TARGET_REGION\" \\\n            --repository-name \"$REPO_NAME\" \\\n            --image-scanning-configuration scanOnPush=true\n\n        # Set lifecycle policy to keep only the last 5 images\n        echo \"Setting lifecycle policy for $REPO_NAME\"\n        aws ecr put-lifecycle-policy \\\n            --region \"$TARGET_REGION\" \\\n            --repository-name \"$REPO_NAME\" \\\n            --lifecycle-policy-text '{\n                \"rules\": [\n                    {\n                        \"rulePriority\": 1,\n                        \"description\": \"Keep only the last 5 images\",\n                        \"selection\": {\n                            \"tagStatus\": \"any\",\n                            \"countType\": \"imageCountMoreThan\",\n                            \"countNumber\": 5\n                        },\n                        \"action\": {\n                            \"type\": \"expire\"\n                        }\n                    }\n                ]\n            }'\n\n        echo \"Repository $REPO_NAME created successfully\"\n    fi\ndone\n\necho \"ECR repository setup complete\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/scripts/create-ecr-repos.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# deploy-core-api.sh\n# Main script for deploying core API endpoints to specified AWS region\n\nset -e  # Exit on error\n\n# Check if region parameter is provided\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 <region> [environment]\"\n    echo \"Example: $0 eu-south-1 production\"\n    exit 1\nfi\n\n# Set variables\nTARGET_REGION=\"$1\"\nENVIRONMENT=\"${2:-production}\"  # Default to production if not specified\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\n\n# Define common tags for all resources\nTAGS=\"Environment=$ENVIRONMENT \\\n      Service=OnaAPI \\\n      Component=Core \\\n      CostCenter=EnergyForecasting \\\n      Owner=PlatformTeam \\\n      UptimeSLA=99.9 \\\n      DataClassification=Internal \\\n      Compliance=ISO27001 \\\n      ManagedBy=CloudFormation \\\n      Version=1.0\"\n\n# Function to check if a CloudFormation stack exists\nstack_exists() {\n    local stack_name=$1\n    aws cloudformation describe-stacks --region \"$TARGET_REGION\" \\\n        --stack-name \"$stack_name\" \\\n        --query 'Stacks[0].StackStatus' \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\n# Function to check if a stack is in a stable state\nis_stack_stable() {\n    local stack_name=$1\n    local status\n    status=$(stack_exists \"$stack_name\")\n    [[ \"$status\" =~ ^(CREATE_COMPLETE|UPDATE_COMPLETE|UPDATE_ROLLBACK_COMPLETE)$ ]]\n}\n\n# Function to wait for a stack to be stable\nwait_for_stack() {\n    local stack_name=$1\n    local max_attempts=30\n    local attempt=1\n\n    echo \"Waiting for stack $stack_name to be stable...\"\n    while [ $attempt -le $max_attempts ]; do\n        if is_stack_stable \"$stack_name\"; then\n            echo \"Stack $stack_name is stable\"\n            return 0\n        fi\n        echo \"Attempt $attempt/$max_attempts: Stack $stack_name is not stable yet...\"\n        sleep 30\n        ((attempt++))\n    done\n    echo \"Stack $stack_name did not become stable in time\"\n    return 1\n}\n\n# Function to check if ECR repository exists\necr_repo_exists() {\n    local repo_name=$1\n    aws ecr describe-repositories --region \"$TARGET_REGION\" \\\n        --repository-names \"$repo_name\" \\\n        --query 'repositories[0].repositoryName' \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\n# Function to check if API Gateway exists\napi_exists() {\n    local api_name=$1\n    aws apigateway get-rest-apis --region \"$TARGET_REGION\" \\\n        --query \"items[?name=='$api_name'].id\" \\\n        --output text 2>/dev/null || echo \"DOES_NOT_EXIST\"\n}\n\necho \"=============================================\"\necho \"Deploying Core API to region: $TARGET_REGION\"\necho \"Environment: $ENVIRONMENT\"\necho \"Account ID: $ACCOUNT_ID\"\necho \"=============================================\"\n\n# Load region-specific configuration\nCONFIG_FILE=\"$SCRIPT_DIR/config/$TARGET_REGION.env\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n    echo \"Error: Configuration file not found: $CONFIG_FILE\"\n    echo \"Please create a configuration file for this region first.\"\n    exit 1\nfi\n\nsource \"$CONFIG_FILE\"\n\n# Load environment-specific configuration (if exists)\nENV_CONFIG_FILE=\"$SCRIPT_DIR/config/$TARGET_REGION-$ENVIRONMENT.env\"\nif [ -f \"$ENV_CONFIG_FILE\" ]; then\n    source \"$ENV_CONFIG_FILE\"\n    echo \"Loaded environment-specific configuration from $ENV_CONFIG_FILE\"\nfi\n\n# Step 1: Create ECR repositories (if they don't exist)\necho \"Creating ECR repositories if they don't exist...\"\nfor repo in ingesthistoricaldata ingestnowcastdata trainforecaster generatepresignedurl \\\n            interpolatedata generateforecast returnforecastingresults marketpriceforecast \\\n            electricitydispatch weather; do\n    if [ \"$(ecr_repo_exists \"$repo/lambda\")\" = \"DOES_NOT_EXIST\" ]; then\n        echo \"Creating ECR repository: $repo/lambda\"\n        aws ecr create-repository --region \"$TARGET_REGION\" \\\n            --repository-name \"$repo/lambda\" \\\n            --tags $TAGS\n    else\n        echo \"ECR repository $repo/lambda already exists\"\n    fi\ndone\n\n# Step 2: Build and push Docker images\necho \"Building and pushing Docker images...\"\n\"$SCRIPT_DIR/scripts/build-and-push-images.sh\" \"$TARGET_REGION\"\n\n# Step 3: Deploy CloudFormation stack for S3 buckets\necho \"Deploying S3 buckets...\"\nS3_STACK_NAME=\"${REGION_PREFIX}-s3-buckets\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/s3-buckets.yaml\" \\\n    --stack-name \"$S3_STACK_NAME\" \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n    --tags $TAGS\n\n# Wait for S3 stack to be stable before proceeding\nwait_for_stack \"$S3_STACK_NAME\"\n\n# Step 4: Deploy CloudFormation stack for IAM roles\necho \"Deploying IAM roles...\"\nIAM_STACK_NAME=\"${REGION_PREFIX}-iam-roles\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/iam-roles.yaml\" \\\n    --stack-name \"$IAM_STACK_NAME\" \\\n    --capabilities CAPABILITY_NAMED_IAM \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n    --tags $TAGS\n\n# Wait for IAM stack to be stable before proceeding\nwait_for_stack \"$IAM_STACK_NAME\"\n\n# Step 5: Deploy CloudFormation stack for Lambda functions\necho \"Deploying Lambda functions...\"\nLAMBDA_STACK_NAME=\"${REGION_PREFIX}-lambda-functions\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/lambda-functions.yaml\" \\\n    --stack-name \"$LAMBDA_STACK_NAME\" \\\n    --capabilities CAPABILITY_IAM \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n        AccountId=\"$ACCOUNT_ID\" \\\n        LambdaMemory=\"$LAMBDA_MEMORY\" \\\n        IngestHistoricalDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/ingesthistoricaldata/lambda:latest\" \\\n        IngestNowcastDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/ingestnowcastdata/lambda:latest\" \\\n        TrainForecasterImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/trainforecaster/lambda:latest\" \\\n        GeneratePresignedUrlImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/generatepresignedurl/lambda:latest\" \\\n        InterpolateDataImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/interpolatedata/lambda:latest\" \\\n        GenerateForecastImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/generateforecast/lambda:latest\" \\\n        ReturnForecastingResultsImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/returnforecastingresults/lambda:latest\" \\\n        MarketPriceForecastImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/marketpriceforecast/lambda:latest\" \\\n        ElectricityDispatchImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/electricitydispatch/lambda:latest\" \\\n        WeatherImage=\"${ACCOUNT_ID}.dkr.ecr.${TARGET_REGION}.amazonaws.com/weather/lambda:latest\" \\\n    --tags $TAGS\n\n# Wait for Lambda stack to be stable before proceeding\nwait_for_stack \"$LAMBDA_STACK_NAME\"\n\n# Step 6: Deploy CloudFormation stack for API Gateway\necho \"Deploying API Gateway...\"\nAPI_STACK_NAME=\"${REGION_PREFIX}-api-gateway\"\naws cloudformation deploy \\\n    --region \"$TARGET_REGION\" \\\n    --template-file \"$SCRIPT_DIR/templates/api-gateway.yaml\" \\\n    --stack-name \"$API_STACK_NAME\" \\\n    --parameter-overrides \\\n        RegionPrefix=\"$REGION_PREFIX\" \\\n        Environment=\"$ENVIRONMENT\" \\\n        EndpointType=\"$API_ENDPOINT_TYPE\" \\\n        IngestHistoricalDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='IngestHistoricalDataFunctionArn'].OutputValue\" --output text) \\\n        IngestNowcastDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='IngestNowcastDataFunctionArn'].OutputValue\" --output text) \\\n        TrainForecasterFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='TrainForecasterFunctionArn'].OutputValue\" --output text) \\\n        GeneratePresignedUrlFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='GeneratePresignedUrlFunctionArn'].OutputValue\" --output text) \\\n        InterpolateDataFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='InterpolateDataFunctionArn'].OutputValue\" --output text) \\\n        GenerateForecastFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='GenerateForecastFunctionArn'].OutputValue\" --output text) \\\n        ReturnForecastingResultsFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='ReturnForecastingResultsFunctionArn'].OutputValue\" --output text) \\\n        MarketPriceForecastFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='MarketPriceForecastFunctionArn'].OutputValue\" --output text) \\\n        ElectricityDispatchFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='ElectricityDispatchFunctionArn'].OutputValue\" --output text) \\\n        WeatherFunctionArn=$(aws cloudformation describe-stacks --region \"$TARGET_REGION\" --stack-name \"$LAMBDA_STACK_NAME\" --query \"Stacks[0].Outputs[?OutputKey=='WeatherFunctionArn'].OutputValue\" --output text) \\\n    --tags $TAGS\n\n# Wait for API Gateway stack to be stable before proceeding\nwait_for_stack \"$API_STACK_NAME\"\n\n# Step 7: Create and configure API keys\necho \"Creating API keys...\"\n\"$SCRIPT_DIR/scripts/create-api-keys.sh\" \"$TARGET_REGION\" \"$ENVIRONMENT\"\n\n# Step 8: Deploy the API\necho \"Deploying API Gateway endpoints...\"\nAPIS=$(aws apigateway get-rest-apis --region \"$TARGET_REGION\" --query \"items[?contains(name, '${REGION_PREFIX}')].id\" --output text)\nfor API_ID in $APIS; do\n    echo \"Deploying API: $API_ID\"\n    aws apigateway create-deployment \\\n        --region \"$TARGET_REGION\" \\\n        --rest-api-id \"$API_ID\" \\\n        --stage-name \"$ENVIRONMENT\" \\\n        --description \"Deployment from deploy-core-api.sh script\" \\\n        --tags $TAGS\ndone\n\n# Step 9: Set up CloudWatch Alarms for monitoring\necho \"Setting up CloudWatch Alarms...\"\n\"$SCRIPT_DIR/scripts/setup-monitoring.sh\" \"$TARGET_REGION\" \"$ENVIRONMENT\"\n\necho \"=============================================\"\necho \"Core API deployment to $TARGET_REGION completed!\"\necho \"=============================================\"\n\n# Output API endpoints\necho \"API Endpoints:\"\nfor API_ID in $APIS; do\n    API_NAME=$(aws apigateway get-rest-api --region \"$TARGET_REGION\" --rest-api-id \"$API_ID\" --query \"name\" --output text)\n    echo \"$API_NAME: https://$API_ID.execute-api.$TARGET_REGION.amazonaws.com/$ENVIRONMENT\"\ndone\n\necho \"See CloudFormation stacks for more details:\"\necho \"https://$TARGET_REGION.console.aws.amazon.com/cloudformation/home?region=$TARGET_REGION#/stacks\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/deploy/deploy-core-api.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\nset -euo pipefail\n\n###############################\n# CONFIGURATION & INITIALIZATION\n###############################\n\n# Region and account information\nREGION=${AWS_DEFAULT_REGION:-us-east-1}\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n\n# Lambda function configuration\nFUNCTION_NAME=\"LogsProxyFunction\"\nZIP_FILE=\"logsProxyLambda.zip\"            # The deployment package to be created if it doesn't exist.\nSOURCE_FILE=\"logsProxyLambda.js\"          # Your Lambda source code file.\nHANDLER=\"logsProxyLambda.handler\"         # Expects an exported function named 'handler' in the source file.\nRUNTIME=\"nodejs18.x\"\nROLE_NAME=\"lambda-execution-role\"\n\n# API Gateway configuration\nAPI_NAME=\"LogsProxyApi\"\nSTAGE_NAME=\"test\"\nRESOURCE_PATH=\"logs\"\nAPI_KEY_NAME=\"LogsProxyApiKey\"\nUSAGE_PLAN_NAME=\"LogsProxyUsagePlan\"\n\n###############################\n# PREPARE LAMBDA DEPLOYMENT PACKAGE\n###############################\n# If the ZIP file does not exist, create it from the SOURCE_FILE.\nif [ ! -f \"$ZIP_FILE\" ]; then\n  if [ ! -f \"$SOURCE_FILE\" ]; then\n    echo \"Error: Lambda source file '$SOURCE_FILE' not found. Aborting.\"\n    exit 1\n  fi\n  echo \"Lambda deployment package not found. Creating '$ZIP_FILE' from '$SOURCE_FILE'...\"\n  zip \"$ZIP_FILE\" \"$SOURCE_FILE\"\nfi\n\n###############################\n# CREATE OR VERIFY IAM ROLE\n###############################\necho \"Checking for IAM role '$ROLE_NAME'...\"\nif ! aws iam get-role --role-name \"$ROLE_NAME\" >/dev/null 2>&1; then\n  echo \"IAM role '$ROLE_NAME' not found. Creating it...\"\n  # Create a temporary trust policy file\n  cat > trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Principal\": { \"Service\": \"lambda.amazonaws.com\" },\n    \"Action\": \"sts:AssumeRole\"\n  }]\n}\nEOF\n  aws iam create-role --role-name \"$ROLE_NAME\" --assume-role-policy-document file://trust-policy.json\n  # Attach the basic Lambda execution policy\n  aws iam attach-role-policy --role-name \"$ROLE_NAME\" --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n  # Wait a few seconds for IAM propagation\n  sleep 10\n  rm trust-policy.json\nfi\nROLE_ARN=$(aws iam get-role --role-name \"$ROLE_NAME\" --query 'Role.Arn' --output text)\necho \"Using IAM Role ARN: $ROLE_ARN\"\n\n###############################\n# CREATE OR UPDATE THE LAMBDA FUNCTION\n###############################\nif aws lambda get-function --function-name \"$FUNCTION_NAME\" >/dev/null 2>&1; then\n  echo \"Lambda function '$FUNCTION_NAME' exists. Updating function code...\"\n  aws lambda update-function-code \\\n    --function-name \"$FUNCTION_NAME\" \\\n    --zip-file fileb://\"$ZIP_FILE\"\nelse\n  echo \"Creating Lambda function '$FUNCTION_NAME'...\"\n  aws lambda create-function \\\n    --function-name \"$FUNCTION_NAME\" \\\n    --runtime \"$RUNTIME\" \\\n    --role \"$ROLE_ARN\" \\\n    --handler \"$HANDLER\" \\\n    --zip-file fileb://\"$ZIP_FILE\" \\\n    --memory-size 128 \\\n    --timeout 30\nfi\n\n# Retrieve the Lambda function ARN for integration\nLAMBDA_ARN=$(aws lambda get-function --function-name \"$FUNCTION_NAME\" --query 'Configuration.FunctionArn' --output text)\necho \"Lambda function ARN: $LAMBDA_ARN\"\n\n###############################\n# CREATE THE API GATEWAY REST API\n###############################\necho \"Creating API Gateway REST API '$API_NAME'...\"\nAPI_ID=$(aws apigateway create-rest-api --name \"$API_NAME\" --query 'id' --output text)\necho \"API ID: $API_ID\"\n\n# Get the root resource ID (the \"/\" resource)\nROOT_ID=$(aws apigateway get-resources --rest-api-id \"$API_ID\" --query 'items[?path==`/`].id' --output text)\necho \"Root Resource ID: $ROOT_ID\"\n\n# Create a new resource for the path \"/logs\"\necho \"Creating resource for '/$RESOURCE_PATH'...\"\nLOGS_RESOURCE_ID=$(aws apigateway create-resource \\\n  --rest-api-id \"$API_ID\" \\\n  --parent-id \"$ROOT_ID\" \\\n  --path-part \"$RESOURCE_PATH\" \\\n  --query 'id' --output text)\necho \"Logs Resource ID: $LOGS_RESOURCE_ID\"\n\n# Create a GET method on the /logs resource with API key requirement\necho \"Creating GET method on '/$RESOURCE_PATH' with API Key required...\"\naws apigateway put-method \\\n  --rest-api-id \"$API_ID\" \\\n  --resource-id \"$LOGS_RESOURCE_ID\" \\\n  --http-method GET \\\n  --authorization-type \"NONE\" \\\n  --api-key-required\n\n# Set up Lambda proxy integration for the GET method\necho \"Setting up Lambda proxy integration for GET '/$RESOURCE_PATH'...\"\naws apigateway put-integration \\\n  --rest-api-id \"$API_ID\" \\\n  --resource-id \"$LOGS_RESOURCE_ID\" \\\n  --http-method GET \\\n  --type AWS_PROXY \\\n  --integration-http-method POST \\\n  --uri \"arn:aws:apigateway:${REGION}:lambda:path/2015-03-31/functions/${LAMBDA_ARN}/invocations\"\n\n# Grant API Gateway permission to invoke the Lambda function\necho \"Adding permission for API Gateway to invoke Lambda...\"\naws lambda add-permission \\\n  --function-name \"$FUNCTION_NAME\" \\\n  --statement-id \"apigateway-invoke-permissions\" \\\n  --action lambda:InvokeFunction \\\n  --principal apigateway.amazonaws.com \\\n  --source-arn \"arn:aws:execute-api:${REGION}:${ACCOUNT_ID}:${API_ID}/*/GET/$RESOURCE_PATH\"\n\n###############################\n# DEPLOY THE API\n###############################\necho \"Deploying API to stage '$STAGE_NAME'...\"\naws apigateway create-deployment --rest-api-id \"$API_ID\" --stage-name \"$STAGE_NAME\"\n\n###############################\n# CREATE API KEY, USAGE PLAN, AND ASSOCIATE THEM\n###############################\necho \"Creating API Key '$API_KEY_NAME'...\"\nAPI_KEY_ID=$(aws apigateway create-api-key --name \"$API_KEY_NAME\" --enabled --query 'id' --output text)\necho \"API Key ID: $API_KEY_ID\"\n\necho \"Creating Usage Plan '$USAGE_PLAN_NAME'...\"\nUSAGE_PLAN_ID=$(aws apigateway create-usage-plan \\\n  --name \"$USAGE_PLAN_NAME\" \\\n  --api-stages apiId=\"$API_ID\",stage=\"$STAGE_NAME\" \\\n  --throttle burstLimit=2,rateLimit=10 \\\n  --query 'id' --output text)\necho \"Usage Plan ID: $USAGE_PLAN_ID\"\n\necho \"Associating API Key with the Usage Plan...\"\naws apigateway create-usage-plan-key \\\n  --usage-plan-id \"$USAGE_PLAN_ID\" \\\n  --key-id \"$API_KEY_ID\" \\\n  --key-type API_KEY\n\n###############################\n# OUTPUT THE ENDPOINT AND API KEY VALUE\n###############################\nAPI_ENDPOINT=\"https://${API_ID}.execute-api.${REGION}.amazonaws.com/${STAGE_NAME}/logs\"\necho \"API Endpoint: $API_ENDPOINT\"\n\nAPI_KEY_VALUE=$(aws apigateway get-api-key --api-key \"$API_KEY_ID\" --include-value --query 'value' --output text)\necho \"API Key: $API_KEY_VALUE\"\n\n###############################################################################\n# Changelog:\n#\n# 1. **Deployment Package Creation:**\n#    - Added a check to see if the ZIP file (logsProxyLambda.zip) exists.\n#    - If it does not exist, the script checks for the source file (logsProxyLambda.js)\n#      and creates the ZIP file using the `zip` command.\n#\n# 2. **Lambda Function Creation/Update:**\n#    - The script checks if the Lambda function exists.\n#      - If it exists, it updates the function code.\n#      - If it does not exist, it creates the function using the newly created ZIP file.\n#\n# 3. **Remaining API Gateway Setup:**\n#    - Continues with creating the API Gateway REST API, resource, method, integration,\n#      deployment, API key, usage plan, and association.\n#\n# This script now does not assume the Lambda function already exists; it packages\n# the source code, creates the Lambda function if needed, and then proceeds with deployment.\n###############################################################################\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/deploy_proxy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n#!/bin/bash\nset -euo pipefail\n\n# This script releases all unused (unassociated) Elastic IP addresses in your AWS account.\n# When you hit the AWS EIP limit, running this script will free up EIPs that are not in use.\n#\n# Usage:\n#   1. Save this script as release_unused_eips.sh\n#   2. Make it executable: chmod +x release_unused_eips.sh\n#   3. Run the script: ./release_unused_eips.sh\n\necho \"Fetching all allocated Elastic IP addresses that are unused...\"\n# Retrieves the AllocationIds of EIPs that are not associated with any resource\nEIP_IDS=$(aws ec2 describe-addresses --query 'Addresses[?AssociationId==null].AllocationId' --output text)\n\nif [ -z \"$EIP_IDS\" ]; then\n    echo \"No unused Elastic IP addresses found. You have not exceeded your limit due to unused addresses.\"\n    exit 0\nfi\n\necho \"Found the following unused Elastic IP addresses:\"\necho \"$EIP_IDS\"\necho\n\nfor eip in $EIP_IDS; do\n    echo \"Releasing Elastic IP: $eip...\"\n    aws ec2 release-address --allocation-id \"$eip\"\n    echo \"Released Elastic IP: $eip\"\ndone\n\necho \"All unused Elastic IP addresses have been released.\"\n\n# Changelog:\n# -------------\n# 1. **Purpose:**\n#    - Added a new script to automatically release any unused (unassociated) Elastic IP addresses.\n#\n# 2. **Elastic IP Retrieval:**\n#    - Uses the command `aws ec2 describe-addresses` with a JMESPath query to filter for addresses\n#      where `AssociationId` is null. This ensures only unused EIPs are targeted.\n#\n# 3. **Loop & Release:**\n#    - Iterates over each unused Elastic IP and calls `aws ec2 release-address` to free it.\n#\n# 4. **Logging:**\n#    - Detailed echo statements are provided to inform the user of which EIPs are being released.\n#\n# 5. **Error Handling:**\n#    - Uses `set -euo pipefail` to ensure the script exits if any command fails or if a variable is undefined.\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/release.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# cleanup.sh\n# Consolidated cleanup script for AWS resources used by the data scraper system\n#=============================================================================\n\n# Source the common library\n# shellcheck disable=SC1091\nsource \"$(dirname \"${BASH_SOURCE[0]}\")/common-lib.sh\"\n\n# Function to display help specific to this script\nshow_help() {\n  display_help \"all       Clean up all AWS resources (Lambda, ECS, ECR, networking)\n  lambda    Clean up Lambda functions, roles, event sources, and SQS queues\n  ecs       Clean up ECS cluster, services, and task definitions\n  ecr       Clean up ECR repositories and container images\n  network   Clean up VPC, subnets, gateways, and security groups\"\n}\n\n#-----------------------------------------------------------------------------\n# ECR REPOSITORY CLEANUP\n#-----------------------------------------------------------------------------\n\n# Clean up ECR resources (repository and images)\ncleanup_ecr() {\n  log_section \"Cleaning up ECR resources\"\n\n  if resource_exists \"ecr\" \"$ECR_REPO\"; then\n    # List all images in the repository\n    local images=$(aws ecr list-images --repository-name \"$ECR_REPO\" --region \"$REGION\" --query 'imageIds[*]' --output json)\n\n    if [[ \"$images\" != \"[]\" && -n \"$images\" ]]; then\n      log_info \"Deleting all images from ECR repository: $ECR_REPO\"\n      aws ecr batch-delete-image \\\n        --repository-name \"$ECR_REPO\" \\\n        --image-ids \"$images\" \\\n        --region \"$REGION\"\n    fi\n\n    log_info \"Deleting ECR repository: $ECR_REPO\"\n    aws ecr delete-repository \\\n      --repository-name \"$ECR_REPO\" \\\n      --force \\\n      --region \"$REGION\"\n  else\n    log_info \"ECR repository '$ECR_REPO' does not exist\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# NETWORKING RESOURCE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Clean up networking resources (VPC, subnets, gateways, etc.)\ncleanup_networking() {\n  log_section \"Cleaning up networking resources\"\n\n  # Get the VPC ID based on the cluster name tag\n  VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=tag:Name,Values=$CLUSTER_NAME-vpc\" --query \"Vpcs[0].VpcId\" --output text --region \"$REGION\")\n\n  if [[ \"$VPC_ID\" != \"None\" && -n \"$VPC_ID\" ]]; then\n    # Get the NAT Gateway ID\n    NAT_GW_ID=$(aws ec2 describe-nat-gateways --filter \"Name=vpc-id,Values=$VPC_ID\" --query \"NatGateways[0].NatGatewayId\" --output text --region \"$REGION\")\n    if [[ \"$NAT_GW_ID\" != \"None\" && -n \"$NAT_GW_ID\" ]]; then\n      log_info \"Deleting NAT Gateway: $NAT_GW_ID\"\n      aws ec2 delete-nat-gateway --nat-gateway-id \"$NAT_GW_ID\" --region \"$REGION\"\n      # Wait for NAT Gateway to be deleted\n      aws ec2 wait nat-gateway-deleted --nat-gateway-ids \"$NAT_GW_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Elastic IP associated with the NAT Gateway\n    EIP_ALLOC_ID=$(aws ec2 describe-addresses --filter \"Name=domain,Values=vpc\" --query \"Addresses[0].AllocationId\" --output text --region \"$REGION\")\n    if [[ \"$EIP_ALLOC_ID\" != \"None\" && -n \"$EIP_ALLOC_ID\" ]]; then\n      log_info \"Releasing Elastic IP: $EIP_ALLOC_ID\"\n      aws ec2 release-address --allocation-id \"$EIP_ALLOC_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Security Group ID\n    SEC_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=group-name,Values=$SEC_GROUP_NAME\" --query \"SecurityGroups[0].GroupId\" --output text --region \"$REGION\")\n    if [[ \"$SEC_GROUP_ID\" != \"None\" && -n \"$SEC_GROUP_ID\" ]]; then\n      log_info \"Deleting Security Group: $SEC_GROUP_ID\"\n      aws ec2 delete-security-group --group-id \"$SEC_GROUP_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Subnet IDs\n    SUBNET_IDS=$(aws ec2 describe-subnets --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"Subnets[].SubnetId\" --output text --region \"$REGION\")\n    if [[ -n \"$SUBNET_IDS\" ]]; then\n      for SUBNET_ID in $SUBNET_IDS; do\n        log_info \"Deleting Subnet: $SUBNET_ID\"\n        aws ec2 delete-subnet --subnet-id \"$SUBNET_ID\" --region \"$REGION\"\n      done\n    fi\n\n    # Get the Route Table ID\n    RT_ID=$(aws ec2 describe-route-tables --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"RouteTables[0].RouteTableId\" --output text --region \"$REGION\")\n    if [[ \"$RT_ID\" != \"None\" && -n \"$RT_ID\" ]]; then\n      log_info \"Deleting Route Table: $RT_ID\"\n      aws ec2 delete-route-table --route-table-id \"$RT_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Internet Gateway ID\n    IGW_ID=$(aws ec2 describe-internet-gateways --filters \"Name=attachment.vpc-id,Values=$VPC_ID\" --query \"InternetGateways[0].InternetGatewayId\" --output text --region \"$REGION\")\n    if [[ \"$IGW_ID\" != \"None\" && -n \"$IGW_ID\" ]]; then\n      log_info \"Detaching Internet Gateway from VPC: $IGW_ID\"\n      aws ec2 detach-internet-gateway --internet-gateway-id \"$IGW_ID\" --vpc-id \"$VPC_ID\" --region \"$REGION\"\n      log_info \"Deleting Internet Gateway: $IGW_ID\"\n      aws ec2 delete-internet-gateway --internet-gateway-id \"$IGW_ID\" --region \"$REGION\"\n    fi\n\n    # Finally, delete the VPC\n    log_info \"Deleting VPC: $VPC_ID\"\n    aws ec2 delete-vpc --vpc-id \"$VPC_ID\" --region \"$REGION\"\n  else\n    log_info \"VPC for cluster '$CLUSTER_NAME' not found\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# ECS RESOURCE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Clean up ECS resources (services, cluster, and log groups)\ncleanup_ecs() {\n  log_section \"Cleaning up ECS resources\"\n\n  # Update service to 0 tasks if it exists\n  if resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    log_info \"Updating ECS Service to 0 tasks: $SERVICE_NAME\"\n    aws ecs update-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --desired-count 0 \\\n      --region \"$REGION\"\n\n    log_info \"Waiting for service to stabilize...\"\n    aws ecs wait services-stable \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --services \"$SERVICE_NAME\" \\\n      --region \"$REGION\"\n\n    log_info \"Deleting ECS Service: $SERVICE_NAME\"\n    aws ecs delete-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --force \\\n      --region \"$REGION\"\n  else\n    log_info \"ECS Service '$SERVICE_NAME' does not exist\"\n  fi\n\n  # Delete ECS Cluster if it exists\n  if resource_exists \"ecs-cluster\" \"$CLUSTER_NAME\"; then\n    log_info \"Deleting ECS Cluster: $CLUSTER_NAME\"\n    aws ecs delete-cluster \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --region \"$REGION\"\n  else\n    log_info \"ECS Cluster '$CLUSTER_NAME' does not exist\"\n  fi\n\n  # Delete CloudWatch Log Group\n  local log_group=\"$LOG_GROUP_PREFIX/$CLUSTER_NAME\"\n  if aws logs describe-log-groups --log-group-name-prefix \"$log_group\" --region \"$REGION\" | grep -q \"$log_group\"; then\n    log_info \"Deleting CloudWatch Log Group: $log_group\"\n    aws logs delete-log-group --log-group-name \"$log_group\" --region \"$REGION\"\n  else\n    log_info \"CloudWatch Log Group '$log_group' does not exist\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# LAMBDA FUNCTION CLEANUP\n#-----------------------------------------------------------------------------\n\n# Clean up Lambda resources (functions, roles, queues, etc.)\ncleanup_lambda() {\n  log_section \"Cleaning up Lambda resources\"\n\n  # Delete CloudWatch rule\n  if aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" &> /dev/null; then\n    log_info \"Removing CloudWatch rule targets...\"\n    aws events remove-targets --rule \"$CLOUDWATCH_RULE_NAME\" --ids 1 --region \"$REGION\" || true\n\n    log_info \"Deleting CloudWatch rule...\"\n    aws events delete-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" || true\n  fi\n\n  # Delete Lambda functions\n  if resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\"; then\n    log_info \"Deleting Master Lambda function...\"\n    aws lambda delete-function --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" || true\n  fi\n\n  if resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\"; then\n    # Delete Event Source Mappings\n    local MAPPINGS=$(aws lambda list-event-source-mappings --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'EventSourceMappings[].UUID' --output text 2>/dev/null || true)\n    if [[ -n \"$MAPPINGS\" ]]; then\n      for UUID in $MAPPINGS; do\n        log_info \"Deleting event source mapping $UUID...\"\n        aws lambda delete-event-source-mapping --uuid \"$UUID\" --region \"$REGION\" || true\n      done\n    fi\n\n    log_info \"Deleting PDF Processor Lambda function...\"\n    aws lambda delete-function --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" || true\n  fi\n\n  # Delete SQS queues\n  if resource_exists \"sqs\" \"$SQS_QUEUE_NAME\"; then\n    QUEUE_URL=$(aws sqs get-queue-url --queue-name \"$SQS_QUEUE_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    log_info \"Deleting SQS queue $SQS_QUEUE_NAME...\"\n    aws sqs delete-queue --queue-url \"$QUEUE_URL\" --region \"$REGION\" || true\n  fi\n\n  if resource_exists \"sqs\" \"$DLQ_NAME\"; then\n    DLQ_URL=$(aws sqs get-queue-url --queue-name \"$DLQ_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    log_info \"Deleting SQS DLQ $DLQ_NAME...\"\n    aws sqs delete-queue --queue-url \"$DLQ_URL\" --region \"$REGION\" || true\n  fi\n\n  # Delete IAM roles and policies\n  if resource_exists \"iam-role\" \"$MASTER_LAMBDA_ROLE_NAME\"; then\n    log_info \"Deleting inline policy from $MASTER_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role-policy --role-name \"$MASTER_LAMBDA_ROLE_NAME\" --policy-name \"MasterLambdaPolicy\" || true\n\n    log_info \"Deleting IAM role $MASTER_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role --role-name \"$MASTER_LAMBDA_ROLE_NAME\" || true\n  fi\n\n  if resource_exists \"iam-role\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\"; then\n    log_info \"Deleting inline policy from $PDF_PROCESSOR_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role-policy --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" --policy-name \"PDFProcessorLambdaPolicy\" || true\n\n    log_info \"Deleting IAM role $PDF_PROCESSOR_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" || true\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# COMPREHENSIVE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Cleanup all resources across all AWS services\ncleanup_all() {\n  # Order matters here to avoid dependency issues\n  cleanup_ecs\n  cleanup_ecr\n  cleanup_lambda\n  cleanup_networking\n}\n\n#-----------------------------------------------------------------------------\n# MAIN FUNCTION\n#-----------------------------------------------------------------------------\n\n# Main function\nmain() {\n  # Parse command line arguments\n  local COMMAND=\"\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -h|--help)\n        show_help\n        ;;\n      all|lambda|ecs|ecr|network)\n        COMMAND=\"$1\"\n        shift\n        ;;\n      *)\n        log_error \"Unknown option: $1\"\n        show_help\n        ;;\n    esac\n  done\n\n  # Initialize the deployment environment\n  init_deployment\n\n  # Execute the command\n  case \"$COMMAND\" in\n    all)\n      cleanup_all\n      ;;\n    lambda)\n      cleanup_lambda\n      ;;\n    ecs)\n      cleanup_ecs\n      ;;\n    ecr)\n      cleanup_ecr\n      ;;\n    network)\n      cleanup_networking\n      ;;\n    *)\n      log_error \"No command specified\"\n      show_help\n      ;;\n  esac\n\n  # Finish the deployment\n  finish_deployment\n}\n\n# Execute main function with all arguments\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/cleanup.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# manage-ecs.sh\n# Consolidated ECS management script for deploying, updating, and\n# managing ECS-based containers for the data scraper system\n#=============================================================================\n\n# Source the common library\n# shellcheck disable=SC1091\nsource \"$(dirname \"${BASH_SOURCE[0]}\")/common-lib.sh\"\n\n# Function to display help specific to this script\nshow_help() {\n  display_help \"deploy     Create and deploy the complete ECS infrastructure including VPC,\n            subnets, cluster, ECR repo, and container service\n  update     Update only the container image with the latest code changes\n  delete     Delete all ECS resources and related infrastructure\n  status     Show the current status of ECS resources and services\"\n}\n\n#-----------------------------------------------------------------------------\n# NETWORKING INFRASTRUCTURE\n#-----------------------------------------------------------------------------\n\n# Create VPC and networking resources\ncreate_networking() {\n  log_section \"Creating networking resources\"\n\n  # Create VPC\n  log_info \"Creating VPC with CIDR block $VPC_CIDR...\"\n  VPC_ID=$(aws ec2 create-vpc --cidr-block \"$VPC_CIDR\" --query \"Vpc.VpcId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$VPC_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-vpc\" --region \"$REGION\"\n  log_info \"Created VPC: $VPC_ID\"\n\n  # Create Internet Gateway\n  log_info \"Creating Internet Gateway...\"\n  IGW_ID=$(aws ec2 create-internet-gateway --query \"InternetGateway.InternetGatewayId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$IGW_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-igw\" --region \"$REGION\"\n  aws ec2 attach-internet-gateway --internet-gateway-id \"$IGW_ID\" --vpc-id \"$VPC_ID\" --region \"$REGION\"\n  log_info \"Created and attached Internet Gateway: $IGW_ID\"\n\n  # Create Route Table\n  log_info \"Creating Route Table...\"\n  RT_ID=$(aws ec2 create-route-table --vpc-id \"$VPC_ID\" --query \"RouteTable.RouteTableId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$RT_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-rt\" --region \"$REGION\"\n  aws ec2 create-route --route-table-id \"$RT_ID\" --destination-cidr-block \"0.0.0.0/0\" --gateway-id \"$IGW_ID\" --region \"$REGION\"\n  log_info \"Created Route Table: $RT_ID\"\n\n  # Create Public Subnet\n  log_info \"Creating Public Subnet...\"\n  PUB_SUBNET_ID=$(aws ec2 create-subnet --vpc-id \"$VPC_ID\" --cidr-block \"$PUBLIC_SUBNET_CIDR\" --query \"Subnet.SubnetId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$PUB_SUBNET_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-pub-subnet\" --region \"$REGION\"\n  aws ec2 associate-route-table --subnet-id \"$PUB_SUBNET_ID\" --route-table-id \"$RT_ID\" --region \"$REGION\"\n  log_info \"Created and associated Public Subnet: $PUB_SUBNET_ID\"\n\n  # Create Private Subnet\n  log_info \"Creating Private Subnet...\"\n  PRI_SUBNET_ID=$(aws ec2 create-subnet --vpc-id \"$VPC_ID\" --cidr-block \"$PRIVATE_SUBNET_CIDR\" --query \"Subnet.SubnetId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$PRI_SUBNET_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-pri-subnet\" --region \"$REGION\"\n  log_info \"Created Private Subnet: $PRI_SUBNET_ID\"\n\n  # Create NAT Gateway (in Public Subnet)\n  log_info \"Creating NAT Gateway (in Public Subnet)...\"\n  EIP_ALLOC_ID=$(aws ec2 allocate-address --query \"AllocationId\" --output text --region \"$REGION\")\n  NAT_GW_ID=$(aws ec2 create-nat-gateway --subnet-id \"$PUB_SUBNET_ID\" --allocation-id \"$EIP_ALLOC_ID\" --query \"NatGateway.NatGatewayId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$NAT_GW_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-nat\" --region \"$REGION\"\n  aws ec2 wait nat-gateway-available --nat-gateway-ids \"$NAT_GW_ID\" --region \"$REGION\"\n  log_info \"Created NAT Gateway: $NAT_GW_ID\"\n\n  # Create Security Group\n  log_info \"Creating Security Group...\"\n  SEC_GROUP_ID=$(aws ec2 create-security-group --group-name \"$SEC_GROUP_NAME\" --description \"Security group for ECS scraper tasks\" --vpc-id \"$VPC_ID\" --query \"GroupId\" --output text --region \"$REGION\")\n  aws ec2 create-tags --resources \"$SEC_GROUP_ID\" --tags Key=Name,Value=\"$CLUSTER_NAME-sg\" --region \"$REGION\"\n  aws ec2 authorize-security-group-ingress --group-id \"$SEC_GROUP_ID\" --protocol tcp --port 80 --cidr \"0.0.0.0/0\" --region \"$REGION\"\n  log_info \"Created Security Group: $SEC_GROUP_ID\"\n\n  # Save the IDs to variables for later use\n  export VPC_ID PUB_SUBNET_ID PRI_SUBNET_ID SEC_GROUP_ID\n}\n\n#-----------------------------------------------------------------------------\n# LOGGING CONFIGURATION\n#-----------------------------------------------------------------------------\n\n# Ensure CloudWatch Log Group exists\nensure_log_group() {\n  local log_group=\"$LOG_GROUP_PREFIX/$CLUSTER_NAME\"\n\n  log_section \"Ensuring CloudWatch Log Group exists\"\n\n  if ! aws logs describe-log-groups --log-group-name-prefix \"$log_group\" --region \"$REGION\" | grep -q \"$log_group\"; then\n    log_info \"Creating CloudWatch Log Group: $log_group\"\n    aws logs create-log-group --log-group-name \"$log_group\" --region \"$REGION\"\n    # Set a retention policy (14 days)\n    aws logs put-retention-policy --log-group-name \"$log_group\" --retention-in-days 14 --region \"$REGION\"\n    log_info \"Created CloudWatch Log Group: $log_group\"\n  else\n    log_info \"CloudWatch Log Group '$log_group' already exists\"\n  fi\n\n  export LOG_GROUP=\"$log_group\"\n}\n\n#-----------------------------------------------------------------------------\n# ECS CLUSTER AND CONTAINER MANAGEMENT\n#-----------------------------------------------------------------------------\n\n# Create ECS Cluster\ncreate_ecs_cluster() {\n  log_section \"Creating ECS Cluster\"\n\n  if ! resource_exists \"ecs-cluster\" \"$CLUSTER_NAME\"; then\n    log_info \"Creating ECS Cluster: $CLUSTER_NAME\"\n    aws ecs create-cluster --cluster-name \"$CLUSTER_NAME\" --region \"$REGION\" >/dev/null\n    log_info \"Created ECS Cluster: $CLUSTER_NAME\"\n  else\n    log_info \"ECS Cluster '$CLUSTER_NAME' already exists\"\n  fi\n}\n\n# Create or verify ECR Repository\ncreate_ecr_repository() {\n  log_section \"Creating ECR Repository\"\n\n  if ! resource_exists \"ecr\" \"$ECR_REPO\"; then\n    log_info \"Creating ECR Repository: $ECR_REPO\"\n    aws ecr create-repository --repository-name \"$ECR_REPO\" --region \"$REGION\"\n    log_info \"Created ECR Repository: $ECR_REPO\"\n  else\n    log_info \"ECR Repository '$ECR_REPO' already exists\"\n  fi\n\n  ECR_URI=$(aws ecr describe-repositories --repository-names \"$ECR_REPO\" --region \"$REGION\" --query 'repositories[0].repositoryUri' --output text)\n  log_info \"ECR Repository URI: $ECR_URI\"\n\n  export ECR_URI\n}\n\n# Build and push Docker image\nbuild_and_push_image() {\n  log_section \"Building and pushing Docker image\"\n\n  # Login to ECR\n  log_info \"Logging in to ECR...\"\n  aws ecr get-login-password --region \"$REGION\" | docker login --username AWS --password-stdin \"${ECR_URI%%/*}\"\n\n  # Build the Docker image\n  log_info \"Building Docker image from Dockerfile...\"\n  docker build -t \"$ECR_URI\" ../docker\n\n  # Tag the image\n  log_info \"Tagging Docker image as latest...\"\n  docker tag \"$ECR_URI\" \"$ECR_URI:latest\"\n\n  # Push the image to ECR\n  log_info \"Pushing Docker image to ECR repository...\"\n  docker push \"$ECR_URI:latest\"\n\n  log_info \"Docker image pushed to ECR: $ECR_URI:latest\"\n}\n\n# Register ECS Task Definition\nregister_task_definition() {\n  log_section \"Registering ECS Task Definition\"\n\n  # Get the caller identity for IAM role ARN\n  ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n\n  # Create the task definition with proper configuration\n  log_info \"Registering ECS Task Definition: $TASK_NAME\"\n  TASK_DEF_ARN=$(aws ecs register-task-definition --family \"$TASK_NAME\" \\\n    --network-mode awsvpc \\\n    --execution-role-arn \"arn:aws:iam::$ACCOUNT_ID:role/$IAM_ROLE\" \\\n    --requires-compatibilities FARGATE \\\n    --cpu \"$ECS_CPU\" --memory \"$ECS_MEMORY\" \\\n    --container-definitions \"[{\n        \\\"name\\\": \\\"$CONTAINER_NAME\\\",\n        \\\"image\\\": \\\"$ECR_URI:latest\\\",\n        \\\"cpu\\\": $CONTAINER_CPU,\n        \\\"memory\\\": $CONTAINER_MEMORY,\n        \\\"essential\\\": true,\n        \\\"portMappings\\\": [{\\\"containerPort\\\": $CONTAINER_PORT, \\\"hostPort\\\": $CONTAINER_PORT}],\n        \\\"logConfiguration\\\": {\n            \\\"logDriver\\\": \\\"awslogs\\\",\n            \\\"options\\\": {\n                \\\"awslogs-group\\\": \\\"$LOG_GROUP\\\",\n                \\\"awslogs-region\\\": \\\"$REGION\\\",\n                \\\"awslogs-stream-prefix\\\": \\\"ecs\\\"\n            }\n        }\n    }]\" \\\n    --region \"$REGION\" \\\n    --query 'taskDefinition.taskDefinitionArn' \\\n    --output text)\n\n  log_info \"Task Definition Registered: $TASK_DEF_ARN\"\n\n  export TASK_DEF_ARN\n}\n\n# Create ECS Service\ncreate_ecs_service() {\n  log_section \"Creating ECS Service\"\n\n  if ! resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    log_info \"Creating ECS Service: $SERVICE_NAME\"\n    aws ecs create-service --cluster \"$CLUSTER_NAME\" --service-name \"$SERVICE_NAME\" \\\n      --task-definition \"$TASK_NAME\" \\\n      --desired-count 1 --launch-type FARGATE \\\n      --network-configuration \"awsvpcConfiguration={\n          subnets=[\\\"$PUB_SUBNET_ID\\\"],\n          securityGroups=[\\\"$SEC_GROUP_ID\\\"],\n          assignPublicIp=\\\"ENABLED\\\"\n      }\" \\\n      --region \"$REGION\"\n\n    log_info \"ECS Service created: $SERVICE_NAME\"\n  else\n    log_info \"ECS Service '$SERVICE_NAME' already exists\"\n  fi\n}\n\n# Update ECS Service with new task definition\nupdate_ecs_service() {\n  log_section \"Updating ECS Service\"\n\n  if resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    log_info \"Updating ECS Service: $SERVICE_NAME\"\n    aws ecs update-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --task-definition \"$TASK_NAME\" \\\n      --force-new-deployment \\\n      --region \"$REGION\"\n\n    log_info \"ECS Service updated: $SERVICE_NAME\"\n  else\n    log_error \"ECS Service '$SERVICE_NAME' does not exist. Cannot update.\"\n    exit 1\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# RESOURCE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Delete ECS resources\ndelete_ecs_resources() {\n  log_section \"Deleting ECS Resources\"\n\n  # Delete ECS Service\n  if resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    log_info \"Updating ECS Service to 0 tasks: $SERVICE_NAME\"\n    aws ecs update-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --desired-count 0 \\\n      --region \"$REGION\"\n\n    log_info \"Waiting for service to stabilize...\"\n    aws ecs wait services-stable \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --services \"$SERVICE_NAME\" \\\n      --region \"$REGION\"\n\n    log_info \"Deleting ECS Service: $SERVICE_NAME\"\n    aws ecs delete-service \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --service \"$SERVICE_NAME\" \\\n      --force \\\n      --region \"$REGION\"\n  else\n    log_info \"ECS Service '$SERVICE_NAME' does not exist\"\n  fi\n\n  # Delete ECS Cluster\n  if resource_exists \"ecs-cluster\" \"$CLUSTER_NAME\"; then\n    log_info \"Deleting ECS Cluster: $CLUSTER_NAME\"\n    aws ecs delete-cluster \\\n      --cluster \"$CLUSTER_NAME\" \\\n      --region \"$REGION\"\n  else\n    log_info \"ECS Cluster '$CLUSTER_NAME' does not exist\"\n  fi\n\n  # Delete networking resources\n  log_info \"Deleting networking resources...\"\n  # Get the VPC ID based on the cluster name tag\n  VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=tag:Name,Values=$CLUSTER_NAME-vpc\" --query \"Vpcs[0].VpcId\" --output text --region \"$REGION\")\n\n  if [[ \"$VPC_ID\" != \"None\" && -n \"$VPC_ID\" ]]; then\n    # Get the NAT Gateway ID\n    NAT_GW_ID=$(aws ec2 describe-nat-gateways --filter \"Name=vpc-id,Values=$VPC_ID\" --query \"NatGateways[0].NatGatewayId\" --output text --region \"$REGION\")\n    if [[ \"$NAT_GW_ID\" != \"None\" && -n \"$NAT_GW_ID\" ]]; then\n      log_info \"Deleting NAT Gateway: $NAT_GW_ID\"\n      aws ec2 delete-nat-gateway --nat-gateway-id \"$NAT_GW_ID\" --region \"$REGION\"\n      # Wait for NAT Gateway to be deleted\n      aws ec2 wait nat-gateway-deleted --nat-gateway-ids \"$NAT_GW_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Elastic IP associated with the NAT Gateway\n    EIP_ALLOC_ID=$(aws ec2 describe-addresses --filter \"Name=domain,Values=vpc\" --query \"Addresses[0].AllocationId\" --output text --region \"$REGION\")\n    if [[ \"$EIP_ALLOC_ID\" != \"None\" && -n \"$EIP_ALLOC_ID\" ]]; then\n      log_info \"Releasing Elastic IP: $EIP_ALLOC_ID\"\n      aws ec2 release-address --allocation-id \"$EIP_ALLOC_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Security Group ID\n    SEC_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=group-name,Values=$SEC_GROUP_NAME\" --query \"SecurityGroups[0].GroupId\" --output text --region \"$REGION\")\n    if [[ \"$SEC_GROUP_ID\" != \"None\" && -n \"$SEC_GROUP_ID\" ]]; then\n      log_info \"Deleting Security Group: $SEC_GROUP_ID\"\n      aws ec2 delete-security-group --group-id \"$SEC_GROUP_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Subnet IDs\n    SUBNET_IDS=$(aws ec2 describe-subnets --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"Subnets[].SubnetId\" --output text --region \"$REGION\")\n    if [[ -n \"$SUBNET_IDS\" ]]; then\n      for SUBNET_ID in $SUBNET_IDS; do\n        log_info \"Deleting Subnet: $SUBNET_ID\"\n        aws ec2 delete-subnet --subnet-id \"$SUBNET_ID\" --region \"$REGION\"\n      done\n    fi\n\n    # Get the Route Table ID\n    RT_ID=$(aws ec2 describe-route-tables --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"RouteTables[0].RouteTableId\" --output text --region \"$REGION\")\n    if [[ \"$RT_ID\" != \"None\" && -n \"$RT_ID\" ]]; then\n      log_info \"Deleting Route Table: $RT_ID\"\n      aws ec2 delete-route-table --route-table-id \"$RT_ID\" --region \"$REGION\"\n    fi\n\n    # Get the Internet Gateway ID\n    IGW_ID=$(aws ec2 describe-internet-gateways --filters \"Name=attachment.vpc-id,Values=$VPC_ID\" --query \"InternetGateways[0].InternetGatewayId\" --output text --region \"$REGION\")\n    if [[ \"$IGW_ID\" != \"None\" && -n \"$IGW_ID\" ]]; then\n      log_info \"Detaching Internet Gateway from VPC: $IGW_ID\"\n      aws ec2 detach-internet-gateway --internet-gateway-id \"$IGW_ID\" --vpc-id \"$VPC_ID\" --region \"$REGION\"\n      log_info \"Deleting Internet Gateway: $IGW_ID\"\n      aws ec2 delete-internet-gateway --internet-gateway-id \"$IGW_ID\" --region \"$REGION\"\n    fi\n\n    # Finally, delete the VPC\n    log_info \"Deleting VPC: $VPC_ID\"\n    aws ec2 delete-vpc --vpc-id \"$VPC_ID\" --region \"$REGION\"\n  else\n    log_info \"VPC for cluster '$CLUSTER_NAME' not found\"\n  fi\n\n  # Delete CloudWatch Log Group\n  local log_group=\"$LOG_GROUP_PREFIX/$CLUSTER_NAME\"\n  if aws logs describe-log-groups --log-group-name-prefix \"$log_group\" --region \"$REGION\" | grep -q \"$log_group\"; then\n    log_info \"Deleting CloudWatch Log Group: $log_group\"\n    aws logs delete-log-group --log-group-name \"$log_group\" --region \"$REGION\"\n  else\n    log_info \"CloudWatch Log Group '$log_group' does not exist\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# STATUS REPORTING\n#-----------------------------------------------------------------------------\n\n# Get status of ECS resources\nget_ecs_status() {\n  log_section \"ECS Resources Status\"\n\n  # Check ECS Cluster\n  printf \"%-20s %-10s %-20s %-10s\\n\" \"CLUSTER NAME\" \"EXISTS\" \"STATUS\" \"ACTIVE SERVICES\"\n  printf \"%-20s %-10s %-20s %-10s\\n\" \"------------\" \"------\" \"------\" \"--------------\"\n\n  if resource_exists \"ecs-cluster\" \"$CLUSTER_NAME\"; then\n    local cluster_info=$(aws ecs describe-clusters --clusters \"$CLUSTER_NAME\" --region \"$REGION\" --query 'clusters[0].[status,activeServicesCount]' --output text)\n    local status=$(echo \"$cluster_info\" | cut -f1)\n    local service_count=$(echo \"$cluster_info\" | cut -f2)\n    printf \"%-20s %-10s %-20s %-10s\\n\" \"$CLUSTER_NAME\" \"Yes\" \"$status\" \"$service_count\"\n  else\n    printf \"%-20s %-10s %-20s %-10s\\n\" \"$CLUSTER_NAME\" \"No\" \"N/A\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Check ECS Service\n  printf \"%-20s %-10s %-15s %-15s %-15s\\n\" \"SERVICE NAME\" \"EXISTS\" \"STATUS\" \"RUNNING TASKS\" \"DESIRED TASKS\"\n  printf \"%-20s %-10s %-15s %-15s %-15s\\n\" \"------------\" \"------\" \"------\" \"------------\" \"-------------\"\n\n  if resource_exists \"ecs-service\" \"$SERVICE_NAME\"; then\n    local service_info=$(aws ecs describe-services --cluster \"$CLUSTER_NAME\" --services \"$SERVICE_NAME\" --region \"$REGION\" --query 'services[0].[status,runningCount,desiredCount]' --output text)\n    local status=$(echo \"$service_info\" | cut -f1)\n    local running_count=$(echo \"$service_info\" | cut -f2)\n    local desired_count=$(echo \"$service_info\" | cut -f3)\n    printf \"%-20s %-10s %-15s %-15s %-15s\\n\" \"$SERVICE_NAME\" \"Yes\" \"$status\" \"$running_count\" \"$desired_count\"\n  else\n    printf \"%-20s %-10s %-15s %-15s %-15s\\n\" \"$SERVICE_NAME\" \"No\" \"N/A\" \"N/A\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Check ECR Repository\n  printf \"%-20s %-10s %-50s\\n\" \"ECR REPOSITORY\" \"EXISTS\" \"URI\"\n  printf \"%-20s %-10s %-50s\\n\" \"--------------\" \"------\" \"---\"\n\n  if resource_exists \"ecr\" \"$ECR_REPO\"; then\n    local uri=$(aws ecr describe-repositories --repository-names \"$ECR_REPO\" --region \"$REGION\" --query 'repositories[0].repositoryUri' --output text)\n    printf \"%-20s %-10s %-50s\\n\" \"$ECR_REPO\" \"Yes\" \"$uri\"\n  else\n    printf \"%-20s %-10s %-50s\\n\" \"$ECR_REPO\" \"No\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Get the VPC ID based on the cluster name tag\n  VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=tag:Name,Values=$CLUSTER_NAME-vpc\" --query \"Vpcs[0].VpcId\" --output text --region \"$REGION\")\n\n  if [[ \"$VPC_ID\" != \"None\" && -n \"$VPC_ID\" ]]; then\n    printf \"%-20s %-10s %-30s\\n\" \"NETWORKING\" \"EXISTS\" \"ID\"\n    printf \"%-20s %-10s %-30s\\n\" \"----------\" \"------\" \"--\"\n    printf \"%-20s %-10s %-30s\\n\" \"VPC\" \"Yes\" \"$VPC_ID\"\n\n    # Get other networking components\n    SEC_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=group-name,Values=$SEC_GROUP_NAME\" --query \"SecurityGroups[0].GroupId\" --output text --region \"$REGION\")\n    [[ \"$SEC_GROUP_ID\" != \"None\" && -n \"$SEC_GROUP_ID\" ]] && printf \"%-20s %-10s %-30s\\n\" \"Security Group\" \"Yes\" \"$SEC_GROUP_ID\" || printf \"%-20s %-10s %-30s\\n\" \"Security Group\" \"No\" \"N/A\"\n\n    SUBNET_IDS=$(aws ec2 describe-subnets --filters \"Name=vpc-id,Values=$VPC_ID\" --query \"Subnets[].SubnetId\" --output text --region \"$REGION\")\n    for SUBNET_ID in $SUBNET_IDS; do\n      printf \"%-20s %-10s %-30s\\n\" \"Subnet\" \"Yes\" \"$SUBNET_ID\"\n    done\n  else\n    printf \"%-20s %-10s %-30s\\n\" \"NETWORKING\" \"EXISTS\" \"ID\"\n    printf \"%-20s %-10s %-30s\\n\" \"----------\" \"------\" \"--\"\n    printf \"%-20s %-10s %-30s\\n\" \"VPC\" \"No\" \"N/A\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# HIGH-LEVEL OPERATION FUNCTIONS\n#-----------------------------------------------------------------------------\n\n# Deploy all ECS resources\ndeploy_all() {\n  ensure_log_group\n  create_networking\n  create_ecs_cluster\n  create_ecr_repository\n  build_and_push_image\n  register_task_definition\n  create_ecs_service\n}\n\n# Update existing ECS deployment\nupdate_existing() {\n  ensure_log_group\n  create_ecr_repository\n  build_and_push_image\n  register_task_definition\n  update_ecs_service\n}\n\n#-----------------------------------------------------------------------------\n# MAIN FUNCTION\n#-----------------------------------------------------------------------------\n\n# Main function\nmain() {\n  # Parse command line arguments\n  local COMMAND=\"\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -h|--help)\n        show_help\n        ;;\n      deploy|update|delete|status)\n        COMMAND=\"$1\"\n        shift\n        ;;\n      *)\n        log_error \"Unknown option: $1\"\n        show_help\n        ;;\n    esac\n  done\n\n  # Initialize the deployment environment\n  init_deployment \"docker\"\n\n  # Execute the command\n  case \"$COMMAND\" in\n    deploy)\n      deploy_all\n      ;;\n    update)\n      update_existing\n      ;;\n    delete)\n      delete_ecs_resources\n      ;;\n    status)\n      get_ecs_status\n      ;;\n    *)\n      log_error \"No command specified\"\n      show_help\n      ;;\n  esac\n\n  # Finish the deployment\n  finish_deployment\n}\n\n# Execute main function with all arguments\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/manage-ecs.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# config.sh\n# Central configuration for the scraper and ETL pipeline infrastructure\n#=============================================================================\n\n#-----------------------------------------------------------------------------\n# CORE AWS CONFIGURATION\n#-----------------------------------------------------------------------------\n# AWS region and account details\nREGION=\"af-south-1\"\nACCOUNT_ID=\"<ACCOUNT_ID>\"\nS3_BUCKET=\"api-policy-repo\"\n\n#-----------------------------------------------------------------------------\n# LAMBDA CONFIGURATION\n#-----------------------------------------------------------------------------\n# Master Lambda (Scheduler)\n# This Lambda runs on a schedule and checks for new PDFs to process\nMASTER_LAMBDA_FUNCTION_NAME=\"MasterLambdaFunction\"\nMASTER_LAMBDA_ROLE_NAME=\"MasterLambdaRole\"\nMASTER_LAMBDA_SOURCE=\"../lambda/master/master_lambda.py\"\nMASTER_LAMBDA_ZIP=\"master_lambda.zip\"\nMASTER_LAMBDA_HANDLER=\"master_lambda.lambda_handler\"\nMASTER_LAMBDA_RUNTIME=\"python3.9\"\nMASTER_LAMBDA_TIMEOUT=60\nMASTER_LAMBDA_MEMORY=128\n\n# PDF Processor Lambda\n# This Lambda processes PDFs, extracts text, and generates embeddings\nPDF_PROCESSOR_LAMBDA_FUNCTION_NAME=\"PDFProcessorLambdaFunction\"\nPDF_PROCESSOR_LAMBDA_ROLE_NAME=\"PDFProcessorLambdaRole\"\nPDF_PROCESSOR_LAMBDA_SOURCE=\"../lambda/pdf_processor/pdf_processor_lambda.py\"\nPDF_PROCESSOR_LAMBDA_ZIP=\"pdf_processor_lambda.zip\"\nPDF_PROCESSOR_LAMBDA_HANDLER=\"pdf_processor_lambda.lambda_handler\"\nPDF_PROCESSOR_LAMBDA_RUNTIME=\"python3.9\"\nPDF_PROCESSOR_LAMBDA_TIMEOUT=300\nPDF_PROCESSOR_LAMBDA_MEMORY=512\n\n# Logs Proxy Lambda\n# This Lambda provides centralized logging for the system\nLOGS_PROXY_LAMBDA_FUNCTION_NAME=\"LogsProxyLambdaFunction\"\nLOGS_PROXY_LAMBDA_ROLE_NAME=\"LogsProxyLambdaRole\"\nLOGS_PROXY_LAMBDA_SOURCE=\"../lambda/logs_proxy/logsProxyLambda.js\"\nLOGS_PROXY_LAMBDA_ZIP=\"logsProxyLambda.zip\"\nLOGS_PROXY_LAMBDA_HANDLER=\"logsProxyLambda.handler\"\nLOGS_PROXY_LAMBDA_RUNTIME=\"nodejs14.x\"\nLOGS_PROXY_LAMBDA_TIMEOUT=60\nLOGS_PROXY_LAMBDA_MEMORY=128\n\n#-----------------------------------------------------------------------------\n# SQS CONFIGURATION\n#-----------------------------------------------------------------------------\n# Main queue for PDF processing messages\nSQS_QUEUE_NAME=\"PDFProcessingQueue\"\n# Dead Letter Queue for failed processing attempts\nDLQ_NAME=\"PDFProcessingDLQ\"\n# Number of messages to process in a batch\nSQS_BATCH_SIZE=10\n\n#-----------------------------------------------------------------------------\n# CLOUDWATCH CONFIGURATION\n#-----------------------------------------------------------------------------\n# CloudWatch rule to schedule the Master Lambda\nCLOUDWATCH_RULE_NAME=\"MasterLambdaScheduleRule\"\n# Daily at midnight UTC\nCLOUDWATCH_RULE_SCHEDULE=\"cron(0 0 * * ? *)\"\n# Prefix for CloudWatch log groups\nLOG_GROUP_PREFIX=\"/ecs\"\n\n#-----------------------------------------------------------------------------\n# ECS CONFIGURATION\n#-----------------------------------------------------------------------------\n# ECS cluster and service settings\nCLUSTER_NAME=\"scraper-cluster\"\nSERVICE_NAME=\"scraper-service\"\nTASK_NAME=\"scraper-task\"\nCONTAINER_NAME=\"scraper\"\nECR_REPO=\"scraper-code\"\n\n# Task and container resource settings\nECS_CPU=\"512\"\nECS_MEMORY=\"1024\"\nCONTAINER_CPU=\"256\"\nCONTAINER_MEMORY=\"512\"\nCONTAINER_PORT=80\n\n# IAM role for ECS task execution\nIAM_ROLE=\"APILambdaManagement\"\n\n#-----------------------------------------------------------------------------\n# NETWORKING CONFIGURATION\n#-----------------------------------------------------------------------------\n# VPC and subnet CIDR blocks\nVPC_CIDR=\"10.0.0.0/16\"\nPUBLIC_SUBNET_CIDR=\"10.0.1.0/24\"\nPRIVATE_SUBNET_CIDR=\"10.0.2.0/24\"\n# Security group name for ECS tasks\nSEC_GROUP_NAME=\"scraper-sg\"\n\n#-----------------------------------------------------------------------------\n# API KEYS AND CREDENTIALS\n#-----------------------------------------------------------------------------\n# WARNING: These should be moved to AWS Secrets Manager for production deployments\nGOVINFO_API_KEY=\"0yyvGVuCtmK28iOU1c6jYO6w0rzXVencKGQxU5o9\"\nLEGISCAN_API_KEY=\"6fac7c423da95e77575205a2b30f858f\"\nOPENEI_API_KEY=\"vpMPBsUopWqUmh33FL1ZFTIuD1LUcwiunfe5LiOq\"\nCOURTLISTENER_API_KEY=\"578d9ab5e03cafdc1ced7dfce158cd42ef60a2c7\"\nNEWSAPI_API_KEY=\"0f4bd0908be448a19534fd7c27db60dc\"\nNYT_API_KEY=\"lAVZGadEGMAvb18GkGqFvvyLn16iz9vW\"\nNEWSDATA_API_KEY=\"pub_72073d9a4c5ff9f932782d9a1f01780127c4d\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/config.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# manage-lambda.sh\n# Consolidated Lambda management script for deploying, updating, and\n# deleting Lambda functions for the ETL pipeline\n#=============================================================================\n\n# Source the common library\n# shellcheck disable=SC1091\nsource \"$(dirname \"${BASH_SOURCE[0]}\")/common-lib.sh\"\n\n# Function to display help specific to this script\nshow_help() {\n  display_help \"deploy     Deploy or update the complete Lambda infrastructure including roles,\n            queues, and functions\n  update     Update only the Lambda function code with latest changes\n  delete     Delete all Lambda functions and related resources (roles, queues, etc.)\n  status     Show the current status of Lambda functions and related resources\"\n}\n\n#-----------------------------------------------------------------------------\n# IAM ROLE FUNCTIONS\n#-----------------------------------------------------------------------------\n\n# Function to create IAM roles for Lambda functions\ncreate_iam_roles() {\n  log_section \"Creating IAM roles\"\n\n  # Master Lambda role\n  if ! resource_exists \"iam-role\" \"$MASTER_LAMBDA_ROLE_NAME\"; then\n    log_info \"Creating IAM role for Master Lambda...\"\n    MASTER_ROLE_TRUST_POLICY='{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},\n        \"Action\": \"sts:AssumeRole\"\n      }]\n    }'\n\n    MASTER_LAMBDA_ROLE_ARN=$(aws iam create-role \\\n      --role-name \"$MASTER_LAMBDA_ROLE_NAME\" \\\n      --assume-role-policy-document \"$MASTER_ROLE_TRUST_POLICY\" \\\n      --query 'Role.Arn' --output text) || { log_error \"Failed to create Master Lambda IAM role\"; exit 1; }\n\n    log_info \"Master Lambda Role ARN: $MASTER_LAMBDA_ROLE_ARN\"\n\n    MASTER_POLICY_DOCUMENT='{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"logs:CreateLogGroup\",\"logs:CreateLogStream\",\"logs:PutLogEvents\"],\n          \"Resource\": \"arn:aws:logs:'$REGION':*:*\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:ListBucket\"],\n          \"Resource\": \"arn:aws:s3:::'$S3_BUCKET'\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"sqs:SendMessage\"],\n          \"Resource\": \"*\"\n        }\n      ]\n    }'\n\n    aws iam put-role-policy \\\n      --role-name \"$MASTER_LAMBDA_ROLE_NAME\" \\\n      --policy-name \"MasterLambdaPolicy\" \\\n      --policy-document \"$MASTER_POLICY_DOCUMENT\"\n\n    log_info \"Attached policy to $MASTER_LAMBDA_ROLE_NAME\"\n  else\n    log_info \"Role $MASTER_LAMBDA_ROLE_NAME already exists\"\n    MASTER_LAMBDA_ROLE_ARN=$(aws iam get-role --role-name \"$MASTER_LAMBDA_ROLE_NAME\" --query 'Role.Arn' --output text)\n  fi\n\n  # PDF Processor Lambda role\n  if ! resource_exists \"iam-role\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\"; then\n    log_info \"Creating IAM role for PDF Processor Lambda...\"\n    PDF_PROCESSOR_ROLE_TRUST_POLICY='{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},\n        \"Action\": \"sts:AssumeRole\"\n      }]\n    }'\n\n    PDF_PROCESSOR_LAMBDA_ROLE_ARN=$(aws iam create-role \\\n      --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" \\\n      --assume-role-policy-document \"$PDF_PROCESSOR_ROLE_TRUST_POLICY\" \\\n      --query 'Role.Arn' --output text) || { log_error \"Failed to create PDF Processor Lambda IAM role\"; exit 1; }\n\n    log_info \"PDF Processor Lambda Role ARN: $PDF_PROCESSOR_LAMBDA_ROLE_ARN\"\n\n    PDF_PROCESSOR_POLICY_DOCUMENT='{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"logs:CreateLogGroup\",\"logs:CreateLogStream\",\"logs:PutLogEvents\"],\n          \"Resource\": \"arn:aws:logs:'$REGION':*:*\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:GetObject\"],\n          \"Resource\": \"arn:aws:s3:::'$S3_BUCKET'/usa/energy/content/*\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:PutObject\"],\n          \"Resource\": \"arn:aws:s3:::'$S3_BUCKET'/usa/extracted/*\"\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\n            \"sqs:ReceiveMessage\",\n            \"sqs:DeleteMessage\",\n            \"sqs:GetQueueAttributes\",\n            \"sqs:ChangeMessageVisibility\"\n          ],\n          \"Resource\": \"*\"\n        }\n      ]\n    }'\n\n    aws iam put-role-policy \\\n      --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" \\\n      --policy-name \"PDFProcessorLambdaPolicy\" \\\n      --policy-document \"$PDF_PROCESSOR_POLICY_DOCUMENT\"\n\n    log_info \"Attached policy to $PDF_PROCESSOR_LAMBDA_ROLE_NAME\"\n  else\n    log_info \"Role $PDF_PROCESSOR_LAMBDA_ROLE_NAME already exists\"\n    PDF_PROCESSOR_LAMBDA_ROLE_ARN=$(aws iam get-role --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" --query 'Role.Arn' --output text)\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# SQS QUEUE MANAGEMENT\n#-----------------------------------------------------------------------------\n\n# Function to create SQS queues\ncreate_sqs_queues() {\n  log_section \"Creating SQS queues\"\n\n  # Create DLQ (Dead Letter Queue)\n  if ! resource_exists \"sqs\" \"$DLQ_NAME\"; then\n    log_info \"Creating Dead Letter Queue (DLQ)...\"\n    DLQ_URL=$(aws sqs create-queue --queue-name \"$DLQ_NAME\" --region \"$REGION\" --output text)\n    log_info \"DLQ created: URL=$DLQ_URL\"\n  else\n    log_info \"DLQ $DLQ_NAME already exists\"\n    DLQ_URL=$(aws sqs get-queue-url --queue-name \"$DLQ_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n  fi\n\n  DLQ_ARN=$(aws sqs get-queue-attributes --queue-url \"$DLQ_URL\" --attribute-names QueueArn --region \"$REGION\" --output text | awk '{print $2}')\n  log_info \"DLQ ARN: $DLQ_ARN\"\n\n  # Create main queue with DLQ configuration\n  if ! resource_exists \"sqs\" \"$SQS_QUEUE_NAME\"; then\n    log_info \"Creating main SQS queue with DLQ configuration...\"\n    # Build the JSON mapping for the attributes from a file\n    QUEUE_ATTRS_FILE=\"sqs-attributes.json\"\n    cat > \"$QUEUE_ATTRS_FILE\" <<EOF\n{\n  \"RedrivePolicy\": \"{\\\"maxReceiveCount\\\":\\\"5\\\",\\\"deadLetterTargetArn\\\":\\\"$DLQ_ARN\\\"}\",\n  \"VisibilityTimeout\": \"320\"\n}\nEOF\n    log_info \"Using attributes file: $QUEUE_ATTRS_FILE\"\n    QUEUE_URL=$(aws sqs create-queue --queue-name \"$SQS_QUEUE_NAME\" --attributes file://\"$QUEUE_ATTRS_FILE\" --region \"$REGION\" --output text)\n    rm -f \"$QUEUE_ATTRS_FILE\"\n  else\n    log_info \"SQS queue $SQS_QUEUE_NAME already exists\"\n    QUEUE_URL=$(aws sqs get-queue-url --queue-name \"$SQS_QUEUE_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n  fi\n\n  QUEUE_ARN=$(aws sqs get-queue-attributes --queue-url \"$QUEUE_URL\" --attribute-names QueueArn --region \"$REGION\" --output text | awk '{print $2}')\n  log_info \"Main SQS queue ARN: $QUEUE_ARN\"\n}\n\n#-----------------------------------------------------------------------------\n# LAMBDA CODE PACKAGING AND DEPLOYMENT\n#-----------------------------------------------------------------------------\n\n# Package Lambda function code into ZIP archives\npackage_lambda_code() {\n  log_section \"Packaging Lambda code\"\n\n  log_info \"Packaging Master Lambda code...\"\n  zip -j \"$MASTER_LAMBDA_ZIP\" \"$MASTER_LAMBDA_SOURCE\"\n\n  log_info \"Packaging PDF Processor Lambda code...\"\n  if [[ \"$PDF_PROCESSOR_LAMBDA_SOURCE\" == *\"/\"* ]]; then\n    # Source is in a subdirectory, copy it to current directory for zipping\n    cp \"$PDF_PROCESSOR_LAMBDA_SOURCE\" .\n    local base_name=$(basename \"$PDF_PROCESSOR_LAMBDA_SOURCE\")\n    zip -j \"$PDF_PROCESSOR_LAMBDA_ZIP\" \"$base_name\"\n    rm -f \"$base_name\"\n  else\n    zip -j \"$PDF_PROCESSOR_LAMBDA_ZIP\" \"$PDF_PROCESSOR_LAMBDA_SOURCE\"\n  fi\n}\n\n# Create or update Lambda functions\ndeploy_lambda_functions() {\n  local update_only=\"${1:-false}\"\n  log_section \"Deploying Lambda functions\"\n\n  # Package Lambda code\n  package_lambda_code\n\n  # Deploy Master Lambda\n  if ! resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\" || [[ \"$update_only\" == \"false\" ]]; then\n    if resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\"; then\n      log_info \"Updating Master Lambda function...\"\n      aws lambda update-function-code \\\n        --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" \\\n        --zip-file fileb://\"$MASTER_LAMBDA_ZIP\" \\\n        --region \"$REGION\"\n    else\n      log_info \"Creating Master Lambda function...\"\n      aws lambda create-function \\\n        --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" \\\n        --runtime \"$MASTER_LAMBDA_RUNTIME\" \\\n        --role \"$MASTER_LAMBDA_ROLE_ARN\" \\\n        --handler \"$MASTER_LAMBDA_HANDLER\" \\\n        --zip-file fileb://\"$MASTER_LAMBDA_ZIP\" \\\n        --timeout \"$MASTER_LAMBDA_TIMEOUT\" \\\n        --memory-size \"$MASTER_LAMBDA_MEMORY\" \\\n        --region \"$REGION\"\n    fi\n  else\n    log_info \"Skipping Master Lambda function creation/update.\"\n  fi\n\n  # Get Master Lambda ARN\n  MASTER_LAMBDA_ARN=$(aws lambda get-function --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.FunctionArn' --output text)\n\n  # Deploy PDF Processor Lambda\n  if ! resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" || [[ \"$update_only\" == \"false\" ]]; then\n    if resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\"; then\n      log_info \"Updating PDF Processor Lambda function...\"\n      aws lambda update-function-code \\\n        --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n        --zip-file fileb://\"$PDF_PROCESSOR_LAMBDA_ZIP\" \\\n        --region \"$REGION\"\n    else\n      log_info \"Creating PDF Processor Lambda function...\"\n      aws lambda create-function \\\n        --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n        --runtime \"$PDF_PROCESSOR_LAMBDA_RUNTIME\" \\\n        --role \"$PDF_PROCESSOR_LAMBDA_ROLE_ARN\" \\\n        --handler \"$PDF_PROCESSOR_LAMBDA_HANDLER\" \\\n        --zip-file fileb://\"$PDF_PROCESSOR_LAMBDA_ZIP\" \\\n        --timeout \"$PDF_PROCESSOR_LAMBDA_TIMEOUT\" \\\n        --memory-size \"$PDF_PROCESSOR_LAMBDA_MEMORY\" \\\n        --region \"$REGION\"\n    fi\n  else\n    log_info \"Skipping PDF Processor Lambda function creation/update.\"\n  fi\n\n  # Get PDF Processor Lambda ARN\n  PDF_PROCESSOR_LAMBDA_ARN=$(aws lambda get-function --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.FunctionArn' --output text)\n\n  # Clean up ZIP files\n  rm -f \"$MASTER_LAMBDA_ZIP\" \"$PDF_PROCESSOR_LAMBDA_ZIP\"\n}\n\n#-----------------------------------------------------------------------------\n# EVENT TRIGGERING AND SCHEDULING\n#-----------------------------------------------------------------------------\n\n# Create event source mapping between SQS and PDF Processor Lambda\ncreate_event_source_mapping() {\n  log_section \"Creating event source mapping\"\n\n  # Check if there's an existing event source mapping\n  local existing_mapping=$(aws lambda list-event-source-mappings \\\n    --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n    --event-source-arn \"$QUEUE_ARN\" \\\n    --region \"$REGION\" \\\n    --query 'EventSourceMappings[0].UUID' \\\n    --output text)\n\n  if [[ \"$existing_mapping\" == \"None\" || -z \"$existing_mapping\" ]]; then\n    log_info \"Creating event source mapping for PDF Processor Lambda...\"\n    aws lambda create-event-source-mapping \\\n      --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n      --batch-size \"$SQS_BATCH_SIZE\" \\\n      --event-source-arn \"$QUEUE_ARN\" \\\n      --enabled \\\n      --region \"$REGION\"\n  else\n    log_info \"Event source mapping already exists for PDF Processor Lambda\"\n  fi\n}\n\n# Create CloudWatch Event Rule for scheduling the Master Lambda\ncreate_cloudwatch_rule() {\n  log_section \"Creating CloudWatch Event Rule\"\n\n  # Check if rule exists\n  local rule_exists=false\n  if aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" &> /dev/null; then\n    rule_exists=true\n  fi\n\n  if [[ \"$rule_exists\" == \"false\" ]]; then\n    log_info \"Creating CloudWatch Events rule to schedule Master Lambda...\"\n    RULE_ARN=$(aws events put-rule \\\n      --name \"$CLOUDWATCH_RULE_NAME\" \\\n      --schedule-expression \"$CLOUDWATCH_RULE_SCHEDULE\" \\\n      --region \"$REGION\" \\\n      --description \"Daily trigger for Master Lambda\" \\\n      --output text)\n\n    log_info \"CloudWatch rule ARN: $RULE_ARN\"\n  else\n    log_info \"CloudWatch rule $CLOUDWATCH_RULE_NAME already exists\"\n    RULE_ARN=$(aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" --query 'Arn' --output text)\n  fi\n\n  # Add permission for CloudWatch Events to invoke Master Lambda\n  log_info \"Adding permission for CloudWatch Events to invoke Master Lambda...\"\n  aws lambda add-permission \\\n    --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" \\\n    --statement-id \"AllowEventsInvokeMasterLambda\" \\\n    --action \"lambda:InvokeFunction\" \\\n    --principal events.amazonaws.com \\\n    --source-arn \"$RULE_ARN\" \\\n    --region \"$REGION\" 2>/dev/null || true\n\n  # Add CloudWatch Events target for Master Lambda\n  log_info \"Adding CloudWatch Events target for Master Lambda...\"\n  aws events put-targets \\\n    --rule \"$CLOUDWATCH_RULE_NAME\" \\\n    --targets \"Id\"=\"1\",\"Arn\"=\"$MASTER_LAMBDA_ARN\" \\\n    --region \"$REGION\"\n}\n\n# Update Lambda environment variables\nupdate_lambda_env_vars() {\n  log_section \"Updating Lambda environment variables\"\n\n  log_info \"Updating environment variables for Master Lambda...\"\n  aws lambda update-function-configuration \\\n    --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" \\\n    --environment \"Variables={S3_BUCKET=$S3_BUCKET,SQS_QUEUE_URL=$QUEUE_URL}\" \\\n    --region \"$REGION\"\n\n  log_info \"Updating environment variables for PDF Processor Lambda...\"\n  aws lambda update-function-configuration \\\n    --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \\\n    --environment \"Variables={S3_BUCKET=$S3_BUCKET}\" \\\n    --region \"$REGION\"\n}\n\n#-----------------------------------------------------------------------------\n# RESOURCE CLEANUP\n#-----------------------------------------------------------------------------\n\n# Delete Lambda functions and resources\ndelete_lambda_resources() {\n  log_section \"Deleting Lambda resources\"\n\n  # Delete CloudWatch rule\n  if aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" &> /dev/null; then\n    log_info \"Removing CloudWatch rule targets...\"\n    aws events remove-targets --rule \"$CLOUDWATCH_RULE_NAME\" --ids 1 --region \"$REGION\" || true\n\n    log_info \"Deleting CloudWatch rule...\"\n    aws events delete-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" || true\n  fi\n\n  # Delete Lambda functions\n  if resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\"; then\n    log_info \"Deleting Master Lambda function...\"\n    aws lambda delete-function --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" || true\n  fi\n\n  if resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\"; then\n    # Delete Event Source Mappings\n    local MAPPINGS=$(aws lambda list-event-source-mappings --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'EventSourceMappings[].UUID' --output text 2>/dev/null || true)\n    if [[ -n \"$MAPPINGS\" ]]; then\n      for UUID in $MAPPINGS; do\n        log_info \"Deleting event source mapping $UUID...\"\n        aws lambda delete-event-source-mapping --uuid \"$UUID\" --region \"$REGION\" || true\n      done\n    fi\n\n    log_info \"Deleting PDF Processor Lambda function...\"\n    aws lambda delete-function --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" || true\n  fi\n\n  # Delete SQS queues\n  if resource_exists \"sqs\" \"$SQS_QUEUE_NAME\"; then\n    QUEUE_URL=$(aws sqs get-queue-url --queue-name \"$SQS_QUEUE_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    log_info \"Deleting SQS queue $SQS_QUEUE_NAME...\"\n    aws sqs delete-queue --queue-url \"$QUEUE_URL\" --region \"$REGION\" || true\n  fi\n\n  if resource_exists \"sqs\" \"$DLQ_NAME\"; then\n    DLQ_URL=$(aws sqs get-queue-url --queue-name \"$DLQ_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    log_info \"Deleting SQS DLQ $DLQ_NAME...\"\n    aws sqs delete-queue --queue-url \"$DLQ_URL\" --region \"$REGION\" || true\n  fi\n\n  # Delete IAM roles and policies\n  if resource_exists \"iam-role\" \"$MASTER_LAMBDA_ROLE_NAME\"; then\n    log_info \"Deleting inline policy from $MASTER_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role-policy --role-name \"$MASTER_LAMBDA_ROLE_NAME\" --policy-name \"MasterLambdaPolicy\" || true\n\n    log_info \"Deleting IAM role $MASTER_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role --role-name \"$MASTER_LAMBDA_ROLE_NAME\" || true\n  fi\n\n  if resource_exists \"iam-role\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\"; then\n    log_info \"Deleting inline policy from $PDF_PROCESSOR_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role-policy --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" --policy-name \"PDFProcessorLambdaPolicy\" || true\n\n    log_info \"Deleting IAM role $PDF_PROCESSOR_LAMBDA_ROLE_NAME...\"\n    aws iam delete-role --role-name \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" || true\n  fi\n\n  # Clean up zip files if they exist\n  rm -f \"$MASTER_LAMBDA_ZIP\" \"$PDF_PROCESSOR_LAMBDA_ZIP\"\n\n  log_info \"Lambda resources deleted\"\n}\n\n#-----------------------------------------------------------------------------\n# STATUS REPORTING\n#-----------------------------------------------------------------------------\n\n# Get status of Lambda functions and resources\nget_lambda_status() {\n  log_section \"Lambda Resources Status\"\n\n  # Check Lambda functions\n  printf \"%-30s %-10s %-20s %-10s\\n\" \"FUNCTION NAME\" \"EXISTS\" \"LAST MODIFIED\" \"RUNTIME\"\n  printf \"%-30s %-10s %-20s %-10s\\n\" \"------------\" \"------\" \"-------------\" \"-------\"\n\n  if resource_exists \"lambda\" \"$MASTER_LAMBDA_FUNCTION_NAME\"; then\n    local info=$(aws lambda get-function --function-name \"$MASTER_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.[LastModified,Runtime]' --output text)\n    local last_modified=$(echo \"$info\" | cut -f1)\n    local runtime=$(echo \"$info\" | cut -f2)\n    printf \"%-30s %-10s %-20s %-10s\\n\" \"$MASTER_LAMBDA_FUNCTION_NAME\" \"Yes\" \"$last_modified\" \"$runtime\"\n  else\n    printf \"%-30s %-10s %-20s %-10s\\n\" \"$MASTER_LAMBDA_FUNCTION_NAME\" \"No\" \"N/A\" \"N/A\"\n  fi\n\n  if resource_exists \"lambda\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\"; then\n    local info=$(aws lambda get-function --function-name \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.[LastModified,Runtime]' --output text)\n    local last_modified=$(echo \"$info\" | cut -f1)\n    local runtime=$(echo \"$info\" | cut -f2)\n    printf \"%-30s %-10s %-20s %-10s\\n\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \"Yes\" \"$last_modified\" \"$runtime\"\n  else\n    printf \"%-30s %-10s %-20s %-10s\\n\" \"$PDF_PROCESSOR_LAMBDA_FUNCTION_NAME\" \"No\" \"N/A\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Check SQS queues\n  printf \"%-30s %-10s %-50s\\n\" \"QUEUE NAME\" \"EXISTS\" \"URL\"\n  printf \"%-30s %-10s %-50s\\n\" \"----------\" \"------\" \"---\"\n\n  if resource_exists \"sqs\" \"$SQS_QUEUE_NAME\"; then\n    local url=$(aws sqs get-queue-url --queue-name \"$SQS_QUEUE_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    printf \"%-30s %-10s %-50s\\n\" \"$SQS_QUEUE_NAME\" \"Yes\" \"$url\"\n  else\n    printf \"%-30s %-10s %-50s\\n\" \"$SQS_QUEUE_NAME\" \"No\" \"N/A\"\n  fi\n\n  if resource_exists \"sqs\" \"$DLQ_NAME\"; then\n    local url=$(aws sqs get-queue-url --queue-name \"$DLQ_NAME\" --region \"$REGION\" --query 'QueueUrl' --output text)\n    printf \"%-30s %-10s %-50s\\n\" \"$DLQ_NAME\" \"Yes\" \"$url\"\n  else\n    printf \"%-30s %-10s %-50s\\n\" \"$DLQ_NAME\" \"No\" \"N/A\"\n  fi\n\n  echo \"\"\n\n  # Check IAM roles\n  printf \"%-30s %-10s\\n\" \"IAM ROLE\" \"EXISTS\"\n  printf \"%-30s %-10s\\n\" \"--------\" \"------\"\n\n  if resource_exists \"iam-role\" \"$MASTER_LAMBDA_ROLE_NAME\"; then\n    printf \"%-30s %-10s\\n\" \"$MASTER_LAMBDA_ROLE_NAME\" \"Yes\"\n  else\n    printf \"%-30s %-10s\\n\" \"$MASTER_LAMBDA_ROLE_NAME\" \"No\"\n  fi\n\n  if resource_exists \"iam-role\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\"; then\n    printf \"%-30s %-10s\\n\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" \"Yes\"\n  else\n    printf \"%-30s %-10s\\n\" \"$PDF_PROCESSOR_LAMBDA_ROLE_NAME\" \"No\"\n  fi\n\n  echo \"\"\n\n  # Check CloudWatch rule\n  printf \"%-30s %-10s %-20s\\n\" \"CLOUDWATCH RULE\" \"EXISTS\" \"SCHEDULE\"\n  printf \"%-30s %-10s %-20s\\n\" \"---------------\" \"------\" \"--------\"\n\n  if aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" &> /dev/null; then\n    local schedule=$(aws events describe-rule --name \"$CLOUDWATCH_RULE_NAME\" --region \"$REGION\" --query 'ScheduleExpression' --output text)\n    printf \"%-30s %-10s %-20s\\n\" \"$CLOUDWATCH_RULE_NAME\" \"Yes\" \"$schedule\"\n  else\n    printf \"%-30s %-10s %-20s\\n\" \"$CLOUDWATCH_RULE_NAME\" \"No\" \"N/A\"\n  fi\n}\n\n#-----------------------------------------------------------------------------\n# HIGH-LEVEL OPERATION FUNCTIONS\n#-----------------------------------------------------------------------------\n\n# Function to deploy all Lambda resources\ndeploy_all() {\n  create_iam_roles\n  create_sqs_queues\n  deploy_lambda_functions false\n  create_event_source_mapping\n  create_cloudwatch_rule\n  update_lambda_env_vars\n}\n\n# Function to update Lambda function code only\nupdate_lambda_code() {\n  deploy_lambda_functions true\n}\n\n#-----------------------------------------------------------------------------\n# MAIN FUNCTION\n#-----------------------------------------------------------------------------\n\n# Main function\nmain() {\n  # Parse command line arguments\n  local COMMAND=\"\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -h|--help)\n        show_help\n        ;;\n      deploy|update|delete|status)\n        COMMAND=\"$1\"\n        shift\n        ;;\n      *)\n        log_error \"Unknown option: $1\"\n        show_help\n        ;;\n    esac\n  done\n\n  # Initialize the deployment environment\n  init_deployment\n\n  # Execute the command\n  case \"$COMMAND\" in\n    deploy)\n      deploy_all\n      ;;\n    update)\n      update_lambda_code\n      ;;\n    delete)\n      delete_lambda_resources\n      ;;\n    status)\n      get_lambda_status\n      ;;\n    *)\n      log_error \"No command specified\"\n      show_help\n      ;;\n  esac\n\n  # Finish the deployment\n  finish_deployment\n}\n\n# Execute main function with all arguments\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/manage-lambda.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n#=============================================================================\n# common-lib.sh\n# Common functions and utilities for all deployment and management scripts\n#=============================================================================\n\n# Source the configuration\n# shellcheck disable=SC1091\nsource \"$(dirname \"${BASH_SOURCE[0]}\")/config.sh\"\n\n#-----------------------------------------------------------------------------\n# ERROR HANDLING AND LOGGING\n#-----------------------------------------------------------------------------\n\n# Print error message in red text\nlog_error() {\n  echo -e \"\\e[31mERROR: $*\\e[0m\" >&2\n}\n\n# Print warning message in yellow text\nlog_warning() {\n  echo -e \"\\e[33mWARNING: $*\\e[0m\" >&2\n}\n\n# Print info message in green text\nlog_info() {\n  echo -e \"\\e[32mINFO: $*\\e[0m\"\n}\n\n# Print section headers in bold blue text\nlog_section() {\n  echo -e \"\\e[1;34m=== $* ===\\e[0m\"\n}\n\n# Generic error trap function that reports line numbers\ngeneric_trap() {\n  log_error \"An error occurred on line $1. Check the logs for details.\"\n  exit 1\n}\n\n# Enable error trapping to catch failures\nenable_error_trapping() {\n  trap 'generic_trap $LINENO' ERR\n}\n\n# Disable error trapping (typically at successful completion)\ndisable_error_trapping() {\n  trap - ERR\n}\n\n#-----------------------------------------------------------------------------\n# AWS AUTHENTICATION AND VALIDATION\n#-----------------------------------------------------------------------------\n\n# Configure AWS CLI with explicit credentials if provided, otherwise use environment\nconfigure_aws_cli() {\n  if [[ -n \"${AWS_ACCESS_KEY_ID:-}\" && -n \"${AWS_SECRET_ACCESS_KEY:-}\" ]]; then\n    log_info \"Using provided AWS credentials\"\n    export AWS_ACCESS_KEY_ID\n    export AWS_SECRET_ACCESS_KEY\n    export AWS_DEFAULT_REGION=\"$REGION\"\n  else\n    log_info \"Using AWS credentials from environment or profile\"\n    export AWS_DEFAULT_REGION=\"$REGION\"\n  fi\n}\n\n# Check if AWS CLI is installed\ncheck_aws_cli() {\n  if ! command -v aws &> /dev/null; then\n    log_error \"AWS CLI is not installed. Please install it first.\"\n    exit 1\n  fi\n}\n\n# Check if Docker is installed\ncheck_docker() {\n  if ! command -v docker &> /dev/null; then\n    log_error \"Docker is not installed. Please install it first.\"\n    exit 1\n  fi\n}\n\n# Test AWS credentials by making a simple API call\nvalidate_aws_credentials() {\n  log_info \"Validating AWS credentials...\"\n  if ! aws sts get-caller-identity &> /dev/null; then\n    log_error \"AWS credentials are invalid or missing. Please check your configuration.\"\n    exit 1\n  fi\n  log_info \"AWS credentials are valid.\"\n}\n\n# Wait for an AWS resource to become available with configurable timeout\nwait_for_resource() {\n  local resource_type=\"$1\"\n  local resource_id=\"$2\"\n  local max_attempts=\"${3:-30}\"\n  local delay=\"${4:-10}\"\n\n  log_info \"Waiting for $resource_type $resource_id to be available...\"\n\n  local attempts=0\n  while [ $attempts -lt \"$max_attempts\" ]; do\n    case \"$resource_type\" in\n      \"lambda\")\n        if aws lambda get-function --function-name \"$resource_id\" --region \"$REGION\" &> /dev/null; then\n          log_info \"$resource_type $resource_id is now available\"\n          return 0\n        fi\n        ;;\n      \"sqs\")\n        if aws sqs get-queue-url --queue-name \"$resource_id\" --region \"$REGION\" &> /dev/null; then\n          log_info \"$resource_type $resource_id is now available\"\n          return 0\n        fi\n        ;;\n      \"ecs-service\")\n        if aws ecs describe-services --cluster \"$ECS_CLUSTER\" --services \"$resource_id\" --region \"$REGION\" | grep -q \"\\\"status\\\": \\\"ACTIVE\\\"\"; then\n          log_info \"$resource_type $resource_id is now available\"\n          return 0\n        fi\n        ;;\n      *)\n        log_warning \"Unknown resource type: $resource_type\"\n        return 1\n        ;;\n    esac\n\n    attempts=$((attempts + 1))\n    log_info \"Waiting for $resource_type $resource_id, attempt $attempts/$max_attempts\"\n    sleep \"$delay\"\n  done\n\n  log_error \"Timed out waiting for $resource_type $resource_id\"\n  return 1\n}\n\n#-----------------------------------------------------------------------------\n# AWS RESOURCE MANAGEMENT\n#-----------------------------------------------------------------------------\n\n# Check if an AWS resource exists\n# Usage: resource_exists \"resource_type\" \"resource_id\"\n# Returns: 0 if exists, 1 if not exists, 2 if unknown resource type\nresource_exists() {\n  local resource_type=\"$1\"\n  local resource_id=\"$2\"\n\n  case \"$resource_type\" in\n    \"lambda\")\n      aws lambda get-function --function-name \"$resource_id\" --region \"$REGION\" &> /dev/null\n      ;;\n    \"sqs\")\n      aws sqs get-queue-url --queue-name \"$resource_id\" --region \"$REGION\" &> /dev/null\n      ;;\n    \"ecr\")\n      aws ecr describe-repositories --repository-names \"$resource_id\" --region \"$REGION\" &> /dev/null\n      ;;\n    \"ecs-cluster\")\n      aws ecs describe-clusters --clusters \"$resource_id\" --region \"$REGION\" | grep -q \"\\\"status\\\": \\\"ACTIVE\\\"\"\n      ;;\n    \"ecs-service\")\n      aws ecs describe-services --cluster \"$ECS_CLUSTER\" --services \"$resource_id\" --region \"$REGION\" | grep -q \"\\\"status\\\": \\\"ACTIVE\\\"\"\n      ;;\n    \"iam-role\")\n      aws iam get-role --role-name \"$resource_id\" &> /dev/null\n      ;;\n    *)\n      log_warning \"Unknown resource type: $resource_type\"\n      return 2\n      ;;\n  esac\n\n  return $?\n}\n\n#-----------------------------------------------------------------------------\n# DEPLOYMENT HELPERS\n#-----------------------------------------------------------------------------\n\n# Initialize deployment environment\n# Usage: init_deployment [\"docker\"] - Pass \"docker\" if Docker is required\ninit_deployment() {\n  check_aws_cli\n  configure_aws_cli\n  validate_aws_credentials\n  enable_error_trapping\n\n  if [[ \"$1\" == \"docker\" ]]; then\n    check_docker\n  fi\n\n  log_section \"Starting deployment process\"\n}\n\n# Complete deployment and clean up\nfinish_deployment() {\n  disable_error_trapping\n  log_section \"Deployment completed successfully\"\n}\n\n# Display script help with command list\n# Usage: display_help \"command1     Description of command1\\n  command2     Description of command2\"\ndisplay_help() {\n  local script_name=$(basename \"$0\")\n  echo \"Usage: $script_name [OPTIONS] COMMAND\"\n  echo\n  echo \"Options:\"\n  echo \"  -h, --help     Display this help message\"\n  echo\n  echo \"Commands:\"\n  echo \"  $1\"\n  echo\n  exit 0\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/scripts/common-lib.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/bash\n# update-lambda.sh\n# Exit immediately if any command fails.\nset -e\n\n# Configuration variables\nREGION=\"af-south-1\"\nACCOUNT_ID=\"<ACCOUNT_ID>\"\nREPO_NAME=\"ona-pdf-processor\"\nLAMBDA_FUNCTION_NAME=\"PDFProcessor\"\nIMAGE_TAG=\"latest\"\nIMAGE_URI=\"$ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/$REPO_NAME:$IMAGE_TAG\"\n\n# Step 1: Build the Docker image (force no-cache to ensure changes are picked up)\necho \"Building Docker image with no cache...\"\ndocker build --no-cache -t $REPO_NAME .\n\n# Step 2: Tag the image with the ECR repository URI\necho \"Tagging image as $IMAGE_URI...\"\ndocker tag $REPO_NAME:$IMAGE_TAG $IMAGE_URI\n\n# Step 3: Log in to Amazon ECR\necho \"Logging in to ECR in region $REGION...\"\naws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com\n\n# Step 4: Push the image to ECR\necho \"Pushing image to ECR...\"\ndocker push $IMAGE_URI\n\n# Step 5: Update the Lambda function to use the new image\necho \"Updating Lambda function $LAMBDA_FUNCTION_NAME with new image...\"\naws lambda update-function-code \\\n  --function-name $LAMBDA_FUNCTION_NAME \\\n  --image-uri $IMAGE_URI \\\n  --region $REGION\n\necho \"Lambda function updated successfully.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/scraping/lambda/pdf_processor/update.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Exit on error\nset -e\n\n# Load environment variables from .env file\nif [ -f .env ]; then\n    source .env\nelse\n    echo \"Error: .env file not found\"\n    exit 1\nfi\n\n# Configuration variables\nEC2_ROLE_NAME=\"fred-ec2-s3-role\"\nEVENTBRIDGE_ROLE_NAME=\"fred-eventbridge-ec2-role\"\nRULE_NAME=\"fred-daily-update-rule\"\nTEMPLATE_NAME=\"fred-daily-template\"\nS3_BUCKET=\"policy-database\"\nREGION=\"${AWS_REGION:-us-east-1}\"\nAMI_ID=\"ami-0a38b8c18f189761a\"  # Amazon Linux 2\nINSTANCE_TYPE=\"t3.small\"\nSECURITY_GROUP_NAME=\"FredProcessorSG\"\nSCHEDULE=\"cron(0 1 * * ? *)\"  # Run at 1:00 AM UTC every day\nSEED_HISTORICAL=false  # Default to not seed historical data\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n    key=\"$1\"\n    case $key in\n        --seed-historical)\n            SEED_HISTORICAL=true\n            shift\n            ;;\n        *)\n            echo \"Unknown option: $1\"\n            echo \"Usage: $0 [--seed-historical]\"\n            exit 1\n            ;;\n    esac\ndone\n\n# Store the current directory\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\necho \"Script directory: $SCRIPT_DIR\"\n\n# Check if ec2-daily-update.txt exists\nif [ ! -f \"$SCRIPT_DIR/ec2-daily-update.txt\" ]; then\n    echo \"Error: ec2-daily-update.txt file not found\"\n    exit 1\nfi\n\n# Check if daily.py and transform.py exist\nif [ ! -f \"$SCRIPT_DIR/daily.py\" ] || [ ! -f \"$SCRIPT_DIR/transform.py\" ]; then\n    echo \"Error: daily.py or transform.py files not found\"\n    exit 1\nfi\n\necho \"Starting FRED ETL EC2-based deployment...\"\n\n# Step 0: Create S3 folder structure if it doesn't exist\necho \"Setting up S3 folder structure...\"\n# Create main folder (this is a no-op if it already exists)\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"financial-metrics/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create daily folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"financial-metrics/daily/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create processed folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"financial-metrics/processed/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create failed folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"financial-metrics/failed/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create logs folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"logs/\" --content-type \"application/x-directory\" 2>/dev/null || true\n# Create scripts folder\naws s3api put-object --bucket \"$S3_BUCKET\" --key \"scripts/\" --content-type \"application/x-directory\" 2>/dev/null || true\n\n# Step 1: Upload scripts to S3\necho \"Uploading scripts to S3...\"\naws s3 cp \"$SCRIPT_DIR/daily.py\" \"s3://$S3_BUCKET/scripts/daily.py\" || true\naws s3 cp \"$SCRIPT_DIR/transform.py\" \"s3://$S3_BUCKET/scripts/transform.py\" || true\n\n# Upload search_series files to S3 if they exist\necho \"Uploading search_series files to S3...\"\nfor file in \"$SCRIPT_DIR\"/search_series*.json; do\n    if [ -f \"$file\" ]; then\n        filename=$(basename \"$file\")\n        aws s3 cp \"$file\" \"s3://$S3_BUCKET/financial-metrics/$filename\" || true\n    fi\ndone\n\n# Step 1.5: Seed historical data if requested\nif [ \"$SEED_HISTORICAL\" = true ]; then\n    echo \"Seeding historical data from FRED...\"\n\n    # Temporarily download search_series files to verify their existence\n    SEARCH_FILES_EXIST=true\n    for i in \"\" \"2\" \"3\" \"4\"; do\n        aws s3 ls \"s3://$S3_BUCKET/financial-metrics/search_series${i}.json\" &>/dev/null || SEARCH_FILES_EXIST=false\n    done\n\n    if [ \"$SEARCH_FILES_EXIST\" = false ]; then\n        echo \"Error: One or more search_series files not found in S3. Please upload them first.\"\n        exit 1\n    fi\n\n    # Create a temporary EC2 instance to run the seed process\n    echo \"Creating temporary EC2 instance for historical data seeding...\"\n\n    # Create a user data script for seeding\n    SEED_USER_DATA_FILE=\"$SCRIPT_DIR/temp_seed_user_data.txt\"\n    cat > \"$SEED_USER_DATA_FILE\" << 'EOL'\n#!/bin/bash\n\n# Log setup start\necho \"Starting FRED historical data seeding on EC2...\" > /var/log/fred-setup.log\n\n# Update the system and install dependencies\nyum update -y >> /var/log/fred-setup.log 2>&1\nyum install -y python3 python3-pip git awscli >> /var/log/fred-setup.log 2>&1\n\n# Create directory structure\nmkdir -p /home/ec2-user/fred\ncd /home/ec2-user/fred\n\n# Set proper ownership\nchown -R ec2-user:ec2-user /home/ec2-user/fred\n\n# Set environment variables in a .env file\ncat > /home/ec2-user/fred/.env << 'ENV_EOL'\nS3_BUCKET=policy-database\nAWS_REGION=us-east-1\nFRED_API_KEY=YOUR_FRED_API_KEY\nENV_EOL\n\n# Install Python dependencies\npip3 install boto3 python-dotenv requests >> /var/log/fred-setup.log 2>&1\n\n# Create the seed script\ncat > /home/ec2-user/fred/run_seed.py << 'PYTHON_EOL'\n#!/usr/bin/env python3\n\"\"\"\nFRED Historical Data Seeding Script\n\nPurpose:\n    This script seeds historical data for all economic indicators in the search_series files.\n\"\"\"\nimport os\nimport json\nimport requests\nimport boto3\nimport time\nimport logging\nfrom dotenv import load_dotenv\nfrom datetime import datetime\n\n# Load environment variables\nload_dotenv()\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('/home/ec2-user/fred/seed.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger()\n\n# AWS Configuration\nS3_BUCKET = os.getenv('S3_BUCKET')\nREGION = os.getenv('AWS_REGION')\nFRED_API_KEY = os.getenv('FRED_API_KEY')\n\ndef download_search_series():\n    \"\"\"Download search_series files from S3\"\"\"\n    s3_client = boto3.client('s3', region_name=REGION)\n    for i in [\"\", \"2\", \"3\", \"4\"]:\n        try:\n            s3_client.download_file(\n                S3_BUCKET,\n                f\"financial-metrics/search_series{i}.json\",\n                f\"search_series{i}.json\"\n            )\n            logger.info(f\"Downloaded search_series{i}.json from S3\")\n        except Exception as e:\n            logger.error(f\"Error downloading search_series{i}.json: {str(e)}\")\n\ndef extract_series_list(filename):\n    \"\"\"Extract series list from search_series file\"\"\"\n    try:\n        with open(filename, 'r') as f:\n            data = json.load(f)\n        series_list = data.get(\"seriess\", [])\n        logger.info(f\"Successfully loaded {len(series_list)} series from {filename}\")\n        return series_list\n    except Exception as e:\n        logger.error(f\"Failed to load series from {filename}: {str(e)}\")\n        return []\n\ndef get_existing_series(s3_client, bucket, prefix):\n    \"\"\"Get list of series that already exist in S3\"\"\"\n    existing_series = set()\n    try:\n        paginator = s3_client.get_paginator('list_objects_v2')\n        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n            if 'Contents' in page:\n                for obj in page['Contents']:\n                    # Extract series_id from the filename (format: series_id_*.json)\n                    filename = obj['Key'].split('/')[-1]\n                    if filename.endswith('.json'):\n                        series_id = filename.split('_')[0]\n                        existing_series.add(series_id)\n    except Exception as e:\n        logger.error(f\"Error listing existing series: {str(e)}\")\n    return existing_series\n\ndef save_response_to_file(series_id, start_date, end_date, response_json):\n    \"\"\"Save API response to local file\"\"\"\n    filename = f\"{series_id}_{start_date}_{end_date}.json\"\n    with open(filename, 'w') as f:\n        json.dump(response_json, f, indent=2)\n    return filename\n\ndef process_series(series_list, existing_series, s3_client):\n    \"\"\"Process each series in the list\"\"\"\n    base_url = \"https://api.stlouisfed.org/fred/series/observations\"\n    processed_count = 0\n    failed_count = 0\n\n    for series in series_list:\n        series_id = series.get(\"id\")\n        if not series_id:\n            continue\n\n        # Skip if series already exists\n        if series_id in existing_series:\n            logger.info(f\"Skipping series {series_id} - already exists in S3\")\n            continue\n\n        logger.info(f\"Processing series: {series_id}\")\n\n        # Get observation date range\n        obs_start = series.get(\"observation_start\", \"1900-01-01\")\n        obs_end = series.get(\"observation_end\", datetime.now().strftime(\"%Y-%m-%d\"))\n\n        # Set up API request parameters\n        params = {\n            'series_id': series_id,\n            'api_key': FRED_API_KEY,\n            'observation_start': obs_start,\n            'observation_end': obs_end,\n            'file_type': 'json'\n        }\n\n        try:\n            # Make the API request\n            response = requests.get(base_url, params=params)\n            response.raise_for_status()\n            response_json = response.json()\n\n            # Check if there are any observations\n            if response_json.get(\"observations\"):\n                # Save the response to a local file\n                local_filename = save_response_to_file(series_id, obs_start, obs_end, response_json)\n\n                # Upload to S3\n                s3_key = f\"financial-metrics/{local_filename}\"\n                s3_client.upload_file(local_filename, S3_BUCKET, s3_key)\n                logger.info(f\"Uploaded {local_filename} to S3\")\n\n                # Remove local file\n                os.remove(local_filename)\n                processed_count += 1\n                existing_series.add(series_id)\n            else:\n                logger.warning(f\"No observations found for series {series_id}\")\n\n            # Add delay to respect API rate limits\n            time.sleep(0.5)\n\n        except Exception as e:\n            failed_count += 1\n            logger.error(f\"Error processing series {series_id}: {str(e)}\")\n            continue\n\n    return processed_count, failed_count\n\ndef main():\n    \"\"\"Main function\"\"\"\n    logger.info(\"Starting FRED historical data seeding\")\n\n    # Download search_series files from S3\n    download_search_series()\n\n    # Setup S3 client\n    s3_client = boto3.client('s3', region_name=REGION)\n\n    # Get existing series\n    existing_series = get_existing_series(s3_client, S3_BUCKET, \"financial-metrics/\")\n    logger.info(f\"Found {len(existing_series)} existing series in S3\")\n\n    # Process each search series file\n    search_files = [\"search_series.json\", \"search_series2.json\", \"search_series3.json\", \"search_series4.json\"]\n\n    total_processed = 0\n    total_failed = 0\n\n    for search_file in search_files:\n        try:\n            if not os.path.exists(search_file):\n                logger.warning(f\"Search file {search_file} not found, skipping\")\n                continue\n\n            # Extract series list\n            series_list = extract_series_list(search_file)\n\n            # Process series\n            processed, failed = process_series(series_list, existing_series, s3_client)\n\n            total_processed += processed\n            total_failed += failed\n\n        except Exception as e:\n            logger.error(f\"Error processing search file {search_file}: {str(e)}\")\n            continue\n\n    # Run transform on all files\n    logger.info(\"Running transform on historical data...\")\n    try:\n        # Download transform script\n        s3_client.download_file(S3_BUCKET, \"scripts/transform.py\", \"transform.py\")\n\n        # Run transform with --prefix financial-metrics\n        os.system(\"python3 transform.py --prefix financial-metrics --debug\")\n\n        # Upload transform log\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        s3_client.upload_file(\"transform.log\", S3_BUCKET, f\"logs/transform_historical_{timestamp}.log\")\n\n    except Exception as e:\n        logger.error(f\"Error running transform on historical data: {str(e)}\")\n\n    logger.info(f\"Historical data seeding completed! Processed: {total_processed}, Failed: {total_failed}\")\n\n    # Upload seed log to S3\n    try:\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        s3_client.upload_file(\"seed.log\", S3_BUCKET, f\"logs/seed_{timestamp}.log\")\n    except Exception as e:\n        logger.error(f\"Error uploading seed log: {str(e)}\")\n\nif __name__ == \"__main__\":\n    main()\nPYTHON_EOL\n\n# Make the script executable\nchmod +x /home/ec2-user/fred/run_seed.py\nchown ec2-user:ec2-user /home/ec2-user/fred/run_seed.py\n\n# Run the seeding script\nsu - ec2-user -c \"cd /home/ec2-user/fred && python3 run_seed.py\"\n\n# Check if the script ran successfully\nRESULT=$?\nif [ $RESULT -eq 0 ]; then\n  echo \"FRED historical data seeding completed successfully\" >> /var/log/fred-setup.log\nelse\n  echo \"FRED historical data seeding failed with exit code $RESULT\" >> /var/log/fred-setup.log\nfi\n\n# Shutdown the instance after seeding is complete\nshutdown -h now\nEOL\n\n    # Encode the seeding user data script\n    SEED_USER_DATA=$(base64 -w 0 \"$SEED_USER_DATA_FILE\")\n\n    # Launch EC2 instance with the seeding user data\n    echo \"Launching EC2 instance for historical data seeding...\"\n\n    # Create a temporary security group for seeding if it doesn't exist\n    SEED_SG_NAME=\"FredSeedingSG\"\n    SEED_SG_ID=$(aws ec2 describe-security-groups --filters \"Name=group-name,Values=$SEED_SG_NAME\" --query \"SecurityGroups[0].GroupId\" --output text 2>/dev/null || echo \"\")\n    if [ \"$SEED_SG_ID\" == \"\" ] || [ \"$SEED_SG_ID\" == \"None\" ]; then\n        # Get default VPC ID\n        VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=isDefault,Values=true\" --query \"Vpcs[0].VpcId\" --output text)\n        if [ -z \"$VPC_ID\" ]; then\n            echo \"Error: No default VPC found\"\n            exit 1\n        fi\n\n        # Create security group\n        SEED_SG_ID=$(aws ec2 create-security-group --group-name \"$SEED_SG_NAME\" --description \"Security group for FRED ETL seeding\" --vpc-id \"$VPC_ID\" --query \"GroupId\" --output text)\n\n        # Add SSH access rule\n        aws ec2 authorize-security-group-ingress --group-id \"$SEED_SG_ID\" --protocol tcp --port 22 --cidr 0.0.0.0/0\n\n        echo \"Created security group: $SEED_SG_ID\"\n    else\n        echo \"Using existing security group: $SEED_SG_ID\"\n    fi\n\n    # Launch EC2 instance\n    INSTANCE_ID=$(aws ec2 run-instances \\\n        --image-id \"$AMI_ID\" \\\n        --instance-type \"$INSTANCE_TYPE\" \\\n        --security-group-ids \"$SEED_SG_ID\" \\\n        --user-data \"$SEED_USER_DATA\" \\\n        --iam-instance-profile \"Name=$EC2_ROLE_NAME\" \\\n        --tag-specifications \"ResourceType=instance,Tags=[{Key=Name,Value=FRED-Historical-Seeding}]\" \\\n        --query \"Instances[0].InstanceId\" \\\n        --output text)\n\n    echo \"Launched instance $INSTANCE_ID for historical data seeding\"\n    echo \"This process will run in the background and may take several hours to complete\"\n    echo \"You can check the status of the seeding process by monitoring the instance status\"\n    echo \"The instance will shut down automatically when seeding is complete\"\n\n    # Clean up temporary file\n    rm -f \"$SEED_USER_DATA_FILE\"\nfi\n\n# Step 2: Create IAM role for EC2 with S3 access\necho \"Creating IAM role for EC2 instances...\"\naws iam create-role --role-name \"$EC2_ROLE_NAME\" --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n        \"Action\": \"sts:AssumeRole\",\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Service\": \"ec2.amazonaws.com\"\n        }\n    }]\n}' 2>/dev/null || true\n\n# Attach S3 access policy to the EC2 role\naws iam attach-role-policy --role-name \"$EC2_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" 2>/dev/null || true\n\n# Create instance profile and add role\naws iam create-instance-profile --instance-profile-name \"$EC2_ROLE_NAME\" 2>/dev/null || true\naws iam add-role-to-instance-profile --instance-profile-name \"$EC2_ROLE_NAME\" --role-name \"$EC2_ROLE_NAME\" 2>/dev/null || true\n\n# Step 3: Create IAM role for EventBridge to launch EC2 instances\necho \"Creating IAM role for EventBridge...\"\naws iam create-role --role-name \"$EVENTBRIDGE_ROLE_NAME\" --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n        \"Action\": \"sts:AssumeRole\",\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Service\": \"events.amazonaws.com\"\n        }\n    }]\n}' 2>/dev/null || true\n\n# Attach policy to allow launching EC2 instances\naws iam put-role-policy --role-name \"$EVENTBRIDGE_ROLE_NAME\" --policy-name \"LaunchEC2Policy\" --policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n            \"Effect\": \"Allow\",\n            \"Action\": [\n            \"ec2:RunInstances\",\n            \"ec2:CreateTags\",\n            \"iam:PassRole\"\n        ],\n        \"Resource\": \"*\"\n    }]\n}' 2>/dev/null || true\n\n# Get the EventBridge role ARN\nEVENTBRIDGE_ROLE_ARN=$(aws iam get-role --role-name \"$EVENTBRIDGE_ROLE_NAME\" --query 'Role.Arn' --output text)\n\n# Step 4: Create security group for EC2 instances if it doesn't exist\necho \"Creating security group for EC2 instances...\"\nSECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=group-name,Values=$SECURITY_GROUP_NAME\" --query \"SecurityGroups[0].GroupId\" --output text 2>/dev/null || echo \"\")\nif [ \"$SECURITY_GROUP_ID\" == \"\" ] || [ \"$SECURITY_GROUP_ID\" == \"None\" ]; then\n    # Get default VPC ID\n    VPC_ID=$(aws ec2 describe-vpcs --filters \"Name=isDefault,Values=true\" --query \"Vpcs[0].VpcId\" --output text)\n    if [ -z \"$VPC_ID\" ]; then\n        echo \"Error: No default VPC found\"\n        exit 1\n    fi\n\n    # Create security group\n    SECURITY_GROUP_ID=$(aws ec2 create-security-group --group-name \"$SECURITY_GROUP_NAME\" --description \"Security group for FRED ETL EC2 instances\" --vpc-id \"$VPC_ID\" --query \"GroupId\" --output text)\n\n    # Add SSH access rule\n    aws ec2 authorize-security-group-ingress --group-id \"$SECURITY_GROUP_ID\" --protocol tcp --port 22 --cidr 0.0.0.0/0\n\n    echo \"Created security group: $SECURITY_GROUP_ID\"\nelse\n    echo \"Using existing security group: $SECURITY_GROUP_ID\"\nfi\n\n# Step 5: Get subnet ID\necho \"Getting subnet ID...\"\nSUBNET_ID=$(aws ec2 describe-subnets --filters \"Name=default-for-az,Values=true\" --query \"Subnets[0].SubnetId\" --output text)\nif [ -z \"$SUBNET_ID\" ]; then\n    echo \"Error: No default subnet found\"\n    exit 1\nfi\necho \"Using subnet: $SUBNET_ID\"\n\n# Step 6: Encode the user data script\necho \"Encoding user data script...\"\nUSER_DATA=$(base64 -w 0 \"$SCRIPT_DIR/ec2-daily-update.txt\")\n\n# Step 7: Create EC2 launch template\necho \"Creating EC2 launch template...\"\naws ec2 create-launch-template \\\n    --launch-template-name \"$TEMPLATE_NAME\" \\\n    --version-description \"Initial version\" \\\n    --launch-template-data \"{\n        \\\"ImageId\\\": \\\"$AMI_ID\\\",\n        \\\"InstanceType\\\": \\\"$INSTANCE_TYPE\\\",\n        \\\"SecurityGroupIds\\\": [\\\"$SECURITY_GROUP_ID\\\"],\n        \\\"UserData\\\": \\\"$USER_DATA\\\",\n        \\\"TagSpecifications\\\": [{\n            \\\"ResourceType\\\": \\\"instance\\\",\n            \\\"Tags\\\": [{\n                \\\"Key\\\": \\\"Name\\\",\n                \\\"Value\\\": \\\"FRED-Daily-ETL\\\"\n            }]\n        }],\n        \\\"IamInstanceProfile\\\": {\n            \\\"Name\\\": \\\"$EC2_ROLE_NAME\\\"\n        }\n    }\" 2>/dev/null || echo \"Launch template exists, updating...\"\n\n# Step 8: Create EventBridge rule\necho \"Creating EventBridge rule...\"\naws events put-rule \\\n    --name \"$RULE_NAME\" \\\n    --schedule-expression \"$SCHEDULE\" \\\n    --state ENABLED \\\n    2>/dev/null || echo \"Rule exists, updating...\"\n\n# Get the rule ARN\nRULE_ARN=$(aws events describe-rule --name \"$RULE_NAME\" --query \"Arn\" --output text)\n\n# Get the template ID\nTEMPLATE_ID=$(aws ec2 describe-launch-templates \\\n    --launch-template-names \"$TEMPLATE_NAME\" \\\n    --query \"LaunchTemplates[0].LaunchTemplateId\" \\\n    --output text)\n\n# Step 9: Create EventBridge target\necho \"Creating EventBridge target...\"\naws events put-targets \\\n    --rule \"$RULE_NAME\" \\\n    --targets \"[{\n        \\\"Id\\\": \\\"1\\\",\n        \\\"Arn\\\": \\\"arn:aws:events:$REGION::event-bus/default\\\",\n        \\\"RoleArn\\\": \\\"$EVENTBRIDGE_ROLE_ARN\\\",\n        \\\"Input\\\": \\\"{\\\\\\\"source\\\\\\\":[\\\\\\\"aws.events\\\\\\\"],\\\\\\\"detail-type\\\\\\\":[\\\\\\\"EC2 Instance Launch Request\\\\\\\"],\\\\\\\"detail\\\\\\\":{\\\\\\\"launch-template-id\\\\\\\":\\\\\\\"$TEMPLATE_ID\\\\\\\",\\\\\\\"subnet-id\\\\\\\":\\\\\\\"$SUBNET_ID\\\\\\\"}}\\\"\n    }]\" 2>/dev/null || echo \"Target updated.\"\n\necho \"Deployment completed successfully!\"\necho \"FRED ETL EC2-based daily update has been configured to run at 1:00 AM UTC every day.\"\necho \"EventBridge rule: $RULE_NAME\"\necho \"Launch template: $TEMPLATE_NAME\"\necho \"IAM roles: $EC2_ROLE_NAME, $EVENTBRIDGE_ROLE_NAME\"\necho \"S3 bucket: $S3_BUCKET\"\n\nif [ \"$SEED_HISTORICAL\" = true ]; then\n    echo \"\"\n    echo \"Historical data seeding is running in the background on instance ID: $INSTANCE_ID\"\n    echo \"You can check the progress by viewing the instance logs or monitoring the S3 bucket\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/indicators/fred/deploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n#!/bin/bash\n\n# Set your variables\nSEED_FUNCTION_NAME=\"commoditic-seed\"\nSEED_ROLE_NAME=\"commoditic-seed-role\"\nSEED_RULE_NAME=\"commoditic-seed-rule\"\nREGION=$(aws configure get region)\n\necho \"Removing seed Lambda function and related resources...\"\n\n# Delete any EventBridge rule targets associated with seed\necho \"Removing EventBridge rule targets...\"\naws events remove-targets --rule \"$SEED_RULE_NAME\" --ids \"1\" 2>/dev/null || true\n\n# Delete EventBridge rule if it exists\necho \"Removing EventBridge rule...\"\naws events delete-rule --name \"$SEED_RULE_NAME\" 2>/dev/null || true\n\n# Delete Lambda function\necho \"Deleting Lambda function: $SEED_FUNCTION_NAME\"\naws lambda delete-function --function-name \"$SEED_FUNCTION_NAME\" 2>/dev/null || true\n\n# Delete CloudWatch log group\necho \"Deleting CloudWatch log group: /aws/lambda/$SEED_FUNCTION_NAME\"\naws logs delete-log-group --log-group-name \"/aws/lambda/$SEED_FUNCTION_NAME\" 2>/dev/null || true\n\n# Delete IAM role policies\necho \"Deleting IAM role policy...\"\naws iam delete-role-policy --role-name \"$SEED_ROLE_NAME\" --policy-name \"commoditic-seed-policy\" 2>/dev/null || true\n\n# Delete IAM role\necho \"Deleting IAM role: $SEED_ROLE_NAME\"\naws iam delete-role --role-name \"$SEED_ROLE_NAME\" 2>/dev/null || true\n\necho \"Seed Lambda resources have been cleaned up!\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/indicators/commoditic/delete_seed_lambda.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Exit on error\nset -e\n\n# Default: run both seed script and ETL setup\nRUN_SEED=true\nRUN_ETL=true\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n  key=\"$1\"\n  case $key in\n    --seed)\n      RUN_SEED=true\n      RUN_ETL=false\n      shift\n      ;;\n    --etl)\n      RUN_SEED=false\n      RUN_ETL=true\n      shift\n      ;;\n    *)\n      shift\n      ;;\n  esac\ndone\n\n# Load environment variables from .env file - located in the parent directory\nif [ -f \"../.env\" ]; then\n    source \"../.env\"\nelse\n    echo \"Error: .env file not found in /RAG/indicators directory\"\n    exit 1\nfi\n\n# Configuration variables\nDAILY_FUNCTION_NAME=\"commoditic-daily-update\"\nTRANSFORM_FUNCTION_NAME=\"commoditic-transform\"\nDAILY_ROLE_NAME=\"commoditic-daily-update-role\"\nTRANSFORM_ROLE_NAME=\"commoditic-transform-role\"\nDAILY_RULE_NAME=\"commoditic-daily-update-rule\"\nTRANSFORM_RULE_NAME=\"commoditic-transform-rule\"\nSECRET_NAME=\"commoditic-api-key\"\nTRANSFORM_SCRIPT_KEY=\"financial-metrics/commoditic-transform.py\"\nS3_BUCKET=\"policy-database\"\n\n# Store the current directory\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\necho \"Script directory: $SCRIPT_DIR\"\n\n# Run seed script if requested\nif [ \"$RUN_SEED\" = true ]; then\n  echo \"Running seed script to download initial data...\"\n\n  # Create a virtual environment for the seed script\n  SEED_VENV_DIR=$(mktemp -d)\n  echo \"Created temporary directory for seed venv: $SEED_VENV_DIR\"\n\n  # Set up virtual environment\n  python3 -m venv \"$SEED_VENV_DIR/venv\"\n  source \"$SEED_VENV_DIR/venv/bin/activate\"\n\n  # Install dependencies\n  echo \"Installing dependencies in virtual environment...\"\n  pip install -r \"$SCRIPT_DIR/requirements.txt\"\n\n  # Run the seed script\n  echo \"Executing seed.py...\"\n  python \"$SCRIPT_DIR/seed.py\"\n\n  # Deactivate and clean up virtual environment\n  deactivate\n  rm -rf \"$SEED_VENV_DIR\"\n\n  echo \"Seed script completed.\"\nfi\n\n# Setup AWS infrastructure if requested\nif [ \"$RUN_ETL\" = true ]; then\n  # Create temporary directory for packaging\n  TEMP_DIR=$(mktemp -d)\n  echo \"Created temporary directory: $TEMP_DIR\"\n\n  # Copy required files to temporary directory\n  cp \"../lambdas/commoditic_daily.py\" \"$TEMP_DIR/daily.py\"\n  cp \"$SCRIPT_DIR/requirements.txt\" \"$TEMP_DIR/\"\n\n  # Install dependencies in temporary directory\n  cd \"$TEMP_DIR\"\n  pip3 install -r requirements.txt -t .\n\n  # Create ZIP file\n  zip -r \"$SCRIPT_DIR/function.zip\" .\n\n  # Clean up temporary directory\n  cd \"$SCRIPT_DIR\"\n  rm -rf \"$TEMP_DIR\"\n\n  # Create IAM roles (idempotent)\n  echo \"Creating IAM roles...\"\n  aws iam create-role --role-name \"$DAILY_ROLE_NAME\" --assume-role-policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [{\n          \"Action\": \"sts:AssumeRole\",\n          \"Effect\": \"Allow\",\n          \"Principal\": {\n              \"Service\": \"lambda.amazonaws.com\"\n          }\n      }]\n  }' 2>/dev/null || true\n\n  aws iam create-role --role-name \"$TRANSFORM_ROLE_NAME\" --assume-role-policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [{\n          \"Action\": \"sts:AssumeRole\",\n          \"Effect\": \"Allow\",\n          \"Principal\": {\n              \"Service\": \"lambda.amazonaws.com\"\n          }\n      }]\n  }' 2>/dev/null || true\n\n  # Create IAM policies (idempotent)\n  echo \"Creating IAM policies...\"\n  aws iam put-role-policy --role-name \"$DAILY_ROLE_NAME\" --policy-name \"commoditic-daily-update-policy\" --policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"s3:PutObject\",\n                  \"s3:GetObject\",\n                  \"s3:ListBucket\",\n                  \"s3:DeleteObject\"\n              ],\n              \"Resource\": [\n                  \"arn:aws:s3:::policy-database/*\",\n                  \"arn:aws:s3:::policy-database\"\n              ]\n          },\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"secretsmanager:GetSecretValue\"\n              ],\n              \"Resource\": \"arn:aws:secretsmanager:*:*:secret:commoditic-api-key-*\"\n          },\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"logs:CreateLogGroup\",\n                  \"logs:CreateLogStream\",\n                  \"logs:PutLogEvents\"\n              ],\n              \"Resource\": \"arn:aws:logs:*:*:*\"\n          }\n      ]\n  }' || true\n\n  aws iam put-role-policy --role-name \"$TRANSFORM_ROLE_NAME\" --policy-name \"commoditic-transform-policy\" --policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"s3:PutObject\",\n                  \"s3:GetObject\",\n                  \"s3:ListBucket\",\n                  \"s3:DeleteObject\"\n              ],\n              \"Resource\": [\n                  \"arn:aws:s3:::policy-database/*\",\n                  \"arn:aws:s3:::policy-database\"\n              ]\n          },\n          {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                  \"logs:CreateLogGroup\",\n                  \"logs:CreateLogStream\",\n                  \"logs:PutLogEvents\"\n              ],\n              \"Resource\": \"arn:aws:logs:*:*:*\"\n          }\n      ]\n  }' || true\n\n  # Get role ARNs\n  DAILY_ROLE_ARN=$(aws iam get-role --role-name \"$DAILY_ROLE_NAME\" --query 'Role.Arn' --output text)\n  TRANSFORM_ROLE_ARN=$(aws iam get-role --role-name \"$TRANSFORM_ROLE_NAME\" --query 'Role.Arn' --output text)\n\n  # Create or update secret (idempotent)\n  echo \"Creating/updating secret...\"\n  aws secretsmanager create-secret \\\n      --name \"$SECRET_NAME\" \\\n      --secret-string \"{\\\"COMMODITIC_API_KEY\\\":\\\"$COMMODITIC_API_KEY\\\"}\" \\\n      2>/dev/null || aws secretsmanager update-secret \\\n          --secret-id \"$SECRET_NAME\" \\\n          --secret-string \"{\\\"COMMODITIC_API_KEY\\\":\\\"$COMMODITIC_API_KEY\\\"}\"\n\n  # Create a temporary directory for transform.py\n  TRANSFORM_TEMP_DIR=$(mktemp -d)\n  echo \"Created temporary directory for transform.py: $TRANSFORM_TEMP_DIR\"\n\n  # Copy transform.py and requirements to temporary directory\n  echo \"Copying transform.py and requirements.txt to temporary directory...\"\n  cp \"$SCRIPT_DIR/transform.py\" \"$TRANSFORM_TEMP_DIR/\"\n  cp \"$SCRIPT_DIR/requirements.txt\" \"$TRANSFORM_TEMP_DIR/\"\n\n  # Install dependencies in temporary directory\n  cd \"$TRANSFORM_TEMP_DIR\"\n  pip3 install -r requirements.txt -t .\n\n  # Create ZIP file for transform function\n  echo \"Creating ZIP file for transform function...\"\n  zip -r \"$SCRIPT_DIR/transform.zip\" .\n\n  # Upload transform.zip to S3 (idempotent)\n  echo \"Uploading transform.zip to S3...\"\n  aws s3 cp \"$SCRIPT_DIR/transform.zip\" \"s3://$S3_BUCKET/$TRANSFORM_SCRIPT_KEY\" || true\n\n  cd \"$SCRIPT_DIR\"\n\n  # Clean up transform temporary directory\n  rm -rf \"$TRANSFORM_TEMP_DIR\"\n\n  # Create CloudWatch log groups (idempotent)\n  echo \"Creating CloudWatch log groups...\"\n  aws logs create-log-group --log-group-name \"/aws/lambda/$DAILY_FUNCTION_NAME\" 2>/dev/null || true\n  aws logs create-log-group --log-group-name \"/aws/lambda/$TRANSFORM_FUNCTION_NAME\" 2>/dev/null || true\n\n  # Create or update Lambda functions\n  echo \"Creating/updating Lambda functions...\"\n\n  # Check if daily function exists\n  if aws lambda get-function --function-name \"$DAILY_FUNCTION_NAME\" 2>/dev/null; then\n      echo \"Updating daily function...\"\n      aws lambda update-function-code \\\n          --function-name \"$DAILY_FUNCTION_NAME\" \\\n          --zip-file \"fileb://$SCRIPT_DIR/function.zip\"\n  else\n      echo \"Creating daily function...\"\n      aws lambda create-function \\\n          --function-name \"$DAILY_FUNCTION_NAME\" \\\n          --runtime python3.9 \\\n          --handler daily.lambda_handler \\\n          --role \"$DAILY_ROLE_ARN\" \\\n          --zip-file \"fileb://$SCRIPT_DIR/function.zip\" \\\n          --timeout 600 \\\n          --memory-size 256 \\\n          --environment \"Variables={S3_BUCKET=policy-database,SECRET_NAME=$SECRET_NAME}\"\n  fi\n\n  # Wait for a few seconds to ensure the transform.py file is available in S3\n  sleep 5\n\n  # Check if transform function exists\n  if aws lambda get-function --function-name \"$TRANSFORM_FUNCTION_NAME\" 2>/dev/null; then\n      echo \"Updating transform function...\"\n      aws lambda update-function-code \\\n          --function-name \"$TRANSFORM_FUNCTION_NAME\" \\\n          --zip-file \"fileb://$SCRIPT_DIR/transform.zip\"\n  else\n      echo \"Creating transform function...\"\n      aws lambda create-function \\\n          --function-name \"$TRANSFORM_FUNCTION_NAME\" \\\n          --runtime python3.9 \\\n          --handler transform.lambda_handler \\\n          --role \"$TRANSFORM_ROLE_ARN\" \\\n          --zip-file \"fileb://$SCRIPT_DIR/transform.zip\" \\\n          --timeout 300 \\\n          --memory-size 256 \\\n          --environment \"Variables={S3_BUCKET=policy-database,COMMODITIC_API_KEY=$COMMODITIC_API_KEY}\"\n  fi\n\n  # Get function ARNs\n  DAILY_FUNCTION_ARN=$(aws lambda get-function --function-name \"$DAILY_FUNCTION_NAME\" --query 'Configuration.FunctionArn' --output text)\n  TRANSFORM_FUNCTION_ARN=$(aws lambda get-function --function-name \"$TRANSFORM_FUNCTION_NAME\" --query 'Configuration.FunctionArn' --output text)\n\n  # Create EventBridge rules (idempotent)\n  echo \"Creating EventBridge rules...\"\n  aws events put-rule \\\n      --name \"$DAILY_RULE_NAME\" \\\n      --schedule-expression \"cron(59 23 * * ? *)\" \\\n      --state ENABLED \\\n      2>/dev/null || true\n\n  aws events put-rule \\\n      --name \"$TRANSFORM_RULE_NAME\" \\\n      --schedule-expression \"cron(0 0 * * ? *)\" \\\n      --state ENABLED \\\n      2>/dev/null || true\n\n  # Add Lambda functions as targets for EventBridge rules (idempotent)\n  echo \"Adding Lambda functions as EventBridge targets...\"\n  aws events put-targets \\\n      --rule \"$DAILY_RULE_NAME\" \\\n      --targets \"Id\"=\"1\",\"Arn\"=\"$DAILY_FUNCTION_ARN\" \\\n      2>/dev/null || true\n\n  aws events put-targets \\\n      --rule \"$TRANSFORM_RULE_NAME\" \\\n      --targets \"Id\"=\"1\",\"Arn\"=\"$TRANSFORM_FUNCTION_ARN\" \\\n      2>/dev/null || true\n\n  # Grant permission for EventBridge to invoke Lambda functions (idempotent)\n  echo \"Granting EventBridge permissions...\"\n  aws lambda remove-permission \\\n      --function-name \"$DAILY_FUNCTION_NAME\" \\\n      --statement-id \"EventBridgeInvokeFunction\" \\\n      2>/dev/null || true\n\n  aws lambda remove-permission \\\n      --function-name \"$TRANSFORM_FUNCTION_NAME\" \\\n      --statement-id \"EventBridgeInvokeFunction\" \\\n      2>/dev/null || true\n\n  aws lambda add-permission \\\n      --function-name \"$DAILY_FUNCTION_NAME\" \\\n      --statement-id \"EventBridgeInvokeFunction\" \\\n      --action \"lambda:InvokeFunction\" \\\n      --principal \"events.amazonaws.com\" \\\n      --source-arn \"arn:aws:events:$AWS_REGION:$AWS_ACCOUNT_ID:rule/$DAILY_RULE_NAME\" \\\n      2>/dev/null || true\n\n  aws lambda add-permission \\\n      --function-name \"$TRANSFORM_FUNCTION_NAME\" \\\n      --statement-id \"EventBridgeInvokeFunction\" \\\n      --action \"lambda:InvokeFunction\" \\\n      --principal \"events.amazonaws.com\" \\\n      --source-arn \"arn:aws:events:$AWS_REGION:$AWS_ACCOUNT_ID:rule/$TRANSFORM_RULE_NAME\" \\\n      2>/dev/null || true\n\n  # Clean up\n  rm \"$SCRIPT_DIR/function.zip\"\n  rm \"$SCRIPT_DIR/transform.zip\"\n\n  echo \"Deployment completed successfully!\"\n  echo \"Daily update Lambda function: $DAILY_FUNCTION_NAME\"\n  echo \"Transform Lambda function: $TRANSFORM_FUNCTION_NAME\"\n  echo \"Daily update EventBridge rule: $DAILY_RULE_NAME\"\n  echo \"Transform EventBridge rule: $TRANSFORM_RULE_NAME\"\n  echo \"IAM roles: $DAILY_ROLE_NAME, $TRANSFORM_ROLE_NAME\"\n  echo \"Secret name: $SECRET_NAME\"\n  echo \"S3 bucket: $S3_BUCKET\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/indicators/commoditic/deploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Exit on error\nset -e\n\n# Load environment variables\nsource .env\n\n# Configuration\nSTACK_NAME=\"sarb-metrics-stack\"\nREGION=\"us-east-1\"\nBUCKET_NAME=\"policy-database\"\nZIP_FILE=\"sarb_lambda.zip\"\nLAMBDA_FUNCTION_NAME=\"sarb-metrics-processor\"\nEVENT_RULE_NAME=\"sarb-metrics-schedule\"\nCLOUDWATCH_LOG_GROUP=\"/aws/lambda/sarb-metrics-processor\"\nS3_FOLDER=\"sarb-metrics\"\nROLE_NAME=\"fred-daily-update-role\"  # Using the same role as FRED deployment\n\n# Asset descriptions\nLAMBDA_DESCRIPTION=\"SARB metrics processor - Fetches and transforms data from SARB API, stores in S3\"\nEVENT_RULE_DESCRIPTION=\"Triggers SARB metrics processor daily at midnight UTC\"\nCLOUDWATCH_DESCRIPTION=\"Logs for SARB metrics processor Lambda function\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Get AWS account ID\nAWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\necho -e \"${YELLOW}Using AWS Account ID: $AWS_ACCOUNT_ID${NC}\"\n\necho -e \"${YELLOW}Starting SARB metrics deployment...${NC}\"\n\n# Create a temporary directory for packaging\nTEMP_DIR=$(mktemp -d)\necho -e \"${YELLOW}Created temporary directory: $TEMP_DIR${NC}\"\n\n# Copy required files to temporary directory\ncp seed_sarb.py transform_sarb.py requirements.txt \"$TEMP_DIR/\"\n\n# Install dependencies in temporary directory\ncd \"$TEMP_DIR\"\necho -e \"${YELLOW}Installing dependencies...${NC}\"\npip install -r requirements.txt -t .\n\n# Create deployment package\necho -e \"${YELLOW}Creating deployment package...${NC}\"\nzip -r ../$ZIP_FILE .\n\n# Clean up temporary directory\ncd ..\nrm -rf \"$TEMP_DIR\"\n\n# Create or update CloudWatch log group with description\necho -e \"${YELLOW}Setting up CloudWatch log group...${NC}\"\naws logs create-log-group \\\n    --log-group-name $CLOUDWATCH_LOG_GROUP \\\n    --region $REGION \\\n    --tags Key=Description,Value=\"$CLOUDWATCH_DESCRIPTION\" \\\n    || true\n\n# Deploy Lambda function\necho -e \"${YELLOW}Deploying Lambda function...${NC}\"\nif aws lambda get-function --function-name $LAMBDA_FUNCTION_NAME 2>/dev/null; then\n    echo \"Updating existing function...\"\n    aws lambda update-function-code \\\n        --function-name $LAMBDA_FUNCTION_NAME \\\n        --zip-file \"fileb://$ZIP_FILE\" \\\n        --region $REGION\nelse\n    echo \"Creating new function...\"\n    aws lambda create-function \\\n        --function-name $LAMBDA_FUNCTION_NAME \\\n        --runtime python3.9 \\\n        --handler seed_sarb.main \\\n        --role \"arn:aws:iam::${AWS_ACCOUNT_ID}:role/${ROLE_NAME}\" \\\n        --zip-file \"fileb://$ZIP_FILE\" \\\n        --timeout 900 \\\n        --memory-size 256 \\\n        --description \"$LAMBDA_DESCRIPTION\" \\\n        --environment Variables=\"{S3_BUCKET=$BUCKET_NAME,S3_FOLDER=$S3_FOLDER}\" \\\n        --region $REGION\nfi\n\n# Wait for function update to complete\necho -e \"${YELLOW}Waiting for function update to complete...${NC}\"\nwhile true; do\n    STATUS=$(aws lambda get-function --function-name $LAMBDA_FUNCTION_NAME --query 'Configuration.State' --output text)\n    if [ \"$STATUS\" = \"Active\" ]; then\n        break\n    fi\n    echo \"Function status: $STATUS\"\n    sleep 5\ndone\n\n# Update function configuration to set timeout\necho -e \"${YELLOW}Updating function configuration...${NC}\"\naws lambda update-function-configuration \\\n    --function-name $LAMBDA_FUNCTION_NAME \\\n    --timeout 900 \\\n    --region $REGION\n\n# Wait for configuration update to complete\necho -e \"${YELLOW}Waiting for configuration update to complete...${NC}\"\nwhile true; do\n    STATUS=$(aws lambda get-function --function-name $LAMBDA_FUNCTION_NAME --query 'Configuration.State' --output text)\n    if [ \"$STATUS\" = \"Active\" ]; then\n        break\n    fi\n    echo \"Function status: $STATUS\"\n    sleep 5\ndone\n\n# Create or update EventBridge rule with description\necho -e \"${YELLOW}Setting up EventBridge rule...${NC}\"\naws events put-rule \\\n    --name $EVENT_RULE_NAME \\\n    --description \"$EVENT_RULE_DESCRIPTION\" \\\n    --schedule-expression \"cron(0 0 * * ? *)\" \\\n    --state ENABLED \\\n    --region $REGION \\\n    || aws events put-targets \\\n        --rule $EVENT_RULE_NAME \\\n        --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:$REGION:$AWS_ACCOUNT_ID:function:$LAMBDA_FUNCTION_NAME\" \\\n        --region $REGION\n\n# Add Lambda permission for EventBridge\necho -e \"${YELLOW}Adding Lambda permission for EventBridge...${NC}\"\naws lambda add-permission \\\n    --function-name $LAMBDA_FUNCTION_NAME \\\n    --statement-id EventBridgeInvokeFunction \\\n    --action lambda:InvokeFunction \\\n    --principal events.amazonaws.com \\\n    --source-arn \"arn:aws:events:$REGION:$AWS_ACCOUNT_ID:rule/$EVENT_RULE_NAME\" \\\n    --region $REGION || true\n\n# Test the Lambda function\necho -e \"${YELLOW}Testing Lambda function...${NC}\"\naws lambda invoke \\\n    --function-name $LAMBDA_FUNCTION_NAME \\\n    --payload '{}' \\\n    response.json \\\n    --region $REGION\n\n# Wait for Lambda invocation to complete (check response.json)\necho -e \"${YELLOW}Waiting for Lambda function to complete...${NC}\"\nwhile true; do\n    if [ -f response.json ]; then\n        STATUS=$(cat response.json | jq -r '.statusCode')\n        if [ \"$STATUS\" = \"200\" ]; then\n            break\n        fi\n    fi\n    sleep 5\ndone\n\n# Wait a moment for logs to be available\nsleep 10\n\n# Get the latest log stream\necho -e \"${YELLOW}Retrieving Lambda logs...${NC}\"\nLOG_STREAM=$(aws logs describe-log-streams \\\n    --log-group-name $CLOUDWATCH_LOG_GROUP \\\n    --order-by LastEventTime \\\n    --descending \\\n    --limit 1 \\\n    --query 'logStreams[0].logStreamName' \\\n    --output text)\n\nif [ \"$LOG_STREAM\" != \"None\" ]; then\n    echo -e \"${YELLOW}Latest log stream: $LOG_STREAM${NC}\"\n    aws logs get-log-events \\\n        --log-group-name $CLOUDWATCH_LOG_GROUP \\\n        --log-stream-name \"$LOG_STREAM\" \\\n        --query 'events[*].[timestamp,message]' \\\n        --output text\nelse\n    echo -e \"${RED}No log streams found${NC}\"\nfi\n\n# Wait a moment for S3 to be updated\nsleep 10\n\n# Check if files were created in S3\necho -e \"${YELLOW}Verifying S3 output...${NC}\"\nS3_COUNT=$(aws s3 ls s3://$BUCKET_NAME/$S3_FOLDER/ | wc -l)\nif [ $S3_COUNT -gt 0 ]; then\n    echo -e \"${GREEN}Found $S3_COUNT files in s3://$BUCKET_NAME/$S3_FOLDER/${NC}\"\n\n    # Check the structure of a sample file\n    SAMPLE_FILE=$(aws s3 ls s3://$BUCKET_NAME/$S3_FOLDER/ | head -n 1 | awk '{print $4}')\n    aws s3 cp \"s3://$BUCKET_NAME/$S3_FOLDER/$SAMPLE_FILE\" sample.json\n    echo -e \"${YELLOW}Sample file structure:${NC}\"\n    cat sample.json | jq '.'\n    rm sample.json\nelse\n    echo -e \"${RED}No files found in s3://$BUCKET_NAME/$S3_FOLDER/${NC}\"\nfi\n\n# Clean up\necho -e \"${YELLOW}Cleaning up...${NC}\"\nrm $ZIP_FILE response.json\n\necho -e \"${GREEN}SARB metrics deployment completed successfully!${NC}\"\necho -e \"${YELLOW}Lambda function: $LAMBDA_FUNCTION_NAME${NC}\"\necho -e \"${YELLOW}EventBridge rule: $EVENT_RULE_NAME${NC}\"\necho -e \"${YELLOW}CloudWatch log group: $CLOUDWATCH_LOG_GROUP${NC}\"\necho -e \"${YELLOW}S3 bucket: s3://$BUCKET_NAME/$S3_FOLDER${NC}\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/indicators/sarb/deploy_sarb.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\nset -e\necho \"Starting orchestration...\"\necho \"Running redeploy2.sh...\"\nREDEPLOY2_OUTPUT=$(./redeploy2.sh)\necho \"redeploy2.sh output:\"\necho \"$REDEPLOY2_OUTPUT\"\nJOB_RUN_ID=$(echo \"$REDEPLOY2_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID\" ] || [ \"$JOB_RUN_ID\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy2.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETLJob JobRunId: $JOB_RUN_ID\"\necho \"Waiting for KnowledgeBaseETLJob to complete...\"\nwhile true; do\n  STATUS=$(aws glue get-job-run --job-name KnowledgeBaseETLJob --run-id \"$JOB_RUN_ID\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS\"\n  if [ \"$STATUS\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETLJob succeeded.\"\n    break\n  elif [[ \"$STATUS\" == \"FAILED\" || \"$STATUS\" == \"TIMEOUT\" || \"$STATUS\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETLJob ended with terminal state: $STATUS\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy3.sh...\"\nREDEPLOY3_OUTPUT=$(./redeploy3.sh)\necho \"redeploy3.sh output:\"\necho \"$REDEPLOY3_OUTPUT\"\nJOB_RUN_ID2=$(echo \"$REDEPLOY3_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID2\" ] || [ \"$JOB_RUN_ID2\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy3.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETL2ndChanceJob JobRunId: $JOB_RUN_ID2\"\necho \"Waiting for KnowledgeBaseETL2ndChanceJob to complete...\"\nwhile true; do\n  STATUS2=$(aws glue get-job-run --job-name KnowledgeBaseETL2ndChanceJob --run-id \"$JOB_RUN_ID2\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS2\"\n  if [ \"$STATUS2\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETL2ndChanceJob succeeded.\"\n    break\n  elif [[ \"$STATUS2\" == \"FAILED\" || \"$STATUS2\" == \"TIMEOUT\" || \"$STATUS2\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETL2ndChanceJob ended with terminal state: $STATUS2\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy4.sh...\"\n./redeploy4.sh\necho \"Orchestration complete.\"\necho \"Shutting down the instance now...\"\nsudo shutdown -h now\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/orchestrator.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# redeploy2.sh\n# This script uploads the updated etl-s3.py file to S3,\n# updates the Glue job configuration for \"KnowledgeBaseETLJob\",\n# and then starts a new job run immediately.\n#\n# Usage: ./redeploy2.sh\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - The updated etl-s3.py file is present in the glue directory.\n# - The Glue job \"KnowledgeBaseETLJob\" already exists.\n# - IAM role \"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\" has necessary permissions.\n#\n# Environment:\n# - S3 Bucket: policy-database\n# - Script S3 Location: s3://policy-database/etl/etl-s3.py\n# - Temp Directory: s3://policy-database/temp/\n# - Region: us-east-1\n\nset -e  # Exit immediately if any command fails\n\n# Variables\nJOB_NAME=\"KnowledgeBaseETLJob\"\nSCRIPT_LOCAL=\"../glue/etl-s3.py\"\nSCRIPT_S3=\"s3://policy-database/etl/etl-s3.py\"\nTEMP_DIR=\"s3://policy-database/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nREGION=\"us-east-1\"\n\necho \"Uploading updated script ($SCRIPT_LOCAL) to S3 ($SCRIPT_S3)...\"\naws s3 cp \"$SCRIPT_LOCAL\" \"$SCRIPT_S3\" --region \"$REGION\"\n\necho \"Updating Glue job configuration for $JOB_NAME...\"\naws glue update-job \\\n  --job-name \"$JOB_NAME\" \\\n  --job-update '{\n    \"Role\": \"'\"$ROLE\"'\",\n    \"Command\": {\n      \"Name\": \"glueetl\",\n      \"ScriptLocation\": \"'\"$SCRIPT_S3\"'\",\n      \"PythonVersion\": \"3\"\n    },\n    \"DefaultArguments\": {\n      \"--TempDir\": \"'\"$TEMP_DIR\"'\",\n      \"--job-language\": \"python\",\n      \"--additional-python-modules\": \"PyPDF2==3.0.1,pycryptodome\"\n    },\n    \"MaxRetries\": 0,\n    \"Timeout\": 2880,\n    \"MaxCapacity\": 2.0,\n    \"GlueVersion\": \"2.0\"\n  }' \\\n  --region \"$REGION\"\n\necho \"Starting a new run of the Glue job $JOB_NAME...\"\nJOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$JOB_NAME\" --region \"$REGION\")\necho \"Job run started:\"\necho \"$JOB_RUN_OUTPUT\"\n\n# CHANGELOG:\n# 1. Defined variables for job name, script location, temp directory, IAM role, and region.\n# 2. Uploaded the updated etl-s3.py file from the glue directory to S3.\n# 3. Updated the existing Glue job \"KnowledgeBaseETLJob\" via aws glue update-job:\n#    - Set the GlueVersion to \"2.0\".\n#    - Removed any deprecated parameters and used --additional-python-modules to install PyPDF2.\n# 4. Immediately started a new Glue job run with aws glue start-job-run.\n# 5. Detailed inline comments and changelog are provided for clarity and transparency.\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/redeploy2.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# setup.sh\n# This script serves as the single, comprehensive source of truth for the initial\n# infrastructure orchestration and setup for the Knowledge Base ETL system.\n# It creates all necessary AWS resources for the ETL process.\n\nset -e\n\n# Configuration Variables\nREGION=\"us-east-1\"\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nBUCKET_NAME=\"policy-database\"\nLOG_GROUP=\"/aws/etl/orchestration\"\n\n# IAM Role Names\nINSTANCE_ROLE_NAME=\"ETLInstanceRole\"\nINSTANCE_PROFILE_NAME=\"ETLInstanceProfile\"\nEVENTBRIDGE_ROLE_NAME=\"EventBridgeSSMRole\"\nLAMBDA_ROLE_NAME=\"StartEC2LambdaRole\"\nGLUE_ROLE_NAME=\"AWSGluePolicyDatabaseRole\"\n\n# Lambda function configuration\nLAMBDA_FUNCTION_NAME=\"StartEC2InstanceFunction\"\nETL_LAMBDA_NAME=\"etl-orchestration-etl\"\n\n# EC2 Instance configuration\nAMI_ID=\"ami-0c2b8ca1dad447f8a\"  # Amazon Linux 2 in us-east-1\nINSTANCE_TYPE=\"t2.micro\"\nSECURITY_GROUP_NAME=\"ETLInstanceSG\"\n\n# EventBridge rules and schedule\nCRON_EXPRESSION=\"cron(0 2 * * ? *)\"  # Daily at 2:00 AM UTC\nRULE_INSTANCE_STATE=\"InstanceRunningRule\"\n\n# Glue Job Names\nMAIN_JOB_NAME=\"KnowledgeBaseETLJob\"\nSECOND_CHANCE_JOB_NAME=\"KnowledgeBaseETL2ndChanceJob\"\nREHOME_JOB_NAME=\"KnowledgeBaseETLRehomeJob\"\n\n# Function to log messages with colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date '+%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date '+%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\n# Utility function to check if a resource exists\nresource_exists() {\n  TYPE=\"$1\"\n  NAME=\"$2\"\n  case \"$TYPE\" in\n    role)\n      if aws iam get-role --role-name \"$NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n        return 0\n      fi ;;\n    instance-profile)\n      if aws iam get-instance-profile --instance-profile-name \"$NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n        return 0\n      fi ;;\n    lambda)\n      if aws lambda get-function --function-name \"$NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n        return 0\n      fi ;;\n    glue-job)\n      if aws glue get-job --job-name \"$NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n        return 0\n      fi ;;\n    *)\n      return 1 ;;\n  esac\n  return 1\n}\n\n# Function to wait for IAM role propagation\nwait_for_propagation() {\n  DELAY=${1:-10}\n  log \"Waiting for $DELAY seconds for IAM role propagation...\"\n  sleep \"$DELAY\"\n}\n\n# Main setup starts here\nlog \"Starting Knowledge Base ETL infrastructure setup...\"\n\n# Create S3 bucket if it doesn't exist\nlog \"Checking for S3 bucket $BUCKET_NAME...\"\nif ! aws s3api head-bucket --bucket \"$BUCKET_NAME\" 2>/dev/null; then\n  log \"Creating S3 bucket $BUCKET_NAME...\"\n  aws s3api create-bucket --bucket \"$BUCKET_NAME\" --region \"$REGION\"\nelse\n  log \"S3 bucket $BUCKET_NAME already exists.\"\nfi\n\n# Create CloudWatch Log Group\nlog \"Checking for CloudWatch Log Group $LOG_GROUP...\"\nif aws logs describe-log-groups --log-group-name-prefix \"$LOG_GROUP\" --region \"$REGION\" | grep -q \"$LOG_GROUP\"; then\n  log \"Log group $LOG_GROUP already exists.\"\nelse\n  log \"Creating log group $LOG_GROUP...\"\n  aws logs create-log-group --log-group-name \"$LOG_GROUP\" --region \"$REGION\"\nfi\n\n# Create IAM role for Glue\nlog \"Creating IAM role for Glue jobs ($GLUE_ROLE_NAME)...\"\nif resource_exists role \"$GLUE_ROLE_NAME\"; then\n  log \"IAM role $GLUE_ROLE_NAME already exists.\"\nelse\n  # Create Glue trust policy file\n  cat > glue-trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"glue.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  # Create Glue role\n  aws iam create-role --role-name \"$GLUE_ROLE_NAME\" --assume-role-policy-document file://glue-trust-policy.json --region \"$REGION\"\n\n  # Create and attach S3 policy for Glue\n  cat > glue-s3-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:*\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::$BUCKET_NAME\",\n        \"arn:aws:s3:::$BUCKET_NAME/*\"\n      ]\n    }\n  ]\n}\nEOF\n\n  aws iam put-role-policy --role-name \"$GLUE_ROLE_NAME\" --policy-name \"GlueS3Policy\" --policy-document file://glue-s3-policy.json --region \"$REGION\"\n\n  # Attach AWS managed policies for Glue\n  aws iam attach-role-policy --role-name \"$GLUE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole\" --region \"$REGION\"\n  aws iam attach-role-policy --role-name \"$GLUE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/CloudWatchLogsFullAccess\" --region \"$REGION\"\nfi\n\n# Add CloudWatch Logs access for the Glue role\nlog \"Adding CloudWatch Logs access to $GLUE_ROLE_NAME...\"\ncat > glue-cloudwatch-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"logs:FilterLogEvents\",\n        \"logs:DescribeLogStreams\",\n        \"logs:GetLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:$REGION:$ACCOUNT_ID:log-group:/aws-glue/jobs/output:*\"\n    }\n  ]\n}\nEOF\n\naws iam put-role-policy --role-name \"$GLUE_ROLE_NAME\" --policy-name \"GlueCloudWatchLogAccessPolicy\" --policy-document file://glue-cloudwatch-policy.json --region \"$REGION\"\n\n# Create IAM role for EC2 instance\nlog \"Creating IAM role for EC2 instance ($INSTANCE_ROLE_NAME)...\"\nif resource_exists role \"$INSTANCE_ROLE_NAME\"; then\n  log \"IAM role $INSTANCE_ROLE_NAME already exists.\"\nelse\n  # Create EC2 trust policy file\n  cat > ec2-trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  # Create EC2 role\n  aws iam create-role --role-name \"$INSTANCE_ROLE_NAME\" --assume-role-policy-document file://ec2-trust-policy.json --region \"$REGION\"\n\n  # Attach AWS managed policies for EC2 instance\n  aws iam attach-role-policy --role-name \"$INSTANCE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\" --region \"$REGION\"\n  aws iam attach-role-policy --role-name \"$INSTANCE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\" --region \"$REGION\"\n  aws iam attach-role-policy --role-name \"$INSTANCE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/AWSGlueConsoleFullAccess\" --region \"$REGION\"\n  aws iam attach-role-policy --role-name \"$INSTANCE_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy\" --region \"$REGION\"\nfi\n\n# Create instance profile and attach role\nlog \"Creating instance profile $INSTANCE_PROFILE_NAME...\"\nif resource_exists instance-profile \"$INSTANCE_PROFILE_NAME\"; then\n  log \"Instance profile $INSTANCE_PROFILE_NAME already exists.\"\nelse\n  aws iam create-instance-profile --instance-profile-name \"$INSTANCE_PROFILE_NAME\" --region \"$REGION\"\nfi\n\n# Check if role is already attached to instance profile\nEXISTING_ROLE=$(aws iam get-instance-profile --instance-profile-name \"$INSTANCE_PROFILE_NAME\" --region \"$REGION\" --query 'InstanceProfile.Roles[0].RoleName' --output text 2>/dev/null || echo \"None\")\nif [ \"$EXISTING_ROLE\" = \"$INSTANCE_ROLE_NAME\" ]; then\n  log \"Role $INSTANCE_ROLE_NAME already attached to instance profile $INSTANCE_PROFILE_NAME.\"\nelse\n  log \"Attaching role $INSTANCE_ROLE_NAME to instance profile $INSTANCE_PROFILE_NAME...\"\n  aws iam add-role-to-instance-profile --instance-profile-name \"$INSTANCE_PROFILE_NAME\" --role-name \"$INSTANCE_ROLE_NAME\" --region \"$REGION\"\nfi\n\nwait_for_propagation 10\n\n# Create security group for EC2 instance\nlog \"Creating security group for EC2 instance...\"\nDEFAULT_VPC_ID=$(aws ec2 describe-vpcs --filters Name=isDefault,Values=true --query \"Vpcs[0].VpcId\" --output text --region \"$REGION\")\nlog \"Default VPC ID: $DEFAULT_VPC_ID\"\n\nSECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters \"Name=group-name,Values=$SECURITY_GROUP_NAME\" \"Name=vpc-id,Values=$DEFAULT_VPC_ID\" --query \"SecurityGroups[0].GroupId\" --output text --region \"$REGION\" 2>/dev/null || echo \"None\")\nif [ \"$SECURITY_GROUP_ID\" = \"None\" ] || [ -z \"$SECURITY_GROUP_ID\" ]; then\n  log \"Creating security group $SECURITY_GROUP_NAME...\"\n  SECURITY_GROUP_ID=$(aws ec2 create-security-group --group-name \"$SECURITY_GROUP_NAME\" --description \"Security group for ETL instance\" --vpc-id \"$DEFAULT_VPC_ID\" --query 'GroupId' --output text --region \"$REGION\")\n  log \"Security Group ID: $SECURITY_GROUP_ID\"\n  aws ec2 authorize-security-group-ingress --group-id \"$SECURITY_GROUP_ID\" --protocol tcp --port 22 --cidr 0.0.0.0/0 --region \"$REGION\"\nelse\n  log \"Security group $SECURITY_GROUP_NAME already exists with ID $SECURITY_GROUP_ID.\"\nfi\n\n# Create IAM role for EventBridge\nlog \"Creating IAM role for EventBridge ($EVENTBRIDGE_ROLE_NAME)...\"\nif resource_exists role \"$EVENTBRIDGE_ROLE_NAME\"; then\n  log \"IAM role $EVENTBRIDGE_ROLE_NAME already exists.\"\nelse\n  # Create EventBridge trust policy file\n  cat > eventbridge-trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"events.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  # Create EventBridge role\n  aws iam create-role --role-name \"$EVENTBRIDGE_ROLE_NAME\" --assume-role-policy-document file://eventbridge-trust-policy.json --region \"$REGION\"\n\n  # Create and attach policy for SSM commands\n  cat > eventbridge-ssm-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"ssm:SendCommand\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n\n  aws iam put-role-policy --role-name \"$EVENTBRIDGE_ROLE_NAME\" --policy-name \"SendCommandPolicy\" --policy-document file://eventbridge-ssm-policy.json --region \"$REGION\"\nfi\n\n# Create IAM role for Lambda function\nlog \"Creating IAM role for Lambda function ($LAMBDA_ROLE_NAME)...\"\nif resource_exists role \"$LAMBDA_ROLE_NAME\"; then\n  log \"IAM role $LAMBDA_ROLE_NAME already exists.\"\nelse\n  # Create Lambda trust policy file\n  cat > lambda-trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  # Create Lambda role\n  aws iam create-role --role-name \"$LAMBDA_ROLE_NAME\" --assume-role-policy-document file://lambda-trust-policy.json --region \"$REGION\"\n\n  # Attach AWS managed policies for Lambda\n  aws iam attach-role-policy --role-name \"$LAMBDA_ROLE_NAME\" --policy-arn \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\" --region \"$REGION\"\nfi\n\nwait_for_propagation 10\n\n# Define EC2 user data script\nlog \"Creating EC2 user data script...\"\nUSER_DATA=$(cat <<'EOF'\n#!/bin/bash\n# Redirect all output to /var/log/orchestration.log for debugging\ntouch /var/log/orchestration.log\nchmod 644 /var/log/orchestration.log\nexec > >(tee -a /var/log/orchestration.log) 2>&1\nset -x\n# Update packages and install aws-cli, jq, and the CloudWatch Agent.\nyum update -y\nyum install -y aws-cli jq amazon-cloudwatch-agent\n# Configure CloudWatch Agent.\ncat <<'CWCONFIG' > /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json\n{\n  \"logs\": {\n    \"logs_collected\": {\n      \"files\": {\n        \"collect_list\": [\n          {\n            \"file_path\": \"/var/log/orchestration.log\",\n            \"log_group_name\": \"/aws/etl/orchestration\",\n            \"log_stream_name\": \"{instance_id}\"\n          }\n        ]\n      }\n    }\n  }\n}\nCWCONFIG\n/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json -s\n# Change to ec2-user home directory.\ncd /home/ec2-user\n# Download redeploy scripts from S3.\naws s3 cp s3://policy-database/etl/scripts/redeploy2.sh ./redeploy2.sh --region us-east-1\naws s3 cp s3://policy-database/etl/scripts/redeploy3.sh ./redeploy3.sh --region us-east-1\naws s3 cp s3://policy-database/etl/scripts/redeploy4.sh ./redeploy4.sh --region us-east-1\nchmod +x redeploy2.sh redeploy3.sh redeploy4.sh\n# Create orchestrator.sh.\ncat <<'EOS' > orchestrator.sh\n#!/bin/bash\nset -e\necho \"Starting orchestration...\"\necho \"Running redeploy2.sh...\"\nREDEPLOY2_OUTPUT=$(./redeploy2.sh)\necho \"redeploy2.sh output:\"\necho \"$REDEPLOY2_OUTPUT\"\nJOB_RUN_ID=$(echo \"$REDEPLOY2_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID\" ] || [ \"$JOB_RUN_ID\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy2.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETLJob JobRunId: $JOB_RUN_ID\"\necho \"Waiting for KnowledgeBaseETLJob to complete...\"\nwhile true; do\n  STATUS=$(aws glue get-job-run --job-name KnowledgeBaseETLJob --run-id \"$JOB_RUN_ID\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS\"\n  if [ \"$STATUS\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETLJob succeeded.\"\n    break\n  elif [[ \"$STATUS\" == \"FAILED\" || \"$STATUS\" == \"TIMEOUT\" || \"$STATUS\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETLJob ended with terminal state: $STATUS\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy3.sh...\"\nREDEPLOY3_OUTPUT=$(./redeploy3.sh)\necho \"redeploy3.sh output:\"\necho \"$REDEPLOY3_OUTPUT\"\nJOB_RUN_ID2=$(echo \"$REDEPLOY3_OUTPUT\" | jq -r '.JobRunId')\nif [ -z \"$JOB_RUN_ID2\" ] || [ \"$JOB_RUN_ID2\" == \"null\" ]; then\n  echo \"Error: Could not extract JobRunId from redeploy3.sh output.\"\n  exit 1\nfi\necho \"KnowledgeBaseETL2ndChanceJob JobRunId: $JOB_RUN_ID2\"\necho \"Waiting for KnowledgeBaseETL2ndChanceJob to complete...\"\nwhile true; do\n  STATUS2=$(aws glue get-job-run --job-name KnowledgeBaseETL2ndChanceJob --run-id \"$JOB_RUN_ID2\" --query 'JobRun.JobRunState' --output text)\n  echo \"Current status: $STATUS2\"\n  if [ \"$STATUS2\" == \"SUCCEEDED\" ]; then\n    echo \"KnowledgeBaseETL2ndChanceJob succeeded.\"\n    break\n  elif [[ \"$STATUS2\" == \"FAILED\" || \"$STATUS2\" == \"TIMEOUT\" || \"$STATUS2\" == \"STOPPED\" ]]; then\n    echo \"KnowledgeBaseETL2ndChanceJob ended with terminal state: $STATUS2\"\n    exit 1\n  fi\n  sleep 60\ndone\necho \"Running redeploy4.sh...\"\n./redeploy4.sh\necho \"Orchestration complete.\"\necho \"Shutting down the instance now...\"\nsudo shutdown -h now\nEOS\nchmod +x orchestrator.sh\necho \"User data initialization complete. orchestrator.sh and redeploy scripts are ready.\"\nEOF\n\n# Launch EC2 instance\nlog \"Launching EC2 instance...\"\nINSTANCE_ID=$(aws ec2 run-instances \\\n  --image-id \"$AMI_ID\" \\\n  --instance-type \"$INSTANCE_TYPE\" \\\n  --iam-instance-profile Name=\"$INSTANCE_PROFILE_NAME\" \\\n  --security-group-ids \"$SECURITY_GROUP_ID\" \\\n  --user-data \"$USER_DATA\" \\\n  --query 'Instances[0].InstanceId' --output text --region \"$REGION\")\n\nlog \"Launched EC2 Instance ID: $INSTANCE_ID\"\naws ec2 create-tags --resources \"$INSTANCE_ID\" --tags Key=Name,Value=ETL-Orchestration-Instance --region \"$REGION\"\n\n# Create Lambda function for starting the EC2 instance\nlog \"Creating Lambda function code...\"\nmkdir -p lambda_code\ncat > lambda_code/start_instance.py <<EOF\nimport boto3\nimport os\n\ndef lambda_handler(event, context):\n    instance_id = os.environ.get('INSTANCE_ID')\n    if not instance_id:\n        return {\"error\": \"INSTANCE_ID environment variable not set\"}\n    ec2 = boto3.client('ec2', region_name=os.environ.get('AWS_REGION', 'us-east-1'))\n    response = ec2.start_instances(InstanceIds=[instance_id])\n    return response\nEOF\n\ncd lambda_code\nzip -q start_instance.zip start_instance.py\ncd ..\n\nlog \"Creating Lambda function $LAMBDA_FUNCTION_NAME...\"\nif resource_exists lambda \"$LAMBDA_FUNCTION_NAME\"; then\n  log \"Lambda function $LAMBDA_FUNCTION_NAME already exists.\"\nelse\n  LAMBDA_ROLE_ARN=$(aws iam get-role --role-name \"$LAMBDA_ROLE_NAME\" --region \"$REGION\" --query 'Role.Arn' --output text)\n  aws lambda create-function \\\n    --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n    --runtime python3.8 \\\n    --role \"$LAMBDA_ROLE_ARN\" \\\n    --handler start_instance.lambda_handler \\\n    --zip-file fileb://lambda_code/start_instance.zip \\\n    --region \"$REGION\"\nfi\n\n# Update Lambda environment with instance ID\nlog \"Updating Lambda environment variables...\"\naws lambda update-function-configuration \\\n  --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n  --environment \"Variables={INSTANCE_ID=${INSTANCE_ID}}\" \\\n  --region \"$REGION\"\n\n# Create Lambda permissions for EC2 instance\ncat > lambda-ec2-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"ec2:StartInstances\",\n      \"Resource\": \"arn:aws:ec2:${REGION}:${ACCOUNT_ID}:instance/${INSTANCE_ID}\"\n    }\n  ]\n}\nEOF\n\naws iam put-role-policy \\\n  --role-name \"$LAMBDA_ROLE_NAME\" \\\n  --policy-name \"StartInstancePolicy\" \\\n  --policy-document file://lambda-ec2-policy.json \\\n  --region \"$REGION\"\n\n# Create EventBridge scheduled rule for starting the instance\nlog \"Creating EventBridge scheduled rule...\"\nSCHEDULED_RULE_NAME=\"StartInstanceScheduleRule\"\nif aws events describe-rule --name \"$SCHEDULED_RULE_NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n  log \"EventBridge rule $SCHEDULED_RULE_NAME already exists.\"\nelse\n  aws events put-rule \\\n    --name \"$SCHEDULED_RULE_NAME\" \\\n    --schedule-expression \"$CRON_EXPRESSION\" \\\n    --region \"$REGION\"\nfi\n\n# Add Lambda as target for the scheduled rule\nLAMBDA_FUNCTION_ARN=$(aws lambda get-function --function-name \"$LAMBDA_FUNCTION_NAME\" --region \"$REGION\" --query 'Configuration.FunctionArn' --output text)\naws events put-targets \\\n  --rule \"$SCHEDULED_RULE_NAME\" \\\n  --targets \"Id=1,Arn=$LAMBDA_FUNCTION_ARN\" \\\n  --region \"$REGION\"\n\n# Add permission for EventBridge to invoke Lambda\naws lambda add-permission \\\n  --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n  --statement-id \"EventBridgeInvoke\" \\\n  --action \"lambda:InvokeFunction\" \\\n  --principal events.amazonaws.com \\\n  --source-arn \"$(aws events describe-rule --name $SCHEDULED_RULE_NAME --region $REGION --query 'Arn' --output text)\" \\\n  --region \"$REGION\"\n\n# Create EventBridge rule for instance state changes\nlog \"Creating EventBridge rule for instance state changes...\"\ncat > instance-state-pattern.json <<EOF\n{\n  \"source\": [\"aws.ec2\"],\n  \"detail-type\": [\"EC2 Instance State-change Notification\"],\n  \"detail\": {\n    \"instance-id\": [\"$INSTANCE_ID\"],\n    \"state\": [\"running\"]\n  }\n}\nEOF\n\nif aws events describe-rule --name \"$RULE_INSTANCE_STATE\" --region \"$REGION\" >/dev/null 2>&1; then\n  log \"EventBridge rule $RULE_INSTANCE_STATE already exists.\"\nelse\n  aws events put-rule \\\n    --name \"$RULE_INSTANCE_STATE\" \\\n    --event-pattern file://instance-state-pattern.json \\\n    --region \"$REGION\"\nfi\n\n# Create SSM command input for EventBridge rule\ncat > ssm-input.json <<EOF\n{\n  \"InstanceIds\": [\"$INSTANCE_ID\"],\n  \"DocumentName\": \"AWS-RunShellScript\",\n  \"Parameters\": {\n    \"commands\": [\"/home/ec2-user/orchestrator.sh\"]\n  }\n}\nEOF\n\n# Add SSM command target to EventBridge rule\nEB_ROLE_ARN=$(aws iam get-role --role-name \"$EVENTBRIDGE_ROLE_NAME\" --region \"$REGION\" --query 'Role.Arn' --output text)\naws events put-targets \\\n  --rule \"$RULE_INSTANCE_STATE\" \\\n  --targets \"Id=1,Arn=arn:aws:ssm:${REGION}:${ACCOUNT_ID}:document/AWS-RunShellScript,RoleArn=$EB_ROLE_ARN,Input=$(cat ssm-input.json | jq -c .)\" \\\n  --region \"$REGION\"\n\n# Clean up temporary files\nlog \"Cleaning up temporary files...\"\nrm -f glue-trust-policy.json glue-s3-policy.json glue-cloudwatch-policy.json\nrm -f ec2-trust-policy.json eventbridge-trust-policy.json eventbridge-ssm-policy.json\nrm -f lambda-trust-policy.json lambda-ec2-policy.json\nrm -f instance-state-pattern.json ssm-input.json\nrm -rf lambda_code\n\nlog \"Infrastructure setup completed successfully. Now you can run the individual redeploy scripts to deploy and update the ETL jobs.\"\nlog \"Next steps:\"\nlog \"1. Upload your ETL scripts to S3 bucket: $BUCKET_NAME\"\nlog \"2. Run the redeploy scripts to create and configure Glue jobs:\"\nlog \"   - ./scripts/redeploy2.sh for the main ETL job\"\nlog \"   - ./scripts/redeploy3.sh for the 2nd chance ETL job\"\nlog \"   - ./scripts/redeploy4.sh for the rehoming ETL job\"\nlog \"3. The EC2 instance with ID $INSTANCE_ID has been created and will automatically:\"\nlog \"   - Download the redeploy scripts from S3\"\nlog \"   - Create and run the orchestrator.sh script when started\"\nlog \"   - Start daily at $CRON_EXPRESSION via the EventBridge rule\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/setup.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# redeploy4.sh\n# This script uploads the rehoming_etl.py file to S3,\n# creates/updates the Glue job configuration for \"KnowledgeBaseETLRehomeJob\",\n# updates the IAM role to include permissions to query CloudWatch logs (logs:FilterLogEvents,\n# logs:DescribeLogStreams, and logs:GetLogEvents),\n# and then starts a new job run immediately.\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - The updated rehoming_etl.py file is present in the glue directory.\n# - The Glue job \"KnowledgeBaseETLRehomeJob\" will be created if it does not exist.\n# - IAM role \"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\" has permissions\n#   to update its inline policies.\n#\n# Environment:\n# - S3 Bucket: policy-database\n# - Script S3 Location: s3://policy-database/etl/rehoming_etl.py\n# - Temp Directory: s3://policy-database/temp/\n# - Region: us-east-1\n\nset -e  # Exit immediately if any command fails\n\n# Variables\nJOB_NAME=\"KnowledgeBaseETLRehomeJob\"\nSCRIPT_LOCAL=\"../glue/rehoming_etl.py\"\nSCRIPT_S3=\"s3://policy-database/etl/rehoming_etl.py\"\nTEMP_DIR=\"s3://policy-database/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nROLE_NAME=\"AWSGluePolicyDatabaseRole\"  # Extracted from the ARN\nREGION=\"us-east-1\"\n\n# Define the inline policy to add necessary CloudWatch Logs permissions.\nINLINE_POLICY_NAME=\"GlueCloudWatchLogAccessPolicy\"\nINLINE_POLICY_DOCUMENT=$(cat <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n          \"logs:FilterLogEvents\",\n          \"logs:DescribeLogStreams\",\n          \"logs:GetLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:$REGION:<ACCOUNT_ID>:log-group:/aws-glue/jobs/output:*\"\n    }\n  ]\n}\nEOF\n)\n\necho \"Uploading rehoming_etl.py to S3 ($SCRIPT_S3)...\"\naws s3 cp \"$SCRIPT_LOCAL\" \"$SCRIPT_S3\" --region \"$REGION\"\n\necho \"Updating IAM role ($ROLE_NAME) to allow CloudWatch Logs access...\"\naws iam put-role-policy \\\n  --role-name \"$ROLE_NAME\" \\\n  --policy-name \"$INLINE_POLICY_NAME\" \\\n  --policy-document \"$INLINE_POLICY_DOCUMENT\" \\\n  --region \"$REGION\"\n\n# Check if the job exists. If it does, update it; otherwise, create it.\nJOB_EXISTS=$(aws glue get-job --job-name \"$JOB_NAME\" --region \"$REGION\" 2>/dev/null || echo \"NotFound\")\nif [ \"$JOB_EXISTS\" == \"NotFound\" ]; then\n    echo \"Creating new Glue job $JOB_NAME...\"\n    aws glue create-job \\\n      --name \"$JOB_NAME\" \\\n      --role \"$ROLE\" \\\n      --command \"Name=glueetl,ScriptLocation=$SCRIPT_S3,PythonVersion=3\" \\\n      --default-arguments \"{\\\"--TempDir\\\":\\\"$TEMP_DIR\\\",\\\"--job-language\\\":\\\"python\\\",\\\"--additional-python-modules\\\":\\\"PyPDF2==3.0.1\\\"}\" \\\n      --max-retries 0 \\\n      --timeout 2880 \\\n      --max-capacity 2.0 \\\n      --glue-version \"2.0\" \\\n      --region \"$REGION\"\nelse\n    echo \"Updating existing Glue job $JOB_NAME...\"\n    aws glue update-job \\\n      --job-name \"$JOB_NAME\" \\\n      --job-update \"{\n        \\\"Role\\\": \\\"$ROLE\\\",\n        \\\"Command\\\": {\n          \\\"Name\\\": \\\"glueetl\\\",\n          \\\"ScriptLocation\\\": \\\"$SCRIPT_S3\\\",\n          \\\"PythonVersion\\\": \\\"3\\\"\n        },\n        \\\"DefaultArguments\\\": {\n          \\\"--TempDir\\\": \\\"$TEMP_DIR\\\",\n          \\\"--job-language\\\": \\\"python\\\",\n          \\\"--additional-python-modules\\\": \\\"PyPDF2==3.0.1\\\"\n        },\n        \\\"MaxRetries\\\": 0,\n        \\\"Timeout\\\": 2880,\n        \\\"MaxCapacity\\\": 2.0,\n        \\\"GlueVersion\\\": \\\"2.0\\\"\n      }\" --region \"$REGION\"\nfi\n\necho \"Starting a new run of the Glue job $JOB_NAME...\"\nJOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$JOB_NAME\" --region \"$REGION\")\necho \"Job run started:\"\necho \"$JOB_RUN_OUTPUT\"\n\n# ------------------------------------------------------------------------------\n# Changelog:\n# 1. Defined an inline policy document (GlueCloudWatchLogAccessPolicy) that grants\n#    logs:FilterLogEvents, logs:DescribeLogStreams, and logs:GetLogEvents permissions\n#    on the log group arn:aws:logs:us-east-1:<ACCOUNT_ID>:log-group:/aws-glue/jobs/output:*.\n# 2. Added a call to aws iam put-role-policy to attach the inline policy to AWSGluePolicyDatabaseRole.\n# 3. The rest of the script remains unchanged.\n# ------------------------------------------------------------------------------\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/redeploy4.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# redeploy3.sh\n# This script uploads the updated etl-s3-failed.py file to S3,\n# checks for the existence of the Glue job \"KnowledgeBaseETL2ndChanceJob\" and creates it if it doesn't exist,\n# then updates the Glue job configuration and starts a new job run.\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - The updated etl-s3-failed.py file is present in the glue directory.\n# - IAM role \"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\" exists and has necessary permissions.\n#\n# Environment:\n# - S3 Bucket: policy-database\n# - Script S3 Location: s3://policy-database/etl/etl-s3-failed.py\n# - Temp Directory: s3://policy-database/temp/\n# - Region: us-east-1\n\nset -e  # Exit immediately if any command fails\n\n# Variables\nJOB_NAME=\"KnowledgeBaseETL2ndChanceJob\"\nSCRIPT_LOCAL=\"../glue/etl-s3-failed.py\"\nSCRIPT_S3=\"s3://policy-database/etl/etl-s3-failed.py\"\nTEMP_DIR=\"s3://policy-database/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nREGION=\"us-east-1\"\nGLUE_VERSION=\"2.0\"\nMAX_CAPACITY=\"2.0\"\nTIMEOUT=\"2880\"\nADDITIONAL_MODULES=\"PyPDF2==3.0.1,pycryptodome\"\n\necho \"Uploading updated script ($SCRIPT_LOCAL) to S3 ($SCRIPT_S3)...\"\naws s3 cp \"$SCRIPT_LOCAL\" \"$SCRIPT_S3\" --region \"$REGION\"\n\necho \"Checking if Glue job $JOB_NAME exists...\"\nif aws glue get-job --job-name \"$JOB_NAME\" --region \"$REGION\" >/dev/null 2>&1; then\n    echo \"Job exists. Updating job configuration...\"\n    aws glue update-job \\\n      --job-name \"$JOB_NAME\" \\\n      --job-update '{\n        \"Role\": \"'\"$ROLE\"'\",\n        \"Command\": {\n          \"Name\": \"glueetl\",\n          \"ScriptLocation\": \"'\"$SCRIPT_S3\"'\",\n          \"PythonVersion\": \"3\"\n        },\n        \"DefaultArguments\": {\n          \"--TempDir\": \"'\"$TEMP_DIR\"'\",\n          \"--job-language\": \"python\",\n          \"--additional-python-modules\": \"'\"$ADDITIONAL_MODULES\"'\"\n        },\n        \"MaxRetries\": 0,\n        \"Timeout\": '\"$TIMEOUT\"',\n        \"MaxCapacity\": '\"$MAX_CAPACITY\"',\n        \"GlueVersion\": \"'\"$GLUE_VERSION\"'\"\n      }' \\\n      --region \"$REGION\"\nelse\n    echo \"Job does not exist. Creating Glue job $JOB_NAME...\"\n    aws glue create-job \\\n      --name \"$JOB_NAME\" \\\n      --role \"$ROLE\" \\\n      --command \"Name=glueetl,ScriptLocation=$SCRIPT_S3,PythonVersion=3\" \\\n      --default-arguments \"{\\\"--TempDir\\\":\\\"$TEMP_DIR\\\",\\\"--job-language\\\":\\\"python\\\",\\\"--additional-python-modules\\\":\\\"$ADDITIONAL_MODULES\\\"}\" \\\n      --max-retries 0 \\\n      --timeout \"$TIMEOUT\" \\\n      --max-capacity \"$MAX_CAPACITY\" \\\n      --glue-version \"$GLUE_VERSION\" \\\n      --region \"$REGION\"\nfi\n\necho \"Starting a new run of the Glue job $JOB_NAME...\"\nJOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$JOB_NAME\" --region \"$REGION\")\necho \"Job run started:\"\necho \"$JOB_RUN_OUTPUT\"\n\n# ------------------------------------------------------------------------------\n# Changelog:\n# 1. Defined variables for the secondary job name, script location, temp directory, IAM role, region, etc.\n# 2. Uploaded etl-s3-failed.py from the glue directory to s3://policy-database/etl/etl-s3-failed.py.\n# 3. Added a check using aws glue get-job to determine if \"KnowledgeBaseETL2ndChanceJob\" exists.\n#    - If it exists, the script updates its configuration with the new script location and parameters.\n#    - If it does not exist, the script creates the Glue job with the appropriate parameters.\n# 4. Finally, the script starts a new job run for \"KnowledgeBaseETL2ndChanceJob\" and outputs the job run details.\n# ------------------------------------------------------------------------------\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/redeploy3.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\n#!/bin/bash\n\n# Configure logging\nLOG_FILE=\"etl_$(date +%Y%m%d_%H%M%S).log\"\nexec 1> >(tee -a \"$LOG_FILE\")\nexec 2> >(tee -a \"$LOG_FILE\" >&2)\n\n# Function to log messages\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\"\n}\n\n# Function to run a script with timeout\nrun_script() {\n    local script_name=$1\n    local timeout=$2\n    local start_time=$(date +%s)\n\n    log \"Starting $script_name with ${timeout}s timeout\"\n\n    # Run the script with timeout\n    timeout $timeout python3 \"$script_name\"\n    local exit_code=$?\n\n    local end_time=$(date +%s)\n    local duration=$((end_time - start_time))\n\n    if [ $exit_code -eq 124 ]; then\n        log \"ERROR: $script_name timed out after ${timeout}s\"\n        return 1\n    elif [ $exit_code -ne 0 ]; then\n        log \"ERROR: $script_name failed with exit code $exit_code\"\n        return 1\n    else\n        log \"SUCCESS: $script_name completed in ${duration}s\"\n        return 0\n    fi\n}\n\n# Main execution\nlog \"Starting ETL process\"\n\n# Run main ETL (4 hour timeout)\nif ! run_script \"../glue/etl-s3.py\" 14400; then\n    log \"Main ETL failed. Stopping process.\"\n    exit 1\nfi\n\n# Wait 1 hour before running failed ETL\nlog \"Waiting 1 hour before running failed ETL...\"\nsleep 3600\n\n# Run failed ETL (4 hour timeout)\nif ! run_script \"../glue/etl-s3-failed.py\" 14400; then\n    log \"Failed ETL failed. Stopping process.\"\n    exit 1\nfi\n\n# Wait 1 hour before running rehoming ETL\nlog \"Waiting 1 hour before running rehoming ETL...\"\nsleep 3600\n\n# Run rehoming ETL (4 hour timeout)\nif ! run_script \"../glue/rehoming_etl.py\" 14400; then\n    log \"Rehoming ETL failed. Stopping process.\"\n    exit 1\nfi\n\nlog \"All ETL processes completed successfully\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/run_etl.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# redeploy.sh\n# This script automates the redeployment of the \"etl-google-alerts\" Lambda function in us-east-1.\n# It performs the following steps:\n#   1. Installs production dependencies.\n#   2. Zips the Lambda handler file and node_modules folder.\n#   3. Updates the Lambda function code using the AWS CLI.\n#\n# Usage: ./redeploy.sh\n\nset -e  # Exit immediately if any command fails\n\n# Variables - adjust these if your file/folder names change\nFUNCTION_NAME=\"etl-google-alerts\"\nZIP_FILE=\"../lambda/etl-lambda.zip\"\nHANDLER_FILE=\"../lambda/etl-google-alerts-lambda.js\"\nNODE_MODULES_DIR=\"../node_modules\"\nREGION=\"us-east-1\"\n\necho \"Starting redeployment of Lambda function: $FUNCTION_NAME\"\n\n# 1. Install production dependencies\necho \"Installing production dependencies...\"\ncd .. && npm install --production && cd scripts\n\n# 2. Create the deployment package zip file\necho \"Creating deployment package: $ZIP_FILE\"\ncd ..\nzip -r \"lambda/etl-lambda.zip\" \"lambda/etl-google-alerts-lambda.js\" \"node_modules\"\ncd scripts\n\n# 3. Update the Lambda function code using AWS CLI\necho \"Updating Lambda function code in region $REGION...\"\naws lambda update-function-code \\\n  --function-name \"$FUNCTION_NAME\" \\\n  --zip-file fileb://\"$ZIP_FILE\" \\\n  --region \"$REGION\"\n\necho \"Redeployment complete.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/redeploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# deploy.sh\n# Comprehensive deployment script for Knowledge Base ETL system\n#\n# This script handles deployment of all components:\n#   1. Lambda Function (etl-google-alerts)\n#   2. Primary Glue Job (KnowledgeBaseETLJob) - etl-s3.py\n#   3. Second Chance Glue Job (KnowledgeBaseETL2ndChanceJob) - etl-s3-failed.py\n#   4. Rehoming Glue Job (KnowledgeBaseETLRehomeJob) - rehoming_etl.py\n#\n# Usage:\n#   ./deploy.sh [--all] [--lambda] [--primary] [--second-chance] [--rehome]\n#\n# Options:\n#   --all            Deploy all components (default if no flag is provided)\n#   --lambda         Deploy only the Lambda function (etl-google-alerts)\n#   --primary        Deploy only the primary ETL job\n#   --second-chance  Deploy only the second chance ETL job\n#   --rehome         Deploy only the rehoming ETL job\n#\n# Prerequisites:\n# - AWS CLI must be installed and configured.\n# - Script files must be present in the respective directories.\n# - IAM role with necessary permissions must exist.\n\nset -e  # Exit immediately if any command fails\n\n# Common variables\nREGION=\"us-east-1\"\nS3_BUCKET=\"policy-database\"\nTEMP_DIR=\"s3://$S3_BUCKET/temp/\"\nROLE=\"arn:aws:iam::<ACCOUNT_ID>:role/AWSGluePolicyDatabaseRole\"\nROLE_NAME=\"AWSGluePolicyDatabaseRole\"  # Extracted from the ARN\nGLUE_VERSION=\"2.0\"\nMAX_CAPACITY=\"2.0\"\nTIMEOUT=\"2880\"\n\n# Lambda variables\nLAMBDA_FUNCTION_NAME=\"etl-google-alerts\"\nLAMBDA_ZIP_FILE=\"../lambda/etl-lambda.zip\"\nLAMBDA_HANDLER_FILE=\"../lambda/etl-google-alerts-lambda.js\"\nNODE_MODULES_DIR=\"../node_modules\"\n\n# Glue job variables\nPRIMARY_JOB_NAME=\"KnowledgeBaseETLJob\"\nPRIMARY_SCRIPT_LOCAL=\"../glue/etl-s3.py\"\nPRIMARY_SCRIPT_S3=\"s3://$S3_BUCKET/etl/etl-s3.py\"\nPRIMARY_MODULES=\"PyPDF2==3.0.1,pycryptodome\"\n\nSECOND_CHANCE_JOB_NAME=\"KnowledgeBaseETL2ndChanceJob\"\nSECOND_CHANCE_SCRIPT_LOCAL=\"../glue/etl-s3-failed.py\"\nSECOND_CHANCE_SCRIPT_S3=\"s3://$S3_BUCKET/etl/etl-s3-failed.py\"\nSECOND_CHANCE_MODULES=\"PyPDF2==3.0.1,pycryptodome\"\n\nREHOME_JOB_NAME=\"KnowledgeBaseETLRehomeJob\"\nREHOME_SCRIPT_LOCAL=\"../glue/rehoming_etl.py\"\nREHOME_SCRIPT_S3=\"s3://$S3_BUCKET/etl/rehoming_etl.py\"\nREHOME_MODULES=\"PyPDF2==3.0.1\"\n\n# CloudWatch logs inline policy document for rehoming job\nINLINE_POLICY_NAME=\"GlueCloudWatchLogAccessPolicy\"\nINLINE_POLICY_DOCUMENT=$(cat <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n          \"logs:FilterLogEvents\",\n          \"logs:DescribeLogStreams\",\n          \"logs:GetLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:$REGION:<ACCOUNT_ID>:log-group:/aws-glue/jobs/output:*\"\n    }\n  ]\n}\nEOF\n)\n\n# Function to deploy a Glue job\ndeploy_glue_job() {\n    local job_name=$1\n    local script_local=$2\n    local script_s3=$3\n    local additional_modules=$4\n    local extra_setup=$5\n\n    echo \"Uploading script $script_local to $script_s3...\"\n    aws s3 cp \"$script_local\" \"$script_s3\" --region \"$REGION\"\n\n    # Run any extra setup if provided (e.g., for rehome job IAM policy)\n    if [ -n \"$extra_setup\" ]; then\n        eval \"$extra_setup\"\n    fi\n\n    echo \"Checking if Glue job $job_name exists...\"\n    if aws glue get-job --job-name \"$job_name\" --region \"$REGION\" >/dev/null 2>&1; then\n        echo \"Job exists. Updating job configuration...\"\n        aws glue update-job \\\n          --job-name \"$job_name\" \\\n          --job-update '{\n            \"Role\": \"'\"$ROLE\"'\",\n            \"Command\": {\n              \"Name\": \"glueetl\",\n              \"ScriptLocation\": \"'\"$script_s3\"'\",\n              \"PythonVersion\": \"3\"\n            },\n            \"DefaultArguments\": {\n              \"--TempDir\": \"'\"$TEMP_DIR\"'\",\n              \"--job-language\": \"python\",\n              \"--additional-python-modules\": \"'\"$additional_modules\"'\"\n            },\n            \"MaxRetries\": 0,\n            \"Timeout\": '\"$TIMEOUT\"',\n            \"MaxCapacity\": '\"$MAX_CAPACITY\"',\n            \"GlueVersion\": \"'\"$GLUE_VERSION\"'\"\n          }' \\\n          --region \"$REGION\"\n    else\n        echo \"Job does not exist. Creating Glue job $job_name...\"\n        aws glue create-job \\\n          --name \"$job_name\" \\\n          --role \"$ROLE\" \\\n          --command \"Name=glueetl,ScriptLocation=$script_s3,PythonVersion=3\" \\\n          --default-arguments \"{\\\"--TempDir\\\":\\\"$TEMP_DIR\\\",\\\"--job-language\\\":\\\"python\\\",\\\"--additional-python-modules\\\":\\\"$additional_modules\\\"}\" \\\n          --max-retries 0 \\\n          --timeout \"$TIMEOUT\" \\\n          --max-capacity \"$MAX_CAPACITY\" \\\n          --glue-version \"$GLUE_VERSION\" \\\n          --region \"$REGION\"\n    fi\n\n    echo \"Starting a new run of the Glue job $job_name...\"\n    JOB_RUN_OUTPUT=$(aws glue start-job-run --job-name \"$job_name\" --region \"$REGION\")\n    echo \"Job run started:\"\n    echo \"$JOB_RUN_OUTPUT\"\n    echo \"---------------------------------------------\"\n}\n\n# Function to deploy Lambda\ndeploy_lambda() {\n    echo \"Starting deployment of Lambda function: $LAMBDA_FUNCTION_NAME\"\n\n    # 1. Install production dependencies\n    echo \"Installing production dependencies...\"\n    (cd .. && npm install --production)\n\n    # 2. Create the deployment package zip file\n    echo \"Creating deployment package: $LAMBDA_ZIP_FILE\"\n    (cd .. && zip -r \"lambda/etl-lambda.zip\" \"lambda/etl-google-alerts-lambda.js\" \"node_modules\")\n\n    # 3. Upload the ZIP file to the same S3 location where Glue scripts are stored\n    echo \"Uploading Lambda package to S3...\"\n    aws s3 cp \"$LAMBDA_ZIP_FILE\" \"s3://$S3_BUCKET/etl/etl-lambda.zip\" --region \"$REGION\"\n\n    # 4. Update the Lambda function code using the S3 reference\n    echo \"Updating Lambda function code from S3 in region $REGION...\"\n    aws lambda update-function-code \\\n      --function-name \"$LAMBDA_FUNCTION_NAME\" \\\n      --s3-bucket \"$S3_BUCKET\" \\\n      --s3-key \"etl/etl-lambda.zip\" \\\n      --region \"$REGION\"\n\n    echo \"Lambda deployment complete.\"\n    echo \"---------------------------------------------\"\n}\n\n# Process command-line arguments\nDEPLOY_LAMBDA=false\nDEPLOY_PRIMARY=false\nDEPLOY_SECOND_CHANCE=false\nDEPLOY_REHOME=false\n\n# Default to deploying all if no arguments provided\nif [ $# -eq 0 ]; then\n    DEPLOY_LAMBDA=true\n    DEPLOY_PRIMARY=true\n    DEPLOY_SECOND_CHANCE=true\n    DEPLOY_REHOME=true\nelse\n    while [ $# -gt 0 ]; do\n        case \"$1\" in\n            --all)\n                DEPLOY_LAMBDA=true\n                DEPLOY_PRIMARY=true\n                DEPLOY_SECOND_CHANCE=true\n                DEPLOY_REHOME=true\n                ;;\n            --lambda)\n                DEPLOY_LAMBDA=true\n                ;;\n            --primary)\n                DEPLOY_PRIMARY=true\n                ;;\n            --second-chance)\n                DEPLOY_SECOND_CHANCE=true\n                ;;\n            --rehome)\n                DEPLOY_REHOME=true\n                ;;\n            *)\n                echo \"Unknown option: $1\"\n                echo \"Usage: ./deploy.sh [--all] [--lambda] [--primary] [--second-chance] [--rehome]\"\n                exit 1\n                ;;\n        esac\n        shift\n    done\nfi\n\n# Extra setup command for rehome job (IAM policy update)\nREHOME_EXTRA_SETUP='echo \"Updating IAM role ($ROLE_NAME) to allow CloudWatch Logs access...\"; aws iam put-role-policy --role-name \"$ROLE_NAME\" --policy-name \"$INLINE_POLICY_NAME\" --policy-document \"$INLINE_POLICY_DOCUMENT\" --region \"$REGION\"'\n\n# Deploy selected components\nif [ \"$DEPLOY_LAMBDA\" = true ]; then\n    echo \"Deploying Lambda Function ($LAMBDA_FUNCTION_NAME)...\"\n    deploy_lambda\nfi\n\nif [ \"$DEPLOY_PRIMARY\" = true ]; then\n    echo \"Deploying Primary ETL Job ($PRIMARY_JOB_NAME)...\"\n    deploy_glue_job \"$PRIMARY_JOB_NAME\" \"$PRIMARY_SCRIPT_LOCAL\" \"$PRIMARY_SCRIPT_S3\" \"$PRIMARY_MODULES\"\nfi\n\nif [ \"$DEPLOY_SECOND_CHANCE\" = true ]; then\n    echo \"Deploying Second Chance ETL Job ($SECOND_CHANCE_JOB_NAME)...\"\n    deploy_glue_job \"$SECOND_CHANCE_JOB_NAME\" \"$SECOND_CHANCE_SCRIPT_LOCAL\" \"$SECOND_CHANCE_SCRIPT_S3\" \"$SECOND_CHANCE_MODULES\"\nfi\n\nif [ \"$DEPLOY_REHOME\" = true ]; then\n    echo \"Deploying Rehoming ETL Job ($REHOME_JOB_NAME)...\"\n    deploy_glue_job \"$REHOME_JOB_NAME\" \"$REHOME_SCRIPT_LOCAL\" \"$REHOME_SCRIPT_S3\" \"$REHOME_MODULES\" \"$REHOME_EXTRA_SETUP\"\nfi\n\necho \"Deployment completed successfully!\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/RAG/ETL/scripts/deploy.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# CloudWatch Monitoring Agent - Lambda Deployment Script\n# Deploys the monitoring agent as an AWS Lambda function\n\nset -e\n\nFUNCTION_NAME=\"cloudwatch-monitoring-agent-api\"\nREGION=\"us-east-1\"\nROLE_NAME=\"CloudWatchMonitoringLambdaRole\"\n\necho \"🚀 Deploying CloudWatch Monitoring Agent to Lambda...\"\n\n# 1. Create IAM role if it doesn't exist\necho \"📋 Creating IAM role...\"\naws iam create-role \\\n    --role-name $ROLE_NAME \\\n    --assume-role-policy-document '{\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Principal\": {\n                    \"Service\": \"lambda.amazonaws.com\"\n                },\n                \"Action\": \"sts:AssumeRole\"\n            }\n        ]\n    }' 2>/dev/null || echo \"Role already exists\"\n\n# 2. Attach required policies\necho \"🔐 Attaching IAM policies...\"\naws iam attach-role-policy \\\n    --role-name $ROLE_NAME \\\n    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n\naws iam put-role-policy \\\n    --role-name $ROLE_NAME \\\n    --policy-name CloudWatchMonitoringPolicy \\\n    --policy-document '{\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"cloudwatch:DescribeAlarms\",\n                    \"logs:FilterLogEvents\",\n                    \"ses:SendEmail\"\n                ],\n                \"Resource\": \"*\"\n            }\n        ]\n    }'\n\n# 3. Get role ARN\nROLE_ARN=$(aws iam get-role --role-name $ROLE_NAME --query 'Role.Arn' --output text)\necho \"📝 Role ARN: $ROLE_ARN\"\n\n# 4. Create deployment package\necho \"📦 Creating deployment package...\"\nmkdir -p lambda_package\ncp cloudwatch_agent.py lambda_package/\ncp lambda_function.py lambda_package/\ncp config.json lambda_package/\ncp requirements-lambda.txt lambda_package/requirements.txt\n\ncd lambda_package\n\n# Install dependencies\npip install -r requirements.txt -t .\n\n# Create zip file\nzip -r ../cloudwatch-monitoring-agent-api.zip . -x \"*.pyc\" \"__pycache__/*\"\n\ncd ..\n\n# 5. Create or update Lambda function\necho \"⚡ Deploying Lambda function...\"\nif aws lambda get-function --function-name $FUNCTION_NAME --region $REGION 2>/dev/null; then\n    echo \"Updating existing function...\"\n    aws lambda update-function-code \\\n        --function-name $FUNCTION_NAME \\\n        --zip-file fileb://cloudwatch-monitoring-agent-api.zip \\\n        --region $REGION\n\n    aws lambda update-function-configuration \\\n        --function-name $FUNCTION_NAME \\\n        --timeout 300 \\\n        --memory-size 512 \\\n        --region $REGION\nelse\n    echo \"Creating new function...\"\n    aws lambda create-function \\\n        --function-name $FUNCTION_NAME \\\n        --runtime python3.9 \\\n        --role $ROLE_ARN \\\n        --handler lambda_function.lambda_handler \\\n        --zip-file fileb://cloudwatch-monitoring-agent-api.zip \\\n        --timeout 300 \\\n        --memory-size 512 \\\n        --region $REGION\nfi\n\n# 6. Create CloudWatch Events rule for scheduling\necho \"⏰ Setting up CloudWatch Events rule...\"\nRULE_NAME=\"cloudwatch-monitoring-schedule\"\n\naws events put-rule \\\n    --name $RULE_NAME \\\n    --schedule-expression \"rate(5 minutes)\" \\\n    --description \"Trigger CloudWatch monitoring agent every 5 minutes\" \\\n    --region $REGION\n\n# 7. Add permission for EventBridge to invoke Lambda\necho \"🔗 Adding EventBridge permissions...\"\naws lambda add-permission \\\n    --function-name $FUNCTION_NAME \\\n    --statement-id cloudwatch-monitoring-schedule \\\n    --action lambda:InvokeFunction \\\n    --principal events.amazonaws.com \\\n    --source-arn \"arn:aws:events:$REGION:$(aws sts get-caller-identity --query Account --output text):rule/$RULE_NAME\" \\\n    --region $REGION 2>/dev/null || echo \"Permission already exists\"\n\n# 8. Add Lambda function as target to the rule\necho \"🎯 Adding Lambda as target...\"\naws events put-targets \\\n    --rule $RULE_NAME \\\n    --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:$REGION:$(aws sts get-caller-identity --query Account --output text):function:$FUNCTION_NAME\" \\\n    --region $REGION\n\n# Cleanup\nrm -rf lambda_package\nrm cloudwatch-monitoring-agent-api.zip\n\necho \"✅ Deployment complete!\"\necho \"📊 Function: $FUNCTION_NAME\"\necho \"⏰ Schedule: Every 5 minutes\"\necho \"📍 Region: $REGION\"\necho \"\"\necho \"🔍 Monitor logs with:\"\necho \"aws logs tail /aws/lambda/$FUNCTION_NAME --follow --region $REGION\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/api/monitoring/deploy_lambda.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/usr/bin/env bash\n# setup-monitoring.sh — CLAUDE.md compliant monitoring with security metrics and business analytics\n# Follows CLAUDE.md principles: No fallbacks, fail-fast, comprehensive tagging for cost analysis\n\nset -euo pipefail\n\n# Add trap for script exit\nfinish() {\n  EXIT_CODE=$?\n  if [ $EXIT_CODE -eq 0 ]; then\n    echo\n    echo \"🎉 Enhanced monitoring setup completed successfully!\"\n    echo \"   Security monitoring, webhook protection, and business analytics enabled.\"\n    echo \"   Test Slack integration with:\"\n    echo \"   aws sns publish --topic-arn $TOPIC_ARN --message '🚀 Enhanced monitoring operational!'\"\n    echo\n  else\n    echo\n    echo \"❌ Enhanced monitoring setup failed (exit code: $EXIT_CODE)\"\n    echo \"   CLAUDE.md principle: Failing fast to surface real issues.\"\n    echo \"   Fix the error above and retry - no fallbacks will mask problems.\"\n    echo\n  fi\n}\ntrap finish EXIT\n\n# 1️⃣ Load .env with CLAUDE.md compliance (no fallbacks)\nif [ ! -f .env ]; then\n  echo \"❌ .env not found. Required for security monitoring and business analytics setup.\"\n  echo \"   Add SERVICE_NAME, STAGE, AWS_REGION, SLACK_WEBHOOK_URL,\"\n  echo \"   AMPLIFY_APP_ID, API_NAME, REQUESTS_PER_MONTH, COST_PER_BEDROCK_REQ\"\n  exit 1\nfi\n\nwhile IFS='=' read -r k v || [ -n \"$k\" ]; do\n  [[ \"$k\" =~ ^# ]] && continue\n  [[ -z \"$k\" ]] && continue\n  v=\"${v%\\\"}\"; v=\"${v#\\\"}\"\n  export \"$k=$v\"\ndone < <(sed 's/\\r$//' .env)\n\n# Trim whitespace from critical variables\nSERVICE_NAME=$(echo \"$SERVICE_NAME\" | xargs)\nSTAGE=$(echo \"$STAGE\" | xargs)\nAPI_NAME=$(echo \"$API_NAME\" | xargs)\n\n# Required variables - fail fast if missing (CLAUDE.md compliance)\n: \"${SERVICE_NAME:?SERVICE_NAME required for monitoring setup}\"\n: \"${STAGE:?STAGE required for monitoring setup}\"\n: \"${AWS_REGION:?AWS_REGION required for monitoring setup}\"\n: \"${SLACK_WEBHOOK_URL:?SLACK_WEBHOOK_URL required for monitoring setup}\"\n: \"${AMPLIFY_APP_ID:?AMPLIFY_APP_ID required for monitoring setup}\"\n: \"${API_NAME:?API_NAME required for monitoring setup}\"\n: \"${API_ID:?API_ID required for monitoring setup}\"\n: \"${REQUESTS_PER_MONTH:?REQUESTS_PER_MONTH required for monitoring setup}\"\n: \"${COST_PER_BEDROCK_REQ:?COST_PER_BEDROCK_REQ required for monitoring setup}\"\n\n# 2️⃣ Derived vars and business analytics tagging\nAWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nif [ -z \"$AWS_ACCOUNT_ID\" ]; then\n  echo \"❌ Failed to get AWS account ID. Check AWS credentials.\"\n  exit 1\nfi\n\nBEDROCK_MONTHLY_BUDGET=$(\n  awk \\\n    -v r=\"$REQUESTS_PER_MONTH\" \\\n    -v c=\"$COST_PER_BEDROCK_REQ\" \\\n    'BEGIN { printf \"%.2f\", r * c }'\n)\n\n# Business Analytics Tagging Strategy\nPROJECT_TAG=\"Project\"\nPROJECT_VALUE=\"${SERVICE_NAME}-${STAGE}\"\nPROJECT_VALUE=$(echo \"$PROJECT_VALUE\" | tr -d ' \\t')\n\n# Cost tracking by business line (endpoint)\nBUSINESS_LINE_TAG=\"BusinessLine\"\nENVIRONMENT_TAG=\"Environment\"\nCOST_TYPE_TAG=\"CostType\"\nENDPOINT_TAG=\"Endpoint\"\n\n# Determine environment and cost types\nif [[ \"$STAGE\" =~ ^(prod|production)$ ]]; then\n  ENVIRONMENT_VALUE=\"production\"\nelse\n  ENVIRONMENT_VALUE=\"development\"\nfi\n\n# Common tag set for all resources\ndeclare -A COMMON_TAGS=(\n  [$PROJECT_TAG]=\"$PROJECT_VALUE\"\n  [$ENVIRONMENT_TAG]=\"$ENVIRONMENT_VALUE\"\n  [\"Owner\"]=\"express-chatbot-team\"\n  [\"Application\"]=\"ona-chatbot\"\n  [\"Version\"]=\"1.0\"\n)\n\necho \"➡️  Setting up CLAUDE.md compliant monitoring for $SERVICE_NAME-$STAGE\"\necho \"   • Enhanced security monitoring enabled\"\necho \"   • Business analytics tagging for cost tracking\"\necho \"   • Environment: $ENVIRONMENT_VALUE\"\necho \"   • Target: $REQUESTS_PER_MONTH req/mo @ \\$$COST_PER_BEDROCK_REQ each\"\necho \"   • Monthly budget: \\$$BEDROCK_MONTHLY_BUDGET\"\necho \"   • No fallback patterns - fail fast on errors\"\necho\n\n# Helper function for applying business analytics tags\napply_business_tags() {\n  local resource_arn=$1\n  local business_line=${2:-\"infrastructure\"}\n  local cost_type=${3:-\"fixed\"}\n  local endpoint=${4:-\"system\"}\n\n  # Apply tags with correct format for each service type\n  if [[ \"$resource_arn\" =~ sns ]]; then\n    # SNS expects list of Key=Value pairs\n    aws sns tag-resource --resource-arn \"$resource_arn\" --region \"$AWS_REGION\" \\\n      --tags Key=Project,Value=\"$PROJECT_VALUE\" Key=Environment,Value=\"$ENVIRONMENT_VALUE\" Key=Owner,Value=\"express-chatbot-team\" Key=Application,Value=\"ona-chatbot\" Key=Version,Value=\"1.0\" Key=BusinessLine,Value=\"$business_line\" Key=CostType,Value=\"$cost_type\" Key=Endpoint,Value=\"$endpoint\"\n\n  elif [[ \"$resource_arn\" =~ lambda ]]; then\n    # Lambda expects JSON object format\n    aws lambda tag-resource --resource \"$resource_arn\" --region \"$AWS_REGION\" \\\n      --tags \"{\\\"Project\\\":\\\"$PROJECT_VALUE\\\",\\\"Environment\\\":\\\"$ENVIRONMENT_VALUE\\\",\\\"Owner\\\":\\\"express-chatbot-team\\\",\\\"Application\\\":\\\"ona-chatbot\\\",\\\"Version\\\":\\\"1.0\\\",\\\"BusinessLine\\\":\\\"$business_line\\\",\\\"CostType\\\":\\\"$cost_type\\\",\\\"Endpoint\\\":\\\"$endpoint\\\"}\"\n\n  elif [[ \"$resource_arn\" =~ amplify ]]; then\n    # Amplify expects comma-separated key=value pairs\n    aws amplify tag-resource --resource-arn \"$resource_arn\" --region \"$AWS_REGION\" \\\n      --tags \"Project=$PROJECT_VALUE,Environment=$ENVIRONMENT_VALUE,Owner=express-chatbot-team,Application=ona-chatbot,Version=1.0,BusinessLine=$business_line,CostType=$cost_type,Endpoint=$endpoint\"\n\n  elif [[ \"$resource_arn\" =~ apigateway ]]; then\n    # API Gateway expects comma-separated key=value pairs\n    aws apigateway tag-resource --resource-arn \"$resource_arn\" --region \"$AWS_REGION\" \\\n      --tags \"Project=$PROJECT_VALUE,Environment=$ENVIRONMENT_VALUE,Owner=express-chatbot-team,Application=ona-chatbot,Version=1.0,BusinessLine=$business_line,CostType=$cost_type,Endpoint=$endpoint\"\n  fi\n}\n\n# 3️⃣ SNS topic (fail fast - no error handling)\nTOPIC_NAME=\"${SERVICE_NAME}-${STAGE}-alerts\"\nTOPIC_NAME=$(echo \"$TOPIC_NAME\" | tr -d ' \\t')\necho \"Creating SNS topic: '$TOPIC_NAME'\"\n\nTOPIC_ARN=$(aws sns create-topic --name \"$TOPIC_NAME\" \\\n  --region \"$AWS_REGION\" --query TopicArn --output text)\n\n# Apply business analytics tags\napply_business_tags \"$TOPIC_ARN\" \"infrastructure\" \"fixed\" \"monitoring\"\n\necho \"✅ SNS topic: $TOPIC_ARN\"\n\n# 4️⃣ Enhanced IAM role for SlackNotifier with CloudWatch permissions\nROLE_NAME=\"${SERVICE_NAME}-${STAGE}-SlackNotifyRole\"\nif aws iam get-role --role-name \"$ROLE_NAME\" &>/dev/null; then\n  ROLE_ARN=$(aws iam get-role --role-name \"$ROLE_NAME\" \\\n    --query 'Role.Arn' --output text)\nelse\n  # Create trust policy file\n  cat > /tmp/trust-policy.json <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n\n  ROLE_ARN=$(aws iam create-role \\\n    --role-name \"$ROLE_NAME\" \\\n    --assume-role-policy-document file:///tmp/trust-policy.json \\\n    --region \"$AWS_REGION\" \\\n    --query 'Role.Arn' --output text)\n\n  aws iam attach-role-policy \\\n    --role-name \"$ROLE_NAME\" \\\n    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole \\\n    --region \"$AWS_REGION\"\n\n  # Add CloudWatch permissions for custom metrics\n  aws iam put-role-policy \\\n    --role-name \"$ROLE_NAME\" \\\n    --policy-name \"CloudWatchMetricsPolicy\" \\\n    --policy-document '{\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\n            \"cloudwatch:PutMetricData\"\n          ],\n          \"Resource\": \"*\"\n        }\n      ]\n    }'\n\n  # Wait for propagation\n  sleep 10\n  rm /tmp/trust-policy.json\nfi\necho \"✅ IAM role: $ROLE_ARN\"\n\n# 5️⃣ Enhanced SlackNotifier Lambda with security alert formatting\nLAMBDA_NAME=\"${SERVICE_NAME}-${STAGE}-SlackNotifier\"\nTMP_ZIP=$(mktemp /tmp/sn.XXXX.zip)\nrm -f \"$TMP_ZIP\"\n\ncat > /tmp/slack_notifier_enhanced.py <<'EOF'\nimport os, json, urllib.request, re\nfrom datetime import datetime, timezone\n\nWEBHOOK = os.environ['SLACK_WEBHOOK_URL']\n\ndef generate_sbar_alert(alarm_data):\n    \"\"\"Generate SBAR format alert for CloudWatch alarms\"\"\"\n    alarm_name = alarm_data.get('AlarmName', '')\n    description = alarm_data.get('AlarmDescription', '')\n    state = alarm_data.get('NewStateValue', '')\n    reason = alarm_data.get('NewStateReason', '')\n    timestamp = alarm_data.get('StateChangeTime', '')\n\n    # Determine alert type and severity\n    if 'SigFail' in alarm_name or 'SecurityFail' in alarm_name:\n        icon = \":warning:\"\n        severity = \"CRITICAL SECURITY\"\n        alert_type = \"SECURITY BREACH\"\n    elif 'Webhook' in alarm_name and 'Security' in alarm_name:\n        icon = \":shield:\"\n        severity = \"HIGH SECURITY\"\n        alert_type = \"WEBHOOK ATTACK\"\n    elif '5XX' in alarm_name:\n        icon = \":rotating_light:\"\n        severity = \"HIGH AVAILABILITY\"\n        alert_type = \"SERVICE OUTAGE\"\n    elif 'Auth0' in alarm_name:\n        icon = \":closed_lock_with_key:\"\n        severity = \"HIGH SECURITY\"\n        alert_type = \"AUTHENTICATION FAILURE\"\n    elif 'CustomerLookup' in alarm_name:\n        icon = \":exclamation:\"\n        severity = \"MEDIUM BUSINESS\"\n        alert_type = \"DATA INTEGRITY\"\n    elif 'Bedrock' in alarm_name:\n        icon = \":brain:\"\n        severity = \"HIGH BUSINESS\"\n        alert_type = \"AI SERVICE FAILURE\"\n    else:\n        icon = \":warning:\"\n        severity = \"MEDIUM SYSTEM\"\n        alert_type = \"SYSTEM ALERT\"\n\n    # Extract meaningful context from reason\n    context = extract_context_from_reason(reason, alarm_name)\n\n    # Generate SBAR sections\n    situation = generate_situation(alarm_name, state, severity)\n    background = generate_background(description, reason, timestamp, context)\n    assessment = generate_assessment(alarm_name, context, severity)\n    recommendation = generate_recommendation(alarm_name, context)\n\n    return f\"\"\"\n{icon} *{severity} - {alert_type}*\n\n📋 *SITUATION*\n{situation}\n\n📊 *BACKGROUND*\n{background}\n\n🔍 *ASSESSMENT*\n{assessment}\n\n💡 *RECOMMENDATION*\n{recommendation}\n\"\"\"\n\ndef extract_context_from_reason(reason, alarm_name):\n    \"\"\"Extract actionable context from CloudWatch alarm reason\"\"\"\n    context = {}\n\n    # Extract threshold information\n    if 'datapoint' in reason.lower():\n        threshold_match = re.search(r'(\\d+\\.?\\d*)\\s*.*?threshold\\s*\\((\\d+\\.?\\d*)\\)', reason)\n        if threshold_match:\n            context['current_value'] = threshold_match.group(1)\n            context['threshold'] = threshold_match.group(2)\n\n    # Extract error counts for security patterns\n    if 'SigFail' in alarm_name or 'SecurityFail' in alarm_name:\n        context['error_type'] = 'signature_verification'\n    elif 'Auth0' in alarm_name:\n        context['error_type'] = 'authentication'\n    elif 'CustomerLookup' in alarm_name:\n        context['error_type'] = 'data_integrity'\n\n    return context\n\ndef generate_situation(alarm_name, state, severity):\n    \"\"\"Generate clear situation statement\"\"\"\n    if 'SigFail' in alarm_name:\n        return f\"Webhook signature verification failures detected. System state: {state}\"\n    elif 'SecurityPattern' in alarm_name:\n        return f\"Repeated webhook security failures indicate ongoing attack. System state: {state}\"\n    elif '5XX' in alarm_name:\n        return f\"API Gateway returning server errors. System state: {state}\"\n    elif 'Auth0' in alarm_name:\n        return f\"Authentication service failures detected. System state: {state}\"\n    elif 'CustomerLookup' in alarm_name:\n        return f\"Customer data lookup failures detected. System state: {state}\"\n    elif 'Bedrock' in alarm_name:\n        return f\"AI service experiencing errors. System state: {state}\"\n    else:\n        return f\"System monitoring alert triggered. State: {state}\"\n\ndef generate_background(description, reason, timestamp, context):\n    \"\"\"Generate technical background with context\"\"\"\n    background = f\"Alert triggered at: {timestamp}\\n\"\n    background += f\"Description: {description}\\n\"\n\n    if context.get('current_value') and context.get('threshold'):\n        background += f\"Current value: {context['current_value']}, Threshold: {context['threshold']}\\n\"\n\n    background += f\"Trigger reason: {reason}\"\n\n    return background\n\ndef generate_assessment(alarm_name, context, severity):\n    \"\"\"Generate impact assessment\"\"\"\n    if 'SigFail' in alarm_name:\n        return f\"{severity}: Potential security breach attempt. Invalid webhook requests being processed. User authentication and payment processing may be compromised.\"\n    elif 'SecurityPattern' in alarm_name:\n        return f\"{severity}: Active attack detected. Multiple signature verification failures suggest coordinated attack on webhook endpoint.\"\n    elif '5XX' in alarm_name:\n        return f\"{severity}: Service degradation affecting user experience. Users cannot access application features.\"\n    elif 'Auth0' in alarm_name:\n        return f\"{severity}: User authentication system compromised. New user registrations and login attempts failing.\"\n    elif 'CustomerLookup' in alarm_name:\n        return f\"{severity}: Payment processing integrity issue. Webhook processing failing for customer data validation.\"\n    elif 'Bedrock' in alarm_name:\n        return f\"{severity}: AI chat functionality unavailable. Core application features not working.\"\n    else:\n        return f\"{severity}: System component experiencing issues. Monitor for user impact.\"\n\ndef generate_recommendation(alarm_name, context):\n    \"\"\"Generate specific actionable recommendations\"\"\"\n    if 'SigFail' in alarm_name:\n        return \"\"\"1. Check webhook endpoint logs for signature verification details\n2. Verify Stripe webhook secret configuration\n3. Investigate source IP addresses of failed requests\n4. Consider blocking suspicious IPs if pattern detected\n5. Review webhook endpoint security configuration\"\"\"\n    elif 'SecurityPattern' in alarm_name:\n        return \"\"\"1. IMMEDIATE: Block source IPs causing repeated failures\n2. Check AWS CloudTrail for related security events\n3. Review webhook logs for attack patterns\n4. Verify webhook endpoint is not exposed to public scanning\n5. Consider implementing rate limiting on webhook endpoint\"\"\"\n    elif '5XX' in alarm_name:\n        return \"\"\"1. Check Lambda function logs for specific error details\n2. Verify Lambda function memory and timeout settings\n3. Check downstream service health (Auth0, Stripe, Bedrock)\n4. Review API Gateway configuration\n5. Monitor error patterns and implement circuit breakers if needed\"\"\"\n    elif 'Auth0' in alarm_name:\n        return \"\"\"1. Check Auth0 service status and quotas\n2. Verify Auth0 API credentials and permissions\n3. Review Auth0 management API logs\n4. Check user lookup and role assignment endpoints\n5. Verify Auth0 domain and client configuration\"\"\"\n    elif 'CustomerLookup' in alarm_name:\n        return \"\"\"1. Check Stripe customer database for data consistency\n2. Review webhook event data for invalid customer IDs\n3. Verify Stripe API connectivity and quotas\n4. Check customer creation/update processes\n5. Implement customer ID validation in webhook processing\"\"\"\n    elif 'Bedrock' in alarm_name:\n        return \"\"\"1. Check AWS Bedrock service quotas and limits\n2. Verify Bedrock model permissions and access\n3. Review Lambda function invoking Bedrock for errors\n4. Check Bedrock model availability and region settings\n5. Implement fallback response for Bedrock failures\"\"\"\n    else:\n        return \"\"\"1. Check CloudWatch logs for detailed error information\n2. Review recent deployments for potential causes\n3. Verify system resource utilization\n4. Check dependent service health\n5. Escalate to on-call engineer if issue persists\"\"\"\n\ndef lambda_handler(event, context):\n    for r in event.get('Records', []):\n        msg = r['Sns']['Message']\n        try:\n            data = json.loads(msg)\n\n            # CloudWatch Alarm - Generate SBAR format\n            if 'AlarmName' in data:\n                text = generate_sbar_alert(data)\n\n            # Budget Alert - SBAR format\n            elif 'BudgetName' in data:\n                notification = data.get('Notification', {})\n                threshold = notification.get('Threshold', 0)\n                budget_name = data.get('BudgetName', '')\n\n                text = f\"\"\"\n:money_with_wings: *HIGH FINANCIAL - BUDGET EXCEEDED*\n\n📋 *SITUATION*\nBudget '{budget_name}' has exceeded {threshold}% threshold\n\n📊 *BACKGROUND*\nAlert Type: {notification.get('NotificationType', 'N/A')}\nThreshold: {threshold}%\nBudget Period: {data.get('TimePeriod', {}).get('Start', 'N/A')}\nCurrent Status: Budget limit reached or exceeded\n\n🔍 *ASSESSMENT*\nHIGH FINANCIAL: Monthly spending has exceeded planned budget. Continued spending may result in unexpected costs.\n\n💡 *RECOMMENDATION*\n1. Review current month spending in AWS Cost Explorer\n2. Identify highest cost services and resources\n3. Verify spending is expected for business operations\n4. Consider implementing cost controls or alerts\n5. Update budget if spending increase is justified\n\"\"\"\n\n            # Cost Anomaly Alert - SBAR format\n            elif 'AnomalyId' in data or 'AnomalyScore' in data:\n                impact = data.get('Impact', {})\n                score = data.get('AnomalyScore', 'N/A')\n\n                text = f\"\"\"\n:chart_with_upwards_trend: *MEDIUM FINANCIAL - COST ANOMALY*\n\n📋 *SITUATION*\nUnusual spending pattern detected in AWS account\n\n📊 *BACKGROUND*\nAnomaly Score: {score}\nImpact: ${impact.get('MaxImpact', 'N/A')}\nStart Date: {data.get('AnomalyStartDate', 'N/A')}\nEnd Date: {data.get('AnomalyEndDate', 'N/A')}\n\n🔍 *ASSESSMENT*\nMEDIUM FINANCIAL: Spending pattern deviation detected. May indicate service misconfiguration or unexpected usage.\n\n💡 *RECOMMENDATION*\n1. Review AWS Cost Explorer for detailed anomaly analysis\n2. Check for new resource deployments or configuration changes\n3. Verify usage patterns match expected business activity\n4. Investigate highest contributing services to anomaly\n5. Set up additional cost monitoring if pattern continues\n\"\"\"\n\n            # Fallback for unknown types\n            else:\n                text = f\"\"\"\n:grey_question: *MEDIUM SYSTEM - UNKNOWN ALERT*\n\n📋 *SITUATION*\nUnrecognized alert type received from monitoring system\n\n📊 *BACKGROUND*\nRaw alert data received but format not recognized by SBAR processor\n\n🔍 *ASSESSMENT*\nMEDIUM SYSTEM: Alert processing needs update to handle new alert type\n\n💡 *RECOMMENDATION*\n1. Review raw alert data below for details\n2. Update SBAR alert processor if new alert type identified\n3. Check CloudWatch and SNS configuration\n```\n{json.dumps(data, indent=2)}\n```\n\"\"\"\n\n        except Exception as e:\n            # CLAUDE.md compliance: Don't hide parsing errors\n            text = f\"\"\"\n:interrobang: *HIGH SYSTEM - ALERT PROCESSING FAILED*\n\n📋 *SITUATION*\nAlert processing system failed to parse incoming notification\n\n📊 *BACKGROUND*\nError: {str(e)}\nRaw message: {msg[:500]}...\n\n🔍 *ASSESSMENT*\nHIGH SYSTEM: Alert processing failure may cause missed critical notifications\n\n💡 *RECOMMENDATION*\n1. Check SlackNotifier Lambda function logs\n2. Verify SNS message format compatibility\n3. Update alert processor for new message formats\n4. Test alert processing with sample messages\n5. Implement alert processing monitoring\n\"\"\"\n\n        req = urllib.request.Request(\n            WEBHOOK,\n            data=json.dumps({\"text\": text}).encode(),\n            headers={'Content-Type': 'application/json'}\n        )\n        urllib.request.urlopen(req)\n\n    return {\"statusCode\": 200, \"body\": \"SBAR alerts processed\"}\nEOF\ncd /tmp && zip -j \"$TMP_ZIP\" slack_notifier_enhanced.py && cd - >/dev/null\n\nif aws lambda get-function --function-name \"$LAMBDA_NAME\" \\\n     --region \"$AWS_REGION\" &>/dev/null; then\n  aws lambda update-function-code \\\n    --function-name \"$LAMBDA_NAME\" \\\n    --zip-file \"fileb://$TMP_ZIP\" \\\n    --region \"$AWS_REGION\"\nelse\n  aws lambda create-function \\\n    --function-name \"$LAMBDA_NAME\" \\\n    --runtime python3.9 \\\n    --handler slack_notifier_enhanced.lambda_handler \\\n    --role \"$ROLE_ARN\" \\\n    --zip-file \"fileb://$TMP_ZIP\" \\\n    --environment \"Variables={SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}}\" \\\n    --timeout 30 --memory-size 128 \\\n    --region \"$AWS_REGION\"\nfi\n\nrm \"$TMP_ZIP\" /tmp/slack_notifier_enhanced.py\n\n# Apply business analytics tags to Lambda\nLAMBDA_ARN=\"arn:aws:lambda:${AWS_REGION}:${AWS_ACCOUNT_ID}:function:${LAMBDA_NAME}\"\napply_business_tags \"$LAMBDA_ARN\" \"infrastructure\" \"fixed\" \"monitoring\"\n\necho \"✅ Enhanced Lambda: $LAMBDA_NAME\"\n\n# Grant SNS invoke permission (idempotent)\naws lambda add-permission \\\n  --function-name \"$LAMBDA_NAME\" \\\n  --statement-id \"AllowSNSTrigger\" \\\n  --action lambda:InvokeFunction \\\n  --principal sns.amazonaws.com \\\n  --source-arn \"$TOPIC_ARN\" \\\n  --region \"$AWS_REGION\" 2>/dev/null || true\n\n# Subscribe Lambda if missing\nif ! aws sns list-subscriptions-by-topic --topic-arn \"$TOPIC_ARN\" \\\n     --region \"$AWS_REGION\" \\\n     --query \"Subscriptions[?Endpoint=='arn:aws:lambda:${AWS_REGION}:${AWS_ACCOUNT_ID}:function:${LAMBDA_NAME}']\" \\\n     --output text | grep -q .; then\n  aws sns subscribe \\\n    --topic-arn \"$TOPIC_ARN\" \\\n    --protocol lambda \\\n    --notification-endpoint \"arn:aws:lambda:${AWS_REGION}:${AWS_ACCOUNT_ID}:function:${LAMBDA_NAME}\" \\\n    --region \"$AWS_REGION\"\nfi\n\n# 6️⃣ Tag resources with business analytics tags\necho \"Applying business analytics tags to AWS resources...\"\n\n# Amplify (frontend hosting - variable cost by traffic)\nAMPLIFY_ARN=\"arn:aws:amplify:${AWS_REGION}:${AWS_ACCOUNT_ID}:apps/${AMPLIFY_APP_ID}\"\napply_business_tags \"$AMPLIFY_ARN\" \"frontend\" \"variable\" \"app-hosting\"\n\n# API Gateway (API endpoints - variable cost by requests)\nAPI_GATEWAY_ARN=\"arn:aws:apigateway:${AWS_REGION}::/restapis/${API_ID}/stages/${STAGE}\"\napply_business_tags \"$API_GATEWAY_ARN\" \"api\" \"variable\" \"gateway\"\n\necho \"✅ Applied business analytics tags to Amplify & API Gateway\"\n\n# 7️⃣ Enhanced CloudWatch alarms with security monitoring\necho \"⏳ Creating enhanced CloudWatch alarms...\"\nCW=\"aws cloudwatch put-metric-alarm --region $AWS_REGION\"\n\n# Original system alarms\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Amplify-5XX\" \\\n    --namespace AWS/AmplifyHosting --metric-name 5xxErrors \\\n    --dimensions Name=App,Value=\"$AMPLIFY_APP_ID\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Amplify 5xx errors\"\n\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-API-5XX\" \\\n    --namespace AWS/ApiGateway --metric-name 5XXError \\\n    --dimensions Name=ApiName,Value=\"$API_NAME\" Name=Stage,Value=\"$STAGE\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"API Gateway 5xx errors\"\n\n# Enhanced Lambda monitoring with security focus\nfor fn in bedrock-post webhook usage-metrics; do\n  $CW --alarm-name \"${SERVICE_NAME}-${STAGE}-LambdaErr-${fn}\" \\\n      --namespace AWS/Lambda --metric-name Errors \\\n      --dimensions Name=FunctionName,Value=\"${SERVICE_NAME}-${STAGE}-${fn}\" \\\n      --statistic Sum --period 300 --evaluation-periods 1 \\\n      --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n      --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n      --alarm-description \"Lambda ${fn} errors\"\ndone\n\n# 🔒 NEW: Security-specific alarms\necho \"⏳ Creating security-specific monitoring alarms...\"\n\n# Webhook signature verification failures\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Webhook-SigFail\" \\\n    --namespace \"Custom/Security\" --metric-name SignatureFailures \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Webhook signature verification failures - potential security breach\"\n\n# Repeated webhook security failures (pattern detection)\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Webhook-SecurityPattern\" \\\n    --namespace \"Custom/Security\" --metric-name SignatureFailures \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 900 --evaluation-periods 2 \\\n    --threshold 3 --comparison-operator GreaterThanThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Repeated webhook signature failures indicate ongoing attack\"\n\n# Customer lookup failures (data integrity)\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-CustomerLookupFail\" \\\n    --namespace \"Custom/Business\" --metric-name CustomerLookupFailures \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 600 --evaluation-periods 2 \\\n    --threshold 3 --comparison-operator GreaterThanThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Repeated customer lookup failures indicate data corruption or attack\"\n\n# Auth0 integration failures\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Auth0-Failures\" \\\n    --namespace \"Custom/Security\" --metric-name Auth0Failures \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 2 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Auth0 integration failures in webhook processing\"\n\n# Stripe API errors (separate from customer lookup)\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Stripe-APIErrors\" \\\n    --namespace \"Custom/Business\" --metric-name StripeAPIErrors \\\n    --dimensions Name=Function,Value=\"webhook\" \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Stripe API errors in webhook processing\"\n\n# Bedrock errors\n$CW --alarm-name \"${SERVICE_NAME}-${STAGE}-Bedrock-Err\" \\\n    --namespace AWS/Bedrock --metric-name InvocationServerErrors \\\n    --statistic Sum --period 300 --evaluation-periods 1 \\\n    --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \\\n    --alarm-actions \"$TOPIC_ARN\" --treat-missing-data notBreaching \\\n    --alarm-description \"Bedrock invocation errors\"\n\necho \"✅ Enhanced alarms created (system + security)\"\n\n# 8️⃣ AWS Budgets\necho \"⏳ Upserting Budgets…\"\nupsert_budget(){\n  NAME=$1 LIMIT=$2\n  # Convert LIMIT to string to avoid type errors\n  LIMIT_STR=\\\"$LIMIT\\\"\n\n  # Directly try to get the specific budget by name\n  if aws budgets describe-budget \\\n    --account-id \"$AWS_ACCOUNT_ID\" \\\n    --region \"$AWS_REGION\" \\\n    --budget-name \"$NAME\" \\\n    --output text >/dev/null 2>&1; then\n\n    echo \"  • Budget '$NAME' exists, updating it...\"\n    aws budgets update-budget \\\n      --account-id \"$AWS_ACCOUNT_ID\" \\\n      --region \"$AWS_REGION\" \\\n      --new-budget \"{\n        \\\"BudgetName\\\":\\\"$NAME\\\",\n        \\\"BudgetType\\\":\\\"COST\\\",\n        \\\"TimeUnit\\\":\\\"MONTHLY\\\",\n        \\\"BudgetLimit\\\":{\\\"Amount\\\":$LIMIT_STR,\\\"Unit\\\":\\\"USD\\\"},\n        \\\"CostFilters\\\":{\n          \\\"TagKeyValue\\\":[\\\"${PROJECT_TAG}\\$${PROJECT_VALUE}\\\"]\n        }\n      }\"\n    echo \"  • Updated budget $NAME = \\$$LIMIT/mo\"\n  else\n    echo \"  • Budget '$NAME' doesn't exist, creating it...\"\n    aws budgets create-budget \\\n      --account-id \"$AWS_ACCOUNT_ID\" \\\n      --region \"$AWS_REGION\" \\\n      --budget \"{\n        \\\"BudgetName\\\":\\\"$NAME\\\",\n        \\\"BudgetType\\\":\\\"COST\\\",\n        \\\"TimeUnit\\\":\\\"MONTHLY\\\",\n        \\\"BudgetLimit\\\":{\\\"Amount\\\":$LIMIT_STR,\\\"Unit\\\":\\\"USD\\\"},\n        \\\"CostFilters\\\":{\n          \\\"TagKeyValue\\\":[\\\"${PROJECT_TAG}\\$${PROJECT_VALUE}\\\"]\n        }\n      }\" \\\n      --notifications-with-subscribers \"[\n        {\\\"Notification\\\":{\n           \\\"NotificationType\\\":\\\"ACTUAL\\\",\n           \\\"ComparisonOperator\\\":\\\"GREATER_THAN\\\",\n           \\\"Threshold\\\":80,\n           \\\"ThresholdType\\\":\\\"PERCENTAGE\\\"},\n         \\\"Subscribers\\\":[{\\\"SubscriptionType\\\":\\\"SNS\\\",\\\"Address\\\":\\\"$TOPIC_ARN\\\"}]\n        },\n        {\\\"Notification\\\":{\n           \\\"NotificationType\\\":\\\"ACTUAL\\\",\n           \\\"ComparisonOperator\\\":\\\"GREATER_THAN\\\",\n           \\\"Threshold\\\":100,\n           \\\"ThresholdType\\\":\\\"PERCENTAGE\\\"},\n         \\\"Subscribers\\\":[{\\\"SubscriptionType\\\":\\\"SNS\\\",\\\"Address\\\":\\\"$TOPIC_ARN\\\"}]\n        }\n      ]\"\n    echo \"  • Created budget $NAME = \\$$LIMIT/mo\"\n  fi\n}\n\nupsert_budget \"BedrockBudget\" \"$BEDROCK_MONTHLY_BUDGET\"\necho \"✅ Budgets upserted\"\n\n# 9️⃣ Cost Anomaly Detection (CLAUDE.md compliant - no fallbacks)\necho \"⏳ Configuring Cost Anomaly Detection...\"\nMON_NAME=\"OverallCostMonitor\"\n\n# Check for existing monitor first\necho \"   Checking for existing monitors...\"\nMON_ARN=$(aws ce get-anomaly-monitors \\\n  --region \"$AWS_REGION\" \\\n  --query \"AnomalyMonitors[?MonitorName=='$MON_NAME'].MonitorArn\" \\\n  --output text)\n\nif [ -z \"$MON_ARN\" ]; then\n  # Try to find ANY existing dimensional monitor to reuse\n  echo \"   No named monitor found, checking for any existing dimensional monitor...\"\n  MON_ARN=$(aws ce get-anomaly-monitors \\\n    --region \"$AWS_REGION\" \\\n    --query \"AnomalyMonitors[?MonitorType=='DIMENSIONAL'] | [0].MonitorArn\" \\\n    --output text)\n\n  if [ -z \"$MON_ARN\" ] || [ \"$MON_ARN\" = \"None\" ]; then\n    echo \"   Creating custom cost anomaly monitor (to avoid dimensional limits)...\"\n    # Use CUSTOM monitor with cost filter instead of DIMENSIONAL\n    MON_ARN=$(aws ce create-anomaly-monitor \\\n      --region \"$AWS_REGION\" \\\n      --anomaly-monitor '{\n        \"MonitorName\":\"'\"$MON_NAME\"'\",\n        \"MonitorType\":\"CUSTOM\",\n        \"MonitorSpecification\":\"{\\\"Dimension\\\":{\\\"Key\\\":\\\"SERVICE\\\",\\\"Values\\\":[\\\"Amazon Elastic Compute Cloud - Compute\\\",\\\"AWS Lambda\\\",\\\"Amazon API Gateway\\\",\\\"Amazon Simple Notification Service\\\",\\\"Amazon Bedrock\\\"],\\\"MatchOptions\\\":[\\\"EQUALS\\\"]}}\"\n      }' \\\n      --query 'MonitorArn' --output text)\n\n    echo \"   Created custom monitor: $MON_ARN\"\n  else\n    echo \"   Reusing existing dimensional monitor: $MON_ARN\"\n  fi\nelse\n  echo \"   Using existing named monitor: $MON_ARN\"\nfi\n\n# Create subscription (fail fast)\nSUB_NAME=\"CostSpikeSub\"\necho \"   Checking for existing subscriptions...\"\nEXISTS=$(aws ce get-anomaly-subscriptions \\\n  --region \"$AWS_REGION\" \\\n  --query \"AnomalySubscriptions[?SubscriptionName=='$SUB_NAME']\" \\\n  --output text)\n\nif [ -z \"$EXISTS\" ]; then\n  echo \"   Creating anomaly subscription...\"\n  aws ce create-anomaly-subscription \\\n    --region \"$AWS_REGION\" \\\n    --anomaly-subscription '{\n      \"SubscriptionName\":\"'\"$SUB_NAME\"'\",\n      \"Threshold\":10,\n      \"Frequency\":\"IMMEDIATE\",\n      \"MonitorArnList\":[\"'\"$MON_ARN\"'\"],\n      \"Subscribers\":[{\"Type\":\"SNS\",\"Address\":\"'\"$TOPIC_ARN\"'\"}]\n    }' >/dev/null\n\n  echo \"   Created subscription: $SUB_NAME\"\nelse\n  echo \"   Using existing subscription: $SUB_NAME\"\nfi\n\necho \"✅ Cost Anomaly Detection configured\"\n\n# 🔟 Final summary\necho\necho \"📋 CLAUDE.md Compliant Enhanced Monitoring Summary:\"\necho \"   ✅ SNS topic: $TOPIC_ARN\"\necho \"   ✅ Enhanced Lambda function: $LAMBDA_NAME\"\necho \"   ✅ System alarms: API Gateway, Lambda, Bedrock\"\necho \"   ✅ Security alarms: Signature failures, auth errors, attack patterns\"\necho \"   ✅ Business alarms: Customer lookup failures, Stripe API errors\"\necho \"   ✅ Budget monitoring: BedrockBudget = \\$$BEDROCK_MONTHLY_BUDGET/mo\"\necho \"   ✅ Cost anomaly detection: $MON_NAME\"\necho \"   ✅ No fallback patterns - fail fast on all errors\"\necho \"   ✅ Business analytics tagging applied to all resources\"\necho\necho \"🔒 Security Features Added:\"\necho \"   • Webhook signature verification failure detection\"\necho \"   • Attack pattern recognition (repeated failures)\"\necho \"   • Customer data integrity monitoring\"\necho \"   • Auth0 integration failure alerts\"\necho \"   • SBAR-format Slack notifications with actionable recommendations\"\necho\necho \"💰 Business Analytics Tags Applied:\"\necho \"   • Environment: $ENVIRONMENT_VALUE (production/development)\"\necho \"   • Cost tracking by business line (frontend/api/infrastructure)\"\necho \"   • Cost type classification (fixed/variable)\"\necho \"   • Endpoint-specific attribution for detailed cost analysis\"\necho\necho \"🎉 Enhanced monitoring setup complete! Test Slack with:\"\necho \"  aws sns publish --topic-arn $TOPIC_ARN --message '🚀 Enhanced monitoring operational!'\"\necho\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/ona-front-end/express-chatbot/setup-monitoring.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Check if AWS CLI is installed\nif ! command -v aws &> /dev/null; then\n    echo \"AWS CLI is not installed. Please install it first.\"\n    exit 1\nfi\n\n# Default region\nREGION=\"us-east-1\"\nAPI_ID=\"\"\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n  case $1 in\n    --region)\n      REGION=\"$2\"\n      shift 2\n      ;;\n    --api-id)\n      API_ID=\"$2\"\n      shift 2\n      ;;\n    --help)\n      echo \"Usage: $0 [options] API_ID\"\n      echo \"Options:\"\n      echo \"  --region REGION     AWS region (default: us-east-1)\"\n      echo \"  --api-id ID         API Gateway ID (required)\"\n      echo \"  --help              Show this help message\"\n      echo \"\"\n      echo \"Or simply provide the API ID as the first argument:\"\n      echo \"  $0 API_ID\"\n      exit 0\n      ;;\n    *)\n      # If no flag but a value, assume it's the API ID\n      if [[ \"$1\" != -* && -z \"$API_ID\" ]]; then\n        API_ID=\"$1\"\n        shift\n      else\n        echo \"Unknown option: $1\"\n        echo \"Run with --help for usage information\"\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# If API ID is not provided via arguments, check if it's the first positional argument\nif [ -z \"$API_ID\" ] && [ $# -gt 0 ]; then\n  API_ID=\"$1\"\nfi\n\n# Validate arguments\nif [ -z \"$API_ID\" ]; then\n    echo \"API Gateway ID is required. Use --api-id parameter or provide it as the first argument.\"\n    exit 1\nfi\n\n# Validate AWS credentials are configured\necho \"Validating AWS credentials...\"\nif ! aws sts get-caller-identity &> /dev/null; then\n    echo \"AWS credentials not configured or invalid. Please run 'aws configure' first.\"\n    exit 1\nfi\n\necho \"Fetching API Gateway resources for API ID: $API_ID\"\necho \"Region: $REGION\"\n\n# Get resources and format the output\naws apigateway get-resources \\\n  --rest-api-id $API_ID \\\n  --region $REGION \\\n  --output table\n\necho \"\"\necho \"To find the root resource ID, look for a resource with path '/' in the output above.\"\necho \"Use this ID with the --root-resource-id parameter in the deploy script.\"\necho \"\"\necho \"Example deployment command:\"\necho \"./deploy-conversation-storage.sh --api-id $API_ID --root-resource-id YOUR_ROOT_RESOURCE_ID --region $REGION\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/ona-front-end/express-chatbot/deployment/conversation-storage/get-api-resources.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\nset -e\n\n# Default parameters\nSTAGE=\"dev\"\nREGION=\"us-east-1\"\nBACKUP_SUFFIX=$(date +%Y%m%d-%H%M%S)\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n  case $1 in\n    --stage)\n      STAGE=\"$2\"\n      shift 2\n      ;;\n    --region)\n      REGION=\"$2\"\n      shift 2\n      ;;\n    --suffix)\n      BACKUP_SUFFIX=\"$2\"\n      shift 2\n      ;;\n    --help)\n      echo \"Usage: $0 [options]\"\n      echo \"Options:\"\n      echo \"  --stage STAGE        Deployment stage - dev, staging, prod (default: dev)\"\n      echo \"  --region REGION      AWS region (default: us-east-1)\"\n      echo \"  --suffix SUFFIX      Backup name suffix (default: current timestamp)\"\n      echo \"  --help               Show this help message\"\n      exit 0\n      ;;\n    *)\n      echo \"Unknown option: $1\"\n      echo \"Run with --help for usage information\"\n      exit 1\n      ;;\n  esac\ndone\n\n# Validate AWS credentials are configured\necho \"Validating AWS credentials...\"\nif ! aws sts get-caller-identity &> /dev/null; then\n    echo \"AWS credentials not configured or invalid. Please run 'aws configure' first.\"\n    exit 1\nfi\n\n# Create backups for all conversation storage tables\necho \"Starting backup process for $STAGE environment in $REGION region...\"\n\n# List of tables to backup\nTABLES=(\n  \"${STAGE}-PolicyAnalyst-Conversations\"\n  \"${STAGE}-PolicyAnalyst-Messages\"\n  \"${STAGE}-PolicyAnalyst-UserConversationMeta\"\n)\n\nfor TABLE in \"${TABLES[@]}\"; do\n  echo \"Creating backup for $TABLE...\"\n\n  # Check if table exists\n  if aws dynamodb describe-table --table-name \"$TABLE\" --region \"$REGION\" &>/dev/null; then\n    # Create backup\n    BACKUP_NAME=\"${TABLE}-${BACKUP_SUFFIX}\"\n\n    aws dynamodb create-backup \\\n      --table-name \"$TABLE\" \\\n      --backup-name \"$BACKUP_NAME\" \\\n      --region \"$REGION\"\n\n    echo \"Backup created: $BACKUP_NAME\"\n  else\n    echo \"Table $TABLE does not exist, skipping backup.\"\n  fi\ndone\n\necho \"Backup process completed successfully!\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/ona-front-end/express-chatbot/deployment/conversation-storage/backup-tables.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n# fix-lambda-with-deps.sh - Package Lambda functions with all dependencies and update them using S3\n\nset -e  # Exit immediately if a command fails\n\n# Set variables\nREGION=\"us-east-1\"\nFUNCTION_OPTIONS=\"express-chatbot-dev-subscription-details-options\"\nFUNCTION_MAIN=\"express-chatbot-dev-subscription-details\"\nPACKAGE_DIR=\"lambda-package\"\nOPTIONS_ZIP=\"options-function.zip\"\nMAIN_ZIP=\"main-function.zip\"\nS3_BUCKET=\"express-chatbot-lambda-packages-$(date +%s)\"\n\necho \"=== Lambda Package and Update Script (via S3) ===\"\necho \"Options function: $FUNCTION_OPTIONS\"\necho \"Main function: $FUNCTION_MAIN\"\necho \"\"\n\n# Check if we have server.js\nif [ ! -f \"server.js\" ]; then\n  echo \"Error: server.js file not found in current directory!\"\n  echo \"Please run this script from the directory containing your server.js file.\"\n  exit 1\nfi\n\n# Create S3 bucket for temporary storage\necho \"Creating S3 bucket for package storage...\"\naws s3 mb s3://$S3_BUCKET --region $REGION\naws s3api put-bucket-lifecycle-configuration \\\n  --bucket $S3_BUCKET \\\n  --lifecycle-configuration '{\"Rules\":[{\"ID\":\"DeleteAfterOneDay\",\"Status\":\"Enabled\",\"Expiration\":{\"Days\":1},\"Prefix\":\"\"}]}' \\\n  --region $REGION\n\n# Prepare packaging directory - clean contents but keep directory\necho \"Preparing packaging directory...\"\nif [ -d \"$PACKAGE_DIR\" ]; then\n  # Clear contents but keep the directory\n  echo \"Cleaning existing $PACKAGE_DIR directory...\"\n  rm -rf \"$PACKAGE_DIR\"/*\nelse\n  # Create directory if it doesn't exist\n  echo \"Creating $PACKAGE_DIR directory...\"\n  mkdir -p \"$PACKAGE_DIR\"\nfi\n\n# Copy server files and package.json\necho \"Copying server files...\"\ncp server.js \"$PACKAGE_DIR/\"\ncp package.json \"$PACKAGE_DIR/\"\ncp -r handlers \"$PACKAGE_DIR/\" 2>/dev/null || echo \"No handlers directory found, skipping\"\ncp -r helpers \"$PACKAGE_DIR/\" 2>/dev/null || echo \"No helpers directory found, skipping\"\ncp -r utils \"$PACKAGE_DIR/\" 2>/dev/null || echo \"No utils directory found, skipping\"\ncp -r lib \"$PACKAGE_DIR/\" 2>/dev/null || echo \"No lib directory found, skipping\"\n\n# Install dependencies\necho \"Installing dependencies (this may take a while)...\"\ncd \"$PACKAGE_DIR\"\nnpm install --production\ncd ..\n\n# Create ZIP files\necho \"Creating Lambda deployment package...\"\ncd \"$PACKAGE_DIR\"\nzip -r \"../$OPTIONS_ZIP\" .\nzip -r \"../$MAIN_ZIP\" .\ncd ..\n\n# Upload packages to S3\necho \"Uploading packages to S3...\"\naws s3 cp \"$OPTIONS_ZIP\" s3://$S3_BUCKET/ --region $REGION\naws s3 cp \"$MAIN_ZIP\" s3://$S3_BUCKET/ --region $REGION\n\n# Update Lambda functions\necho \"Updating OPTIONS Lambda function from S3...\"\naws lambda update-function-code \\\n  --function-name \"$FUNCTION_OPTIONS\" \\\n  --s3-bucket \"$S3_BUCKET\" \\\n  --s3-key \"$OPTIONS_ZIP\" \\\n  --region \"$REGION\"\n\necho \"Updating main Lambda function from S3...\"\naws lambda update-function-code \\\n  --function-name \"$FUNCTION_MAIN\" \\\n  --s3-bucket \"$S3_BUCKET\" \\\n  --s3-key \"$MAIN_ZIP\" \\\n  --region \"$REGION\"\n\n# Clean up temporary files but keep the directory structure\necho \"Cleaning up temporary files...\"\nrm \"$OPTIONS_ZIP\" \"$MAIN_ZIP\"\nrm -rf \"$PACKAGE_DIR/node_modules\"\n\necho \"\"\necho \"Lambda functions updated successfully with all dependencies!\"\necho \"Note: The S3 bucket $S3_BUCKET will be automatically deleted after 1 day.\"\necho \"Testing...\"\n\n# Wait for function to update\necho \"Waiting 15 seconds for Lambda functions to update...\"\nsleep 15\n\n# Test the OPTIONS endpoint\necho \"Testing OPTIONS request...\"\ncurl -i -X OPTIONS \\\n  \"https://y1spda7tbb.execute-api.us-east-1.amazonaws.com/dev/api/subscription-details\" \\\n  -H \"Origin: https://app.asoba.co\" \\\n  -H \"Access-Control-Request-Method: POST\" \\\n  -H \"Access-Control-Request-Headers: Content-Type,Authorization\"\n\necho \"\"\necho \"Lambda update complete. Please check your web application to verify that it works correctly.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/ona-front-end/express-chatbot/fix-lambda-with-deps.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Stop Mistral LLM Deployment Script\n# This script safely terminates the Mistral LLM instance and cleans up resources\n\nset -e\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Logging function\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Configuration\nPROJECT_NAME=\"mistral-base\"  # Match deploy script\nREGION=\"${AWS_REGION:-us-west-2}\"   # Default to us-west-2 (matches deploy script)\n\n# Function to stop instance\nstop_instance() {\n    local instance_id=$1\n    local volume_id=$2\n\n    if [ -z \"$instance_id\" ]; then\n        error \"No instance ID provided\"\n    fi\n\n    log \"Stopping Mistral LLM deployment...\"\n    log \"Instance ID: $instance_id\"\n\n    # Check if instance exists and is running\n    INSTANCE_STATE=$(aws ec2 describe-instances \\\n        --region $REGION \\\n        --instance-ids $instance_id \\\n        --query 'Reservations[0].Instances[0].State.Name' \\\n        --output text 2>/dev/null || echo \"not-found\")\n\n    if [ \"$INSTANCE_STATE\" = \"not-found\" ]; then\n        warn \"Instance $instance_id not found or already terminated\"\n        return 0\n    fi\n\n    log \"Current instance state: $INSTANCE_STATE\"\n\n    # Create snapshot if volume exists\n    if [ -n \"$volume_id\" ]; then\n        log \"Creating snapshot of volume $volume_id before termination...\"\n        SNAPSHOT_ID=$(aws ec2 create-snapshot \\\n            --region $REGION \\\n            --volume-id $volume_id \\\n            --description \"Mistral LLM snapshot created on $(date +%Y-%m-%d-%H-%M-%S)\" \\\n            --tag-specifications \"ResourceType=snapshot,Tags=[{Key=Name,Value=${PROJECT_NAME}-snapshot-$(date +%Y%m%d)},{Key=Project,Value=${PROJECT_NAME}}]\" \\\n            --query 'SnapshotId' --output text 2>/dev/null || echo \"failed\")\n\n        if [ \"$SNAPSHOT_ID\" != \"failed\" ]; then\n            log \"Created snapshot: $SNAPSHOT_ID\"\n        else\n            warn \"Failed to create snapshot, continuing with termination\"\n        fi\n    fi\n\n    # Terminate instance\n    if [ \"$INSTANCE_STATE\" != \"terminated\" ] && [ \"$INSTANCE_STATE\" != \"terminating\" ]; then\n        log \"Terminating instance...\"\n        aws ec2 terminate-instances --region $REGION --instance-ids $instance_id\n\n        log \"Waiting for instance to terminate...\"\n        aws ec2 wait instance-terminated --region $REGION --instance-ids $instance_id\n        log \"Instance terminated successfully\"\n    else\n        log \"Instance already terminated or terminating\"\n    fi\n\n    # Delete volume (optional)\n    if [ -n \"$volume_id\" ]; then\n        read -p \"Delete the EBS volume $volume_id? (y/N): \" -r\n        if [[ $REPLY =~ ^[Yy]$ ]]; then\n            log \"Deleting EBS volume...\"\n            aws ec2 delete-volume --volume-id $volume_id 2>/dev/null || warn \"Failed to delete volume (it may already be deleted)\"\n            log \"Volume deletion initiated\"\n        else\n            log \"Keeping EBS volume: $volume_id\"\n        fi\n    fi\n}\n\n# Function to get cost summary\nget_cost_summary() {\n    local instance_id=$1\n\n    if [ -z \"$instance_id\" ]; then\n        return\n    fi\n\n    log \"Calculating cost summary...\"\n\n    # Get instance launch time\n    LAUNCH_TIME=$(aws ec2 describe-instances \\\n        --instance-ids $instance_id \\\n        --query 'Reservations[0].Instances[0].LaunchTime' \\\n        --output text 2>/dev/null || echo \"unknown\")\n\n    if [ \"$LAUNCH_TIME\" != \"unknown\" ]; then\n        # Calculate runtime (rough estimate)\n        LAUNCH_EPOCH=$(date -d \"$LAUNCH_TIME\" +%s 2>/dev/null || echo \"0\")\n        CURRENT_EPOCH=$(date +%s)\n        RUNTIME_HOURS=$(( (CURRENT_EPOCH - LAUNCH_EPOCH) / 3600 ))\n\n        # Cost calculation (c7g.2xlarge = $0.289/hour)\n        COMPUTE_COST=$(echo \"$RUNTIME_HOURS * 0.289\" | bc -l 2>/dev/null || echo \"0\")\n\n        log \"Runtime: ~$RUNTIME_HOURS hours\"\n        log \"Estimated compute cost: ~\\$$(printf \"%.2f\" $COMPUTE_COST)\"\n        log \"Plus storage costs: ~\\$0.80/day for EBS volume\"\n    fi\n}\n\n# Function to cleanup tracking files\ncleanup_files() {\n    log \"Cleaning up tracking files...\"\n\n    if [ -f .mistral-instance-id ]; then\n        rm .mistral-instance-id\n        log \"Removed .mistral-instance-id\"\n    fi\n\n    if [ -f .mistral-volume-id ]; then\n        rm .mistral-volume-id\n        log \"Removed .mistral-volume-id\"\n    fi\n\n    if [ -f mistral_client.py ]; then\n        log \"Keeping mistral_client.py for future use\"\n    fi\n}\n\n# Function to optionally cleanup infrastructure\ncleanup_infrastructure() {\n    read -p \"Do you want to delete ALL infrastructure (VPC, subnets, etc.)? This will remove everything created by deploy-mistral.sh (y/N): \" -r\n\n    if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n        log \"Keeping infrastructure for future use\"\n        return 0\n    fi\n\n    warn \"This will delete ALL Mistral LLM infrastructure!\"\n    read -p \"Are you absolutely sure? Type 'DELETE' to confirm: \" -r\n\n    if [ \"$REPLY\" != \"DELETE\" ]; then\n        log \"Infrastructure deletion cancelled\"\n        return 0\n    fi\n\n    log \"Deleting infrastructure...\"\n\n    # Get VPC ID\n    VPC_ID=$(aws ec2 describe-vpcs \\\n        --filters \"Name=tag:Name,Values=${PROJECT_NAME}-vpc\" \\\n        --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$VPC_ID\" = \"None\" ]; then\n        log \"No infrastructure found to delete\"\n        return 0\n    fi\n\n    log \"Found VPC: $VPC_ID\"\n\n    # Delete NAT Gateway\n    NAT_GW_ID=$(aws ec2 describe-nat-gateways \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=state,Values=available\" \\\n        --query 'NatGateways[0].NatGatewayId' --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$NAT_GW_ID\" != \"None\" ]; then\n        log \"Deleting NAT Gateway: $NAT_GW_ID\"\n        aws ec2 delete-nat-gateway --nat-gateway-id $NAT_GW_ID\n        log \"Waiting for NAT Gateway deletion...\"\n        aws ec2 wait nat-gateway-deleted --nat-gateway-ids $NAT_GW_ID 2>/dev/null || true\n    fi\n\n    # Delete Internet Gateway\n    IGW_ID=$(aws ec2 describe-internet-gateways \\\n        --filters \"Name=attachment.vpc-id,Values=$VPC_ID\" \\\n        --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$IGW_ID\" != \"None\" ]; then\n        log \"Detaching and deleting Internet Gateway: $IGW_ID\"\n        aws ec2 detach-internet-gateway --vpc-id $VPC_ID --internet-gateway-id $IGW_ID\n        aws ec2 delete-internet-gateway --internet-gateway-id $IGW_ID\n    fi\n\n    # Delete subnets\n    SUBNET_IDS=$(aws ec2 describe-subnets \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \\\n        --query 'Subnets[].SubnetId' --output text 2>/dev/null || echo \"\")\n\n    for SUBNET_ID in $SUBNET_IDS; do\n        if [ -n \"$SUBNET_ID\" ]; then\n            log \"Deleting subnet: $SUBNET_ID\"\n            aws ec2 delete-subnet --subnet-id $SUBNET_ID 2>/dev/null || true\n        fi\n    done\n\n    # Delete route tables (except main)\n    RT_IDS=$(aws ec2 describe-route-tables \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \\\n        --query 'RouteTables[?Associations[0].Main==`false`].RouteTableId' --output text 2>/dev/null || echo \"\")\n\n    for RT_ID in $RT_IDS; do\n        if [ -n \"$RT_ID\" ]; then\n            log \"Deleting route table: $RT_ID\"\n            aws ec2 delete-route-table --route-table-id $RT_ID 2>/dev/null || true\n        fi\n    done\n\n    # Delete security groups (except default)\n    SG_IDS=$(aws ec2 describe-security-groups \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \\\n        --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text 2>/dev/null || echo \"\")\n\n    for SG_ID in $SG_IDS; do\n        if [ -n \"$SG_ID\" ]; then\n            log \"Deleting security group: $SG_ID\"\n            aws ec2 delete-security-group --group-id $SG_ID 2>/dev/null || true\n        fi\n    done\n\n    # Delete VPC\n    log \"Deleting VPC: $VPC_ID\"\n    aws ec2 delete-vpc --vpc-id $VPC_ID 2>/dev/null || warn \"Failed to delete VPC (may have dependencies)\"\n\n    # Delete IAM resources\n    ROLE_NAME=\"${PROJECT_NAME}-role\"\n    PROFILE_NAME=\"${PROJECT_NAME}-profile\"\n\n    if aws iam get-instance-profile --instance-profile-name $PROFILE_NAME &>/dev/null; then\n        log \"Deleting IAM instance profile: $PROFILE_NAME\"\n        aws iam remove-role-from-instance-profile --instance-profile-name $PROFILE_NAME --role-name $ROLE_NAME 2>/dev/null || true\n        aws iam delete-instance-profile --instance-profile-name $PROFILE_NAME 2>/dev/null || true\n    fi\n\n    if aws iam get-role --role-name $ROLE_NAME &>/dev/null; then\n        log \"Deleting IAM role: $ROLE_NAME\"\n        aws iam delete-role-policy --role-name $ROLE_NAME --policy-name \"${PROJECT_NAME}-policy\" 2>/dev/null || true\n        aws iam delete-role --role-name $ROLE_NAME 2>/dev/null || true\n    fi\n\n    # Release Elastic IPs\n    EIP_ALLOC_IDS=$(aws ec2 describe-addresses \\\n        --filters \"Name=domain,Values=vpc\" \\\n        --query 'Addresses[?AssociationId==null].AllocationId' --output text 2>/dev/null || echo \"\")\n\n    for EIP_ID in $EIP_ALLOC_IDS; do\n        if [ -n \"$EIP_ID\" ]; then\n            log \"Releasing Elastic IP: $EIP_ID\"\n            aws ec2 release-address --allocation-id $EIP_ID 2>/dev/null || true\n        fi\n    done\n\n    log \"Infrastructure cleanup completed\"\n}\n\n# Main function\nmain() {\n    log \"Mistral LLM Stop Script\"\n\n    # Check if tracking files exist (try multiple possible names)\n    if [ -f .mistral-base-instance-id ]; then\n        INSTANCE_ID=$(cat .mistral-base-instance-id)\n        VOLUME_ID=$(cat .mistral-volume-id 2>/dev/null || echo \"\")\n        log \"Found marketplace tracking files\"\n    elif [ -f .mistral-instance-id ]; then\n        INSTANCE_ID=$(cat .mistral-instance-id)\n        VOLUME_ID=$(cat .mistral-volume-id 2>/dev/null || echo \"\")\n        log \"Found tracking files\"\n    else\n        # Check command line argument\n        if [ $# -eq 1 ]; then\n            INSTANCE_ID=$1\n            VOLUME_ID=\"\"\n            log \"Using instance ID from command line: $INSTANCE_ID\"\n        else\n            error \"No instance ID found. Either run from the deployment directory or provide instance ID as argument.\"\n        fi\n    fi\n\n    # Get cost summary before stopping\n    get_cost_summary $INSTANCE_ID\n\n    # Stop the instance\n    stop_instance $INSTANCE_ID $VOLUME_ID\n\n    # Cleanup tracking files\n    cleanup_files\n\n    # Ask about infrastructure cleanup\n    cleanup_infrastructure\n\n    log \"=== STOP COMPLETE ===\"\n    log \"\"\n    log \"Mistral LLM instance has been stopped\"\n    log \"Any snapshots created are preserved for future use\"\n    log \"\"\n    log \"To redeploy, run: ./deploy-mistral.sh\"\n}\n\n# Check prerequisites\nif ! command -v aws &> /dev/null; then\n    error \"AWS CLI not found. Please install AWS CLI.\"\nfi\n\nif ! aws sts get-caller-identity &> /dev/null; then\n    error \"AWS credentials not configured. Run 'aws configure' first.\"\nfi\n\n# Run main function\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/scripts/stop-mistral.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for system service management", "completion": "```bash\n#!/bin/bash\n\n# Unified AI Services Control Script\n# Manages both Flux.1 Dev (image generation) and Mistral (text generation)\n\nset -e\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n}\n\ninfo() {\n    echo -e \"${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\n# Show usage\nusage() {\n    echo \"\"\n    echo \"🤖 AI Services Control Panel\"\n    echo \"\"\n    echo \"Usage: $0 <command> [service]\"\n    echo \"\"\n    echo \"Commands:\"\n    echo \"  start [flux|mistral|all]     Start AI service(s)\"\n    echo \"  stop [flux|mistral|all]      Stop AI service(s)\"\n    echo \"  status                       Show status of all services\"\n    echo \"  costs                        Show estimated running costs\"\n    echo \"\"\n    echo \"Examples:\"\n    echo \"  $0 start flux               Start only Flux image generation\"\n    echo \"  $0 start mistral            Start only Mistral chat\"\n    echo \"  $0 start all                Start both services\"\n    echo \"  $0 stop all                 Stop both services\"\n    echo \"  $0 status                   Check what's running\"\n    echo \"\"\n}\n\n# Check service status\ncheck_status() {\n    local service=\"$1\"\n    local instance_file=\"\"\n    local service_name=\"\"\n\n    case \"$service\" in\n        \"flux\")\n            instance_file=\".flux-dev-instance-id\"\n            service_name=\"Flux.1 Dev\"\n            ;;\n        \"mistral\")\n            instance_file=\".mistral-base-instance-id\"\n            service_name=\"Mistral Chat\"\n            ;;\n        *)\n            error \"Unknown service: $service\"\n            ;;\n    esac\n\n    if [ ! -f \"$instance_file\" ]; then\n        echo \"None\"\n        return\n    fi\n\n    local instance_id=$(cat \"$instance_file\")\n    local regions=\"us-east-1 us-west-2\"\n\n    for region in $regions; do\n        local state=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].State.Name' \\\n            --output text 2>/dev/null || echo \"None\")\n\n        if [ \"$state\" != \"None\" ]; then\n            echo \"$state\"\n            return\n        fi\n    done\n\n    echo \"Not found\"\n}\n\n# Get instance details\nget_instance_details() {\n    local service=\"$1\"\n    local instance_file=\"\"\n\n    case \"$service\" in\n        \"flux\")\n            instance_file=\".flux-dev-instance-id\"\n            ;;\n        \"mistral\")\n            instance_file=\".mistral-base-instance-id\"\n            ;;\n        *)\n            return\n            ;;\n    esac\n\n    if [ ! -f \"$instance_file\" ]; then\n        return\n    fi\n\n    local instance_id=$(cat \"$instance_file\")\n    local regions=\"us-east-1 us-west-2\"\n\n    for region in $regions; do\n        local instance_info=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].[PublicIpAddress,InstanceType,State.Name]' \\\n            --output text 2>/dev/null || echo \"None None None\")\n\n        if [ \"$(echo \"$instance_info\" | cut -f3)\" != \"None\" ]; then\n            echo \"$instance_info|$region\"\n            return\n        fi\n    done\n}\n\n# Show status command\nshow_status() {\n    log \"🔍 AI Services Status\"\n    echo \"\"\n\n    # Check Flux\n    local flux_status=$(check_status \"flux\")\n    info \"🎨 Flux.1 Dev (Image Generation): $flux_status\"\n\n    if [ \"$flux_status\" = \"running\" ]; then\n        local details=$(get_instance_details \"flux\")\n        local public_ip=$(echo \"$details\" | cut -d'|' -f1 | cut -f1)\n        local instance_type=$(echo \"$details\" | cut -d'|' -f1 | cut -f2)\n        local region=$(echo \"$details\" | cut -d'|' -f2)\n\n        echo \"  💻 Instance: $instance_type in $region\"\n        echo \"  🌐 Web Interface: http://$public_ip\"\n        echo \"  📡 API: http://$public_ip/api/generate\"\n    fi\n\n    echo \"\"\n\n    # Check Mistral\n    local mistral_status=$(check_status \"mistral\")\n    info \"💬 Mistral Chat (Text Generation): $mistral_status\"\n\n    if [ \"$mistral_status\" = \"running\" ]; then\n        local details=$(get_instance_details \"mistral\")\n        local public_ip=$(echo \"$details\" | cut -d'|' -f1 | cut -f1)\n        local instance_type=$(echo \"$details\" | cut -d'|' -f1 | cut -f2)\n        local region=$(echo \"$details\" | cut -d'|' -f2)\n\n        echo \"  💻 Instance: $instance_type in $region\"\n        echo \"  🌐 Chat Interface: http://$public_ip:8080\"\n        echo \"  📡 API: http://$public_ip:8000/v1/completions\"\n    fi\n\n    echo \"\"\n}\n\n# Show costs\nshow_costs() {\n    log \"💰 Estimated Running Costs (per hour)\"\n    echo \"\"\n\n    local flux_status=$(check_status \"flux\")\n    local mistral_status=$(check_status \"mistral\")\n    local total_cost=0\n\n    if [ \"$flux_status\" = \"running\" ]; then\n        local details=$(get_instance_details \"flux\")\n        local instance_type=$(echo \"$details\" | cut -d'|' -f1 | cut -f2)\n\n        case \"$instance_type\" in\n            \"g4dn.xlarge\")\n                echo \"🎨 Flux.1 Dev: ~$0.53/hour (g4dn.xlarge)\"\n                total_cost=$(echo \"$total_cost + 0.53\" | bc -l)\n                ;;\n            \"g5.xlarge\")\n                echo \"🎨 Flux.1 Dev: ~$1.01/hour (g5.xlarge)\"\n                total_cost=$(echo \"$total_cost + 1.01\" | bc -l)\n                ;;\n        esac\n    else\n        echo \"🎨 Flux.1 Dev: $0.00/hour (stopped)\"\n    fi\n\n    if [ \"$mistral_status\" = \"running\" ]; then\n        local details=$(get_instance_details \"mistral\")\n        local instance_type=$(echo \"$details\" | cut -d'|' -f1 | cut -f2)\n\n        case \"$instance_type\" in\n            \"g4dn.xlarge\")\n                echo \"💬 Mistral Chat: ~$0.53/hour\"\n                total_cost=$(echo \"$total_cost + 0.53\" | bc -l)\n                ;;\n            \"g5.xlarge\")\n                echo \"💬 Mistral Chat: ~$1.01/hour\"\n                total_cost=$(echo \"$total_cost + 1.01\" | bc -l)\n                ;;\n        esac\n    else\n        echo \"💬 Mistral Chat: $0.00/hour (stopped)\"\n    fi\n\n    echo \"\"\n    echo \"📊 Total Base Cost: ~$$(printf \"%.2f\" $total_cost)/hour\"\n    if [ \"$mistral_status\" = \"running\" ]; then\n        echo \"   (base model costs only)\"\n    fi\n    echo \"\"\n}\n\n# Start service\nstart_service() {\n    local service=\"$1\"\n\n    case \"$service\" in\n        \"flux\")\n            log \"🎨 Starting Flux.1 Dev...\"\n            ./start-flux-dev.sh\n            ;;\n        \"mistral\")\n            log \"💬 Starting Mistral...\"\n            ./start-mistral-simple.sh\n            ;;\n        \"all\")\n            log \"🚀 Starting all AI services...\"\n            ./start-flux-dev.sh\n            echo \"\"\n            ./start-mistral-simple.sh\n            ;;\n        *)\n            error \"Unknown service: $service. Use 'flux', 'mistral', or 'all'\"\n            ;;\n    esac\n}\n\n# Stop service\nstop_service() {\n    local service=\"$1\"\n\n    case \"$service\" in\n        \"flux\")\n            log \"🎨 Stopping Flux.1 Dev...\"\n            ./stop-flux-dev.sh\n            ;;\n        \"mistral\")\n            log \"💬 Stopping Mistral...\"\n            ./stop-mistral-simple.sh\n            ;;\n        \"all\")\n            log \"🛑 Stopping all AI services...\"\n            ./stop-flux-dev.sh\n            echo \"\"\n            ./stop-mistral-simple.sh\n            ;;\n        *)\n            error \"Unknown service: $service. Use 'flux', 'mistral', or 'all'\"\n            ;;\n    esac\n}\n\n# Main function\nmain() {\n    if [ $# -eq 0 ]; then\n        usage\n        exit 1\n    fi\n\n    local command=\"$1\"\n    local service=\"${2:-all}\"\n\n    case \"$command\" in\n        \"start\")\n            start_service \"$service\"\n            ;;\n        \"stop\")\n            stop_service \"$service\"\n            ;;\n        \"status\")\n            show_status\n            ;;\n        \"costs\")\n            show_costs\n            ;;\n        \"help\"|\"-h\"|\"--help\")\n            usage\n            ;;\n        *)\n            error \"Unknown command: $command\"\n            usage\n            exit 1\n            ;;\n    esac\n}\n\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/scripts/ai-services.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\necho \"🔧 Setting up Flux API as systemd service...\"\n\n# Copy service file\nsudo cp flux-api.service /etc/systemd/system/\n\n# Set proper permissions\nsudo chmod 644 /etc/systemd/system/flux-api.service\n\n# Create log directory\nsudo mkdir -p /var/log/flux\nsudo chown ubuntu:ubuntu /var/log/flux\n\n# Reload systemd\nsudo systemctl daemon-reload\n\n# Enable service for startup\nsudo systemctl enable flux-api\n\necho \"✅ Flux API service installed and enabled for startup\"\necho \"📋 Service commands:\"\necho \"  sudo systemctl start flux-api     # Start service\"\necho \"  sudo systemctl stop flux-api      # Stop service\"\necho \"  sudo systemctl status flux-api    # Check status\"\necho \"  sudo journalctl -u flux-api -f    # View logs\"\n\n# Check if service can start\necho \"🧪 Testing service startup...\"\nif sudo systemctl start flux-api; then\n    echo \"✅ Service started successfully\"\n    sleep 5\n    sudo systemctl status flux-api --no-pager\nelse\n    echo \"❌ Service failed to start\"\n    sudo journalctl -u flux-api --no-pager -l\n    exit 1\nfi\n\necho \"🎉 Flux API service setup complete!\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/scripts/setup_flux_service.sh", "category": "infrastructure", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# PRODUCTION AMI AVAILABLE: ami-0e6b0570006182a68\n# For production use, launch directly from AMI instead of running this script:\n# aws ec2 run-instances --image-id ami-0e6b0570006182a68 --instance-type g5.4xlarge --key-name mistral-base\n\n# Load environment variables\nif [[ -f .env ]]; then\n  # shellcheck disable=SC1091\n  source .env\nelse\n  echo \"❌ .env file not found\" >&2\n  exit 1\nfi\n\ndie() { echo \"❌ $*\" >&2; exit 1; }\n\n#######################################\n# 0. Configuration & Secrets\n#######################################\nREGION=\"${AWS_REGION:-us-west-2}\"\nINSTANCE_TYPE=\"g5.4xlarge\"  # Updated: g5.2xlarge causes OOM, g5.4xlarge required\nPROJECT_TAG=\"FluxDeploy\"\nOWNER_TAG=\"$(whoami)\"\nVOLUME_SIZE=500  # GiB\nKEY_NAME=\"mistral-base\"\nREMOTE_CHECK_SCRIPT='/tmp/flux_sanity.sh'\nS3_MODEL_PATH=\"s3://flux-model-cache-1752234728/flux-complete/\"\nDLAMI_OWNER=\"<ACCOUNT_ID>\"      # AWS DLAMI publishing account\n# SSH username for this DLAMI (ubuntu instead of ec2-user)\nREMOTE_USER=\"ubuntu\"\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nKEY_PATH=\"$SCRIPT_DIR/${KEY_NAME}.pem\"\n[[ -f \"$KEY_PATH\" ]] || die \"SSH key not found at $KEY_PATH\"\n\n# SSH username for this DLAMI (ubuntu instead of ec2-user)\nREMOTE_USER=\"ubuntu\"\n\n\n\n#######################################\n# 1. vCPU Quota Pre-Flight\n#######################################\npreflight() {\n  echo \"🔍 1/6  vCPU quota pre-flight…\"\n  local requested=8 used total\n  used=$(aws ec2 describe-instances --region \"$REGION\" \\\n    --filters Name=instance-state-name,Values=pending,running Name=tag:Project,Values=\"$PROJECT_TAG\" \\\n    --query 'Reservations[].Instances[].CpuOptions.CoreCount' --output text \\\n    | awk 'BEGIN{sum=0}!/^(None)?$/{sum+=$1}END{print sum}')\n  used=${used:-0}\n  total=$(aws service-quotas get-service-quota --service-code ec2 --quota-code L-1216C47A --region \"$REGION\" \\\n    --query 'ServiceQuota.Value' --output text 2>/dev/null || echo 64)\n  [[ \"$total\" == \"None\" ]] && total=64\n  if (( used + requested > total )); then\n    die \"vCPU limit ($total) insufficient (used=$used, req=$requested)\"\n  fi\n}\n\n#######################################\n# 2. Locate GPU PyTorch DLAMI\n#######################################\nlocate_dlami() {\n  echo \"🔍 2/6  Locating GPU PyTorch DLAMI…\"\n  local ssm\n  ssm=\"/aws/service/deeplearning/ami/x86_64/oss-nvidia-driver-gpu-pytorch-2.7-ubuntu-22.04/latest/ami-id\"\n  AMI_ID=$(aws ssm get-parameter --name \"$ssm\" --region \"$REGION\" --query 'Parameter.Value' --output text) || die \"SSM query failed\"\n  [[ \"$AMI_ID\" =~ ^ami- ]] || die \"Invalid AMI ID: $AMI_ID\"\n  echo \"✅ Found DLAMI: $AMI_ID\"\n}\n\n#######################################\n# 3. Locate & Health-Check Existing Instance\n#######################################\nfind_existing() {\n  echo \"🔍 3/6  Checking for existing instance…\"\n  local json\n  json=$(aws ec2 describe-instances --region \"$REGION\" \\\n    --filters Name=tag:Project,Values=\"$PROJECT_TAG\" Name=instance-state-name,Values=pending,running \\\n    --query 'Reservations[].Instances[].{Id:InstanceId,IP:PublicIpAddress}' --output json)\n  INSTANCE_ID=$(jq -r '.[0].Id // empty' <<<\"$json\")\n  PUBLIC_IP=$(jq -r '.[0].IP // empty' <<<\"$json\")\n  # --- detect actual key-pair name on the instance ---\nINSTANCE_KEY_NAME=$(aws ec2 describe-instances \\\n  --instance-ids \"$INSTANCE_ID\" \\\n  --region \"$REGION\" \\\n  --query 'Reservations[0].Instances[0].KeyName' \\\n  --output text)\n\necho \"🔍 3.1/6  Instance $INSTANCE_ID uses key-pair: $INSTANCE_KEY_NAME\"\n\nif [[ \"$INSTANCE_KEY_NAME\" != \"$KEY_NAME\" ]]; then\n  echo \"⚠️ 3.2/6  Key-pair mismatch! Updating to use '$INSTANCE_KEY_NAME'.pem\"\n  KEY_NAME=\"$INSTANCE_KEY_NAME\"\n  KEY_PATH=\"$SCRIPT_DIR/${KEY_NAME}.pem\"\n  [[ -f \"$KEY_PATH\" ]] || die \"Private key not found at $KEY_PATH for instance key-pair '$KEY_NAME'\"\nfi\n\necho \"✅ 3.3/6  Using SSH key: $KEY_PATH\"\n\n  if [[ -n \"$INSTANCE_ID\" ]]; then\n    echo \"✅ Found instance $INSTANCE_ID at $PUBLIC_IP. Repairing/updating…\"\n    # Copy .env file for AWS credentials\n    scp -o StrictHostKeyChecking=no -i \"$KEY_PATH\" .env ${REMOTE_USER}@\"$PUBLIC_IP\":/tmp/.env\n    ssh -o StrictHostKeyChecking=no -i \"$KEY_PATH\" ${REMOTE_USER}@\"$PUBLIC_IP\" bash -s \"$S3_MODEL_PATH\" << 'REPAIR'\nset -euo pipefail\n# Set up AWS credentials file\nmkdir -p ~/.aws\ngrep AWS_ACCESS_KEY_ID /tmp/.env | cut -d= -f2 > /tmp/access_key\ngrep AWS_SECRET_ACCESS_KEY /tmp/.env | cut -d= -f2 > /tmp/secret_key\ncat > ~/.aws/credentials << EOF\n[default]\naws_access_key_id = $(cat /tmp/access_key)\naws_secret_access_key = $(cat /tmp/secret_key)\nEOF\ncat > ~/.aws/config << EOF\n[default]\nregion = us-west-2\noutput = json\nEOF\nrm /tmp/access_key /tmp/secret_key\nS3_MODEL_PATH=\"$1\"\nsource /opt/pytorch/bin/activate\n# Fix XFormers compatibility\npip uninstall xformers -y\npip install xformers==0.0.29.post2 --no-deps\nsudo mkdir -p /opt/models/flux\nsudo chown -R ubuntu:ubuntu /opt/models\n\n# Check if model files already exist in expected structure\necho \"🔍 Checking for model files in expected structure: /opt/models/flux/model_index.json\"\nif [[ -f \"/opt/models/flux/model_index.json\" ]]; then\n    echo \"✅ Model files already in correct structure\"\nelse\n    echo \"❌ Model files not in expected structure\"\n    # Check if model exists in HuggingFace cache structure\n    hf_model_path=\"/opt/models/flux/models--black-forest-labs--FLUX.1-dev/snapshots/3de623fc3c33e44ffbe2bad470d0f45bccf2eb21\"\n    echo \"🔍 Checking for HuggingFace cache: $hf_model_path/model_index.json\"\n    if [[ -f \"$hf_model_path/model_index.json\" ]]; then\n        echo \"✅ Found model in HuggingFace cache structure\"\n        echo \"🔄 Restructuring existing model files from HuggingFace cache\"\n        # Copy files from HF cache to expected structure\n        cp -r \"$hf_model_path\"/* /opt/models/flux/\n        echo \"🧹 Cleaning up old HuggingFace cache structure\"\n        # Clean up old structure\n        rm -rf /opt/models/flux/models--black-forest-labs--FLUX.1-dev\n        rm -rf /opt/models/flux/.locks\n        rm -rf /opt/models/flux/blobs\n    else\n        echo \"❌ No model found in HuggingFace cache either\"\n        echo \"⬇️ Downloading model from S3\"\n        aws s3 sync \"$S3_MODEL_PATH/models--black-forest-labs--FLUX.1-dev/snapshots/3de623fc3c33e44ffbe2bad470d0f45bccf2eb21/\" /opt/models/flux --region us-west-2\n    fi\nfi\n\n# Verify specific files needed by health check exist\nrequired_files=(\"model_index.json\" \"transformer/config.json\" \"text_encoder/config.json\" \"vae/config.json\")\nmissing_files=()\nfor file in \"${required_files[@]}\"; do\n    if [[ ! -f \"/opt/models/flux/$file\" ]]; then\n        missing_files+=(\"$file\")\n    fi\ndone\nif [[ ${#missing_files[@]} -eq 0 ]]; then\n    echo \"✅ Model files ready - all required files present\"\nelse\n    echo \"❌ Model setup incomplete - missing files: ${missing_files[*]}\"\n    echo \"Files in /opt/models/flux: $(find /opt/models/flux -type f | head -10)\"\n    exit 1\nfi\nREPAIR\n\n    # Now run health check AFTER repair\n    echo \"🔍 Running health check after setup…\"\n    cat << 'EOF' > \"$REMOTE_CHECK_SCRIPT\"\n#!/usr/bin/env bash\nset -euo pipefail\nsource /opt/pytorch/bin/activate || exit 1\n\n# Diagnostic collection function\ncollect_failure_diagnostics() {\n    local failure_type=\"$1\"\n    echo \"🔍 Collecting diagnostics for: $failure_type\"\n\n    echo \"=== FAILURE DIAGNOSTICS ===\"\n    echo \"Failure Type: $failure_type\"\n    echo \"Time: $(date)\"\n    echo\n\n    echo \"--- Last 50 lines of health check log ---\"\n    tail -50 /tmp/flux_health.log 2>/dev/null || echo \"No log available\"\n    echo\n\n    echo \"--- GPU Status ---\"\n    nvidia-smi 2>/dev/null || echo \"nvidia-smi failed\"\n    echo\n\n    echo \"--- System Memory ---\"\n    free -h 2>/dev/null || echo \"free command failed\"\n    echo\n\n    echo \"--- Recent kernel messages ---\"\n    sudo dmesg 2>/dev/null | tail -20 || echo \"dmesg not accessible\"\n    echo\n\n    echo \"--- Python processes ---\"\n    ps aux | grep python 2>/dev/null || echo \"No python processes\"\n    echo\n\n    echo \"=== END DIAGNOSTICS ===\"\n}\n\n# Start health check in background and monitor\nscreen -dmS flux_health bash -c '\npython - << \"PY\" 2>&1 | tee /tmp/flux_health.log\nimport importlib.util,sys,pathlib\nmods=[\"torch\",\"diffusers\",\"transformers\",\"accelerate\",\"xformers\"]\nif any(importlib.util.find_spec(m) is None for m in mods): sys.exit(1)\n\n# Test image generation\nfrom diffusers import FluxPipeline\nimport torch\npipe = FluxPipeline.from_pretrained(\"/opt/models/flux/\", torch_dtype=torch.float16, local_files_only=True)\npipe.enable_model_cpu_offload()\npipe.safety_checker = None  # Remove NSFW filter\nimage = pipe(\"test\", height=512, width=512, num_inference_steps=4).images[0]\nprint(\"✅ Image generation test passed - NSFW filter removed\")\nPY\necho \"Exit code: $?\" >> /tmp/flux_health.log\n'\n\n# Monitor the health check process with comprehensive logic\nstart_time=$(date +%s)\nlast_log_size=0\nstuck_counter=0\nmax_runtime=900  # 15 minutes max\n\necho \"🔍 Starting comprehensive health monitoring...\"\n\nwhile true; do\n    current_time=$(date +%s)\n    elapsed=$((current_time - start_time))\n\n    # Check if process completed normally\n    if ! screen -list | grep -q flux_health; then\n        if tail -1 /tmp/flux_health.log 2>/dev/null | grep -q \"Exit code: 0\"; then\n            echo \"✅ Health check passed\"\n            exit 0\n        else\n            echo \"❌ Health check failed\"\n            collect_failure_diagnostics \"process_exit_failure\"\n            exit 1\n        fi\n    fi\n\n    # FAST FAIL CONDITIONS (check every iteration)\n\n    # 1. Check for OOM in dmesg (skip if no permission)\n    if sudo dmesg 2>/dev/null | tail -20 | grep -qi \"out of memory\\|killed process.*python\"; then\n        echo \"❌ OOM detected in system logs\"\n        collect_failure_diagnostics \"oom_detected\"\n        screen -S flux_health -X quit 2>/dev/null || true\n        exit 1\n    fi\n\n    # 2. Check for CUDA errors (skip if no permission)\n    if sudo dmesg 2>/dev/null | tail -10 | grep -qi \"cuda\\|nvidia.*error\"; then\n        echo \"❌ CUDA/driver errors detected\"\n        collect_failure_diagnostics \"cuda_error\"\n        screen -S flux_health -X quit 2>/dev/null || true\n        exit 1\n    fi\n\n    # 3. Check if Python process crashed\n    if ! pgrep -f \"python.*flux\" > /dev/null; then\n        if [[ -f /tmp/flux_health.log ]] && [[ $(wc -l < /tmp/flux_health.log) -gt 0 ]]; then\n            echo \"❌ Python process crashed unexpectedly\"\n            collect_failure_diagnostics \"process_crash\"\n            exit 1\n        fi\n    fi\n\n    # LOG ANALYSIS\n    if [[ -f /tmp/flux_health.log ]]; then\n        current_log_size=$(wc -c < /tmp/flux_health.log)\n\n        # Check for error accumulation\n        error_count=$(grep -c \"ERROR\\|WARN\\|Failed\\|Exception\\|Traceback\" /tmp/flux_health.log 2>/dev/null || echo 0)\n        if [[ $error_count -gt 10 ]]; then\n            echo \"❌ High error count detected ($error_count errors)\"\n            collect_failure_diagnostics \"error_accumulation\"\n            screen -S flux_health -X quit 2>/dev/null || true\n            exit 1\n        fi\n\n        # Check for infinite loops (same line repeated many times)\n        max_repeats=$(tail -30 /tmp/flux_health.log | sort | uniq -c | sort -nr | head -1 | awk '{print $1}' 2>/dev/null || echo 0)\n        if [[ $max_repeats -gt 15 ]]; then\n            echo \"❌ Infinite loop detected (line repeated $max_repeats times)\"\n            collect_failure_diagnostics \"infinite_loop\"\n            screen -S flux_health -X quit 2>/dev/null || true\n            exit 1\n        fi\n\n        # Progress detection\n        if [[ $current_log_size -gt $last_log_size ]]; then\n            stuck_counter=0  # Reset stuck counter on progress\n            echo \"📊 Progress detected (log: ${current_log_size} bytes, elapsed: ${elapsed}s)\"\n        else\n            ((stuck_counter++))\n            echo \"⏳ No log progress (stuck count: $stuck_counter, elapsed: ${elapsed}s)\"\n        fi\n\n        last_log_size=$current_log_size\n    else\n        if [[ $elapsed -gt 120 ]]; then  # No log file after 2 minutes\n            echo \"❌ No log file created after 2 minutes\"\n            collect_failure_diagnostics \"no_log_file\"\n            screen -S flux_health -X quit 2>/dev/null || true\n            exit 1\n        fi\n    fi\n\n    # GPU ANALYSIS\n    gpu_info=$(nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits 2>/dev/null || echo \"0,0,0\")\n    gpu_mem_used=$(echo \"$gpu_info\" | cut -d',' -f1 | tr -d ' \\n')\n    gpu_mem_total=$(echo \"$gpu_info\" | cut -d',' -f2 | tr -d ' \\n')\n    gpu_util=$(echo \"$gpu_info\" | cut -d',' -f3 | tr -d ' \\n')\n\n    # Ensure numeric values (default to 0 if empty/invalid)\n    gpu_mem_used=${gpu_mem_used:-0}\n    gpu_mem_total=${gpu_mem_total:-0}\n    gpu_util=${gpu_util:-0}\n\n    # Check for GPU memory allocation failure\n    if [[ $gpu_mem_used -eq 0 ]] && [[ $elapsed -gt 300 ]]; then  # No GPU memory after 5 minutes\n        echo \"❌ No GPU memory allocated after 5 minutes\"\n        collect_failure_diagnostics \"no_gpu_allocation\"\n        screen -S flux_health -X quit 2>/dev/null || true\n        exit 1\n    fi\n\n    # STUCK DETECTION (no progress for 3 minutes = 12 iterations of 15s)\n    if [[ $stuck_counter -gt 12 ]]; then\n        # But allow if GPU is actively computing\n        if [[ ${gpu_util:-0} -gt 5 ]]; then\n            echo \"🔄 No log progress but GPU active (${gpu_util}% util) - continuing...\"\n            stuck_counter=0  # Reset since GPU is working\n        else\n            echo \"❌ Process stuck (no progress for 3+ minutes, GPU idle)\"\n            collect_failure_diagnostics \"stuck_process\"\n            screen -S flux_health -X quit 2>/dev/null || true\n            exit 1\n        fi\n    fi\n\n    # MAXIMUM RUNTIME CHECK (only if genuinely stuck)\n    if [[ $elapsed -gt $max_runtime ]]; then\n        echo \"❌ Maximum runtime exceeded (${max_runtime}s) - forcing termination\"\n        collect_failure_diagnostics \"max_runtime_exceeded\"\n        screen -S flux_health -X quit 2>/dev/null || true\n        exit 1\n    fi\n\n    # Show current status\n    last_log_line=$(tail -1 /tmp/flux_health.log 2>/dev/null | head -c 80 || echo \"Starting...\")\n    echo \"📊 Status: GPU ${gpu_mem_used}MB/${gpu_mem_total}MB (${gpu_util}% util) | ${last_log_line}\"\n\n    sleep 15\ndone\nEOF\n    chmod +x \"$REMOTE_CHECK_SCRIPT\"\n    scp -o StrictHostKeyChecking=no -i \"$KEY_PATH\" \"$REMOTE_CHECK_SCRIPT\" ${REMOTE_USER}@\"$PUBLIC_IP\":$REMOTE_CHECK_SCRIPT >/dev/null\n    if ssh -o StrictHostKeyChecking=no -i \"$KEY_PATH\" ${REMOTE_USER}@\"$PUBLIC_IP\" \"bash $REMOTE_CHECK_SCRIPT\"; then\n      echo \"🎉 Deployment successful! SSH: ssh -i $KEY_PATH ${REMOTE_USER}@$PUBLIC_IP\"\n      exit 0\n    else\n      echo \"❌ Health check failed after repair\"\n      exit 1\n    fi\n  fi\n}\n\n#######################################\n# 4. Launch New Instance\n#######################################\nlaunch_new() {\n  echo \"🚀 4/6  No healthy instance. Launching new one…\"\n  USER_DATA=$(base64 << 'CLOUD'\n#!/bin/bash\nset -euo pipefail\nexec > >(tee /var/log/flux-bootstrap.log) 2>&1\napt-get update && apt-get install -y git jq\nsource /opt/pytorch/bin/activate\npip install --upgrade pip setuptools wheel\npip install diffusers>=0.34.0 transformers>=4.44 accelerate>=0.30 safetensors>=0.8 ninja triton xformers\ngit clone https://github.com/black-forest-labs/flux /opt/flux\npip install -e \"/opt/flux[all]\"\nmkdir -p /opt/models/flux\naws s3 sync $S3_MODEL_PATH /opt/models/flux --region $REGION\nCLOUD\n)\n  local resp\n  resp=$(aws ec2 run-instances --region \"$REGION\" --image-id \"$AMI_ID\" \\\n    --instance-type \"$INSTANCE_TYPE\" --key-name \"$KEY_NAME\" \\\n    --block-device-mappings '[{\"DeviceName\":\"/dev/sda1\",\"Ebs\":{\"VolumeSize\":'$VOLUME_SIZE',\"VolumeType\":\"gp3\"}}]' \\\n    --tag-specifications '[{\"ResourceType\":\"instance\",\"Tags\":[{\"Key\":\"Project\",\"Value\":\"'$PROJECT_TAG'\"},{\"Key\":\"Owner\",\"Value\":\"'$OWNER_TAG'\"}]}]' \\\n    --user-data \"$USER_DATA\")\n  INSTANCE_ID=$(jq -r '.Instances[0].InstanceId' <<<\"$resp\")\n  echo \"🔍 5/6  Waiting for instance $INSTANCE_ID to run…\"\n  aws ec2 wait instance-running --instance-ids \"$INSTANCE_ID\" --region \"$REGION\"\n  PUBLIC_IP=$(aws ec2 describe-instances --instance-ids \"$INSTANCE_ID\" --region \"$REGION\" --query 'Reservations[0].Instances[0].PublicIpAddress' --output text)\n  echo \"🔍 6/6  New instance ready at $PUBLIC_IP\"\n  echo \"🎯 SSH: ssh -i $KEY_PATH ${REMOTE_USER}@$PUBLIC_IP\"\n}\n\nmain() {\n  preflight\n  locate_dlami\n  find_existing\n  launch_new\n}\n\nmain\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/infrastructure/flux_one_shot.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Auto-retry Mistral deployment script\n# Runs every hour until successful, then notifies you\n\nset -e\n\n# Configuration\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nDEPLOY_SCRIPT=\"$SCRIPT_DIR/deploy-mistral.sh\"\nLOG_FILE=\"$SCRIPT_DIR/auto-deploy.log\"\nSTATUS_FILE=\"$SCRIPT_DIR/.deployment-status\"\nMAX_ATTEMPTS=168  # 7 days worth of hourly attempts\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Logging function\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\" | tee -a \"$LOG_FILE\"\n}\n\n# Send notification function\nsend_notification() {\n    local status=\"$1\"\n    local message=\"$2\"\n    local instance_id=\"$3\"\n    local public_ip=\"$4\"\n\n    # Multiple notification methods\n\n    # Method 1: Email via AWS SES (if configured)\n    if command -v aws &> /dev/null; then\n        aws ses send-email \\\n            --source \"<EMAIL>\" \\\n            --destination ToAddresses=\"<EMAIL>\" \\\n            --message \"Subject={Data='Mistral Deployment $status'},Body={Text={Data='$message\\n\\nInstance ID: $instance_id\\nPublic IP: $public_ip\\n\\nTime: $(date)'}}\" \\\n            2>/dev/null || log \"Email notification failed (SES not configured)\"\n    fi\n\n    # Method 2: Slack webhook (if you have one)\n    SLACK_WEBHOOK=\"${SLACK_WEBHOOK_URL:-}\"\n    if [ -n \"$SLACK_WEBHOOK\" ]; then\n        curl -X POST -H 'Content-type: application/json' \\\n            --data \"{\\\"text\\\":\\\"🤖 Mistral Deployment $status\\\\n$message\\\\nInstance: $instance_id\\\\nIP: $public_ip\\\"}\" \\\n            \"$SLACK_WEBHOOK\" 2>/dev/null || log \"Slack notification failed\"\n    fi\n\n    # Method 3: System notification (local desktop)\n    if command -v notify-send &> /dev/null; then\n        notify-send \"Mistral Deployment $status\" \"$message\"\n    fi\n\n    # Method 4: Write to a status file you can monitor\n    echo \"STATUS: $status\" > \"$STATUS_FILE\"\n    echo \"MESSAGE: $message\" >> \"$STATUS_FILE\"\n    echo \"INSTANCE_ID: $instance_id\" >> \"$STATUS_FILE\"\n    echo \"PUBLIC_IP: $public_ip\" >> \"$STATUS_FILE\"\n    echo \"TIMESTAMP: $(date)\" >> \"$STATUS_FILE\"\n\n    log \"Notification sent: $status - $message\"\n}\n\n# Check if already deployed\ncheck_existing_deployment() {\n    if [ -f \".mistral-base-instance-id\" ]; then\n        local existing_id=$(cat .mistral-base-instance-id)\n        # Check both regions\n        for region in us-east-1 us-west-2; do\n            local state=$(aws ec2 describe-instances --region \"$region\" --instance-ids \"$existing_id\" --query 'Reservations[0].Instances[0].State.Name' --output text 2>/dev/null || echo \"None\")\n\n            if [ \"$state\" = \"running\" ]; then\n                local public_ip=$(aws ec2 describe-instances --region \"$region\" --instance-ids \"$existing_id\" --query 'Reservations[0].Instances[0].PublicIpAddress' --output text 2>/dev/null || echo \"None\")\n                log \"Found existing running instance in $region: $existing_id (IP: $public_ip)\"\n                send_notification \"ALREADY RUNNING\" \"Mistral base model instance was already deployed and running\" \"$existing_id\" \"$public_ip\"\n                exit 0\n            fi\n        done\n    fi\n}\n\n# Single deployment attempt\nattempt_deployment() {\n    local attempt_num=\"$1\"\n\n    log \"=== DEPLOYMENT ATTEMPT #$attempt_num ===\"\n    log \"Starting deployment attempt at $(date)\"\n\n    # Run the deployment script and capture output\n    if timeout 600 \"$DEPLOY_SCRIPT\" &>> \"$LOG_FILE\"; then\n        log \"✅ DEPLOYMENT SUCCESSFUL!\"\n\n        # Get instance details\n        if [ -f \".mistral-base-instance-id\" ]; then\n            local instance_id=$(cat .mistral-base-instance-id)\n            # Find which region the instance is in\n            local region=\"\"\n            for r in us-east-1 us-west-2; do\n                if aws ec2 describe-instances --region \"$r\" --instance-ids \"$instance_id\" &>/dev/null; then\n                    region=\"$r\"\n                    break\n                fi\n            done\n\n            local instance_info=$(aws ec2 describe-instances --region \"$region\" --instance-ids \"$instance_id\" --query 'Reservations[0].Instances[0].[PublicIpAddress,InstanceType,State.Name]' --output text 2>/dev/null || echo \"None None None\")\n            local public_ip=$(echo \"$instance_info\" | cut -f1)\n            local instance_type=$(echo \"$instance_info\" | cut -f2)\n            local state=$(echo \"$instance_info\" | cut -f3)\n\n            local success_message=\"Mistral base model deployment successful after $attempt_num attempts!\nInstance Type: $instance_type\nState: $state\nRegion: $region\nWeb Interface: http://$public_ip\nAPI Endpoint: http://$public_ip/api/v1/completions\nSSH: ssh -i ~/.ssh/mistral-base-key.pem ubuntu@$public_ip\n\nThe uncensored Mistral 7B v0.3 base model is now being set up.\nInitial setup takes 15-30 minutes. Check progress:\nssh -i ~/.ssh/mistral-base-key.pem ubuntu@$public_ip 'tail -f /var/log/user-data.log'\"\n\n            send_notification \"SUCCESS\" \"$success_message\" \"$instance_id\" \"$public_ip\"\n            log \"$success_message\"\n            return 0\n        else\n            warn \"Deployment script succeeded but no instance ID found\"\n            return 1\n        fi\n    else\n        warn \"❌ Deployment attempt #$attempt_num failed\"\n        return 1\n    fi\n}\n\n# Main retry loop\nmain() {\n    log \"Starting auto-deployment monitoring at $(date)\"\n    log \"Will attempt deployment every hour for up to $MAX_ATTEMPTS attempts\"\n    log \"Logs: $LOG_FILE\"\n    log \"Status: $STATUS_FILE\"\n\n    # Check if already deployed\n    check_existing_deployment\n\n    local attempt=1\n\n    while [ $attempt -le $MAX_ATTEMPTS ]; do\n        log \"--- Attempt $attempt of $MAX_ATTEMPTS ---\"\n\n        if attempt_deployment \"$attempt\"; then\n            log \"Deployment successful! Exiting auto-retry loop.\"\n            exit 0\n        fi\n\n        if [ $attempt -lt $MAX_ATTEMPTS ]; then\n            log \"Attempt $attempt failed. Waiting 1 hour before next attempt...\"\n            log \"Next attempt will be at $(date -d '+1 hour')\"\n\n            # Sleep for 1 hour (3600 seconds)\n            sleep 3600\n        fi\n\n        ((attempt++))\n    done\n\n    # All attempts failed\n    local failure_message=\"All $MAX_ATTEMPTS deployment attempts failed over 7 days. AWS GPU capacity may be severely constrained. Consider:\n1. Requesting quota in different region (us-west-2)\n2. Using CPU instance temporarily\n3. Trying during off-peak hours manually\"\n\n    error \"$failure_message\"\n    send_notification \"FAILED\" \"$failure_message\" \"None\" \"None\"\n    exit 1\n}\n\n# Handle script interruption\ncleanup() {\n    log \"Auto-deployment script interrupted. Status saved to $STATUS_FILE\"\n    exit 1\n}\n\ntrap cleanup INT TERM\n\n# Run main function\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/infrastructure/auto-deploy-mistral.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for deploying AWS infrastructure", "completion": "```bash\n#!/bin/bash\n\n# Mistral Deployment Script for us-west-2 (Oregon)\n# Uses your approved 8 vCPU Spot quota\n\nset -e\n\n# Configuration\nREGION=\"us-west-2\"\nPROJECT_NAME=\"mistral-uswest2\"\nINSTANCE_TYPES=(\"g4dn.xlarge\" \"g5.xlarge\")  # 4 vCPUs each, saving 4 vCPUs for SDXL\nPRODUCT_CODE=\"prod-md5sjr2k4sdu6\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Logging function\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Find Ubuntu AMI for base model installation in us-west-2\nfind_base_ami() {\n    log \"Looking for Ubuntu 22.04 LTS AMI in us-west-2...\"\n\n    # Try to find AMI by product code\n    AMI_ID=$(aws ec2 describe-images \\\n        --region $REGION \\\n        --owners <ACCOUNT_ID> \\\n        --filters \"Name=product-code,Values=${PRODUCT_CODE}\" \\\n        --query 'Images[0].ImageId' \\\n        --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$AMI_ID\" = \"None\" ] || [ -z \"$AMI_ID\" ]; then\n        # Try to find by name pattern\n        log \"Searching by name pattern in us-west-2...\"\n        AMI_ID=$(aws ec2 describe-images \\\n            --region $REGION \\\n            --owners <ACCOUNT_ID> \\\n            --filters \"Name=name,Values=*mistral*7b*\" \"Name=state,Values=available\" \\\n            --query 'Images | sort_by(@, &CreationDate) | [-1].ImageId' \\\n            --output text 2>/dev/null || echo \"None\")\n    fi\n\n    if [ \"$AMI_ID\" = \"None\" ] || [ -z \"$AMI_ID\" ]; then\n        error \"Could not find Ubuntu AMI in us-west-2.\"\n    fi\n\n    # Get AMI details\n    AMI_NAME=$(aws ec2 describe-images \\\n        --region $REGION \\\n        --image-ids $AMI_ID \\\n        --query 'Images[0].Name' \\\n        --output text)\n\n    log \"Found AMI: $AMI_ID\"\n    log \"AMI Name: $AMI_NAME\"\n\n    export AMI_ID\n}\n\n# Setup network configuration in us-west-2\nsetup_network() {\n    log \"Setting up network configuration in us-west-2...\"\n\n    # Use default VPC in us-west-2\n    VPC_ID=$(aws ec2 describe-vpcs \\\n        --region $REGION \\\n        --filters \"Name=is-default,Values=true\" \\\n        --query 'Vpcs[0].VpcId' \\\n        --output text)\n\n    if [ \"$VPC_ID\" = \"None\" ]; then\n        error \"No default VPC found in us-west-2. Please create a VPC first.\"\n    fi\n\n    # Get all public subnets in default VPC (for multiple AZ fallback)\n    SUBNETS=$(aws ec2 describe-subnets \\\n        --region $REGION \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=default-for-az,Values=true\" \\\n        --query 'Subnets[*].[SubnetId,AvailabilityZone]' \\\n        --output text)\n\n    # Store subnets for fallback\n    echo \"$SUBNETS\" > /tmp/available_subnets_uswest2.txt\n\n    log \"Using VPC: $VPC_ID\"\n    log \"Available subnets in us-west-2:\"\n    while read -r subnet_line; do\n        if [ -n \"$subnet_line\" ]; then\n            subnet_id=$(echo \"$subnet_line\" | cut -f1)\n            subnet_az=$(echo \"$subnet_line\" | cut -f2)\n            log \"  - $subnet_id ($subnet_az)\"\n        fi\n    done < /tmp/available_subnets_uswest2.txt\n\n    export VPC_ID\n}\n\n# Create security group in us-west-2\nsetup_security_group() {\n    log \"Setting up security group in us-west-2...\"\n\n    # Get your public IP\n    YOUR_IP=$(curl -s ipinfo.io/ip 2>/dev/null || echo \"0.0.0.0\")\n    if [ \"$YOUR_IP\" = \"0.0.0.0\" ]; then\n        warn \"Could not determine your IP. Using 0.0.0.0/0 (not recommended for production)\"\n        YOUR_IP=\"0.0.0.0/0\"\n    else\n        YOUR_IP=\"$YOUR_IP/32\"\n        log \"Detected your IP: $YOUR_IP\"\n    fi\n\n    # Check if security group exists\n    SG_ID=$(aws ec2 describe-security-groups \\\n        --region $REGION \\\n        --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=group-name,Values=${PROJECT_NAME}-sg\" \\\n        --query 'SecurityGroups[0].GroupId' \\\n        --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$SG_ID\" = \"None\" ]; then\n        log \"Creating security group in us-west-2...\"\n        SG_ID=$(aws ec2 create-security-group \\\n            --region $REGION \\\n            --group-name \"${PROJECT_NAME}-sg\" \\\n            --description \"Security group for ${PROJECT_NAME} in us-west-2\" \\\n            --vpc-id $VPC_ID \\\n            --query 'GroupId' \\\n            --output text)\n\n        # Add rules for SSH and API access\n        aws ec2 authorize-security-group-ingress \\\n            --region $REGION \\\n            --group-id $SG_ID \\\n            --protocol tcp \\\n            --port 22 \\\n            --cidr $YOUR_IP\n\n        aws ec2 authorize-security-group-ingress \\\n            --region $REGION \\\n            --group-id $SG_ID \\\n            --protocol tcp \\\n            --port 8000 \\\n            --cidr $YOUR_IP\n\n        aws ec2 authorize-security-group-ingress \\\n            --region $REGION \\\n            --group-id $SG_ID \\\n            --protocol tcp \\\n            --port 8080 \\\n            --cidr $YOUR_IP\n\n        log \"Created security group: $SG_ID\"\n    else\n        log \"Using existing security group: $SG_ID\"\n    fi\n\n    export SG_ID\n}\n\n# Setup SSH key in us-west-2\nsetup_ssh_key() {\n    log \"Setting up SSH key in us-west-2...\"\n\n    SSH_KEY_NAME=\"${PROJECT_NAME}-key\"\n\n    # Check if key exists in us-west-2\n    if aws ec2 describe-key-pairs \\\n        --region $REGION \\\n        --key-names $SSH_KEY_NAME &>/dev/null; then\n        log \"Using existing SSH key: $SSH_KEY_NAME\"\n    else\n        log \"Creating SSH key: $SSH_KEY_NAME\"\n        aws ec2 create-key-pair \\\n            --region $REGION \\\n            --key-name $SSH_KEY_NAME \\\n            --query 'KeyMaterial' \\\n            --output text > ~/.ssh/$SSH_KEY_NAME.pem\n        chmod 600 ~/.ssh/$SSH_KEY_NAME.pem\n        log \"SSH key saved to ~/.ssh/$SSH_KEY_NAME.pem\"\n    fi\n\n    export SSH_KEY_NAME\n}\n\n# Launch instance in us-west-2\nlaunch_instance() {\n    log \"Launching Mistral instance in us-west-2...\"\n    log \"Using Spot instance (you have 8 vCPU Spot quota approved)\"\n\n    # Check if instance already running\n    EXISTING_INSTANCE=$(aws ec2 describe-instances \\\n        --region $REGION \\\n        --filters \"Name=tag:Name,Values=${PROJECT_NAME}-instance\" \"Name=instance-state-name,Values=running,pending\" \\\n        --query 'Reservations[].Instances[0].InstanceId' \\\n        --output text 2>/dev/null || echo \"None\")\n\n    if [ \"$EXISTING_INSTANCE\" != \"None\" ] && [ \"$EXISTING_INSTANCE\" != \"\" ]; then\n        log \"Found existing instance: $EXISTING_INSTANCE\"\n        INSTANCE_ID=$EXISTING_INSTANCE\n        USED_INSTANCE_TYPE=\"existing\"\n    else\n        # Try each instance type and availability zone combination\n        INSTANCE_ID=\"\"\n        USED_INSTANCE_TYPE=\"\"\n\n        for instance_type in \"${INSTANCE_TYPES[@]}\"; do\n            log \"Trying instance type: $instance_type\"\n\n            while read -r subnet_line; do\n                if [ -n \"$subnet_line\" ]; then\n                    try_subnet_id=$(echo \"$subnet_line\" | cut -f1)\n                    try_subnet_az=$(echo \"$subnet_line\" | cut -f2)\n\n                    log \"  → Trying $instance_type in AZ: $try_subnet_az\"\n\n                    INSTANCE_ID=$(aws ec2 run-instances \\\n                        --region $REGION \\\n                        --image-id $AMI_ID \\\n                        --instance-type $instance_type \\\n                        --key-name $SSH_KEY_NAME \\\n                        --security-group-ids $SG_ID \\\n                        --subnet-id $try_subnet_id \\\n                        --associate-public-ip-address \\\n                        --instance-market-options '{\n                            \"MarketType\": \"spot\",\n                            \"SpotOptions\": {\n                                \"MaxPrice\": \"1.00\",\n                                \"SpotInstanceType\": \"one-time\"\n                            }\n                        }' \\\n                        --tag-specifications \"ResourceType=instance,Tags=[{Key=Name,Value=${PROJECT_NAME}-instance},{Key=Project,Value=${PROJECT_NAME}},{Key=InstanceType,Value=$instance_type},{Key=Region,Value=us-west-2}]\" \\\n                        --query 'Instances[0].InstanceId' \\\n                        --output text 2>/dev/null || echo \"\")\n\n                    if [ -n \"$INSTANCE_ID\" ] && [ \"$INSTANCE_ID\" != \"None\" ]; then\n                        log \"✅ Successfully launched $instance_type in AZ: $try_subnet_az\"\n                        USED_INSTANCE_TYPE=$instance_type\n                        break 2  # Break out of both loops\n                    else\n                        warn \"    ❌ No $instance_type capacity in AZ: $try_subnet_az\"\n                    fi\n                fi\n            done < /tmp/available_subnets_uswest2.txt\n        done\n\n        if [ -z \"$INSTANCE_ID\" ] || [ \"$INSTANCE_ID\" = \"None\" ]; then\n            error \"Failed to launch instance in any availability zone in us-west-2.\"\n        fi\n\n        log \"Launched instance: $INSTANCE_ID ($USED_INSTANCE_TYPE)\"\n        log \"Waiting for instance to be running...\"\n        aws ec2 wait instance-running \\\n            --region $REGION \\\n            --instance-ids $INSTANCE_ID\n\n        # Save instance ID\n        echo $INSTANCE_ID > .mistral-uswest2-instance-id\n    fi\n\n    # Get instance details\n    INSTANCE_INFO=$(aws ec2 describe-instances \\\n        --region $REGION \\\n        --instance-ids $INSTANCE_ID \\\n        --query 'Reservations[0].Instances[0].[PrivateIpAddress,PublicIpAddress,State.Name,InstanceType,Placement.AvailabilityZone]' \\\n        --output text)\n\n    PRIVATE_IP=$(echo $INSTANCE_INFO | cut -d' ' -f1)\n    PUBLIC_IP=$(echo $INSTANCE_INFO | cut -d' ' -f2)\n    STATE=$(echo $INSTANCE_INFO | cut -d' ' -f3)\n    ACTUAL_TYPE=$(echo $INSTANCE_INFO | cut -d' ' -f4)\n    ACTUAL_AZ=$(echo $INSTANCE_INFO | cut -d' ' -f5)\n\n    log \"Instance Details:\"\n    log \"  Instance ID: $INSTANCE_ID\"\n    log \"  Instance Type: $ACTUAL_TYPE\"\n    log \"  Availability Zone: $ACTUAL_AZ\"\n    log \"  State: $STATE\"\n    log \"  Private IP: $PRIVATE_IP\"\n    log \"  Public IP: $PUBLIC_IP\"\n    log \"\"\n    log \"🎉 Mistral deployment successful in us-west-2!\"\n    log \"SSH: ssh -i ~/.ssh/${SSH_KEY_NAME}.pem ubuntu@$PUBLIC_IP\"\n    log \"API: http://$PUBLIC_IP:8000\"\n    log \"Wait 5-15 minutes for Mistral service to start, then test:\"\n    log \"curl http://$PUBLIC_IP:8000/health\"\n}\n\n# Main execution\nmain() {\n    log \"Starting Mistral deployment in us-west-2 (Oregon)...\"\n    log \"Using 4 vCPUs (saving 4 vCPUs for SDXL server)\"\n\n    find_base_ami\n    setup_network\n    setup_security_group\n    setup_ssh_key\n    launch_instance\n\n    log \"Deployment complete! Instance running in us-west-2.\"\n}\n\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/infrastructure/deploy-mistral-us-west-2.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for application deployment", "completion": "```bash\n#!/bin/bash\n# QLoRA Instance Setup Script\n# Following CLAUDE.md: Automate environment setup and run TDD tests\n\nset -euo pipefail\n\n# Configuration\nINSTANCE_IP=\"54.197.142.172\"\nKEY_PATH=\"/home/shingai/sort/deployments/mistral-base.pem\"\nINSTANCE_USER=\"ubuntu\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Verify connection\ncheck_connection() {\n    log \"Checking SSH connection to g5.2xlarge instance...\"\n\n    if ! ssh -i \"$KEY_PATH\" -o ConnectTimeout=10 -o StrictHostKeyChecking=no \\\n        \"$INSTANCE_USER@$INSTANCE_IP\" \"echo 'Connection successful'\" 2>/dev/null; then\n        error \"Cannot connect to instance $INSTANCE_IP\"\n    fi\n\n    log \"✅ SSH connection verified\"\n}\n\n# Validate GPU environment\nvalidate_gpu_environment() {\n    log \"Validating GPU environment on instance...\"\n\n    ssh -i \"$KEY_PATH\" \"$INSTANCE_USER@$INSTANCE_IP\" << 'EOF'\n        echo \"=== GPU Environment Check ===\"\n\n        # Check NVIDIA driver\n        if ! nvidia-smi >/dev/null 2>&1; then\n            echo \"❌ NVIDIA driver not working\"\n            exit 1\n        fi\n\n        echo \"✅ NVIDIA driver working\"\n        nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits\n\n        # Check Python and basic packages\n        echo -e \"\\n=== Python Environment ===\"\n        python3 --version\n\n        if python3 -c \"import torch\" 2>/dev/null; then\n            echo \"✅ PyTorch available\"\n            python3 -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\n            python3 -c \"import torch; print(f'GPU count: {torch.cuda.device_count()}')\"\n        else\n            echo \"❌ PyTorch not available\"\n        fi\n\n        # Check disk space\n        echo -e \"\\n=== Disk Space ===\"\n        df -h / | grep -v Filesystem\n\n        # Check memory\n        echo -e \"\\n=== System Memory ===\"\n        free -h\nEOF\n\n    log \"✅ Environment validation complete\"\n}\n\n# Transfer test file\ntransfer_test_file() {\n    log \"Transferring QLoRA test file to instance...\"\n\n    scp -i \"$KEY_PATH\" -o StrictHostKeyChecking=no \\\n        \"test_qlora_setup.py\" \"$INSTANCE_USER@$INSTANCE_IP:~/\" || \\\n        error \"Failed to transfer test file\"\n\n    log \"✅ Test file transferred\"\n}\n\n# Install QLoRA dependencies\ninstall_qlora_dependencies() {\n    log \"Installing QLoRA dependencies on instance...\"\n\n    ssh -i \"$KEY_PATH\" \"$INSTANCE_USER@$INSTANCE_IP\" << 'EOF'\n        echo \"=== Installing QLoRA Dependencies ===\"\n\n        # Update pip first\n        python3 -m pip install --upgrade pip\n\n        # Install QLoRA packages with specific versions\n        echo \"Installing core QLoRA packages...\"\n        pip install transformers>=4.36.0\n        pip install accelerate>=0.25.0\n        pip install peft>=0.8.0\n        pip install bitsandbytes>=0.41.0\n        pip install datasets>=2.16.0\n\n        # Install additional dependencies\n        echo \"Installing additional packages...\"\n        pip install pytest psutil scipy\n\n        # Verify installations\n        echo -e \"\\n=== Verification ===\"\n        python3 -c \"\nimport transformers, accelerate, peft, bitsandbytes, datasets\nprint(f'✅ transformers: {transformers.__version__}')\nprint(f'✅ accelerate: {accelerate.__version__}')\nprint(f'✅ peft: {peft.__version__}')\nprint(f'✅ bitsandbytes: {bitsandbytes.__version__}')\nprint(f'✅ datasets: {datasets.__version__}')\n\"\n\n        echo \"✅ All QLoRA dependencies installed\"\nEOF\n\n    log \"✅ QLoRA dependencies installation complete\"\n}\n\n# Run TDD tests\nrun_tdd_tests() {\n    log \"Running TDD tests (should show initial failures and first successes)...\"\n\n    ssh -i \"$KEY_PATH\" \"$INSTANCE_USER@$INSTANCE_IP\" << 'EOF'\n        echo \"=== Running QLoRA Setup Tests ===\"\n\n        # Run tests with verbose output\n        python3 test_qlora_setup.py\nEOF\n\n    local exit_code=$?\n\n    if [ $exit_code -eq 0 ]; then\n        warn \"Tests passed - this is unexpected in TDD red phase!\"\n        warn \"Some tests may need to be updated to ensure proper failure initially\"\n    else\n        log \"✅ Tests failed as expected (TDD red phase)\"\n        log \"Next step: Implement features to make tests pass (TDD green phase)\"\n    fi\n}\n\n# Main execution\nmain() {\n    log \"🚀 Starting QLoRA Instance Setup (CLAUDE.md TDD approach)\"\n    log \"Instance: $INSTANCE_IP\"\n\n    check_connection\n    validate_gpu_environment\n    transfer_test_file\n    install_qlora_dependencies\n    run_tdd_tests\n\n    log \"🎯 Setup phase complete!\"\n    log \"Next: Implement QLoRA features to make tests pass\"\n\n    echo -e \"\\n${GREEN}=== Connection Command ===${NC}\"\n    echo \"ssh -i $KEY_PATH $INSTANCE_USER@$INSTANCE_IP\"\n}\n\n# Run if executed directly\nif [[ \"${BASH_SOURCE[0]}\" == \"${0}\" ]]; then\n    main \"$@\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/infrastructure/setup_qlora_instance.sh", "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#!/bin/bash\nset -euo pipefail\n\n# Comprehensive monitoring setup for Flux model loading\necho \"Setting up monitoring infrastructure...\"\n\n# Install monitoring tools\nsudo apt update\nsudo apt install -y htop iotop sysstat nethogs\n\n# Create monitoring directories\nsudo mkdir -p /var/log/flux-monitoring\nsudo chown ubuntu:ubuntu /var/log/flux-monitoring\n\n# System resource monitoring script\ncat > /tmp/system_monitor.py << 'EOF'\n#!/usr/bin/env python3\nimport psutil\nimport subprocess\nimport time\nimport json\nimport sys\nfrom datetime import datetime\n\ndef get_gpu_info():\n    try:\n        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total,utilization.gpu,temperature.gpu'],\n                              capture_output=True, text=True, check=True)\n        lines = result.stdout.strip().split('\\n')[1:]  # Skip header\n        if lines:\n            memory_used, memory_total, gpu_util, temp = lines[0].split(', ')\n            return {\n                'memory_used_mb': int(memory_used.split()[0]),\n                'memory_total_mb': int(memory_total.split()[0]),\n                'utilization_percent': int(gpu_util.split()[0]),\n                'temperature_c': int(temp.split()[0])\n            }\n    except:\n        pass\n    return {'error': 'GPU info unavailable'}\n\ndef get_process_info(process_name):\n    processes = []\n    for proc in psutil.process_iter(['pid', 'name', 'memory_info', 'cpu_percent', 'status']):\n        try:\n            if process_name.lower() in proc.info['name'].lower():\n                processes.append({\n                    'pid': proc.info['pid'],\n                    'memory_mb': proc.info['memory_info'].rss / 1024 / 1024,\n                    'cpu_percent': proc.info['cpu_percent'],\n                    'status': proc.info['status']\n                })\n        except:\n            continue\n    return processes\n\ndef monitor_system():\n    timestamp = datetime.now().isoformat()\n\n    # System metrics\n    memory = psutil.virtual_memory()\n    cpu = psutil.cpu_percent(interval=1)\n    disk = psutil.disk_usage('/')\n\n    # Network stats\n    net = psutil.net_io_counters()\n\n    data = {\n        'timestamp': timestamp,\n        'memory': {\n            'total_gb': memory.total / 1024**3,\n            'used_gb': memory.used / 1024**3,\n            'available_gb': memory.available / 1024**3,\n            'percent': memory.percent\n        },\n        'cpu_percent': cpu,\n        'disk': {\n            'total_gb': disk.total / 1024**3,\n            'used_gb': disk.used / 1024**3,\n            'free_gb': disk.free / 1024**3\n        },\n        'network': {\n            'bytes_sent': net.bytes_sent,\n            'bytes_recv': net.bytes_recv\n        },\n        'gpu': get_gpu_info(),\n        'python_processes': get_process_info('python')\n    }\n\n    return data\n\nif __name__ == '__main__':\n    if len(sys.argv) > 1 and sys.argv[1] == '--continuous':\n        # Continuous monitoring mode\n        log_file = '/var/log/flux-monitoring/system_metrics.log'\n        while True:\n            try:\n                data = monitor_system()\n                with open(log_file, 'a') as f:\n                    f.write(json.dumps(data) + '\\n')\n                time.sleep(5)\n            except KeyboardInterrupt:\n                break\n            except Exception as e:\n                print(f\"Monitoring error: {e}\")\n    else:\n        # Single measurement\n        data = monitor_system()\n        print(json.dumps(data, indent=2))\nEOF\n\nchmod +x /tmp/system_monitor.py\n\n# Process monitoring script\ncat > /tmp/process_monitor.sh << 'EOF'\n#!/bin/bash\nset -euo pipefail\n\nLOG_FILE=\"/var/log/flux-monitoring/process.log\"\n\nmonitor_process() {\n    local pid=$1\n    local name=$2\n\n    echo \"$(date): Monitoring process $name (PID: $pid)\" >> \"$LOG_FILE\"\n\n    while kill -0 \"$pid\" 2>/dev/null; do\n        # Get process stats\n        ps -o pid,ppid,rss,vsz,pcpu,time,cmd -p \"$pid\" >> \"$LOG_FILE\" 2>/dev/null || break\n\n        # Check if process is responding\n        if [ -d \"/proc/$pid\" ]; then\n            echo \"$(date): Process $pid still alive\" >> \"$LOG_FILE\"\n        else\n            echo \"$(date): Process $pid disappeared\" >> \"$LOG_FILE\"\n            break\n        fi\n\n        sleep 10\n    done\n\n    echo \"$(date): Process $name (PID: $pid) monitoring ended\" >> \"$LOG_FILE\"\n}\n\n# Export function for external use\nexport -f monitor_process\nEOF\n\nchmod +x /tmp/process_monitor.sh\n\n# Kernel message monitoring\ncat > /tmp/kernel_monitor.sh << 'EOF'\n#!/bin/bash\nset -euo pipefail\n\nLOG_FILE=\"/var/log/flux-monitoring/kernel.log\"\n\necho \"$(date): Starting kernel message monitoring\" >> \"$LOG_FILE\"\n\n# Monitor dmesg for OOM, GPU, and other critical messages\nsudo dmesg -w | while read line; do\n    echo \"$(date): $line\" >> \"$LOG_FILE\"\n\n    # Alert on critical messages\n    if echo \"$line\" | grep -i -E \"(oom|killed|cuda|nvidia|memory|hung|panic)\"; then\n        echo \"$(date): CRITICAL: $line\" >> \"$LOG_FILE\"\n    fi\ndone &\n\necho $! > /tmp/kernel_monitor_pid\nEOF\n\nchmod +x /tmp/kernel_monitor.sh\n\necho \"Monitoring infrastructure installed\"\necho \"Available commands:\"\necho \"  - /tmp/system_monitor.py                 # Single system snapshot\"\necho \"  - /tmp/system_monitor.py --continuous    # Continuous monitoring\"\necho \"  - /tmp/process_monitor.sh                # Process monitoring functions\"\necho \"  - /tmp/kernel_monitor.sh                 # Kernel message monitoring\"\necho \"\"\necho \"Logs will be written to /var/log/flux-monitoring/\"\nEOF\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/monitoring/setup_monitoring.sh", "category": "monitoring", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\necho \"🧪 Testing Server Status Page Resilience\"\necho \"========================================\"\n\nFLUX_IP=\"34.217.17.67\"\nFLUX_PORT=\"8000\"\nFLUX_ENDPOINT=\"http://${FLUX_IP}:${FLUX_PORT}\"\n\necho \"📍 Testing Flux instance: ${FLUX_ENDPOINT}\"\n\n# Test 1: Basic connectivity\necho \"🔍 Test 1: Basic connectivity to Flask server\"\nif curl -s --connect-timeout 10 \"${FLUX_ENDPOINT}/\" >/dev/null 2>&1; then\n    echo \"✅ Flask server is reachable\"\nelse\n    echo \"❌ Flask server not reachable\"\nfi\n\n# Test 2: Health endpoint (model may still be loading)\necho \"🔍 Test 2: Health endpoint status\"\nhealth_response=$(curl -s --connect-timeout 15 \"${FLUX_ENDPOINT}/health\" 2>/dev/null || echo \"FAILED\")\nif [[ \"$health_response\" == \"FAILED\" ]]; then\n    echo \"⏳ Health endpoint not ready (model likely loading)\"\nelse\n    echo \"✅ Health endpoint responding:\"\n    echo \"$health_response\" | jq . 2>/dev/null || echo \"$health_response\"\nfi\n\n# Test 3: Service auto-start verification\necho \"🔍 Test 3: Systemd service configuration\"\nssh -o StrictHostKeyChecking=no -i mistral-base.pem ubuntu@${FLUX_IP} \"\n    echo '  Service enabled:' \\$(sudo systemctl is-enabled flux-api)\n    echo '  Service active:' \\$(sudo systemctl is-active flux-api)\n    echo '  Service uptime:' \\$(sudo systemctl show flux-api --property=ActiveEnterTimestamp --value)\n\"\n\n# Test 4: Server discovery resilience\necho \"🔍 Test 4: Testing local status page discovery\"\ncat > test_discovery.html << 'EOF'\n<!DOCTYPE html>\n<html>\n<head><title>Status Test</title></head>\n<body>\n<div id=\"result\"></div>\n<script>\n// Test the same discovery logic as the status page\nasync function testFluxDiscovery() {\n    const fluxEndpoint = 'http://34.217.17.67:8000/health';\n    try {\n        const response = await fetch(fluxEndpoint, {\n            signal: AbortSignal.timeout(8000),\n            mode: 'no-cors'  // Avoid CORS issues for test\n        });\n        document.getElementById('result').textContent = 'Flux discovery: SUCCESS';\n    } catch (error) {\n        document.getElementById('result').textContent = 'Flux discovery: ' + error.message;\n    }\n}\ntestFluxDiscovery();\n</script>\n</body>\n</html>\nEOF\n\necho \"📁 Created test_discovery.html for manual browser testing\"\n\n# Test 5: Restart resilience\necho \"🔍 Test 5: Service restart resilience\"\necho \"  Testing if service can restart gracefully...\"\nssh -o StrictHostKeyChecking=no -i mistral-base.pem ubuntu@${FLUX_IP} \"\n    echo '  Restarting flux-api service...'\n    sudo systemctl restart flux-api\n    sleep 3\n    echo '  Service status after restart:' \\$(sudo systemctl is-active flux-api)\n\"\n\necho \"\"\necho \"🎯 Summary:\"\necho \"✅ Flux API Server configured as systemd service\"\necho \"✅ Auto-start on boot enabled\"\necho \"✅ Service restart resilience tested\"\necho \"✅ Server status page updated with robust discovery\"\necho \"✅ Lambda function updated with dynamic instance detection\"\necho \"\"\necho \"📋 Manual verification steps:\"\necho \"1. Open server-status.html in browser to test UI\"\necho \"2. Reboot instance to verify auto-start: 'sudo reboot'\"\necho \"3. Test image generation once model loads: 'curl -X POST http://${FLUX_IP}:8000/generate ...'\"\necho \"\"\necho \"🔧 Service management commands:\"\necho \"  sudo systemctl status flux-api    # Check status\"\necho \"  sudo systemctl restart flux-api   # Restart service\"\necho \"  sudo journalctl -u flux-api -f    # View logs\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/monitoring/test_server_resilience.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for system service management", "completion": "```bash\n#!/bin/bash\n\n# AI Server Status API\n# Returns JSON with current running instance information\n\nset -e\n\n# Output JSON header\necho \"Content-Type: application/json\"\necho \"\"\n\n# Initialize JSON response\necho \"{\"\n\n# Function to get instance details\nget_instance_info() {\n    local instance_file=\"$1\"\n    local service_name=\"$2\"\n\n    if [ ! -f \"$instance_file\" ]; then\n        echo \"null\"\n        return\n    fi\n\n    local instance_id=$(cat \"$instance_file\" 2>/dev/null | tr -d '\\n\\r')\n    if [ -z \"$instance_id\" ]; then\n        echo \"null\"\n        return\n    fi\n\n    # Try both regions\n    for region in us-east-1 us-west-2; do\n        local state=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].State.Name' \\\n            --output text 2>/dev/null || echo \"None\")\n\n        if [ \"$state\" = \"None\" ]; then\n            continue\n        fi\n\n        local public_ip=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].PublicIpAddress' \\\n            --output text 2>/dev/null || echo \"None\")\n\n        local instance_type=$(aws ec2 describe-instances \\\n            --region \"$region\" \\\n            --instance-ids \"$instance_id\" \\\n            --query 'Reservations[0].Instances[0].InstanceType' \\\n            --output text 2>/dev/null || echo \"None\")\n\n        if [ \"$state\" != \"None\" ]; then\n            echo \"{\"\n            echo \"  \\\"instance_id\\\": \\\"$instance_id\\\",\"\n            echo \"  \\\"state\\\": \\\"$state\\\",\"\n            echo \"  \\\"public_ip\\\": \\\"$public_ip\\\",\"\n            echo \"  \\\"instance_type\\\": \\\"$instance_type\\\",\"\n            echo \"  \\\"region\\\": \\\"$region\\\"\"\n            echo \"}\"\n            return\n        fi\n    done\n\n    echo \"null\"\n}\n\n# Check Mistral Base instance\necho \"  \\\"mistral_base\\\": $(get_instance_info \".mistral-base-instance-id\" \"mistral-base\"),\"\n\n# Check Flux instance\necho \"  \\\"flux\\\": $(get_instance_info \".flux-dev-instance-id\" \"flux-dev\"),\"\n\n# Add timestamp\necho \"  \\\"timestamp\\\": \\\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\\\",\"\necho \"  \\\"status\\\": \\\"success\\\"\"\n\necho \"}\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/home/shingai/sort/deployments/monitoring/get-server-status.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/bash\n\n# Copyright The OpenTelemetry Authors\n# SPDX-License-Identifier: Apache-2.0\n\nset -euo pipefail\n\nTARGET=\"${1:?Must provide target ref}\"\n\nFILE=\"CHANGELOG.md\"\nTEMP_DIR=$(mktemp -d)\necho \"Temp folder: $TEMP_DIR\"\n\n# Only the latest commit of the feature branch is available\n# automatically. To diff with the base branch, we need to\n# fetch that too (and we only need its latest commit).\ngit fetch origin \"${TARGET}\" --depth=1\n\n# Checkout the previous version on the base branch of the changelog to tmpfolder\ngit --work-tree=\"$TEMP_DIR\" checkout FETCH_HEAD $FILE\n\nPREVIOUS_FILE=\"$TEMP_DIR/$FILE\"\nCURRENT_FILE=\"$FILE\"\nPREVIOUS_LOCKED_FILE=\"$TEMP_DIR/previous_locked_section.md\"\nCURRENT_LOCKED_FILE=\"$TEMP_DIR/current_locked_section.md\"\n\n# Extract released sections from the previous version\nawk '/^<!-- Released section -->/ {flag=1} /^<!-- Released section ended -->/ {flag=0} flag' \"$PREVIOUS_FILE\" > \"$PREVIOUS_LOCKED_FILE\"\n\n# Extract released sections from the current version\nawk '/^<!-- Released section -->/ {flag=1} /^<!-- Released section ended -->/ {flag=0} flag' \"$CURRENT_FILE\" > \"$CURRENT_LOCKED_FILE\"\n\n# Compare the released sections\nif ! diff -q \"$PREVIOUS_LOCKED_FILE\" \"$CURRENT_LOCKED_FILE\"; then\n    echo \"Error: The released sections of the changelog file have been modified.\"\n    diff \"$PREVIOUS_LOCKED_FILE\" \"$CURRENT_LOCKED_FILE\"\n    rm -rf \"$TEMP_DIR\"\n    false\nfi\n\nrm -rf \"$TEMP_DIR\"\necho \"The released sections remain unchanged.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/vendor/go.opentelemetry.io/otel/verify_released_changelog.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright 2009 The Go Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style\n# license that can be found in the LICENSE file.\n\n# This script runs or (given -n) prints suggested commands to generate files for\n# the Architecture/OS specified by the GOARCH and GOOS environment variables.\n# See README.md for more information about how the build system works.\n\nGOOSARCH=\"${GOOS}_${GOARCH}\"\n\n# defaults\nmksyscall=\"go run mksyscall.go\"\nmkerrors=\"./mkerrors.sh\"\nzerrors=\"zerrors_$GOOSARCH.go\"\nmksysctl=\"\"\nzsysctl=\"zsysctl_$GOOSARCH.go\"\nmksysnum=\nmktypes=\nmkasm=\nrun=\"sh\"\ncmd=\"\"\n\ncase \"$1\" in\n-syscalls)\n\tfor i in zsyscall*go\n\tdo\n\t\t# Run the command line that appears in the first line\n\t\t# of the generated file to regenerate it.\n\t\tsed 1q $i | sed 's;^// ;;' | sh > _$i && gofmt < _$i > $i\n\t\trm _$i\n\tdone\n\texit 0\n\t;;\n-n)\n\trun=\"cat\"\n\tcmd=\"echo\"\n\tshift\nesac\n\ncase \"$#\" in\n0)\n\t;;\n*)\n\techo 'usage: mkall.sh [-n]' 1>&2\n\texit 2\nesac\n\nif [[ \"$GOOS\" = \"linux\" ]]; then\n\t# Use the Docker-based build system\n\t# Files generated through docker (use $cmd so you can Ctl-C the build or run)\n\t$cmd docker build --tag generate:$GOOS $GOOS\n\t$cmd docker run --interactive --tty --volume $(cd -- \"$(dirname -- \"$0\")/..\" && pwd):/build generate:$GOOS\n\texit\nfi\n\nGOOSARCH_in=syscall_$GOOSARCH.go\ncase \"$GOOSARCH\" in\n_* | *_ | _)\n\techo 'undefined $GOOS_$GOARCH:' \"$GOOSARCH\" 1>&2\n\texit 1\n\t;;\naix_ppc)\n\tmkerrors=\"$mkerrors -maix32\"\n\tmksyscall=\"go run mksyscall_aix_ppc.go -aix\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\naix_ppc64)\n\tmkerrors=\"$mkerrors -maix64\"\n\tmksyscall=\"go run mksyscall_aix_ppc64.go -aix\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\ndarwin_amd64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\tmkasm=\"go run mkasm.go\"\n\t;;\ndarwin_arm64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\tmkasm=\"go run mkasm.go\"\n\t;;\ndragonfly_amd64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -dragonfly\"\n\tmksysnum=\"go run mksysnum.go 'https://gitweb.dragonflybsd.org/dragonfly.git/blob_plain/HEAD:/sys/kern/syscalls.master'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nfreebsd_386)\n\tmkerrors=\"$mkerrors -m32\"\n\tmksyscall=\"go run mksyscall.go -l32\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nfreebsd_amd64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nfreebsd_arm)\n\tmkerrors=\"$mkerrors\"\n\tmksyscall=\"go run mksyscall.go -l32 -arm\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nfreebsd_arm64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nfreebsd_riscv64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksysnum=\"go run mksysnum.go 'https://cgit.freebsd.org/src/plain/sys/kern/syscalls.master?h=stable/12'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nnetbsd_386)\n\tmkerrors=\"$mkerrors -m32\"\n\tmksyscall=\"go run mksyscall.go -l32 -netbsd\"\n\tmksysnum=\"go run mksysnum.go 'http://cvsweb.netbsd.org/bsdweb.cgi/~checkout~/src/sys/kern/syscalls.master'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nnetbsd_amd64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -netbsd\"\n\tmksysnum=\"go run mksysnum.go 'http://cvsweb.netbsd.org/bsdweb.cgi/~checkout~/src/sys/kern/syscalls.master'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nnetbsd_arm)\n\tmkerrors=\"$mkerrors\"\n\tmksyscall=\"go run mksyscall.go -l32 -netbsd -arm\"\n\tmksysnum=\"go run mksysnum.go 'http://cvsweb.netbsd.org/bsdweb.cgi/~checkout~/src/sys/kern/syscalls.master'\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nnetbsd_arm64)\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -netbsd\"\n\tmksysnum=\"go run mksysnum.go 'http://cvsweb.netbsd.org/bsdweb.cgi/~checkout~/src/sys/kern/syscalls.master'\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nopenbsd_386)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m32\"\n\tmksyscall=\"go run mksyscall.go -l32 -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nopenbsd_amd64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nopenbsd_arm)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors\"\n\tmksyscall=\"go run mksyscall.go -l32 -openbsd -arm -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nopenbsd_arm64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nopenbsd_mips64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nopenbsd_ppc64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nopenbsd_riscv64)\n\tmkasm=\"go run mkasm.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksyscall=\"go run mksyscall.go -openbsd -libc\"\n\tmksysctl=\"go run mksysctl_openbsd.go\"\n\t# Let the type of C char be signed for making the bare syscall\n\t# API consistent across platforms.\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs -- -fsigned-char\"\n\t;;\nsolaris_amd64)\n\tmksyscall=\"go run mksyscall_solaris.go\"\n\tmkerrors=\"$mkerrors -m64\"\n\tmksysnum=\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\nillumos_amd64)\n        mksyscall=\"go run mksyscall_solaris.go\"\n\tmkerrors=\n\tmksysnum=\n\tmktypes=\"GOARCH=$GOARCH go tool cgo -godefs\"\n\t;;\n*)\n\techo 'unrecognized $GOOS_$GOARCH: ' \"$GOOSARCH\" 1>&2\n\texit 1\n\t;;\nesac\n\n(\n\tif [ -n \"$mkerrors\" ]; then echo \"$mkerrors |gofmt >$zerrors\"; fi\n\tcase \"$GOOS\" in\n\t*)\n\t\tsyscall_goos=\"syscall_$GOOS.go\"\n\t\tcase \"$GOOS\" in\n\t\tdarwin | dragonfly | freebsd | netbsd | openbsd)\n\t\t\tsyscall_goos=\"syscall_bsd.go $syscall_goos\"\n\t\t\t;;\n\t\tesac\n\t\tif [ -n \"$mksyscall\" ]; then\n\t\t\tif [ \"$GOOSARCH\" == \"aix_ppc64\" ]; then\n\t\t\t\t# aix/ppc64 script generates files instead of writing to stdin.\n\t\t\t\techo \"$mksyscall -tags $GOOS,$GOARCH $syscall_goos $GOOSARCH_in && gofmt -w zsyscall_$GOOSARCH.go && gofmt -w zsyscall_\"$GOOSARCH\"_gccgo.go && gofmt -w zsyscall_\"$GOOSARCH\"_gc.go \" ;\n\t\t\telif [ \"$GOOS\" == \"illumos\" ]; then\n\t\t\t        # illumos code generation requires a --illumos switch\n\t\t\t        echo \"$mksyscall -illumos -tags illumos,$GOARCH syscall_illumos.go |gofmt > zsyscall_illumos_$GOARCH.go\";\n\t\t\t        # illumos implies solaris, so solaris code generation is also required\n\t\t\t\techo \"$mksyscall -tags solaris,$GOARCH syscall_solaris.go syscall_solaris_$GOARCH.go |gofmt >zsyscall_solaris_$GOARCH.go\";\n\t\t\telse\n\t\t\t\techo \"$mksyscall -tags $GOOS,$GOARCH $syscall_goos $GOOSARCH_in |gofmt >zsyscall_$GOOSARCH.go\";\n\t\t\tfi\n\t\tfi\n\tesac\n\tif [ -n \"$mksysctl\" ]; then echo \"$mksysctl |gofmt >$zsysctl\"; fi\n\tif [ -n \"$mksysnum\" ]; then echo \"$mksysnum |gofmt >zsysnum_$GOOSARCH.go\"; fi\n\tif [ -n \"$mktypes\" ]; then echo \"$mktypes types_$GOOS.go | go run mkpost.go > ztypes_$GOOSARCH.go\"; fi\n\tif [ -n \"$mkasm\" ]; then echo \"$mkasm $GOOS $GOARCH\"; fi\n) | $run\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/vendor/golang.org/x/sys/unix/mkall.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for backup automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright 2009 The Go Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style\n# license that can be found in the LICENSE file.\n\n# Generate Go code listing errors and other #defined constant\n# values (ENAMETOOLONG etc.), by asking the preprocessor\n# about the definitions.\n\nunset LANG\nexport LC_ALL=C\nexport LC_CTYPE=C\n\nif test -z \"$GOARCH\" -o -z \"$GOOS\"; then\n\techo 1>&2 \"GOARCH or GOOS not defined in environment\"\n\texit 1\nfi\n\n# Check that we are using the new build system if we should\nif [[ \"$GOOS\" = \"linux\" ]] && [[ \"$GOLANG_SYS_BUILD\" != \"docker\" ]]; then\n\techo 1>&2 \"In the Docker based build system, mkerrors should not be called directly.\"\n\techo 1>&2 \"See README.md\"\n\texit 1\nfi\n\nif [[ \"$GOOS\" = \"aix\" ]]; then\n\tCC=${CC:-gcc}\nelse\n\tCC=${CC:-cc}\nfi\n\nif [[ \"$GOOS\" = \"solaris\" ]]; then\n\t# Assumes GNU versions of utilities in PATH.\n\texport PATH=/usr/gnu/bin:$PATH\nfi\n\nuname=$(uname)\n\nincludes_AIX='\n#include <net/if.h>\n#include <net/netopt.h>\n#include <netinet/ip_mroute.h>\n#include <sys/protosw.h>\n#include <sys/stropts.h>\n#include <sys/mman.h>\n#include <sys/poll.h>\n#include <sys/select.h>\n#include <sys/termio.h>\n#include <termios.h>\n#include <fcntl.h>\n\n#define AF_LOCAL AF_UNIX\n'\n\nincludes_Darwin='\n#define _DARWIN_C_SOURCE\n#define KERNEL 1\n#define _DARWIN_USE_64_BIT_INODE\n#define __APPLE_USE_RFC_3542\n#include <stdint.h>\n#include <sys/stdio.h>\n#include <sys/attr.h>\n#include <sys/clonefile.h>\n#include <sys/kern_control.h>\n#include <sys/types.h>\n#include <sys/event.h>\n#include <sys/ptrace.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/stat.h>\n#include <sys/un.h>\n#include <sys/sockio.h>\n#include <sys/sys_domain.h>\n#include <sys/sysctl.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/utsname.h>\n#include <sys/wait.h>\n#include <sys/xattr.h>\n#include <sys/vsock.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <termios.h>\n\n// for backwards compatibility because moved TIOCREMOTE to Kernel.framework after MacOSX12.0.sdk.\n#define TIOCREMOTE 0x80047469\n'\n\nincludes_DragonFly='\n#include <sys/types.h>\n#include <sys/event.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/sockio.h>\n#include <sys/stat.h>\n#include <sys/sysctl.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/wait.h>\n#include <sys/ioctl.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_clone.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <termios.h>\n#include <netinet/ip.h>\n#include <net/ip_mroute/ip_mroute.h>\n'\n\nincludes_FreeBSD='\n#include <sys/capsicum.h>\n#include <sys/param.h>\n#include <sys/types.h>\n#include <sys/disk.h>\n#include <sys/event.h>\n#include <sys/sched.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/un.h>\n#include <sys/sockio.h>\n#include <sys/stat.h>\n#include <sys/sysctl.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/wait.h>\n#include <sys/ioctl.h>\n#include <sys/ptrace.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <termios.h>\n#include <netinet/ip.h>\n#include <netinet/ip_mroute.h>\n#include <sys/extattr.h>\n\n#if __FreeBSD__ >= 10\n#define IFT_CARP\t0xf8\t// IFT_CARP is deprecated in FreeBSD 10\n#undef SIOCAIFADDR\n#define SIOCAIFADDR\t_IOW(105, 26, struct oifaliasreq)\t// ifaliasreq contains if_data\n#undef SIOCSIFPHYADDR\n#define SIOCSIFPHYADDR\t_IOW(105, 70, struct oifaliasreq)\t// ifaliasreq contains if_data\n#endif\n'\n\nincludes_Linux='\n#define _LARGEFILE_SOURCE\n#define _LARGEFILE64_SOURCE\n#ifndef __LP64__\n#define _FILE_OFFSET_BITS 64\n#endif\n#define _GNU_SOURCE\n\n// See the description in unix/linux/types.go\n#if defined(__ARM_EABI__) || \\\n\t(defined(__mips__) && (_MIPS_SIM == _ABIO32)) || \\\n\t(defined(__powerpc__) && (!defined(__powerpc64__)))\n# ifdef   _TIME_BITS\n#  undef  _TIME_BITS\n# endif\n# define  _TIME_BITS 32\n#endif\n\n// <sys/ioctl.h> is broken on powerpc64, as it fails to include definitions of\n// these structures. We just include them copied from <bits/termios.h>.\n#if defined(__powerpc__)\nstruct sgttyb {\n        char    sg_ispeed;\n        char    sg_ospeed;\n        char    sg_erase;\n        char    sg_kill;\n        short   sg_flags;\n};\n\nstruct tchars {\n        char    t_intrc;\n        char    t_quitc;\n        char    t_startc;\n        char    t_stopc;\n        char    t_eofc;\n        char    t_brkc;\n};\n\nstruct ltchars {\n        char    t_suspc;\n        char    t_dsuspc;\n        char    t_rprntc;\n        char    t_flushc;\n        char    t_werasc;\n        char    t_lnextc;\n};\n#endif\n\n#include <bits/sockaddr.h>\n#include <sys/epoll.h>\n#include <sys/eventfd.h>\n#include <sys/inotify.h>\n#include <sys/ioctl.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/prctl.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <sys/time.h>\n#include <sys/select.h>\n#include <sys/signalfd.h>\n#include <sys/socket.h>\n#include <sys/timerfd.h>\n#include <sys/uio.h>\n#include <sys/xattr.h>\n#include <netinet/udp.h>\n#include <linux/audit.h>\n#include <linux/bpf.h>\n#include <linux/can.h>\n#include <linux/can/error.h>\n#include <linux/can/netlink.h>\n#include <linux/can/raw.h>\n#include <linux/capability.h>\n#include <linux/cryptouser.h>\n#include <linux/devlink.h>\n#include <linux/dm-ioctl.h>\n#include <linux/errqueue.h>\n#include <linux/ethtool_netlink.h>\n#include <linux/falloc.h>\n#include <linux/fanotify.h>\n#include <linux/fib_rules.h>\n#include <linux/filter.h>\n#include <linux/fs.h>\n#include <linux/fscrypt.h>\n#include <linux/fsverity.h>\n#include <linux/genetlink.h>\n#include <linux/hdreg.h>\n#include <linux/hidraw.h>\n#include <linux/if.h>\n#include <linux/if_addr.h>\n#include <linux/if_alg.h>\n#include <linux/if_arp.h>\n#include <linux/if_ether.h>\n#include <linux/if_ppp.h>\n#include <linux/if_tun.h>\n#include <linux/if_packet.h>\n#include <linux/if_xdp.h>\n#include <linux/input.h>\n#include <linux/kcm.h>\n#include <linux/kexec.h>\n#include <linux/keyctl.h>\n#include <linux/landlock.h>\n#include <linux/loop.h>\n#include <linux/lwtunnel.h>\n#include <linux/magic.h>\n#include <linux/memfd.h>\n#include <linux/module.h>\n#include <linux/mount.h>\n#include <linux/netfilter/nfnetlink.h>\n#include <linux/netfilter/nf_tables.h>\n#include <linux/netlink.h>\n#include <linux/net_namespace.h>\n#include <linux/nfc.h>\n#include <linux/nsfs.h>\n#include <linux/perf_event.h>\n#include <linux/pps.h>\n#include <linux/ptp_clock.h>\n#include <linux/ptrace.h>\n#include <linux/random.h>\n#include <linux/reboot.h>\n#include <linux/rtc.h>\n#include <linux/rtnetlink.h>\n#include <linux/sched.h>\n#include <linux/seccomp.h>\n#include <linux/serial.h>\n#include <linux/sock_diag.h>\n#include <linux/sockios.h>\n#include <linux/taskstats.h>\n#include <linux/tipc.h>\n#include <linux/vm_sockets.h>\n#include <linux/wait.h>\n#include <linux/watchdog.h>\n#include <linux/wireguard.h>\n\n#include <mtd/ubi-user.h>\n#include <mtd/mtd-user.h>\n#include <net/route.h>\n\n#if defined(__sparc__)\n// On sparc{,64}, the kernel defines struct termios2 itself which clashes with the\n// definition in glibc. As only the error constants are needed here, include the\n// generic termibits.h (which is included by termbits.h on sparc).\n#include <asm-generic/termbits.h>\n#else\n#include <asm/termbits.h>\n#endif\n\n#ifndef PTRACE_GETREGS\n#define PTRACE_GETREGS\t0xc\n#endif\n\n#ifndef PTRACE_SETREGS\n#define PTRACE_SETREGS\t0xd\n#endif\n\n#ifdef SOL_BLUETOOTH\n// SPARC includes this in /usr/include/sparc64-linux-gnu/bits/socket.h\n// but it is already in bluetooth_linux.go\n#undef SOL_BLUETOOTH\n#endif\n\n// Certain constants are missing from the fs/crypto UAPI\n#define FS_KEY_DESC_PREFIX              \"fscrypt:\"\n#define FS_KEY_DESC_PREFIX_SIZE         8\n#define FS_MAX_KEY_SIZE                 64\n\n// The code generator produces -0x1 for (~0), but an unsigned value is necessary\n// for the tipc_subscr timeout __u32 field.\n#undef TIPC_WAIT_FOREVER\n#define TIPC_WAIT_FOREVER 0xffffffff\n\n// Copied from linux/netfilter/nf_nat.h\n// Including linux/netfilter/nf_nat.h here causes conflicts between linux/in.h\n// and netinet/in.h.\n#define NF_NAT_RANGE_MAP_IPS\t\t\t(1 << 0)\n#define NF_NAT_RANGE_PROTO_SPECIFIED\t\t(1 << 1)\n#define NF_NAT_RANGE_PROTO_RANDOM\t\t(1 << 2)\n#define NF_NAT_RANGE_PERSISTENT\t\t\t(1 << 3)\n#define NF_NAT_RANGE_PROTO_RANDOM_FULLY\t\t(1 << 4)\n#define NF_NAT_RANGE_PROTO_OFFSET\t\t(1 << 5)\n#define NF_NAT_RANGE_NETMAP\t\t\t(1 << 6)\n#define NF_NAT_RANGE_PROTO_RANDOM_ALL\t\t\\\n\t(NF_NAT_RANGE_PROTO_RANDOM | NF_NAT_RANGE_PROTO_RANDOM_FULLY)\n#define NF_NAT_RANGE_MASK\t\t\t\t\t\\\n\t(NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED |\t\\\n\t NF_NAT_RANGE_PROTO_RANDOM | NF_NAT_RANGE_PERSISTENT |\t\\\n\t NF_NAT_RANGE_PROTO_RANDOM_FULLY | NF_NAT_RANGE_PROTO_OFFSET | \\\n\t NF_NAT_RANGE_NETMAP)\n\n// Copied from linux/hid.h.\n// Keep in sync with the size of the referenced fields.\n#define _HIDIOCGRAWNAME_LEN\t128 // sizeof_field(struct hid_device, name)\n#define _HIDIOCGRAWPHYS_LEN\t64  // sizeof_field(struct hid_device, phys)\n#define _HIDIOCGRAWUNIQ_LEN\t64  // sizeof_field(struct hid_device, uniq)\n\n#define _HIDIOCGRAWNAME\t\tHIDIOCGRAWNAME(_HIDIOCGRAWNAME_LEN)\n#define _HIDIOCGRAWPHYS\t\tHIDIOCGRAWPHYS(_HIDIOCGRAWPHYS_LEN)\n#define _HIDIOCGRAWUNIQ\t\tHIDIOCGRAWUNIQ(_HIDIOCGRAWUNIQ_LEN)\n\n'\n\nincludes_NetBSD='\n#include <sys/types.h>\n#include <sys/param.h>\n#include <sys/event.h>\n#include <sys/extattr.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/sched.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/sockio.h>\n#include <sys/sysctl.h>\n#include <sys/termios.h>\n#include <sys/ttycom.h>\n#include <sys/wait.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <netinet/in_systm.h>\n#include <netinet/ip.h>\n#include <netinet/ip_mroute.h>\n#include <netinet/if_ether.h>\n\n// Needed since <sys/param.h> refers to it...\n#define schedppq 1\n'\n\nincludes_OpenBSD='\n#include <sys/types.h>\n#include <sys/param.h>\n#include <sys/event.h>\n#include <sys/mman.h>\n#include <sys/mount.h>\n#include <sys/select.h>\n#include <sys/sched.h>\n#include <sys/socket.h>\n#include <sys/sockio.h>\n#include <sys/stat.h>\n#include <sys/sysctl.h>\n#include <sys/termios.h>\n#include <sys/ttycom.h>\n#include <sys/unistd.h>\n#include <sys/wait.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_types.h>\n#include <net/if_var.h>\n#include <net/route.h>\n#include <netinet/in.h>\n#include <netinet/in_systm.h>\n#include <netinet/ip.h>\n#include <netinet/ip_mroute.h>\n#include <netinet/if_ether.h>\n#include <net/if_bridge.h>\n\n// We keep some constants not supported in OpenBSD 5.5 and beyond for\n// the promise of compatibility.\n#define EMUL_ENABLED\t\t0x1\n#define EMUL_NATIVE\t\t0x2\n#define IPV6_FAITH\t\t0x1d\n#define IPV6_OPTIONS\t\t0x1\n#define IPV6_RTHDR_STRICT\t0x1\n#define IPV6_SOCKOPT_RESERVED1\t0x3\n#define SIOCGIFGENERIC\t\t0xc020693a\n#define SIOCSIFGENERIC\t\t0x80206939\n#define WALTSIG\t\t\t0x4\n'\n\nincludes_SunOS='\n#include <limits.h>\n#include <sys/types.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/sockio.h>\n#include <sys/stat.h>\n#include <sys/stream.h>\n#include <sys/mman.h>\n#include <sys/wait.h>\n#include <sys/ioctl.h>\n#include <sys/mkdev.h>\n#include <net/bpf.h>\n#include <net/if.h>\n#include <net/if_arp.h>\n#include <net/if_types.h>\n#include <net/route.h>\n#include <netinet/icmp6.h>\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <netinet/ip_mroute.h>\n#include <termios.h>\n'\n\n\nincludes='\n#include <sys/types.h>\n#include <sys/file.h>\n#include <fcntl.h>\n#include <dirent.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <netinet/ip6.h>\n#include <netinet/tcp.h>\n#include <errno.h>\n#include <sys/signal.h>\n#include <signal.h>\n#include <sys/resource.h>\n#include <time.h>\n'\nccflags=\"$@\"\n\n# Write go tool cgo -godefs input.\n(\n\techo package unix\n\techo\n\techo '/*'\n\tindirect=\"includes_$(uname)\"\n\techo \"${!indirect} $includes\"\n\techo '*/'\n\techo 'import \"C\"'\n\techo 'import \"syscall\"'\n\techo\n\techo 'const ('\n\n\t# The gcc command line prints all the #defines\n\t# it encounters while processing the input\n\techo \"${!indirect} $includes\" | $CC -x c - -E -dM $ccflags |\n\tawk '\n\t\t$1 != \"#define\" || $2 ~ /\\(/ || $3 == \"\" {next}\n\n\t\t$2 ~ /^E([ABCD]X|[BIS]P|[SD]I|S|FL)$/ {next}  # 386 registers\n\t\t$2 ~ /^(SIGEV_|SIGSTKSZ|SIGRT(MIN|MAX))/ {next}\n\t\t$2 ~ /^(SCM_SRCRT)$/ {next}\n\t\t$2 ~ /^(MAP_FAILED)$/ {next}\n\t\t$2 ~ /^ELF_.*$/ {next}# <asm/elf.h> contains ELF_ARCH, etc.\n\n\t\t$2 ~ /^EXTATTR_NAMESPACE_NAMES/ ||\n\t\t$2 ~ /^EXTATTR_NAMESPACE_[A-Z]+_STRING/ {next}\n\n\t\t$2 !~ /^ECCAPBITS/ &&\n\t\t$2 !~ /^ETH_/ &&\n\t\t$2 !~ /^EPROC_/ &&\n\t\t$2 !~ /^EQUIV_/ &&\n\t\t$2 !~ /^EXPR_/ &&\n\t\t$2 !~ /^EVIOC/ &&\n\t\t$2 ~ /^E[A-Z0-9_]+$/ ||\n\t\t$2 ~ /^B[0-9_]+$/ ||\n\t\t$2 ~ /^(OLD|NEW)DEV$/ ||\n\t\t$2 == \"BOTHER\" ||\n\t\t$2 ~ /^CI?BAUD(EX)?$/ ||\n\t\t$2 == \"IBSHIFT\" ||\n\t\t$2 ~ /^V[A-Z0-9]+$/ ||\n\t\t$2 ~ /^CS[A-Z0-9]/ ||\n\t\t$2 ~ /^I(SIG|CANON|CRNL|UCLC|EXTEN|MAXBEL|STRIP|UTF8)$/ ||\n\t\t$2 ~ /^IGN/ ||\n\t\t$2 ~ /^IX(ON|ANY|OFF)$/ ||\n\t\t$2 ~ /^IN(LCR|PCK)$/ ||\n\t\t$2 !~ \"X86_CR3_PCID_NOFLUSH\" &&\n\t\t$2 ~ /(^FLU?SH)|(FLU?SH$)/ ||\n\t\t$2 ~ /^C(LOCAL|READ|MSPAR|RTSCTS)$/ ||\n\t\t$2 == \"BRKINT\" ||\n\t\t$2 == \"HUPCL\" ||\n\t\t$2 == \"PENDIN\" ||\n\t\t$2 == \"TOSTOP\" ||\n\t\t$2 == \"XCASE\" ||\n\t\t$2 == \"ALTWERASE\" ||\n\t\t$2 == \"NOKERNINFO\" ||\n\t\t$2 == \"NFDBITS\" ||\n\t\t$2 ~ /^PAR/ ||\n\t\t$2 ~ /^SIG[^_]/ ||\n\t\t$2 ~ /^O[CNPFPL][A-Z]+[^_][A-Z]+$/ ||\n\t\t$2 ~ /^(NL|CR|TAB|BS|VT|FF)DLY$/ ||\n\t\t$2 ~ /^(NL|CR|TAB|BS|VT|FF)[0-9]$/ ||\n\t\t$2 ~ /^O?XTABS$/ ||\n\t\t$2 ~ /^TC[IO](ON|OFF)$/ ||\n\t\t$2 ~ /^IN_/ ||\n\t\t$2 ~ /^KCM/ ||\n\t\t$2 ~ /^LANDLOCK_/ ||\n\t\t$2 ~ /^LOCK_(SH|EX|NB|UN)$/ ||\n\t\t$2 ~ /^LO_(KEY|NAME)_SIZE$/ ||\n\t\t$2 ~ /^LOOP_(CLR|CTL|GET|SET)_/ ||\n\t\t$2 == \"LOOP_CONFIGURE\" ||\n\t\t$2 ~ /^(AF|SOCK|SO|SOL|IPPROTO|IP|IPV6|TCP|MCAST|EVFILT|NOTE|SHUT|PROT|MAP|MREMAP|MFD|T?PACKET|MSG|SCM|MCL|DT|MADV|PR|LOCAL|TCPOPT|UDP)_/ ||\n\t\t$2 ~ /^NFC_(GENL|PROTO|COMM|RF|SE|DIRECTION|LLCP|SOCKPROTO)_/ ||\n\t\t$2 ~ /^NFC_.*_(MAX)?SIZE$/ ||\n\t\t$2 ~ /^PTP_/ ||\n\t\t$2 ~ /^RAW_PAYLOAD_/ ||\n\t\t$2 ~ /^[US]F_/ ||\n\t\t$2 ~ /^TP_STATUS_/ ||\n\t\t$2 ~ /^FALLOC_/ ||\n\t\t$2 ~ /^ICMPV?6?_(FILTER|SEC)/ ||\n\t\t$2 == \"SOMAXCONN\" ||\n\t\t$2 == \"NAME_MAX\" ||\n\t\t$2 == \"IFNAMSIZ\" ||\n\t\t$2 ~ /^CTL_(HW|KERN|MAXNAME|NET|QUERY)$/ ||\n\t\t$2 ~ /^KERN_(HOSTNAME|OS(RELEASE|TYPE)|VERSION)$/ ||\n\t\t$2 ~ /^HW_MACHINE$/ ||\n\t\t$2 ~ /^SYSCTL_VERS/ ||\n\t\t$2 !~ \"MNT_BITS\" &&\n\t\t$2 ~ /^(MS|MNT|MOUNT|UMOUNT)_/ ||\n\t\t$2 ~ /^NS_GET_/ ||\n\t\t$2 ~ /^TUN(SET|GET|ATTACH|DETACH)/ ||\n\t\t$2 ~ /^(O|F|[ES]?FD|NAME|S|PTRACE|PT|PIOD|TFD)_/ ||\n\t\t$2 ~ /^KEXEC_/ ||\n\t\t$2 ~ /^LINUX_REBOOT_CMD_/ ||\n\t\t$2 ~ /^LINUX_REBOOT_MAGIC[12]$/ ||\n\t\t$2 ~ /^MODULE_INIT_/ ||\n\t\t$2 !~ \"NLA_TYPE_MASK\" &&\n\t\t$2 !~ /^RTC_VL_(ACCURACY|BACKUP|DATA)/ &&\n\t\t$2 ~ /^(NETLINK|NLM|NLMSG|NLA|IFA|IFAN|RT|RTC|RTCF|RTN|RTPROT|RTNH|ARPHRD|ETH_P|NETNSA)_/ ||\n\t\t$2 ~ /^SOCK_|SK_DIAG_|SKNLGRP_$/ ||\n\t\t$2 ~ /^(CONNECT|SAE)_/ ||\n\t\t$2 ~ /^FIORDCHK$/ ||\n\t\t$2 ~ /^SIOC/ ||\n\t\t$2 ~ /^TIOC/ ||\n\t\t$2 ~ /^TCGET/ ||\n\t\t$2 ~ /^TCSET/ ||\n\t\t$2 ~ /^TC(FLSH|SBRKP?|XONC)$/ ||\n\t\t$2 !~ \"RTF_BITS\" &&\n\t\t$2 ~ /^(IFF|IFT|NET_RT|RTM(GRP)?|RTF|RTV|RTA|RTAX)_/ ||\n\t\t$2 ~ /^BIOC/ ||\n\t\t$2 ~ /^DIOC/ ||\n\t\t$2 ~ /^RUSAGE_(SELF|CHILDREN|THREAD)/ ||\n\t\t$2 ~ /^RLIMIT_(AS|CORE|CPU|DATA|FSIZE|LOCKS|MEMLOCK|MSGQUEUE|NICE|NOFILE|NPROC|RSS|RTPRIO|RTTIME|SIGPENDING|STACK)|RLIM_INFINITY/ ||\n\t\t$2 ~ /^PRIO_(PROCESS|PGRP|USER)/ ||\n\t\t$2 ~ /^CLONE_[A-Z_]+/ ||\n\t\t$2 !~ /^(BPF_TIMEVAL|BPF_FIB_LOOKUP_[A-Z]+|BPF_F_LINK)$/ &&\n\t\t$2 ~ /^(BPF|DLT)_/ ||\n\t\t$2 ~ /^AUDIT_/ ||\n\t\t$2 ~ /^(CLOCK|TIMER)_/ ||\n\t\t$2 ~ /^CAN_/ ||\n\t\t$2 ~ /^CAP_/ ||\n\t\t$2 ~ /^CP_/ ||\n\t\t$2 ~ /^CPUSTATES$/ ||\n\t\t$2 ~ /^CTLIOCGINFO$/ ||\n\t\t$2 ~ /^ALG_/ ||\n\t\t$2 ~ /^FI(CLONE|DEDUPERANGE)/ ||\n\t\t$2 ~ /^FS_(POLICY_FLAGS|KEY_DESC|ENCRYPTION_MODE|[A-Z0-9_]+_KEY_SIZE)/ ||\n\t\t$2 ~ /^FS_IOC_.*(ENCRYPTION|VERITY|[GS]ETFLAGS)/ ||\n\t\t$2 ~ /^FS_VERITY_/ ||\n\t\t$2 ~ /^FSCRYPT_/ ||\n\t\t$2 ~ /^DM_/ ||\n\t\t$2 ~ /^GRND_/ ||\n\t\t$2 ~ /^RND/ ||\n\t\t$2 ~ /^KEY_(SPEC|REQKEY_DEFL)_/ ||\n\t\t$2 ~ /^KEYCTL_/ ||\n\t\t$2 ~ /^PERF_/ ||\n\t\t$2 ~ /^SECCOMP_/ ||\n\t\t$2 ~ /^SEEK_/ ||\n\t\t$2 ~ /^SCHED_/ ||\n\t\t$2 ~ /^SPLICE_/ ||\n\t\t$2 ~ /^SYNC_FILE_RANGE_/ ||\n\t\t$2 !~ /IOC_MAGIC/ &&\n\t\t$2 ~ /^[A-Z][A-Z0-9_]+_MAGIC2?$/ ||\n\t\t$2 ~ /^(VM|VMADDR)_/ ||\n\t\t$2 ~ /^IOCTL_VM_SOCKETS_/ ||\n\t\t$2 ~ /^(TASKSTATS|TS)_/ ||\n\t\t$2 ~ /^CGROUPSTATS_/ ||\n\t\t$2 ~ /^GENL_/ ||\n\t\t$2 ~ /^STATX_/ ||\n\t\t$2 ~ /^RENAME/ ||\n\t\t$2 ~ /^UBI_IOC[A-Z]/ ||\n\t\t$2 ~ /^UTIME_/ ||\n\t\t$2 ~ /^XATTR_(CREATE|REPLACE|NO(DEFAULT|FOLLOW|SECURITY)|SHOWCOMPRESSION)/ ||\n\t\t$2 ~ /^ATTR_(BIT_MAP_COUNT|(CMN|VOL|FILE)_)/ ||\n\t\t$2 ~ /^FSOPT_/ ||\n\t\t$2 ~ /^WDIO[CFS]_/ ||\n\t\t$2 ~ /^NFN/ ||\n\t\t$2 !~ /^NFT_META_IIFTYPE/ &&\n\t\t$2 ~ /^NFT_/ ||\n\t\t$2 ~ /^NF_NAT_/ ||\n\t\t$2 ~ /^XDP_/ ||\n\t\t$2 ~ /^RWF_/ ||\n\t\t$2 ~ /^(HDIO|WIN|SMART)_/ ||\n\t\t$2 ~ /^CRYPTO_/ ||\n\t\t$2 ~ /^TIPC_/ ||\n\t\t$2 !~  \"DEVLINK_RELOAD_LIMITS_VALID_MASK\" &&\n\t\t$2 ~ /^DEVLINK_/ ||\n\t\t$2 ~ /^ETHTOOL_/ ||\n\t\t$2 ~ /^LWTUNNEL_IP/ ||\n\t\t$2 ~ /^ITIMER_/ ||\n\t\t$2 !~ \"WMESGLEN\" &&\n\t\t$2 ~ /^W[A-Z0-9]+$/ ||\n\t\t$2 ~ /^P_/ ||\n\t\t$2 ~/^PPPIOC/ ||\n\t\t$2 ~ /^FAN_|FANOTIFY_/ ||\n\t\t$2 == \"HID_MAX_DESCRIPTOR_SIZE\" ||\n\t\t$2 ~ /^_?HIDIOC/ ||\n\t\t$2 ~ /^BUS_(USB|HIL|BLUETOOTH|VIRTUAL)$/ ||\n\t\t$2 ~ /^MTD/ ||\n\t\t$2 ~ /^OTP/ ||\n\t\t$2 ~ /^MEM/ ||\n\t\t$2 ~ /^WG/ ||\n\t\t$2 ~ /^FIB_RULE_/ ||\n\t\t$2 ~ /^BLK[A-Z]*(GET$|SET$|BUF$|PART$|SIZE|IOMIN$|IOOPT$|ALIGNOFF$|DISCARD|ROTATIONAL$|ZEROOUT$|GETDISKSEQ$)/ {printf(\"\\t%s = C.%s\\n\", $2, $2)}\n\t\t$2 ~ /^__WCOREFLAG$/ {next}\n\t\t$2 ~ /^__W[A-Z0-9]+$/ {printf(\"\\t%s = C.%s\\n\", substr($2,3), $2)}\n\n\t\t{next}\n\t' | sort\n\n\techo ')'\n) >_const.go\n\n# Pull out the error names for later.\nerrors=$(\n\techo '#include <errno.h>' | $CC -x c - -E -dM $ccflags |\n\tawk '$1==\"#define\" && $2 ~ /^E[A-Z0-9_]+$/ { print $2 }' |\n\tsort\n)\n\n# Pull out the signal names for later.\nsignals=$(\n\techo '#include <signal.h>' | $CC -x c - -E -dM $ccflags |\n\tawk '$1==\"#define\" && $2 ~ /^SIG[A-Z0-9]+$/ { print $2 }' |\n\tgrep -E -v '(SIGSTKSIZE|SIGSTKSZ|SIGRT|SIGMAX64)' |\n\tsort\n)\n\n# Again, writing regexps to a file.\necho '#include <errno.h>' | $CC -x c - -E -dM $ccflags |\n\tawk '$1==\"#define\" && $2 ~ /^E[A-Z0-9_]+$/ { print \"^\\t\" $2 \"[ \\t]*=\" }' |\n\tsort >_error.grep\necho '#include <signal.h>' | $CC -x c - -E -dM $ccflags |\n\tawk '$1==\"#define\" && $2 ~ /^SIG[A-Z0-9]+$/ { print \"^\\t\" $2 \"[ \\t]*=\" }' |\n\tgrep -E -v '(SIGSTKSIZE|SIGSTKSZ|SIGRT|SIGMAX64)' |\n\tsort >_signal.grep\n\necho '// mkerrors.sh' \"$@\"\necho '// Code generated by the command above; see README.md. DO NOT EDIT.'\necho\necho \"//go:build ${GOARCH} && ${GOOS}\"\necho\ngo tool cgo -godefs -- \"$@\" _const.go >_error.out\ncat _error.out | grep -vf _error.grep | grep -vf _signal.grep\necho\necho '// Errors'\necho 'const ('\ncat _error.out | grep -f _error.grep | sed 's/=\\(.*\\)/= syscall.Errno(\\1)/'\necho ')'\n\necho\necho '// Signals'\necho 'const ('\ncat _error.out | grep -f _signal.grep | sed 's/=\\(.*\\)/= syscall.Signal(\\1)/'\necho ')'\n\n# Run C program to print error and syscall strings.\n(\n\techo -E \"\n#include <stdio.h>\n#include <stdlib.h>\n#include <errno.h>\n#include <ctype.h>\n#include <string.h>\n#include <signal.h>\n\n#define nelem(x) (sizeof(x)/sizeof((x)[0]))\n\nenum { A = 'A', Z = 'Z', a = 'a', z = 'z' }; // avoid need for single quotes below\n\nstruct tuple {\n\tint num;\n\tconst char *name;\n};\n\nstruct tuple errors[] = {\n\"\n\tfor i in $errors\n\tdo\n\t\techo -E '\t{'$i', \"'$i'\" },'\n\tdone\n\n\techo -E \"\n};\n\nstruct tuple signals[] = {\n\"\n\tfor i in $signals\n\tdo\n\t\techo -E '\t{'$i', \"'$i'\" },'\n\tdone\n\n\t# Use -E because on some systems bash builtin interprets \\n itself.\n\techo -E '\n};\n\nstatic int\ntuplecmp(const void *a, const void *b)\n{\n\treturn ((struct tuple *)a)->num - ((struct tuple *)b)->num;\n}\n\nint\nmain(void)\n{\n\tint i, e;\n\tchar buf[1024], *p;\n\n\tprintf(\"\\n\\n// Error table\\n\");\n\tprintf(\"var errorList = [...]struct {\\n\");\n\tprintf(\"\\tnum  syscall.Errno\\n\");\n\tprintf(\"\\tname string\\n\");\n\tprintf(\"\\tdesc string\\n\");\n\tprintf(\"} {\\n\");\n\tqsort(errors, nelem(errors), sizeof errors[0], tuplecmp);\n\tfor(i=0; i<nelem(errors); i++) {\n\t\te = errors[i].num;\n\t\tif(i > 0 && errors[i-1].num == e)\n\t\t\tcontinue;\n\t\tstrncpy(buf, strerror(e), sizeof(buf) - 1);\n\t\tbuf[sizeof(buf) - 1] = '\\0';\n\t\t// lowercase first letter: Bad -> bad, but STREAM -> STREAM.\n\t\tif(A <= buf[0] && buf[0] <= Z && a <= buf[1] && buf[1] <= z)\n\t\t\tbuf[0] += a - A;\n\t\tprintf(\"\\t{ %d, \\\"%s\\\", \\\"%s\\\" },\\n\", e, errors[i].name, buf);\n\t}\n\tprintf(\"}\\n\\n\");\n\n\tprintf(\"\\n\\n// Signal table\\n\");\n\tprintf(\"var signalList = [...]struct {\\n\");\n\tprintf(\"\\tnum  syscall.Signal\\n\");\n\tprintf(\"\\tname string\\n\");\n\tprintf(\"\\tdesc string\\n\");\n\tprintf(\"} {\\n\");\n\tqsort(signals, nelem(signals), sizeof signals[0], tuplecmp);\n\tfor(i=0; i<nelem(signals); i++) {\n\t\te = signals[i].num;\n\t\tif(i > 0 && signals[i-1].num == e)\n\t\t\tcontinue;\n\t\tstrncpy(buf, strsignal(e), sizeof(buf) - 1);\n\t\tbuf[sizeof(buf) - 1] = '\\0';\n\t\t// lowercase first letter: Bad -> bad, but STREAM -> STREAM.\n\t\tif(A <= buf[0] && buf[0] <= Z && a <= buf[1] && buf[1] <= z)\n\t\t\tbuf[0] += a - A;\n\t\t// cut trailing : number.\n\t\tp = strrchr(buf, \":\"[0]);\n\t\tif(p)\n\t\t\t*p = '\\0';\n\t\tprintf(\"\\t{ %d, \\\"%s\\\", \\\"%s\\\" },\\n\", e, signals[i].name, buf);\n\t}\n\tprintf(\"}\\n\\n\");\n\n\treturn 0;\n}\n\n'\n) >_errors.c\n\n$CC $ccflags -o _errors _errors.c && $GORUN ./_errors && rm -f _errors.c _errors _const.go _error.grep _signal.grep _error.out\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/vendor/golang.org/x/sys/unix/mkerrors.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/bash\nset -e\nset -x\n\nif [ ! -d /tmp/build-golang/src/github.com/json-iterator ]; then\n    mkdir -p /tmp/build-golang/src/github.com/json-iterator\n    ln -s $PWD /tmp/build-golang/src/github.com/json-iterator/go\nfi\nexport GOPATH=/tmp/build-golang\ngo get -u github.com/golang/dep/cmd/dep\ncd /tmp/build-golang/src/github.com/json-iterator/go\nexec $GOPATH/bin/dep ensure -update\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/vendor/github.com/json-iterator/go/build.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Usage: get-logs.sh [<job ID>]\n#\n# Downloads the latest job output or the one with the specified ID\n# and prepares running benchmarks for it.\n\nset -o pipefail\nset -o errexit\nset -x\n\ncd \"$(dirname \"$0\")\"\n\nlatest_job () {\n    gsutil cat gs://kubernetes-jenkins/logs/ci-kubernetes-kind-e2e-json-logging/latest-build.txt\n}\n\njob=${1:-$(latest_job)}\n\nrm -rf ci-kubernetes-kind-e2e-json-logging\nmkdir ci-kubernetes-kind-e2e-json-logging\ngsutil -m cp -R \"gs://kubernetes-jenkins/logs/ci-kubernetes-kind-e2e-json-logging/${job}/*\" ci-kubernetes-kind-e2e-json-logging/\n\nfor i in kube-apiserver kube-controller-manager kube-scheduler; do\n    # Before (container runtime log dump (?)):\n    #   2023-03-07T07:30:52.193301924Z stderr F {\"ts\":1678174252192.0676,\"caller\":\"scheduler/schedule_one.go:81\",\"msg\":\"Attempting to schedule pod\",\"v\":3,\"pod\":{\"name\":\"simpletest.rc-zgd47\",\"namespace\":\"gc-5422\"}}\n    # After:\n    #   {\"ts\":1678174252192.0676,\"caller\":\"scheduler/schedule_one.go:81\",\"msg\":\"Attempting to schedule pod\",\"v\":3,\"pod\":{\"name\":\"simpletest.rc-zgd47\",\"namespace\":\"gc-5422\"}}\n    sed -e 's/^20[^ ]* stderr . //' \\\n        ci-kubernetes-kind-e2e-json-logging/artifacts/kind-control-plane/containers/$i-*.log \\\n        > ci-kubernetes-kind-e2e-json-logging/$i.log;\ndone\n\n# Before (systemd format):\n#   Mar 07 07:22:05 kind-control-plane kubelet[288]: {\"ts\":1678173725722.4487,\"caller\":\"flag/flags.go:64\",\"msg\":\"FLAG: --address=\\\"0.0.0.0\\\"\\n\",\"v\":1}\n# After:\n#   {\"ts\":1678173725722.4487,\"caller\":\"flag/flags.go:64\",\"msg\":\"FLAG: --address=\\\"0.0.0.0\\\"\\n\",\"v\":1}\ngrep 'kind-worker kubelet' ci-kubernetes-kind-e2e-json-logging/artifacts/kind-worker/kubelet.log | \\\n    sed -e 's;^.* kind-worker kubelet[^ ]*: ;;' > ci-kubernetes-kind-e2e-json-logging/kind-worker-kubelet.log\n\n# Create copies of the actual files, whether they already exist or not. To\n# clean up disk space, use \"git clean -fx test/integration/logs/benchmark\".\ncopy () {\n    from=\"$1\"\n    to=\"$2\"\n\n    mkdir -p \"$(dirname \"$to\")\"\n    rm -f \"$to\"\n    cp \"$from\" \"$to\"\n}\ncopy ci-kubernetes-kind-e2e-json-logging/kind-worker-kubelet.log data/kind-worker-kubelet.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-apiserver.log data/kube-apiserver.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-controller-manager.log data/kube-controller-manager.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-scheduler.log data/kube-scheduler.log\n\ncopy ci-kubernetes-kind-e2e-json-logging/kind-worker-kubelet.log data/v3/kind-worker-kubelet.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-apiserver.log data/v3/kube-apiserver.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-controller-manager.log data/v3/kube-controller-manager.log\ncopy ci-kubernetes-kind-e2e-json-logging/kube-scheduler.log data/v3/kube-scheduler.log\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/logs/benchmark/get-logs.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Create a shell script for Kubernetes cluster management", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2024 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Invoke this script with a list of *.dat and it'll plot them with gnuplot.\n# Any non-file parameter is passed through to gnuplot. By default,\n# an X11 window is used to display the result. To write into a file,\n# use\n#  -e \"set term png; set output <output>.png\"\n\nfiles=()\nargs=( -e \"set term x11 persist\" )\n\nfor i in \"$@\"; do\n    if [ -f \"$i\" ]; then\n        files+=(\"$i\")\n    else\n        args+=(\"$i\")\n    fi\ndone\n\n(\n    cat <<EOF\nset ytics autofreq nomirror tc lt 1\nset xlabel 'measurement runtime [seconds]'\nset ylabel 'scheduling rate [pods/second]' tc lt 1\nset y2tics autofreq nomirror tc lt 2\nset y2label 'scheduling attempts per pod' tc lt 2\n\n# Derivative from https://stackoverflow.com/questions/15751226/how-can-i-plot-the-derivative-of-a-graph-in-gnuplot.\nd2(x,y) = (\\$0 == 0) ? (x1 = x, y1 = y, 1/0) : (x2 = x1, x1 = x, y2 = y1, y1 = y, (y1-y2)/(x1-x2))\ndx = 0.25\n\nEOF\n    echo -n \"plot \"\n    for file in \"${files[@]}\"; do\n        echo -n \"'${file}' using (\\$1 - dx):(d2(\\$1, \\$2)) with linespoints title '$(basename \"$file\" .dat | sed -e 's/_/ /g') metric rate' axis x1y1, \"\n        echo -n \"'${file}' using (\\$1 - dx):(d2(\\$1, \\$4)) with linespoints title '$(basename \"$file\" .dat | sed -e 's/_/ /g') observed rate' axis x1y1, \"\n        echo -n \"'${file}' using 1:(\\$3/\\$2) with linespoints title '$(basename \"$file\" .dat | sed -e 's/_/ /g') attempts' axis x1y2, \"\n    done\n    echo\n) | tee /dev/stderr | gnuplot \"${args[@]}\" -\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/scheduler_perf/gnuplot.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Create a shell script for Kubernetes cluster management", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\nif [[ -n \"${EXEC_PLUGIN_OUTPUT_FILE-\"\"}\" ]]; then\n  cat \"$EXEC_PLUGIN_OUTPUT_FILE\"\n  exit\nfi\n\necho \"${EXEC_PLUGIN_OUTPUT-\"\"}\"\n\nexit \"${EXEC_PLUGIN_EXEC_CODE-0}\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/client/testdata/exec-plugin.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Create a shell script for Kubernetes cluster management", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This file is not executable, and therefore it will not be run.\nexit 1\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/client/testdata/exec-plugin-not-executable.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\nTEST_ARGS=\"\"\nRUN_PATTERN=\".*\"\nPROFILE_OPTS=\"\"\n\nfunction usage() {\n  echo \"usage: $0 <options>\"\n  echo \" -h display this help message\"\n  echo \" -d enable debug logs in tests\"\n  echo \" -r <pattern> regex pattern to match for tests\"\n  echo \" -o <filename> file to write JSON formatted results to\"\n  echo \" -p <id> enable cpu and memory profiles, output written to mem-<id>.out and cpu-<id>.out\"\n  echo \" -c enable custom test configuration\"\n  echo \" -a <name> allocator name, one of RangeAllocator, CloudAllocator, IPAMFromCluster, IPAMFromCloud\"\n  echo \" -k <num> api server qps for allocator\"\n  echo \" -n <num> number of nodes to simulate\"\n  echo \" -m <num> api server qps for node creation\"\n  echo \" -l <num> gce cloud endpoint qps\"\n  exit 1\n}\n\nwhile getopts \":hdr:o:p:ca:k:n:m:l:\" opt; do\n  case ${opt} in\n    d) TEST_ARGS=\"${TEST_ARGS} -v=6\"\n      ;;\n    r) RUN_PATTERN=\"${OPTARG}\"\n      ;;\n    o) TEST_ARGS=\"${TEST_ARGS} -log ${OPTARG}\"\n      ;;\n    p) PROFILE_OPTS=\"-memprofile mem-${OPTARG}.out -cpuprofile cpu-${OPTARG}.out\"\n      ;;\n    c) TEST_ARGS=\"${TEST_ARGS} -custom\"\n      ;;\n    a) TEST_ARGS=\"${TEST_ARGS} -allocator ${OPTARG}\"\n      ;;\n    k) TEST_ARGS=\"${TEST_ARGS} -kube-qps ${OPTARG}\"\n      ;;\n    n) TEST_ARGS=\"${TEST_ARGS} -num-nodes ${OPTARG}\"\n      ;;\n    m) TEST_ARGS=\"${TEST_ARGS} -create-qps ${OPTARG}\"\n      ;;\n    l) TEST_ARGS=\"${TEST_ARGS} -cloud-qps ${OPTARG}\"\n      ;;\n    h) usage\n      ;;\n    \\?) usage\n      ;;\n  esac\ndone\n\nKUBE_ROOT=$(dirname \"${BASH_SOURCE[0]}\")/../../../\nsource \"${KUBE_ROOT}/hack/lib/init.sh\"\n\nkube::golang::setup_env\n\nDIR_BASENAME=$(dirname \"${BASH_SOURCE[0]}\")\npushd \"${DIR_BASENAME}\"\n\ncleanup() {\n  popd 2> /dev/null\n  kube::etcd::cleanup\n  kube::log::status \"performance test cleanup complete\"\n}\n\ntrap cleanup EXIT\n\nkube::etcd::start\n\n# Running IPAM tests. It might take a long time.\nkube::log::status \"performance test (IPAM) start\"\ngo test \"${PROFILE_OPTS}\" -test.run=\"${RUN_PATTERN}\" -test.timeout=60m -test.short=false -v -args \"${TEST_ARGS}\"\nkube::log::status \"... IPAM tests finished.\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/integration/ipamperf/test-performance.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#! /bin/bash\n\n# Copyright 2016 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This volume is assumed to exist and is shared with parent of the init\n# container. It contains the zookeeper installation.\nINSTALL_VOLUME=\"/opt\"\n\n# This volume is assumed to exist and is shared with the peer-finder\n# init container. It contains on-start/change configuration scripts.\nWORKDIR_VOLUME=\"/work-dir\"\n\n# As of April-2016 is 3.4.8 is the latest stable, but versions 3.5.0 onward\n# allow dynamic reconfiguration.\nVERSION=\"3.5.0-alpha\"\n\nfor i in \"$@\"\ndo\ncase $i in\n    -i=*|--install-into=*)\n    INSTALL_VOLUME=\"${i#*=}\"\n    shift\n    ;;\n    -w=*|--work-dir=*)\n    WORKDIR_VOLUME=\"${i#*=}\"\n    shift\n    ;;\n    *)\n    # unknown option\n    ;;\nesac\ndone\n\necho installing config scripts into \"${WORKDIR_VOLUME}\"\nmkdir -p \"${WORKDIR_VOLUME}\"\ncp /on-start.sh \"${WORKDIR_VOLUME}\"/\ncp /peer-finder \"${WORKDIR_VOLUME}\"/\n\necho installing zookeeper-\"${VERSION}\" into \"${INSTALL_VOLUME}\"\nmkdir -p \"${INSTALL_VOLUME}\"\nmv /zookeeper \"${INSTALL_VOLUME}\"/zookeeper\ncp \"${INSTALL_VOLUME}\"/zookeeper/conf/zoo_sample.cfg \"${INSTALL_VOLUME}\"/zookeeper/conf/zoo.cfg\n\n# TODO: Should dynamic config be tied to the version?\nIFS=\".\" read -ra RELEASE <<< \"${VERSION}\"\nif [ \"$((\"${RELEASE[1]}\"))\" -gt 4 ]; then\n    echo zookeeper-\"${VERSION}\" supports dynamic reconfiguration, enabling it\n    echo \"standaloneEnabled=false\" >> \"${INSTALL_VOLUME}\"/zookeeper/conf/zoo.cfg\n    echo \"dynamicConfigFile=${INSTALL_VOLUME}/zookeeper/conf/zoo.cfg.dynamic\" >> \"${INSTALL_VOLUME}\"/zookeeper/conf/zoo.cfg\nfi\n\n# TODO: This is a hack, netcat is convenient to have in the zookeeper container\n# I want to avoid using a custom zookeeper image just for this. So copy it.\nNC=$(which nc)\nif [ \"${NC}\" != \"\" ]; then\n    echo copying nc into \"${INSTALL_VOLUME}\"\n    cp \"${NC}\" \"${INSTALL_VOLUME}\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/kubernetes/test/images/pets/zookeeper-installer/install.sh", "category": "orchestration", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env sh\n\n# Test script checking that all expected os/arch compile properly.\n# Does not actually test the logic, just the compilation so we make sure we don't break code depending on the lib.\n\necho2() {\n  echo $@ >&2\n}\n\ntrap end 0\nend() {\n  [ \"$?\" = 0 ] && echo2 \"Pass.\" || (echo2 \"Fail.\"; exit 1)\n}\n\ncross() {\n  os=$1\n  shift\n  echo2 \"Build for $os.\"\n  for arch in $@; do\n    echo2 \"  - $os/$arch\"\n    GOOS=$os GOARCH=$arch go build\n  done\n  echo2\n}\n\nset -e\n\ncross linux     amd64 386 arm arm64 ppc64 ppc64le s390x mips mipsle mips64 mips64le riscv64\ncross darwin    amd64 arm64\ncross freebsd   amd64 386 arm arm64 riscv64\ncross netbsd    amd64 386 arm arm64\ncross openbsd   amd64 386 arm arm64\ncross dragonfly amd64\ncross solaris   amd64\n\n# Not expected to work but should still compile.\ncross windows amd64 386 arm\n\n# TODO: Fix compilation error on openbsd/arm.\n# TODO: Merge the solaris PR.\n\n# Some os/arch require a different compiler. Run in docker.\nif ! hash docker; then\n  # If docker is not present, stop here.\n  return\nfi\n\n# Golang dropped support for darwin 32bits since go1.15. Make sure the lib still compile with go1.14 on those archs.\necho2 \"Build for darwin (32bits).\"\necho2 \"  - darwin/386\"\ndocker build -t creack-pty-test -f Dockerfile.golang --build-arg=GOVERSION=1.14 --build-arg=GOOS=darwin --build-arg=GOARCH=386 .\necho2 \"  - darwin/arm\"\ndocker build -t creack-pty-test -f Dockerfile.golang --build-arg=GOVERSION=1.14 --build-arg=GOOS=darwin --build-arg=GOARCH=arm .\n\n# Run a single test for an old go version. Would be best with go1.0, but not available on Dockerhub.\n# Using 1.6 as it is the base version for the RISCV compiler.\n# Would also be better to run all the tests, not just one, need to refactor this file to allow for specifc archs per version.\necho2 \"Build for linux - go1.6.\"\necho2 \"  - linux/amd64\"\ndocker build -t creack-pty-test -f Dockerfile.golang --build-arg=GOVERSION=1.6 --build-arg=GOOS=linux --build-arg=GOARCH=amd64 .\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/creack/pty/test_crosscompile.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for Git workflow automation", "completion": "```bash\n#1/usr/bin/env bash\n\nPROJECT_DIR=\"\"\nSMITHY_SOURCE_DIR=$(cd `dirname $0` && pwd)\n\nusage() {\n  echo \"Usage: $0 [-s SMITHY_SOURCE_DIR] [-d PROJECT_DIR]\" 1>&2\n  exit 1\n}\n\nwhile getopts \"hs:d:\" options; do\n  case \"${options}\" in\n  s)\n    SMITHY_SOURCE_DIR=${OPTARG}\n    if [ \"$SMITHY_SOURCE_DIR\" == \"\" ]; then\n      echo \"path to smithy-go source directory is required\" || exit\n      usage\n    fi\n    ;;\n  d)\n    PROJECT_DIR=${OPTARG}\n    ;;\n  h)\n    usage\n    ;;\n  *)\n    usage\n    ;;\n  esac\ndone\n\nif [ \"$PROJECT_DIR\" != \"\" ]; then\n  cd $PROJECT_DIR || exit\nfi\n\ngo mod graph | awk '{print $1}' | cut -d '@' -f 1 | sort | uniq | grep \"github.com/aws/smithy-go\" | while read x; do\n  repPath=${x/github.com\\/aws\\/smithy-go/${SMITHY_SOURCE_DIR}}\n  echo -replace $x=$repPath\ndone | xargs go mod edit\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/aws/smithy-go/local-mod-replace.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\nset -ev\n\nif [[ \"$1\" == \"goveralls\" ]]; then\n\techo \"Testing with goveralls...\"\n\tgo get github.com/mattn/goveralls\n\t$HOME/gopath/bin/goveralls -service=travis-ci\nelse\n\techo \"Testing with go test...\"\n\tgo test -v ./...\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/agext/levenshtein/test.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#! /bin/sh\nset -eu\n\ngo get github.com/dvyukov/go-fuzz/go-fuzz\ngo get github.com/dvyukov/go-fuzz/go-fuzz-build\n\nif [ ! -e toml-fuzz.zip ]; then\n    go-fuzz-build github.com/pelletier/go-toml\nfi\n\nrm -fr fuzz\nmkdir -p fuzz/corpus\ncp *.toml fuzz/corpus\n\ngo-fuzz -bin=toml-fuzz.zip -workdir=fuzz\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/pelletier/go-toml/fuzz.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/bash\n\nset -ex\n\nreference_ref=${1:-master}\nreference_git=${2:-.}\n\nif ! `hash benchstat 2>/dev/null`; then\n    echo \"Installing benchstat\"\n    go get golang.org/x/perf/cmd/benchstat\nfi\n\ntempdir=`mktemp -d /tmp/go-toml-benchmark-XXXXXX`\nref_tempdir=\"${tempdir}/ref\"\nref_benchmark=\"${ref_tempdir}/benchmark-`echo -n ${reference_ref}|tr -s '/' '-'`.txt\"\nlocal_benchmark=\"`pwd`/benchmark-local.txt\"\n\necho \"=== ${reference_ref} (${ref_tempdir})\"\ngit clone ${reference_git} ${ref_tempdir} >/dev/null 2>/dev/null\npushd ${ref_tempdir} >/dev/null\ngit checkout ${reference_ref} >/dev/null 2>/dev/null\ngo test -bench=. -benchmem | tee ${ref_benchmark}\ncd benchmark\ngo test -bench=. -benchmem | tee -a ${ref_benchmark}\npopd >/dev/null\n\necho \"\"\necho \"=== local\"\ngo test -bench=. -benchmem  | tee ${local_benchmark}\ncd benchmark\ngo test -bench=. -benchmem | tee -a ${local_benchmark}\n\necho \"\"\necho \"=== diff\"\nbenchstat -delta-test=none ${ref_benchmark} ${local_benchmark}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/vendor/github.com/pelletier/go-toml/benchmark.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\n#\n# This script is used to coerce certain commands which rely on the presence of\n# a go.mod into working with our repository. It works by creating a fake\n# go.mod, running a specified command (passed via arguments), and removing it\n# when the command is finished. This script should be dropped when this\n# repository is a proper Go module with a permanent go.mod.\n\nset -e\n\nSCRIPTDIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nROOTDIR=\"$(cd \"${SCRIPTDIR}/..\" && pwd)\"\n\nif test -e \"${ROOTDIR}/go.mod\"; then\n\t{\n\t\tscriptname=$(basename \"$0\")\n\t\tcat >&2 <<- EOF\n\t\t\t$scriptname: WARN: go.mod exists in the repository root!\n\t\t\t$scriptname: WARN: Using your go.mod instead of our generated version -- this may misbehave!\n\t\tEOF\n\t} >&2\nelse\n\tset -x\n\n\ttee \"${ROOTDIR}/go.mod\" >&2 <<- EOF\n\t\tmodule github.com/docker/docker\n\n\t\tgo 1.23.0\n\tEOF\n\ttrap 'rm -f \"${ROOTDIR}/go.mod\"' EXIT\nfi\n\nGO111MODULE=on GOTOOLCHAIN=local \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/with-go-mod.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for system service management", "completion": "```bash\n#!/bin/sh\nset -eu\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types --skip-validator -C api/swagger-gen.yaml \\\n\t-n ErrorResponse \\\n\t-n Plugin \\\n\t-n PluginDevice \\\n\t-n PluginMount \\\n\t-n PluginEnv \\\n\t-n PluginInterfaceType\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/common --skip-validator -C api/swagger-gen.yaml \\\n\t-n IDResponse\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/storage --skip-validator -C api/swagger-gen.yaml \\\n\t-n DriverData\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/container --skip-validator -C api/swagger-gen.yaml \\\n\t-n ContainerCreateResponse \\\n\t-n ContainerUpdateResponse \\\n\t-n ContainerTopResponse \\\n\t-n ContainerWaitResponse \\\n\t-n ContainerWaitExitError \\\n\t-n ChangeType \\\n\t-n FilesystemChange \\\n\t-n Port\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/image --skip-validator -C api/swagger-gen.yaml \\\n\t-n ImageDeleteResponseItem\n#-n ImageSummary TODO: Restore when go-swagger is updated\n# See https://github.com/moby/moby/pull/47526#discussion_r1551800022\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/network --skip-validator -C api/swagger-gen.yaml \\\n\t-n NetworkCreateResponse\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/volume --skip-validator -C api/swagger-gen.yaml \\\n\t-n Volume \\\n\t-n VolumeCreateOptions \\\n\t-n VolumeListResponse\n\nswagger generate operation -f api/swagger.yaml \\\n\t-t api -a types -m types -C api/swagger-gen.yaml \\\n\t-T api/templates --skip-responses --skip-parameters --skip-validator \\\n\t-n Authenticate \\\n\t-n ImageHistory\n\nswagger generate model -f api/swagger.yaml \\\n\t-t api -m types/swarm --skip-validator -C api/swagger-gen.yaml \\\n\t-n ServiceCreateResponse \\\n\t-n ServiceUpdateResponse\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/generate-swagger-api.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\nset -e\n\n# This script builds various binary artifacts from a checkout of the docker\n# source code.\n#\n# Requirements:\n# - The current directory should be a checkout of the docker source code\n#   (https://github.com/docker/docker). Whatever version is checked out\n#   will be built.\n# - The VERSION file, at the root of the repository, should exist, and\n#   will be used as Docker binary version and package version.\n# - The hash of the git commit will also be included in the Docker binary,\n#   with the suffix -unsupported if the repository isn't clean.\n# - The script is intended to be run inside the docker container specified\n#   in the Dockerfile at the root of the source. In other words:\n#   DO NOT CALL THIS SCRIPT DIRECTLY.\n# - The right way to call this script is to invoke \"make\" from\n#   your checkout of the Docker repository.\n#   the Makefile will do a \"docker build -t docker .\" and then\n#   \"docker run hack/make.sh\" in the resulting image.\n#\n\nset -o pipefail\n\nexport DOCKER_PKG='github.com/docker/docker'\nexport SCRIPTDIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nexport MAKEDIR=\"$SCRIPTDIR/make\"\nexport PKG_CONFIG=${PKG_CONFIG:-pkg-config}\n\necho\n\n# List of bundles to create when no argument is passed\nDEFAULT_BUNDLES=(\n\tbinary-daemon\n\tdynbinary\n\ttest-integration\n\ttest-docker-py\n)\n\nVERSION=${VERSION:-dev}\ncase \"$VERSION\" in\n\trefs/tags/v*) VERSION=${VERSION#refs/tags/v} ;;\n\trefs/tags/*) VERSION=${VERSION#refs/tags/} ;;\n\trefs/heads/*) VERSION=$(echo \"${VERSION#refs/heads/}\" | sed -r 's#/+#-#g') ;;\n\trefs/pull/*) VERSION=pr-$(echo \"$VERSION\" | grep -o '[0-9]\\+') ;;\nesac\n\n! BUILDTIME=$(date -u -d \"@${SOURCE_DATE_EPOCH:-$(date +%s)}\" --rfc-3339 ns 2> /dev/null | sed -e 's/ /T/')\nif [ \"$DOCKER_GITCOMMIT\" ]; then\n\tGITCOMMIT=\"$DOCKER_GITCOMMIT\"\nelif command -v git &> /dev/null && [ -e .git ] && git rev-parse &> /dev/null; then\n\tGITCOMMIT=$(git rev-parse HEAD)\n\tif [ -n \"$(git status --porcelain --untracked-files=no)\" ]; then\n\t\tGITCOMMIT=\"$GITCOMMIT-unsupported\"\n\t\techo \"#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\t\techo \"# GITCOMMIT = $GITCOMMIT\"\n\t\techo \"# The version you are building is listed as unsupported because\"\n\t\techo \"# there are some files in the git repository that are in an uncommitted state.\"\n\t\techo \"# Commit these changes, or add to .gitignore to remove the -unsupported from the version.\"\n\t\techo \"# Here is the current list:\"\n\t\tgit status --porcelain --untracked-files=no\n\t\techo \"#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\tfi\nelse\n\techo >&2 'error: .git directory missing and DOCKER_GITCOMMIT not specified'\n\techo >&2 '  Please either build with the .git directory accessible, or specify the'\n\techo >&2 '  exact commit hash you are building using DOCKER_GITCOMMIT for future'\n\techo >&2 '  accountability in diagnosing build issues.  Thanks!'\n\texit 1\nfi\n\nif [ \"$AUTO_GOPATH\" ]; then\n\trm -rf .gopath\n\tmkdir -p .gopath/src/\"$(dirname \"${DOCKER_PKG}\")\"\n\tln -sf ../../../.. .gopath/src/\"${DOCKER_PKG}\"\n\texport GOPATH=\"${PWD}/.gopath\"\nfi\n\nif [ -z \"${EXCLUDE_AUTO_BUILDTAG_JOURNALD:-}\" ] && ${PKG_CONFIG} 'libsystemd' 2> /dev/null; then\n\tDOCKER_BUILDTAGS+=\" journald\"\nfi\n\n# Use these flags when compiling the tests and final binary\n\nif [ -z \"$DOCKER_DEBUG\" ]; then\n\tLDFLAGS='-w'\nfi\n\nBUILDFLAGS=(${BUILDFLAGS} -tags \"netgo osusergo static_build $DOCKER_BUILDTAGS\")\nLDFLAGS_STATIC=\"-extldflags -static\"\n\nif [ \"$(uname -s)\" = 'FreeBSD' ]; then\n\t# Tell cgo the compiler is Clang, not GCC\n\t# https://code.google.com/p/go/source/browse/src/cmd/cgo/gcc.go?spec=svne77e74371f2340ee08622ce602e9f7b15f29d8d3&r=e6794866ebeba2bf8818b9261b54e2eef1c9e588#752\n\texport CC=clang\n\n\t# \"-extld clang\" is a workaround for\n\t# https://code.google.com/p/go/issues/detail?id=6845\n\tLDFLAGS=\"$LDFLAGS -extld clang\"\nfi\n\nbundle() {\n\tlocal bundle=\"$1\"\n\tshift\n\techo \"---> Making bundle: $(basename \"$bundle\") (in $DEST)\"\n\tsource \"$SCRIPTDIR/make/$bundle\" \"$@\"\n}\n\nmain() {\n\tbundle_dir=\"bundles\"\n\tif [ -n \"${PREFIX}\" ]; then\n\t\tbundle_dir=\"${PREFIX}/${bundle_dir}\"\n\tfi\n\n\tif [ -z \"${KEEPBUNDLE-}\" ]; then\n\t\techo \"Removing ${bundle_dir}/\"\n\t\trm -rf \"${bundle_dir}\"/*\n\t\techo\n\tfi\n\tmkdir -p \"${bundle_dir}\"\n\n\tif [ $# -lt 1 ]; then\n\t\tbundles=(${DEFAULT_BUNDLES[@]})\n\telse\n\t\tbundles=($@)\n\tfi\n\tfor bundle in ${bundles[@]}; do\n\t\texport DEST=\"${bundle_dir}/$(basename \"$bundle\")\"\n\t\t# Cygdrive paths don't play well with go build -o.\n\t\tif [[ \"$(uname -s)\" == CYGWIN* ]]; then\n\t\t\texport DEST=\"$(cygpath -mw \"$DEST\")\"\n\t\tfi\n\t\tmkdir -p \"$DEST\"\n\t\tABS_DEST=\"$(cd \"$DEST\" && pwd -P)\"\n\t\tbundle \"$bundle\"\n\t\techo\n\tdone\n}\n\nmain \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/make.sh", "category": "containerization", "authentic": true}}
{"prompt": "Write a shell script for system installation and setup", "completion": "```bash\n#!/bin/bash\n\nset -e\nset -x\n\nRM_GOPATH=0\n\nTMP_GOPATH=${TMP_GOPATH:-\"\"}\n\n: ${PREFIX:=\"/usr/local/bin\"}\n\nif [ -z \"$TMP_GOPATH\" ]; then\n\texport GOPATH=\"$(mktemp -d)\"\n\tRM_GOPATH=1\nelse\n\texport GOPATH=\"$TMP_GOPATH\"\nfi\ncase \"$(go env GOARCH)\" in\n\tmips* | ppc64)\n\t\t# pie build mode is not supported on mips architectures\n\t\texport GO_BUILDMODE=\"\"\n\t\t;;\n\t*)\n\t\texport GO_BUILDMODE=\"-buildmode=pie\"\n\t\t;;\nesac\n\ndir=\"$(dirname $0)\"\n\nbin=$1\nshift\n\nif [ ! -f \"${dir}/${bin}.installer\" ]; then\n\techo \"Could not find installer for \\\"$bin\\\"\"\n\texit 1\nfi\n\n. ${dir}/${bin}.installer\ninstall_${bin} \"$@\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/dockerfile/install/install.sh", "category": "infrastructure", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/sh\n\nset -e\nversion=\"$1\"\nrepository=\"$2\"\noutdir=\"$3\"\n\nDOWNLOAD_URL=\"https://download.docker.com/linux/static/stable/$(xx-info march)/docker-${version#v}.tgz\"\n\nmkdir \"$outdir\"\nif curl --head --silent --fail \"${DOWNLOAD_URL}\" 1> /dev/null 2>&1; then\n\tcurl -fsSL \"${DOWNLOAD_URL}\" | tar -xz docker/docker\n\tmv docker/docker \"${outdir}/docker\"\nelse\n\tgit init -q .\n\tgit remote remove origin 2> /dev/null || true\n\tgit remote add origin \"${repository}\"\n\tgit fetch -q --depth 1 origin \"${version}\" +refs/tags/*:refs/tags/*\n\tgit checkout -fq \"${version}\"\n\tif [ -d ./components/cli ]; then\n\t\tmv ./components/cli/* ./\n\t\tCGO_ENABLED=0 xx-go build -o \"${outdir}/docker\" ./cmd/docker\n\t\tgit reset --hard \"${version}\"\n\telse\n\t\txx-go --wrap && CGO_ENABLED=0 TARGET=\"${outdir}\" ./scripts/build/binary\n\tfi\nfi\n\nxx-verify \"${outdir}/docker\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/docker/hack/dockerfile/cli.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for Git workflow automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n# This repository contains one logical codebase but as an implementation detail\n# it's split into multiple modules at the boundaries of code ownership, so\n# that we can keep track of which dependency changes might affect which\n# components.\n#\n# This script runs \"go mod tidy\" in each module to synchronize any dependency\n# updates that were made in any one of the modules.\n\nset -eufo pipefail\n\n# We'll do our work in the root of the repository, which is the parent\n# directory of where this script is.\ncd \"$( dirname \"${BASH_SOURCE[0]}\" )/..\"\n\n# We need to make sure the root go.mod is synchronized first, because otherwise\n# the \"go list\" command below might fail.\ngo mod tidy\n\n# Each of the modules starting at our root gets its go.mod and go.sum\n# synchronized, so that we can see which components are affected by an\n# update and therefore which codeowners might be interested in the change.\nfor dir in $(go list -m -f '{{.Dir}}' github.com/hashicorp/terraform/...); do\n    (cd $dir && go mod tidy)\ndone\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/scripts/syncdeps.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Create a shell script for Git workflow automation", "completion": "```bash\n#!/bin/bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n\n# This script rewrites [GH-nnnn]-style references in the CHANGELOG.md file to\n# be Markdown links to the given github issues.\n#\n# This is run during releases so that the issue references in all of the\n# released items are presented as clickable links, but we can just use the\n# easy [GH-nnnn] shorthand for quickly adding items to the \"Unrelease\" section\n# while merging things between releases.\n\nset -e\n\nif [[ ! -f CHANGELOG.md ]]; then\n  echo \"ERROR: CHANGELOG.md not found in pwd.\"\n  echo \"Please run this from the root of the terraform source repository\"\n  exit 1\nfi\n\nif [[ `uname` == \"Darwin\" ]]; then\n  echo \"Using BSD sed\"\n  SED=\"sed -i.bak -E -e\"\nelse\n  echo \"Using GNU sed\"\n  SED=\"sed -i.bak -r -e\"\nfi\n\n$SED 's/GH-([0-9]+)/\\[#\\1\\]\\(https:\\/\\/github.com\\/hashicorp\\/terraform\\/issues\\/\\1\\)/g' -e 's/\\[\\[#(.+)([0-9])\\)]$/(\\[#\\1\\2))/g' CHANGELOG.md\n\nrm CHANGELOG.md.bak\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/scripts/changelog-links.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n#\n# This script builds the application from source for multiple platforms.\n\n# Get the parent directory of where this script is.\nSOURCE=\"${BASH_SOURCE[0]}\"\nwhile [ -h \"$SOURCE\" ] ; do SOURCE=\"$(readlink \"$SOURCE\")\"; done\nDIR=\"$( cd -P \"$( dirname \"$SOURCE\" )/..\" && pwd )\"\n\n# Change into that directory\ncd \"$DIR\" || exit\n\n# Determine the arch/os combos we're building for\nXC_ARCH=${XC_ARCH:-\"386 amd64 arm\"}\nXC_OS=${XC_OS:-linux darwin windows freebsd openbsd solaris}\nXC_EXCLUDE_OSARCH=\"!darwin/arm !darwin/386\"\n\n# Delete the old dir\necho \"==> Removing old directory...\"\nrm -f bin/*\nrm -rf pkg/*\nmkdir -p bin/\n\n# If its dev mode, only build for ourself\nif [[ -n \"${TF_DEV}\" ]]; then\n    XC_OS=$(go env GOOS)\n    XC_ARCH=$(go env GOARCH)\nfi\n\nif ! which gox > /dev/null; then\n    echo \"==> Installing gox...\"\n    go install github.com/mitchellh/gox\nfi\n\n# Instruct gox to build statically linked binaries\nexport CGO_ENABLED=0\n\n# Set module download mode to readonly to not implicitly update go.mod\nexport GOFLAGS=\"-mod=readonly\"\n\n# In release mode we don't want debug information in the binary and we don't\n# want the -dev version marker\nif [[ -n \"${TF_RELEASE}\" ]]; then\n    LD_FLAGS=\"-s -w -X 'github.com/hashicorp/terraform/version.dev=no'\"\nfi\n\n# Ensure all remote modules are downloaded and cached before build so that\n# the concurrent builds launched by gox won't race to redundantly download them.\ngo mod download\n\n# Build!\necho \"==> Building...\"\ngox \\\n    -os=\"${XC_OS}\" \\\n    -arch=\"${XC_ARCH}\" \\\n    -osarch=\"${XC_EXCLUDE_OSARCH}\" \\\n    -ldflags \"${LD_FLAGS}\" \\\n    -output \"pkg/{{.OS}}_{{.Arch}}/terraform\" \\\n    .\n\n# Move all the compiled things to the $GOPATH/bin\nGOPATH=${GOPATH:-$(go env GOPATH)}\ncase $(uname) in\n    CYGWIN*)\n        GOPATH=\"$(cygpath $GOPATH)\"\n        ;;\nesac\nOLDIFS=$IFS\nIFS=: MAIN_GOPATH=($GOPATH)\nIFS=$OLDIFS\n\n# Create GOPATH/bin if it's doesn't exists\nif [ ! -d $MAIN_GOPATH/bin ]; then\n    echo \"==> Creating GOPATH/bin directory...\"\n    mkdir -p $MAIN_GOPATH/bin\nfi\n\n# Copy our OS/Arch to the bin/ directory\nDEV_PLATFORM=\"./pkg/$(go env GOOS)_$(go env GOARCH)\"\nif [[ -d \"${DEV_PLATFORM}\" ]]; then\n    for F in $(find ${DEV_PLATFORM} -mindepth 1 -maxdepth 1 -type f); do\n        cp ${F} bin/\n        cp ${F} ${MAIN_GOPATH}/bin/\n    done\nfi\n\nif [ \"${TF_DEV}x\" = \"x\" ]; then\n    # Zip and copy to the dist dir\n    echo \"==> Packaging...\"\n    for PLATFORM in $(find ./pkg -mindepth 1 -maxdepth 1 -type d); do\n        OSARCH=$(basename ${PLATFORM})\n        echo \"--> ${OSARCH}\"\n\n        pushd $PLATFORM >/dev/null 2>&1\n        zip ../${OSARCH}.zip ./*\n        popd >/dev/null 2>&1\n    done\nfi\n\n# Done!\necho\necho \"==> Results:\"\nls -hl bin/\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/scripts/build.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n\nset -uo pipefail\n\nCHANGIE_VERSION=\"${CHANGIE_VERSION:-1.21.0}\"\nSEMVER_VERSION=\"${SEMVER_VERSION:-7.6.3}\"\n\nfunction usage {\n  cat <<-'EOF'\nUsage: ./changelog.sh <command> [<options>]\n\nDescription:\n  This script will update CHANGELOG.md with the given version and date and add the changelog entries.\n  It will also set the version/VERSION file to the correct version.\n  In general this script should handle most release related tasks within this repository.\n\nCommands:\n  generate <release-type>\n    generate will create a new section in the CHANGELOG.md file for the given release\n    type. The release type should be one of \"dev\", \"alpha\", \"rc\", \"release\", or \"patch\".\n    `dev`: will update the changelog with the latest unreleased changes.\n    `alpha`: will generate a new section with an alpha version for today.\n    `beta`: will generate a new beta release.\n    `rc`: will generate a new rc release.\n    `release`: will make the initial minor release for this branch.\n    `patch`: will generate a new patch release\n\n  nextminor:\n    Run on main branch: Updates the minor version.\n\n  listIssuesInRelease:\n    Lists all issues in the release passed as an argument.\nEOF\n}\n\nfunction generate {\n    RELEASE_TYPE=\"${1:-}\"\n\n    if [[ -z \"$RELEASE_TYPE\" ]]; then\n        echo \"missing <release-type> argument\"\n        usage\n        exit 1\n    fi\n\n    FOOTER_FILE='footer.md'\n\n    case \"$RELEASE_TYPE\" in\n\n        dev)\n        FOOTER_FILE='footer-with-experiments.md'\n        LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n\n        # Check if we already released this version already\n        if git tag -l \"v$LATEST_VERSION\" | grep -q \"v$LATEST_VERSION\"; then\n            LATEST_VERSION=$(npx -y semver@$SEMVER_VERSION -i patch $LATEST_VERSION)\n        fi\n\n        COMPLETE_VERSION=\"$LATEST_VERSION-dev\"\n\n        npx -y changie@$CHANGIE_VERSION merge -u \"## $LATEST_VERSION (Unreleased)\"\n\n        # If we have no changes yet, the changelog is empty now, so we need to add a header\n        if ! grep -q \"## $LATEST_VERSION\" CHANGELOG.md; then\n            CURRENT_CHANGELOG=$(cat CHANGELOG.md)\n            echo \"## $LATEST_VERSION (Unreleased)\" > CHANGELOG.md\n            echo \"\" >> CHANGELOG.md\n            echo \"$CURRENT_CHANGELOG\" >> CHANGELOG.md\n        fi\n        ;;\n\n        alpha)\n        FOOTER_FILE='footer-with-experiments.md'\n        PRERELEASE_VERSION=$(date +\"alpha%Y%m%d\")\n        LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n        HUMAN_DATE=$(date +\"%B %d, %Y\") # Date in Janurary 1st, 2022 format\n        COMPLETE_VERSION=\"$LATEST_VERSION-$PRERELEASE_VERSION\"\n\n        npx -y changie@$CHANGIE_VERSION merge -u \"## $COMPLETE_VERSION ($HUMAN_DATE)\"\n        ;;\n\n        beta)\n        LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n        # We need to check if this is the first RC of the version\n        BETA_NUMBER=$(git tag -l \"v$LATEST_VERSION-beta*\" | wc -l)\n        BETA_NUMBER=$((BETA_NUMBER + 1))\n        HUMAN_DATE=$(date +\"%B %d, %Y\") # Date in Janurary 1st, 2022 format\n        COMPLETE_VERSION=\"$LATEST_VERSION-beta$BETA_NUMBER\"\n\n        npx -y changie@$CHANGIE_VERSION merge -u \"## $COMPLETE_VERSION ($HUMAN_DATE)\"\n        ;;\n\n        rc)\n        LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n        # We need to check if this is the first RC of the version\n        RC_NUMBER=$(git tag -l \"v$LATEST_VERSION-rc*\" | wc -l)\n        RC_NUMBER=$((RC_NUMBER + 1))\n        HUMAN_DATE=$(date +\"%B %d, %Y\") # Date in Janurary 1st, 2022 format\n        COMPLETE_VERSION=\"$LATEST_VERSION-rc$RC_NUMBER\"\n\n        npx -y changie@$CHANGIE_VERSION merge -u \"## $COMPLETE_VERSION ($HUMAN_DATE)\"\n        ;;\n\n        patch)\n        COMPLETE_VERSION=$(npx -y changie@$CHANGIE_VERSION next patch)\n        npx -y changie@$CHANGIE_VERSION batch patch\n        npx -y changie@$CHANGIE_VERSION merge\n        ;;\n\n        release)\n        # This is the first release of the branch, releasing the new minor version\n        COMPLETE_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n        # We currently keep a file that looks like this release to ensure the alphas and dev versions are generated correctly\n        rm ./.changes/$COMPLETE_VERSION.md\n\n        npx -y changie@$CHANGIE_VERSION batch $COMPLETE_VERSION\n        npx -y changie@$CHANGIE_VERSION merge\n        ;;\n\n        *)\n        echo \"invalid <release-type> argument\"\n        usage\n        exit 1\n\n        ;;\n    esac\n\n    # Set version/VERSION to the to be released version\n    echo \"$COMPLETE_VERSION\" > version/VERSION\n\n    # Add footer to the changelog\n    cat ./.changes/$FOOTER_FILE >> CHANGELOG.md\n    echo \"\" >> CHANGELOG.md\n    cat ./.changes/previous-releases.md >> CHANGELOG.md\n}\n\n# This function expects the current branch to be main. Run it if you want to set main to the next\n# minor version.\nfunction nextminor {\n    # Prepend the latest version to the previous releases\n    LATEST_VERSION=$(npx -y changie@$CHANGIE_VERSION latest -r --skip-prereleases)\n    LATEST_VERSION=${LATEST_VERSION%.*} # Remove the patch version\n    CURRENT_FILE_CONTENT=$(cat ./.changes/previous-releases.md)\n    echo \"- [v$LATEST_VERSION](https://github.com/hashicorp/terraform/blob/v$LATEST_VERSION/CHANGELOG.md)\" > ./.changes/previous-releases.md\n    echo \"$CURRENT_FILE_CONTENT\" >> ./.changes/previous-releases.md\n\n    NEXT_VERSION=$(npx -y changie@$CHANGIE_VERSION next minor)\n    # Remove all existing per-release changelogs\n    rm ./.changes/*.*.*.md\n\n    # Remove all old changelog entries\n    rm ./.changes/v*/*.yaml\n\n\n\n    # Create a new empty version file for the next minor version\n    touch ./.changes/$NEXT_VERSION.md\n\n    LATEST_MAJOR_MINOR=$(echo $LATEST_VERSION | awk -F. '{print $1\".\"$2}')\n    NEXT_MAJOR_MINOR=$(echo $NEXT_VERSION | awk -F. '{print $1\".\"$2}')\n\n    # Create a new changes directory for the next minor version\n    mkdir ./.changes/v$NEXT_MAJOR_MINOR\n    touch ./.changes/v$NEXT_MAJOR_MINOR/.gitkeep\n\n    # Set changies changes dir to the new version\n    awk \"{sub(/unreleasedDir: v$LATEST_MAJOR_MINOR/, \\\"unreleasedDir: v$NEXT_MAJOR_MINOR\\\")}1\" ./.changie.yaml > temp && mv temp ./.changie.yaml\n    generate \"dev\"\n}\n\nfunction listIssuesInRelease() {\n    RELEASE_MAJOR_MINOR=\"${1:-}\"\n    if [ -z \"$RELEASE_MAJOR_MINOR\" ]; then\n        echo \"No release version specified\"\n        exit 1\n    fi\n\n    # Check if yq is installed\n    if ! command -v yq &> /dev/null; then\n        echo \"yq could not be found\"\n        exit 1\n    fi\n\n    echo \"Listing issues in release $RELEASE_MAJOR_MINOR\"\n    # Loop through files in .changes/v$RELEASE_MAJOR_MINOR\n    for file in ./.changes/v$RELEASE_MAJOR_MINOR/*.yaml; do\n        ISSUE=$(cat \"$file\" | yq '.custom.Issue')\n        echo \"- https://github.com/hashicorp/terraform/issues/$ISSUE\"\n    done\n}\n\nfunction main {\n  case \"$1\" in\n    generate)\n    generate \"${@:2}\"\n      ;;\n\n    nextminor)\n    nextminor \"${@:2}\"\n      ;;\n\n    listIssuesInRelease)\n    listIssuesInRelease \"${@:2}\"\n      ;;\n\n    *)\n      usage\n      exit 1\n\n      ;;\n  esac\n}\n\nmain \"$@\"\nexit $?\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/scripts/changelog.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n\n# For normal use this package can just be tested with \"go test\" as standard,\n# but this script is an alternative to allow the tests to be run somewhere\n# other than where they are built.\n\n# The primary use for this is cross-compilation, where e.g. we can produce an\n# archive that can be extracted on a Windows system to run the e2e tests there:\n#    $ GOOS=windows GOARCH=amd64 ./make-archive.sh\n#\n# This will produce a zip file build/terraform-e2etest_windows_amd64.zip which\n# can be shipped off to a Windows amd64 system, extracted to some directory,\n# and then executed as follows:\n#    set TF_ACC=1\n#    ./e2etest.exe\n#\n# Because separated e2etest harnesses are intended for testing against \"real\"\n# release executables, the generated archives don't include a copy of\n# the Terraform executable. Instead, the caller of the tests must retrieve\n# and extract a release package into the working directory before running\n# the e2etest executable, so that \"e2etest\" can find and execute it.\n\nset +euo pipefail\n\n# Always run from the directory where this script lives\ncd \"$( dirname \"${BASH_SOURCE[0]}\" )\"\n\nGOOS=\"$(go env GOOS)\"\nGOARCH=\"$(go env GOARCH)\"\nGOEXE=\"$(go env GOEXE)\"\nOUTDIR=\"build/${GOOS}_${GOARCH}\"\nOUTFILE=\"terraform-e2etest_${GOOS}_${GOARCH}.zip\"\n\nLDFLAGS=\"-X github.com/hashicorp/terraform/internal/command/e2etest.terraformBin=./terraform$GOEXE\"\n# Caller may pass in the environment variable GO_LDFLAGS with additional\n# flags we'll use when building.\nif [ -n \"${GO_LDFLAGS+set}\" ]; then\n    LDFLAGS=\"${GO_LDFLAGS} ${LDFLAGS}\"\nfi\n\nmkdir -p \"$OUTDIR\"\n\n# We need the test fixtures available when we run the tests.\ncp -r testdata \"$OUTDIR/testdata\"\n\n# Build the test program\ngo test -o \"$OUTDIR/e2etest$GOEXE\" -c -ldflags \"$LDFLAGS\" github.com/hashicorp/terraform/internal/command/e2etest\n\n# Now bundle it all together for easy shipping!\ncd \"$OUTDIR\"\nzip -r \"../$OUTFILE\" *\n\necho \"e2etest archive created at build/$OUTFILE\"\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/internal/command/e2etest/make-archive.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n\n######################################################\n# NOTE: This file is managed by the Digital Team's   #\n# Terraform configuration @ hashicorp/mktg-terraform #\n######################################################\n\n# This is run during the website build step to determine if we should skip the build or not.\n# More information: https://vercel.com/docs/platform/projects#ignored-build-step\n\nif [[ \"$VERCEL_GIT_COMMIT_REF\" == \"stable-website\"  ]] ; then\n  # Proceed with the build if the branch is stable-website\n  echo \"✅ - Build can proceed\"\n  exit 1;\nelse\n  # Check for differences in the website directory\n  git diff --quiet HEAD^ HEAD ./\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/website/scripts/should-build.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for application deployment", "completion": "```bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n######################################################\n# NOTE: This file is managed by the Digital Team's   #\n# Terraform configuration @ hashicorp/mktg-terraform #\n######################################################\n\n# Repo which we are cloning and executing npm run build:deploy-preview within\nREPO_TO_CLONE=dev-portal\n# Set the subdirectory name for the dev-portal app\nPREVIEW_DIR=website-preview\n# The product for which we are building the deploy preview\nPRODUCT=terraform\n# Preview mode, controls the UI rendered (either the product site or developer). Can be `io` or `developer`\nPREVIEW_MODE=developer\n\n# Get the git branch of the commit that triggered the deploy preview\n# This will power remote image assets in local and deploy previews\nCURRENT_GIT_BRANCH=$(git rev-parse --abbrev-ref HEAD)\n\n# This is where content files live, relative to the website-preview dir. If omitted, \"../content\" will be used\nLOCAL_CONTENT_DIR=../docs\n\nshould_pull=true\n\n# Clone the dev-portal project, if needed\nif [ ! -d \"$PREVIEW_DIR\" ]; then\n    echo \"⏳ Cloning the $REPO_TO_CLONE repo, this might take a while...\"\n    git clone --depth=1 https://github.com/hashicorp/$REPO_TO_CLONE.git \"$PREVIEW_DIR\"\n    should_pull=false\nfi\n\ncd \"$PREVIEW_DIR\"\n\n# If the directory already existed, pull to ensure the clone is fresh\nif [ \"$should_pull\" = true ]; then\n    git pull origin main\nfi\n\n# Run the dev-portal content-repo start script\nREPO=$PRODUCT \\\nPREVIEW_FROM_REPO=$PRODUCT \\\nLOCAL_CONTENT_DIR=$LOCAL_CONTENT_DIR \\\nCURRENT_GIT_BRANCH=$CURRENT_GIT_BRANCH \\\nPREVIEW_MODE=$PREVIEW_MODE \\\nnpm run start:local-preview\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/website/scripts/website-start.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for application deployment", "completion": "```bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n######################################################\n# NOTE: This file is managed by the Digital Team's   #\n# Terraform configuration @ hashicorp/mktg-terraform #\n######################################################\n\n# Repo which we are cloning and executing npm run build:deploy-preview within\nREPO_TO_CLONE=dev-portal\n# Set the subdirectory name for the base project\nPREVIEW_DIR=website-preview\n# The directory we want to clone the project into\nCLONE_DIR=website-preview\n# The product for which we are building the deploy preview\nPRODUCT=terraform\n# Preview mode, controls the UI rendered (either the product site or developer). Can be `io` or `developer`\nPREVIEW_MODE=developer\n\n# Get the git branch of the commit that triggered the deploy preview\n# This will power remote image assets in local and deploy previews\nCURRENT_GIT_BRANCH=$VERCEL_GIT_COMMIT_REF\n\n# This is where content files live, relative to the website-preview dir. If omitted, \"../content\" will be used\nLOCAL_CONTENT_DIR=../docs\n\nfrom_cache=false\n\nif [ -d \"$PREVIEW_DIR\" ]; then\n  echo \"$PREVIEW_DIR found\"\n  CLONE_DIR=\"$PREVIEW_DIR-tmp\"\n  from_cache=true\nfi\n\n# Clone the base project, if needed\necho \"⏳ Cloning the $REPO_TO_CLONE repo, this might take a while...\"\ngit clone --depth=1 \"https://github.com/hashicorp/$REPO_TO_CLONE.git\" \"$CLONE_DIR\"\n\nif [ \"$from_cache\" = true ]; then\n  echo \"Setting up $PREVIEW_DIR\"\n  cp -R \"./$CLONE_DIR/.\" \"./$PREVIEW_DIR\"\nfi\n\n# cd into the preview directory project\ncd \"$PREVIEW_DIR\"\n\n# Run the build:deploy-preview start script\nPREVIEW_FROM_REPO=$PRODUCT \\\nIS_CONTENT_PREVIEW=true \\\nPREVIEW_MODE=$PREVIEW_MODE \\\nREPO=$PRODUCT \\\nHASHI_ENV=project-preview \\\nLOCAL_CONTENT_DIR=$LOCAL_CONTENT_DIR \\\nCURRENT_GIT_BRANCH=$CURRENT_GIT_BRANCH \\\nnpm run build:deploy-preview\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/website/scripts/website-build.sh", "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\nset -uo pipefail\n\nfunction usage {\n  cat <<-'EOF'\nUsage: ./equivalence-test.sh <command> [<args>] [<options>]\n\nDescription:\n  This script will handle various commands related to the execution of the\n  Terraform equivalence tests.\n\nCommands:\n  get_target_branch <version>\n    get_target_branch returns the default target branch for a given Terraform\n    version.\n\n    target_branch=$(./equivalence-test.sh get_target_branch v1.4.3); target_branch=v1.4\n    target_branch=$(./equivalence-test.sh get_target_branch 1.4.3); target_branch=v1.4\n\n  download_equivalence_test_binary <version> <target> <os> <arch>\n    download_equivalence_test_binary downloads the equivalence testing binary\n    for a given version and places it at the target path.\n\n    ./equivalence-test.sh download_equivalence_test_binary 0.3.0 ./bin/terraform-equivalence-testing linux amd64\n\n  build_terraform_binary <target>\n    download_terraform_binary builds the Terraform binary and places it at the\n    target path.\n\n    ./equivalence-test.sh build_terraform_binary ./bin/terraform\nEOF\n}\n\nfunction download_equivalence_test_binary {\n  VERSION=\"${1:-}\"\n  TARGET=\"${2:-}\"\n  OS=\"${3:-}\"\n  ARCH=\"${4:-}\"\n\n  if [[ -z \"$VERSION\" || -z \"$TARGET\" || -z \"$OS\" || -z \"$ARCH\" ]]; then\n    echo \"missing at least one of [<version>, <target>, <os>, <arch>] arguments\"\n    usage\n    exit 1\n  fi\n\n  curl \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"https://api.github.com/repos/hashicorp/terraform-equivalence-testing/releases\" > releases.json\n\n  ASSET=\"terraform-equivalence-testing_v${VERSION}_${OS}_${ARCH}.zip\"\n  ASSET_ID=$(jq -r --arg VERSION \"v$VERSION\" --arg ASSET \"$ASSET\" '.[] | select(.name == $VERSION) | .assets[] | select(.name == $ASSET) | .id' releases.json)\n\n  mkdir -p zip\n  curl -L \\\n    -H \"Accept: application/octet-stream\" \\\n    \"https://api.github.com/repos/hashicorp/terraform-equivalence-testing/releases/assets/$ASSET_ID\" > \"zip/$ASSET\"\n\n  mkdir -p bin\n  unzip -p \"zip/$ASSET\" terraform-equivalence-testing > \"$TARGET\"\n  chmod u+x \"$TARGET\"\n  rm -r zip\n  rm releases.json\n}\n\nfunction build_terraform_binary {\n  TARGET=\"${1:-}\"\n\n  if [[ -z \"$TARGET\" ]]; then\n    echo \"target argument\"\n    usage\n    exit 1\n  fi\n\n  go build -o \"$TARGET\" ./\n  chmod u+x \"$TARGET\"\n}\n\nfunction get_target_branch {\n  VERSION=\"${1:-}\"\n\n  if [ -z \"$VERSION\" ]; then\n    echo \"missing <version> argument\"\n    usage\n    exit 1\n  fi\n\n\n  # Split off the build metadata part, if any\n  # (we won't actually include it in our final version, and handle it only for\n  # completeness against semver syntax.)\n  IFS='+' read -ra VERSION BUILD_META <<< \"$VERSION\"\n\n  # Separate out the prerelease part, if any\n  IFS='-' read -r BASE_VERSION PRERELEASE <<< \"$VERSION\"\n\n  # Separate out major, minor and patch versions.\n  IFS='.' read -r MAJOR_VERSION MINOR_VERSION PATCH_VERSION <<< \"$BASE_VERSION\"\n\n  if [[ \"$PRERELEASE\" == *\"alpha\"* ]]; then\n    TARGET_BRANCH=main\n  else\n    if [[ $MAJOR_VERSION = v* ]]; then\n      TARGET_BRANCH=${MAJOR_VERSION}.${MINOR_VERSION}\n    else\n      TARGET_BRANCH=v${MAJOR_VERSION}.${MINOR_VERSION}\n    fi\n  fi\n\n  echo \"$TARGET_BRANCH\"\n}\n\nfunction main {\n  case \"$1\" in\n    get_target_branch)\n      if [ \"${#@}\" != 2 ]; then\n        echo \"invalid number of arguments\"\n        usage\n        exit 1\n      fi\n\n      get_target_branch \"$2\"\n\n      ;;\n    download_equivalence_test_binary)\n      if [ \"${#@}\" != 5 ]; then\n        echo \"invalid number of arguments\"\n        usage\n        exit 1\n      fi\n\n      download_equivalence_test_binary \"$2\" \"$3\" \"$4\" \"$5\"\n\n      ;;\n    build_terraform_binary)\n      if [ \"${#@}\" != 2 ]; then\n        echo \"invalid number of arguments\"\n        usage\n        exit 1\n      fi\n\n      build_terraform_binary \"$2\"\n\n      ;;\n    *)\n      echo \"unrecognized command $*\"\n      usage\n      exit 1\n\n      ;;\n  esac\n}\n\nmain \"$@\"\nexit $?\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/.github/scripts/equivalence-test.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\nset -uo pipefail\n\nif [[ $arch == 'arm' || $arch == 'arm64' ]]\nthen\n    export DIR=$(mktemp -d)\n    unzip -d $DIR \"${e2e_cache_path}/terraform-e2etest_${os}_${arch}.zip\"\n    unzip -d $DIR \"./terraform_${version}_${os}_${arch}.zip\"\n    sudo chmod +x $DIR/e2etest\n    docker run --platform=linux/arm64 -v $DIR:/src -w /src arm64v8/alpine ./e2etest -test.v\nelse\n    unzip \"${e2e_cache_path}/terraform-e2etest_${os}_${arch}.zip\"\n    unzip \"./terraform_${version}_${os}_${arch}.zip\"\n    TF_ACC=1 ./e2etest -test.v\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmp30511jgu/terraform/.github/scripts/e2e_test_linux_darwin.sh", "category": "containerization", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/bash\n#\n# Review the cron tasks defined in the system and warn the admin\n# if some of the files will not be run\n#\n# This program is copyright 2011 by Javier Fernandez-Sanguino <<EMAIL>>\n#\n#    This program is free software; you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation; either version 2 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program; if not, write to the Free Software\n#    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n#\n# For more information please see\n#  http://www.gnu.org/licenses/licenses.html#GPL\n\n\nset -e\n# reset locale, just in case\nLC_ALL=C\nexport LC_ALL\n\nPROGNAME=${0##*/}\nPROGVERSION=1.0\n# Command line options\nSHORTOPTS=hvsi\nLONGOPTS=help,version,syslog,info\nset -- $(getopt -s bash -o $SHORTOPTS -l $LONGOPTS --n $PROGNAME -- \"$@\")\n\nversion () {\n  echo \"$PROGNAME $PROGVERSION\"\n  echo \"$PROGNAME is copyright © Javier Fernandez-Sanguino <<EMAIL>>\"\n  echo \"Released under the terms of the GPL version 2 or later\"\n  echo \"This program is part of the cron package\"\n}\n\nusage () {\n    cat <<EOUSE\n    Usage: $PROGNAME [-si]\n\n    Reviews the directories used by cron and reports scripts that\n    might not be run by cron due to problems in their naming or\n    in their setup.\n\n    You should run this program as root to prevent false positives.\n\n    Options:\n        -s       -- Use syslog to report information\n        -i       -- Report also informational messages\nEOUSE\n}\n\nsyslog=\"no\"\nsend_info=\"no\"\nfor opt in $@; do\n    case $opt in\n        -h|--help) usage; exit 0;;\n        -v|--version) version; exit 0;;\n        -s|--syslog) syslog=\"yes\";;\n        -i|--info)   send_info=\"yes\";;\n        *)  ;;\n    esac\ndone\n\n\nsend_message () {\n\n    level=$1\n    msg=$2\n    [ \"$level\" = \"info\" ] && [ \"$send_info\" = \"no\" ] && return\n\n    if [ \"$syslog\" = \"yes\" ] ; then\n        logger -p cron.$level -t CRON $msg\n    else\n        case $level in\n            \"warn\")\n                echo \"WARN: $msg\" >&2\n                ;;\n            \"info\")\n                echo \"INFO: $msg\"\n                ;;\n        esac\n    fi\n}\n\nwarn () {\n# Send a warning to the user\n    file=$1\n    reason=$2\n\n    name=`basename $file`\n    # Skip hidden files\n    echo $name | grep -q -E '^\\.' && return\n    # Skip disabled files\n    echo $name | grep -q -E '\\.disabled' && return\n\n    # TODO: Should we send warnings for '.old' or '.orig'?\n\n    # Do not send a warning if the file is '.dpkg-old' or '.dpkg-dist'\n    if ! echo $file | grep -q -E '\\.dpkg-(old|dist)$' ; then\n        send_message \"warn\" \"The file $file will not be executed by cron: $reason\"\n    else\n        send_message \"info\" \"The file $file is a leftover from the Debian package manager\"\n    fi\n}\n\ncheck_results () {\n\n    dir=$1\n    run_file=$2\n    exec_test=$3\n\n    # Now check the files we found and the ones that exist in the directory\n    find $dir \\( -type f -o -type l \\) -printf '%p %l\\n'  |\n    while read file pointer; do\n        if ! grep -q \"^$file$\" $run_file; then\n            [ -L \"$file\" ] && [ ! -e \"$pointer\" ] && \\\n                    warn $file \"Points to an nonexistent location ($pointer)\" && continue\n            [ \"$exec_test\" = \"yes\" ]  && [ ! -x \"$file\" ] &&  \\\n                    warn $file \"Is not executable\" && continue\n            [ ! -r \"$file\" ] && [ \"`id -u`\" != \"0\" ] && \\\n                    warn $file \"Cannot read the file to determine if it will be run ($PROGNAME is not running as root)\" && continue\n            [ ! -r \"$file\" ] && \\\n                    warn $file \"File is unreadable\" && continue\n             warn $file \"Does not conform to the run-parts convention\"\n        else\n\n# do additional checks for symlinks for files that *are* listed by run-parts\n            if [ -L \"$file\" ] ; then\n# for symlinks: does the file exist?\n                if [ ! -e \"$pointer\" ] ; then\n                    warn $file \"Points to an nonexistent location ($pointer)\"\n                fi\n# for symlinks: is it owned by root?\n                 owner=`ls -l $pointer  | awk '{print $3}'`\n                 if [ \"$owner\" != \"root\" ]; then\n                       warn $file \"Is not owned by root\"\n                 fi\n            fi\n\n       fi\n    done\n\n}\n\n# Setup for the tests\n\n# First: check if we are using -l\n[ -r /etc/default/cron ] &&  . /etc/default/cron\nuse_lsb=\"no\"\n[ \"$LSBNAMES\" = \"-l\" ] && use_lsb=\"yes\"\necho $EXTRA_OPTS | grep -q -- '-l' && use_lsb=\"yes\"\n# Set the options for run parts\nrun_opts=\"\"\n[ \"$use_lsb\" = \"yes\" ] &&  run_opts=\"--lsbsysinit\"\n\ntemp=`tempfile` || { echo \"ERROR: Cannot create temporary file\" >&2 ; exit 1; }\ntrap \"rm -f $temp\" 0 1 2 3 13 15\n\n# Now review the scripts, note that cron does not use run-parts to run these\n# so they are *not* required to be executables, just to conform with the\n\n# Step 1: Review /etc/cron.d\nrun-parts $run_opts --list /etc/cron.d >$temp\ncheck_results /etc/cron.d $temp \"no\"\n\n\n# Step 2: Review /etc/cron.{hourly,daily,weekly,monthly}\n\nfor interval in hourly daily weekly monthly; do\n    testdir=/etc/cron.$interval\n    run-parts $run_opts --test $testdir >$temp\n    check_results $testdir $temp \"yes\"\ndone\n\n\nexit 0\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/cron/examples/cron-tasks-review.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for build automation", "completion": "```bash\n#!/bin/sh\n(\n\tcd ../../../t\n\ttest_description='git-credential-netrc'\n\t. ./test-lib.sh\n\n\tif ! test_have_prereq PERL; then\n\t\tskip_all='skipping perl interface tests, perl not available'\n\t\ttest_done\n\tfi\n\n\tperl -MTest::More -e 0 2>/dev/null || {\n\t\tskip_all=\"Perl Test::More unavailable, skipping test\"\n\t\ttest_done\n\t}\n\n\t# set up test repository\n\n\ttest_expect_success \\\n\t\t'set up test repository' \\\n\t\t'git config --add gpg.program test.git-config-gpg'\n\n\t# The external test will outputs its own plan\n\ttest_external_has_tap=1\n\n\texport PERL5LIB=\"$GITPERLLIB\"\n\ttest_external \\\n\t\t'git-credential-netrc' \\\n\t\tperl \"$GIT_BUILD_DIR\"/contrib/credential/netrc/test.pl\n\n\ttest_done\n)\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/credential/netrc/t-git-credential-netrc.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/sh\n\nUSAGE=\"[-a] [-r] [-m] [-t] [-n] [-b <newname>] <name>\"\nLONG_USAGE=\"git-resurrect attempts to find traces of a branch tip\ncalled <name>, and tries to resurrect it.  Currently, the reflog is\nsearched for checkout messages, and with -r also merge messages.  With\n-m and -t, the history of all refs is scanned for Merge <name> into\nother/Merge <other> into <name> (respectively) commit subjects, which\nis rather slow but allows you to resurrect other people's topic\nbranches.\"\n\nOPTIONS_KEEPDASHDASH=\nOPTIONS_STUCKLONG=\nOPTIONS_SPEC=\"\\\ngit resurrect $USAGE\n--\nb,branch=            save branch as <newname> instead of <name>\na,all                same as -l -r -m -t\nk,keep-going         full rev-list scan (instead of first match)\nl,reflog             scan reflog for checkouts (enabled by default)\nr,reflog-merges      scan for merges recorded in reflog\nm,merges             scan for merges into other branches (slow)\nt,merge-targets      scan for merges of other branches into <name>\nn,dry-run            don't recreate the branch\"\n\n. git-sh-setup\n\nsearch_reflog () {\n\tsed -ne 's~^\\([^ ]*\\) .*\tcheckout: moving from '\"$1\"' .*~\\1~p' \\\n\t\t< \"$GIT_DIR\"/logs/HEAD\n}\n\nsearch_reflog_merges () {\n\tgit rev-parse $(\n\t\tsed -ne 's~^[^ ]* \\([^ ]*\\) .*\tmerge '\"$1\"':.*~\\1^2~p' \\\n\t\t\t< \"$GIT_DIR\"/logs/HEAD\n\t)\n}\n\noid_pattern=$(git hash-object --stdin </dev/null | sed -e 's/./[0-9a-f]/g')\n\nsearch_merges () {\n\tgit rev-list --all --grep=\"Merge branch '$1'\" \\\n\t\t--pretty=tformat:\"%P %s\" |\n\tsed -ne \"/^$oid_pattern \\($oid_pattern\\) Merge .*/ {s//\\1/p;$early_exit}\"\n}\n\nsearch_merge_targets () {\n\tgit rev-list --all --grep=\"Merge branch '[^']*' into $branch\\$\" \\\n\t\t--pretty=tformat:\"%H %s\" --all |\n\tsed -ne \"/^\\($oid_pattern\\) Merge .*/ {s//\\1/p;$early_exit} \"\n}\n\ndry_run=\nearly_exit=q\nscan_reflog=t\nscan_reflog_merges=\nscan_merges=\nscan_merge_targets=\nnew_name=\n\nwhile test \"$#\" != 0; do\n\tcase \"$1\" in\n\t    -b|--branch)\n\t\tshift\n\t\tnew_name=\"$1\"\n\t\t;;\n\t    -n|--dry-run)\n\t\tdry_run=t\n\t\t;;\n\t    --no-dry-run)\n\t\tdry_run=\n\t\t;;\n\t    -k|--keep-going)\n\t\tearly_exit=\n\t\t;;\n\t    --no-keep-going)\n\t\tearly_exit=q\n\t\t;;\n\t    -m|--merges)\n\t\tscan_merges=t\n\t\t;;\n\t    --no-merges)\n\t\tscan_merges=\n\t\t;;\n\t    -l|--reflog)\n\t\tscan_reflog=t\n\t\t;;\n\t    --no-reflog)\n\t\tscan_reflog=\n\t\t;;\n\t    -r|--reflog_merges)\n\t\tscan_reflog_merges=t\n\t\t;;\n\t    --no-reflog_merges)\n\t\tscan_reflog_merges=\n\t\t;;\n\t    -t|--merge-targets)\n\t\tscan_merge_targets=t\n\t\t;;\n\t    --no-merge-targets)\n\t\tscan_merge_targets=\n\t\t;;\n\t    -a|--all)\n\t\tscan_reflog=t\n\t\tscan_reflog_merges=t\n\t\tscan_merges=t\n\t\tscan_merge_targets=t\n\t\t;;\n\t    --)\n\t\tshift\n\t\tbreak\n\t\t;;\n\t    *)\n\t\tusage\n\t\t;;\n\tesac\n\tshift\ndone\n\ntest \"$#\" = 1 || usage\n\nall_strategies=\"$scan_reflog$scan_reflog_merges$scan_merges$scan_merge_targets\"\nif test -z \"$all_strategies\"; then\n\tdie \"must enable at least one of -lrmt\"\nfi\n\nbranch=\"$1\"\ntest -z \"$new_name\" && new_name=\"$branch\"\n\nif test ! -z \"$scan_reflog\"; then\n\tif test -r \"$GIT_DIR\"/logs/HEAD; then\n\t\tcandidates=\"$(search_reflog $branch)\"\n\telse\n\t\tdie 'reflog scanning requested, but' \\\n\t\t\t'$GIT_DIR/logs/HEAD not readable'\n\tfi\nfi\nif test ! -z \"$scan_reflog_merges\"; then\n\tif test -r \"$GIT_DIR\"/logs/HEAD; then\n\t\tcandidates=\"$candidates $(search_reflog_merges $branch)\"\n\telse\n\t\tdie 'reflog scanning requested, but' \\\n\t\t\t'$GIT_DIR/logs/HEAD not readable'\n\tfi\nfi\nif test ! -z \"$scan_merges\"; then\n\tcandidates=\"$candidates $(search_merges $branch)\"\nfi\nif test ! -z \"$scan_merge_targets\"; then\n\tcandidates=\"$candidates $(search_merge_targets $branch)\"\nfi\n\ncandidates=\"$(git rev-parse $candidates | sort -u)\"\n\nif test -z \"$candidates\"; then\n\thint=\n\ttest \"z$all_strategies\" != \"ztttt\" \\\n\t\t&& hint=\" (maybe try again with -a)\"\n\tdie \"no candidates for $branch found$hint\"\nfi\n\necho \"** Candidates for $branch **\"\nfor cmt in $candidates; do\n\tgit --no-pager log --pretty=tformat:\"%ct:%h [%cr] %s\" --abbrev-commit -1 $cmt\ndone \\\n| sort -n | cut -d: -f2-\n\nnewest=\"$(git rev-list -1 $candidates)\"\nif test ! -z \"$dry_run\"; then\n\tprintf \"** Most recent: \"\n\tgit --no-pager log -1 --pretty=tformat:\"%h %s\" $newest\nelif ! git rev-parse --verify --quiet $new_name >/dev/null; then\n\tprintf \"** Restoring $new_name to \"\n\tgit --no-pager log -1 --pretty=tformat:\"%h %s\" $newest\n\tgit branch $new_name $newest\nelse\n\tprintf \"Most recent: \"\n\tgit --no-pager log -1 --pretty=tformat:\"%h %s\" $newest\n\techo \"** $new_name already exists, doing nothing\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/git-resurrect.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for monitoring and alerting", "completion": "```bash\n#!/bin/sh\n\ndie () {\n\techo \"$*\" >&2\n\texit 1\n}\n\ncd \"$(dirname \"$0\")\"/../.. ||\ndie \"Could not cd to top-level directory\"\n\nmkdir -p .vscode ||\ndie \"Could not create .vscode/\"\n\n# General settings\n\ncat >.vscode/settings.json.new <<\\EOF ||\n{\n    \"C_Cpp.intelliSenseEngine\": \"Default\",\n    \"C_Cpp.intelliSenseEngineFallback\": \"Disabled\",\n    \"[git-commit]\": {\n        \"editor.wordWrap\": \"wordWrapColumn\",\n        \"editor.wordWrapColumn\": 72\n    },\n    \"[c]\": {\n        \"editor.detectIndentation\": false,\n        \"editor.insertSpaces\": false,\n        \"editor.tabSize\": 8,\n        \"editor.wordWrap\": \"wordWrapColumn\",\n        \"editor.wordWrapColumn\": 80,\n        \"files.trimTrailingWhitespace\": true\n    },\n    \"files.associations\": {\n        \"*.h\": \"c\",\n        \"*.c\": \"c\"\n    },\n    \"cSpell.ignorePaths\": [\n    ],\n    \"cSpell.words\": [\n        \"DATAW\",\n        \"DBCACHED\",\n        \"DFCHECK\",\n        \"DTYPE\",\n        \"Hamano\",\n        \"HCAST\",\n        \"HEXSZ\",\n        \"HKEY\",\n        \"HKLM\",\n        \"IFGITLINK\",\n        \"IFINVALID\",\n        \"ISBROKEN\",\n        \"ISGITLINK\",\n        \"ISSYMREF\",\n        \"Junio\",\n        \"LPDWORD\",\n        \"LPPROC\",\n        \"LPWSTR\",\n        \"MSVCRT\",\n        \"NOARG\",\n        \"NOCOMPLETE\",\n        \"NOINHERIT\",\n        \"RENORMALIZE\",\n        \"STARTF\",\n        \"STARTUPINFOEXW\",\n        \"Schindelin\",\n        \"UCRT\",\n        \"YESNO\",\n        \"argcp\",\n        \"beginthreadex\",\n        \"committish\",\n        \"contentp\",\n        \"cpath\",\n        \"cpidx\",\n        \"ctim\",\n        \"dequote\",\n        \"envw\",\n        \"ewah\",\n        \"fdata\",\n        \"fherr\",\n        \"fhin\",\n        \"fhout\",\n        \"fragp\",\n        \"fsmonitor\",\n        \"hnsec\",\n        \"idents\",\n        \"includeif\",\n        \"interpr\",\n        \"iprog\",\n        \"isexe\",\n        \"iskeychar\",\n        \"kompare\",\n        \"mksnpath\",\n        \"mktag\",\n        \"mktree\",\n        \"mmblob\",\n        \"mmbuffer\",\n        \"mmfile\",\n        \"noenv\",\n        \"nparents\",\n        \"ntpath\",\n        \"ondisk\",\n        \"ooid\",\n        \"oplen\",\n        \"osdl\",\n        \"pnew\",\n        \"pold\",\n        \"ppinfo\",\n        \"pushf\",\n        \"pushv\",\n        \"rawsz\",\n        \"rebasing\",\n        \"reencode\",\n        \"repo\",\n        \"rerere\",\n        \"scld\",\n        \"sharedrepo\",\n        \"spawnv\",\n        \"spawnve\",\n        \"spawnvpe\",\n        \"strdup'ing\",\n        \"submodule\",\n        \"submodules\",\n        \"topath\",\n        \"topo\",\n        \"tpatch\",\n        \"unexecutable\",\n        \"unhide\",\n        \"unkc\",\n        \"unkv\",\n        \"unmark\",\n        \"unmatch\",\n        \"unsets\",\n        \"unshown\",\n        \"untracked\",\n        \"untrackedcache\",\n        \"unuse\",\n        \"upos\",\n        \"uval\",\n        \"vreportf\",\n        \"wargs\",\n        \"wargv\",\n        \"wbuffer\",\n        \"wcmd\",\n        \"wcsnicmp\",\n        \"wcstoutfdup\",\n        \"wdeltaenv\",\n        \"wdir\",\n        \"wenv\",\n        \"wenvblk\",\n        \"wenvcmp\",\n        \"wenviron\",\n        \"wenvpos\",\n        \"wenvsz\",\n        \"wfile\",\n        \"wfilename\",\n        \"wfopen\",\n        \"wfreopen\",\n        \"wfullpath\",\n        \"which'll\",\n        \"wlink\",\n        \"wmain\",\n        \"wmkdir\",\n        \"wmktemp\",\n        \"wnewpath\",\n        \"wotype\",\n        \"wpath\",\n        \"wpathname\",\n        \"wpgmptr\",\n        \"wpnew\",\n        \"wpointer\",\n        \"wpold\",\n        \"wpos\",\n        \"wputenv\",\n        \"wrmdir\",\n        \"wship\",\n        \"wtarget\",\n        \"wtemplate\",\n        \"wunlink\",\n        \"xcalloc\",\n        \"xgetcwd\",\n        \"xmallocz\",\n        \"xmemdupz\",\n        \"xmmap\",\n        \"xopts\",\n        \"xrealloc\",\n        \"xsnprintf\",\n        \"xutftowcs\",\n        \"xutftowcsn\",\n        \"xwcstoutf\"\n    ],\n    \"cSpell.ignoreRegExpList\": [\n        \"\\\\\\\"(DIRC|FSMN|REUC|UNTR)\\\\\\\"\",\n        \"\\\\\\\\u[0-9a-fA-Fx]{4}\\\\b\",\n        \"\\\\b(filfre|frotz|xyzzy)\\\\b\",\n        \"\\\\bCMIT_FMT_DEFAULT\\\\b\",\n        \"\\\\bde-munge\\\\b\",\n        \"\\\\bGET_OID_DISAMBIGUATORS\\\\b\",\n        \"\\\\bHASH_RENORMALIZE\\\\b\",\n        \"\\\\bTREESAMEness\\\\b\",\n        \"\\\\bUSE_STDEV\\\\b\",\n        \"\\\\Wchar *\\\\*\\\\W*utfs\\\\W\",\n        \"cURL's\",\n        \"nedmalloc'ed\",\n        \"ntifs\\\\.h\",\n    ],\n}\nEOF\ndie \"Could not write settings.json\"\n\n# Infer some setup-specific locations/names\n\nGCCPATH=\"$(which gcc)\"\nGDBPATH=\"$(which gdb)\"\nMAKECOMMAND=\"make -j5 DEVELOPER=1\"\nOSNAME=\nX=\ncase \"$(uname -s)\" in\nMINGW*)\n\tGCCPATH=\"$(cygpath -am \"$GCCPATH\")\"\n\tGDBPATH=\"$(cygpath -am \"$GDBPATH\")\"\n\tMAKE_BASH=\"$(cygpath -am /git-cmd.exe) --command=usr\\\\\\\\bin\\\\\\\\bash.exe\"\n\tMAKECOMMAND=\"$MAKE_BASH -lc \\\\\\\"$MAKECOMMAND\\\\\\\"\"\n\tOSNAME=Win32\n\tX=.exe\n\t;;\nLinux)\n\tOSNAME=Linux\n\t;;\nDarwin)\n\tOSNAME=macOS\n\t;;\nesac\n\n# Default build task\n\ncat >.vscode/tasks.json.new <<EOF ||\n{\n    // See https://go.microsoft.com/fwlink/?LinkId=733558\n    // for the documentation about the tasks.json format\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"make\",\n            \"type\": \"shell\",\n            \"command\": \"$MAKECOMMAND\",\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        }\n    ]\n}\nEOF\ndie \"Could not install default build task\"\n\n# Debugger settings\n\ncat >.vscode/launch.json.new <<EOF ||\n{\n    // Use IntelliSense to learn about possible attributes.\n    // Hover to view descriptions of existing attributes.\n    // For more information, visit:\n    // https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"(gdb) Launch\",\n            \"type\": \"cppdbg\",\n            \"request\": \"launch\",\n            \"program\": \"\\${workspaceFolder}/git$X\",\n            \"args\": [],\n            \"stopAtEntry\": false,\n            \"cwd\": \"\\${workspaceFolder}\",\n            \"environment\": [],\n            \"externalConsole\": true,\n            \"MIMode\": \"gdb\",\n            \"miDebuggerPath\": \"$GDBPATH\",\n            \"setupCommands\": [\n                {\n                    \"description\": \"Enable pretty-printing for gdb\",\n                    \"text\": \"-enable-pretty-printing\",\n                    \"ignoreFailures\": true\n                }\n            ]\n        }\n    ]\n}\nEOF\ndie \"Could not write launch configuration\"\n\n# C/C++ extension settings\n\nmake -f - OSNAME=$OSNAME GCCPATH=\"$GCCPATH\" vscode-init \\\n\t>.vscode/c_cpp_properties.json <<\\EOF ||\ninclude Makefile\n\nvscode-init:\n\t@mkdir -p .vscode && \\\n\tincs= && defs= && \\\n\tfor e in $(ALL_CFLAGS) \\\n\t\t\t'-DGIT_EXEC_PATH=\"$(gitexecdir_SQ)\"' \\\n\t\t\t'-DGIT_LOCALE_PATH=\"$(localedir_relative_SQ)\"' \\\n\t\t\t'-DBINDIR=\"$(bindir_relative_SQ)\"' \\\n\t\t\t'-DFALLBACK_RUNTIME_PREFIX=\"$(prefix_SQ)\"' \\\n\t\t\t'-DDEFAULT_GIT_TEMPLATE_DIR=\"$(template_dir_SQ)\"' \\\n\t\t\t'-DETC_GITCONFIG=\"$(ETC_GITCONFIG_SQ)\"' \\\n\t\t\t'-DETC_GITATTRIBUTES=\"$(ETC_GITATTRIBUTES_SQ)\"' \\\n\t\t\t'-DGIT_LOCALE_PATH=\"$(localedir_relative_SQ)\"' \\\n\t\t\t'-DCURL_DISABLE_TYPECHECK', \\\n\t\t\t'-DGIT_HTML_PATH=\"$(htmldir_relative_SQ)\"' \\\n\t\t\t'-DGIT_MAN_PATH=\"$(mandir_relative_SQ)\"' \\\n\t\t\t'-DGIT_INFO_PATH=\"$(infodir_relative_SQ)\"'; do \\\n\t\tcase \"$$e\" in \\\n\t\t-I.) \\\n\t\t\tincs=\"$$(printf '% 16s\"$${workspaceRoot}\",\\n%s' \\\n\t\t\t\t\"\" \"$$incs\")\" \\\n\t\t\t;; \\\n\t\t-I/*) \\\n\t\t\tincs=\"$$(printf '% 16s\"%s\",\\n%s' \\\n\t\t\t\t\"\" \"$${e#-I}\" \"$$incs\")\" \\\n\t\t\t;; \\\n\t\t-I*) \\\n\t\t\tincs=\"$$(printf '% 16s\"$${workspaceRoot}/%s\",\\n%s' \\\n\t\t\t\t\"\" \"$${e#-I}\" \"$$incs\")\" \\\n\t\t\t;; \\\n\t\t-D*) \\\n\t\t\tdefs=\"$$(printf '% 16s\"%s\",\\n%s' \\\n\t\t\t\t\"\" \"$$(echo \"$${e#-D}\" | sed 's/\"/\\\\&/g')\" \\\n\t\t\t\t\"$$defs\")\" \\\n\t\t\t;; \\\n\t\tesac; \\\n\tdone && \\\n\techo '{' && \\\n\techo '    \"configurations\": [' && \\\n\techo '        {' && \\\n\techo '            \"name\": \"$(OSNAME)\",' && \\\n\techo '            \"intelliSenseMode\": \"clang-x64\",' && \\\n\techo '            \"includePath\": [' && \\\n\techo \"$$incs\" | sort | sed '$$s/,$$//' && \\\n\techo '            ],' && \\\n\techo '            \"defines\": [' && \\\n\techo \"$$defs\" | sort | sed '$$s/,$$//' && \\\n\techo '            ],' && \\\n\techo '            \"browse\": {' && \\\n\techo '                \"limitSymbolsToIncludedHeaders\": true,' && \\\n\techo '                \"databaseFilename\": \"\",' && \\\n\techo '                \"path\": [' && \\\n\techo '                    \"$${workspaceRoot}\"' && \\\n\techo '                ]' && \\\n\techo '            },' && \\\n\techo '            \"cStandard\": \"c11\",' && \\\n\techo '            \"cppStandard\": \"c++17\",' && \\\n\techo '            \"compilerPath\": \"$(GCCPATH)\"' && \\\n\techo '        }' && \\\n\techo '    ],' && \\\n\techo '    \"version\": 4' && \\\n\techo '}'\nEOF\ndie \"Could not write settings for the C/C++ extension\"\n\nfor file in .vscode/settings.json .vscode/tasks.json .vscode/launch.json\ndo\n\tif test -f $file\n\tthen\n\t\tif git diff --no-index --quiet --exit-code $file $file.new\n\t\tthen\n\t\t\trm $file.new\n\t\telse\n\t\t\tprintf \"The file $file.new has these changes:\\n\\n\"\n\t\t\tgit --no-pager diff --no-index $file $file.new\n\t\t\tprintf \"\\n\\nMaybe \\`mv $file.new $file\\`?\\n\\n\"\n\t\tfi\n\telse\n\t\tmv $file.new $file\n\tfi\ndone\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/vscode/init.sh", "category": "aws_operations", "authentic": true}}
{"prompt": "Create a shell script for Git workflow automation", "completion": "```bash\n#!/bin/sh\n\n# Use this tool to rewrite your .git/remotes/ files into the config.\n\n. git-sh-setup\n\nif [ -d \"$GIT_DIR\"/remotes ]; then\n\techo \"Rewriting $GIT_DIR/remotes\" >&2\n\terror=0\n\t# rewrite into config\n\t{\n\t\tcd \"$GIT_DIR\"/remotes\n\t\tls | while read f; do\n\t\t\tname=$(printf \"$f\" | tr -c \"A-Za-z0-9-\" \".\")\n\t\t\tsed -n \\\n\t\t\t-e \"s/^URL:[ \t]*\\(.*\\)$/remote.$name.url \\1 ./p\" \\\n\t\t\t-e \"s/^Pull:[ \t]*\\(.*\\)$/remote.$name.fetch \\1 ^$ /p\" \\\n\t\t\t-e \"s/^Push:[ \t]*\\(.*\\)$/remote.$name.push \\1 ^$ /p\" \\\n\t\t\t< \"$f\"\n\t\tdone\n\t\techo done\n\t} | while read key value regex; do\n\t\tcase $key in\n\t\tdone)\n\t\t\tif [ $error = 0 ]; then\n\t\t\t\tmv \"$GIT_DIR\"/remotes \"$GIT_DIR\"/remotes.old\n\t\t\tfi ;;\n\t\t*)\n\t\t\techo \"git config $key \"$value\" $regex\"\n\t\t\tgit config $key \"$value\" $regex || error=1 ;;\n\t\tesac\n\tdone\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/remotes2config.sh", "category": "system_administration", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/sh\n#See http://www.unicode.org/reports/tr44/\n#\n#Me Enclosing_Mark  an enclosing combining mark\n#Mn Nonspacing_Mark a nonspacing combining mark (zero advance width)\n#Cf Format          a format control character\n#\ncd \"$(dirname \"$0\")\"\nUNICODEWIDTH_H=$(git rev-parse --show-toplevel)/unicode-width.h\n\nwget -N http://www.unicode.org/Public/UCD/latest/ucd/UnicodeData.txt \\\n\thttp://www.unicode.org/Public/UCD/latest/ucd/EastAsianWidth.txt &&\nif ! test -d uniset; then\n\tgit clone https://github.com/depp/uniset.git &&\n\t( cd uniset && git checkout 4b186196dd )\nfi &&\n(\n\tcd uniset &&\n\tif ! test -x uniset; then\n\t\tautoreconf -i &&\n\t\t./configure --enable-warnings=-Werror CFLAGS='-O0 -ggdb'\n\tfi &&\n\tmake\n) &&\nUNICODE_DIR=. && export UNICODE_DIR &&\ncat >$UNICODEWIDTH_H <<-EOF\nstatic const struct interval zero_width[] = {\n\t$(uniset/uniset --32 cat:Me,Mn,Cf + U+1160..U+11FF - U+00AD)\n};\nstatic const struct interval double_width[] = {\n\t$(uniset/uniset --32 eaw:F,W)\n};\nEOF\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/update-unicode/update_unicode.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/sh\n# Copyright (c) 2008, Nanako Shiraishi\n# Prime rerere database from existing merge commits\n\nme=rerere-train\nUSAGE=$(cat <<-EOF\nusage: $me [--overwrite] <rev-list-args>\n\n    -h, --help            show the help\n    -o, --overwrite       overwrite any existing rerere cache\nEOF\n)\n\nSUBDIRECTORY_OK=Yes\n\noverwrite=0\n\nwhile test $# -gt 0\ndo\n\topt=\"$1\"\n\tcase \"$opt\" in\n\t-h|--help)\n\t\techo \"$USAGE\"\n\t\texit 0\n\t\t;;\n\t-o|--overwrite)\n\t\toverwrite=1\n\t\tshift\n\t\tbreak\n\t\t;;\n\t--)\n\t\tshift\n\t\tbreak\n\t\t;;\n\t*)\n\t\tbreak\n\t\t;;\n\tesac\ndone\n\n# Overwrite or help options are not valid except as first arg\nfor opt in \"$@\"\ndo\n\tcase \"$opt\" in\n\t-h|--help)\n\t\techo \"$USAGE\"\n\t\texit 0\n\t\t;;\n\t-o|--overwrite)\n\t\techo \"$USAGE\"\n\t\texit 0\n\t\t;;\n\tesac\ndone\n\n. \"$(git --exec-path)/git-sh-setup\"\nrequire_work_tree\ncd_to_toplevel\n\n# Remember original branch\nbranch=$(git symbolic-ref -q HEAD) ||\noriginal_HEAD=$(git rev-parse --verify HEAD) || {\n\techo >&2 \"Not on any branch and no commit yet?\"\n\texit 1\n}\n\nmkdir -p \"$GIT_DIR/rr-cache\" || exit\n\ngit rev-list --parents \"$@\" |\nwhile read commit parent1 other_parents\ndo\n\tif test -z \"$other_parents\"\n\tthen\n\t\t# Skip non-merges\n\t\tcontinue\n\tfi\n\tgit checkout -q \"$parent1^0\"\n\tif git merge $other_parents >/dev/null 2>&1\n\tthen\n\t\t# Cleanly merges\n\t\tcontinue\n\tfi\n\tif test $overwrite = 1\n\tthen\n\t\tgit rerere forget .\n\tfi\n\tif test -s \"$GIT_DIR/MERGE_RR\"\n\tthen\n\t\tgit show -s --pretty=format:\"Learning from %h %s\" \"$commit\"\n\t\tgit rerere\n\t\tgit checkout -q $commit -- .\n\t\tgit rerere\n\tfi\n\tgit reset -q --hard  # Might nuke untracked files...\ndone\n\nif test -z \"$branch\"\nthen\n\tgit checkout \"$original_HEAD\"\nelse\n\tgit checkout \"${branch#refs/heads/}\"\nfi\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/rerere-train.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for testing automation", "completion": "```bash\n#!/bin/sh\n\ntest_description='Test diff-highlight'\n\nCURR_DIR=$(pwd)\nTEST_OUTPUT_DIRECTORY=$(pwd)\nTEST_DIRECTORY=\"$CURR_DIR\"/../../../t\nDIFF_HIGHLIGHT=\"$CURR_DIR\"/../diff-highlight\n\nCW=\"$(printf \"\\033[7m\")\"\t# white\nCR=\"$(printf \"\\033[27m\")\"\t# reset\n\n. \"$TEST_DIRECTORY\"/test-lib.sh\n\nif ! test_have_prereq PERL\nthen\n\tskip_all='skipping diff-highlight tests; perl not available'\n\ttest_done\nfi\n\n# dh_test is a test helper function which takes 3 file names as parameters. The\n# first 2 files are used to generate diff and commit output, which is then\n# piped through diff-highlight. The 3rd file should contain the expected output\n# of diff-highlight (minus the diff/commit header, ie. everything after and\n# including the first @@ line).\ndh_test () {\n\ta=\"$1\" b=\"$2\" &&\n\n\tcat >patch.exp &&\n\n\t{\n\t\tcat \"$a\" >file &&\n\t\tgit add file &&\n\t\tgit commit -m \"Add a file\" &&\n\n\t\tcat \"$b\" >file &&\n\t\tgit diff file >diff.raw &&\n\t\tgit commit -a -m \"Update a file\" &&\n\t\tgit show >commit.raw\n\t} >/dev/null &&\n\n\t\"$DIFF_HIGHLIGHT\" <diff.raw | test_strip_patch_header >diff.act &&\n\t\"$DIFF_HIGHLIGHT\" <commit.raw | test_strip_patch_header >commit.act &&\n\ttest_cmp patch.exp diff.act &&\n\ttest_cmp patch.exp commit.act\n}\n\ntest_strip_patch_header () {\n\tsed -n '/^@@/,$p' $*\n}\n\n# dh_test_setup_history generates a contrived graph such that we have at least\n# 1 nesting (E) and 2 nestings (F).\n#\n#\t  A---B master\n#\t /\n#\tD---E---F branch\n#\n#\tgit log --all --graph\n#\t* commit\n#\t|    B\n#\t| * commit\n#\t| |    F\n#\t* | commit\n#\t| |    A\n#\t| * commit\n#\t|/\n#\t|    E\n#\t* commit\n#\t     D\n#\ndh_test_setup_history () {\n\techo file1 >file &&\n\tgit add file &&\n\ttest_tick &&\n\tgit commit -m \"D\" &&\n\n\tgit checkout -b branch &&\n\techo file2 >file &&\n\ttest_tick &&\n\tgit commit -a -m \"E\" &&\n\n\tgit checkout master &&\n\techo file2 >file &&\n\ttest_tick &&\n\tgit commit -a -m \"A\" &&\n\n\tgit checkout branch &&\n\techo file3 >file &&\n\ttest_tick &&\n\tgit commit -a -m \"F\" &&\n\n\tgit checkout master &&\n\techo file3 >file &&\n\ttest_tick &&\n\tgit commit -a -m \"B\"\n}\n\nleft_trim () {\n\t\"$PERL_PATH\" -pe 's/^\\s+//'\n}\n\ntrim_graph () {\n\t# graphs start with * or |\n\t# followed by a space or / or \\\n\t\"$PERL_PATH\" -pe 's@^((\\*|\\|)( |/|\\\\))+@@'\n}\n\ntest_expect_success 'diff-highlight highlights the beginning of a line' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\t\tccc\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\t0bb\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-${CW}b${CR}bb\n\t\t+${CW}0${CR}bb\n\t\t ccc\n\tEOF\n'\n\ntest_expect_success 'diff-highlight highlights the end of a line' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\t\tccc\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\tbb0\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-bb${CW}b${CR}\n\t\t+bb${CW}0${CR}\n\t\t ccc\n\tEOF\n'\n\ntest_expect_success 'diff-highlight highlights the middle of a line' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\t\tccc\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\tb0b\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-b${CW}b${CR}b\n\t\t+b${CW}0${CR}b\n\t\t ccc\n\tEOF\n'\n\ntest_expect_success 'diff-highlight does not highlight whole line' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\t\tccc\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\t000\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-bbb\n\t\t+000\n\t\t ccc\n\tEOF\n'\n\ntest_expect_failure 'diff-highlight highlights mismatched hunk size' '\n\tcat >a <<-\\EOF &&\n\t\taaa\n\t\tbbb\n\tEOF\n\n\tcat >b <<-\\EOF &&\n\t\taaa\n\t\tb0b\n\t\tccc\n\tEOF\n\n\tdh_test a b <<-EOF\n\t\t@@ -1,3 +1,3 @@\n\t\t aaa\n\t\t-b${CW}b${CR}b\n\t\t+b${CW}0${CR}b\n\t\t+ccc\n\tEOF\n'\n\n# These two code points share the same leading byte in UTF-8 representation;\n# a naive byte-wise diff would highlight only the second byte.\n#\n#   - U+00f3 (\"o\" with acute)\no_accent=$(printf '\\303\\263')\n#   - U+00f8 (\"o\" with stroke)\no_stroke=$(printf '\\303\\270')\n\ntest_expect_success 'diff-highlight treats multibyte utf-8 as a unit' '\n\techo \"unic${o_accent}de\" >a &&\n\techo \"unic${o_stroke}de\" >b &&\n\tdh_test a b <<-EOF\n\t\t@@ -1 +1 @@\n\t\t-unic${CW}${o_accent}${CR}de\n\t\t+unic${CW}${o_stroke}${CR}de\n\tEOF\n'\n\n# Unlike the UTF-8 above, these are combining code points which are meant\n# to modify the character preceding them:\n#\n#   - U+0301 (combining acute accent)\ncombine_accent=$(printf '\\314\\201')\n#   - U+0302 (combining circumflex)\ncombine_circum=$(printf '\\314\\202')\n\ntest_expect_failure 'diff-highlight treats combining code points as a unit' '\n\techo \"unico${combine_accent}de\" >a &&\n\techo \"unico${combine_circum}de\" >b &&\n\tdh_test a b <<-EOF\n\t\t@@ -1 +1 @@\n\t\t-unic${CW}o${combine_accent}${CR}de\n\t\t+unic${CW}o${combine_circum}${CR}de\n\tEOF\n'\n\ntest_expect_success 'diff-highlight works with the --graph option' '\n\tdh_test_setup_history &&\n\n\t# date-order so that the commits are interleaved for both\n\t# trim graph elements so we can do a diff\n\t# trim leading space because our trim_graph is not perfect\n\tgit log --branches -p --date-order |\n\t\t\"$DIFF_HIGHLIGHT\" | left_trim >graph.exp &&\n\tgit log --branches -p --date-order --graph |\n\t\t\"$DIFF_HIGHLIGHT\" | trim_graph | left_trim >graph.act &&\n\ttest_cmp graph.exp graph.act\n'\n\n# Just reuse the previous graph test, but with --color.  Our trimming\n# doesn't know about color, so just sanity check that something got\n# highlighted.\ntest_expect_success 'diff-highlight works with color graph' '\n\tgit log --branches -p --date-order --graph --color |\n\t\t\"$DIFF_HIGHLIGHT\" | trim_graph | left_trim >graph &&\n\tgrep \"\\[7m\" graph\n'\n\n# Most combined diffs won't meet diff-highlight's line-number filter. So we\n# create one here where one side drops a line and the other modifies it. That\n# should result in a diff like:\n#\n#    - modified content\n#    ++resolved content\n#\n# which naively looks like one side added \"+resolved\".\ntest_expect_success 'diff-highlight ignores combined diffs' '\n\techo \"content\" >file &&\n\tgit add file &&\n\tgit commit -m base &&\n\n\t>file &&\n\tgit commit -am master &&\n\n\tgit checkout -b other HEAD^ &&\n\techo \"modified content\" >file &&\n\tgit commit -am other &&\n\n\ttest_must_fail git merge master &&\n\techo \"resolved content\" >file &&\n\tgit commit -am resolved &&\n\n\tcat >expect <<-\\EOF &&\n\t--- a/file\n\t+++ b/file\n\t@@@ -1,1 -1,0 +1,1 @@@\n\t- modified content\n\t++resolved content\n\tEOF\n\n\tgit show -c | \"$DIFF_HIGHLIGHT\" >actual.raw &&\n\tsed -n \"/^---/,\\$p\" <actual.raw >actual &&\n\ttest_cmp expect actual\n'\n\ntest_expect_success 'diff-highlight handles --graph with leading dash' '\n\tcat >file <<-\\EOF &&\n\tbefore\n\tthe old line\n\t-leading dash\n\tEOF\n\tgit add file &&\n\tgit commit -m before &&\n\n\tsed s/old/new/ <file >file.tmp &&\n\tmv file.tmp file &&\n\tgit add file &&\n\tgit commit -m after &&\n\n\tcat >expect <<-EOF &&\n\t--- a/file\n\t+++ b/file\n\t@@ -1,3 +1,3 @@\n\t before\n\t-the ${CW}old${CR} line\n\t+the ${CW}new${CR} line\n\t -leading dash\n\tEOF\n\tgit log --graph -p -1 | \"$DIFF_HIGHLIGHT\" >actual.raw &&\n\ttrim_graph <actual.raw | sed -n \"/^---/,\\$p\" >actual &&\n\ttest_cmp expect actual\n'\n\ntest_done\n```", "metadata": {"source": "real_local_repository", "file_path": "/usr/share/doc/git/contrib/diff-highlight/t/t9400-diff-highlight.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for Docker container automation", "completion": "```bash\n#!/usr/bin/env sh\nset -e\n\nEXITCODE=0\n\n# bits of this were adapted from lxc-checkconfig\n# see also https://github.com/lxc/lxc/blob/lxc-1.0.2/src/lxc/lxc-checkconfig.in\n\npossibleConfigs=\"\n\t/proc/config.gz\n\t/boot/config-$(uname -r)\n\t/usr/src/linux-$(uname -r)/.config\n\t/usr/src/linux/.config\n\"\n\nif [ $# -gt 0 ]; then\n\tCONFIG=\"$1\"\nelse\n\t: \"${CONFIG:=/proc/config.gz}\"\nfi\n\nif ! command -v zgrep > /dev/null 2>&1; then\n\tzgrep() {\n\t\tzcat \"$2\" | grep \"$1\"\n\t}\nfi\n\nuseColor=true\nif [ \"$NO_COLOR\" = \"1\" ] || [ ! -t 1 ]; then\n\tuseColor=false\nfi\nkernelVersion=\"$(uname -r)\"\nkernelMajor=\"${kernelVersion%%.*}\"\nkernelMinor=\"${kernelVersion#$kernelMajor.}\"\nkernelMinor=\"${kernelMinor%%.*}\"\n\nis_set() {\n\tzgrep \"CONFIG_$1=[y|m]\" \"$CONFIG\" > /dev/null\n}\nis_set_in_kernel() {\n\tzgrep \"CONFIG_$1=y\" \"$CONFIG\" > /dev/null\n}\nis_set_as_module() {\n\tzgrep \"CONFIG_$1=m\" \"$CONFIG\" > /dev/null\n}\n\ncolor() {\n\t# if stdout is not a terminal, then don't do color codes.\n\tif [ \"$useColor\" = \"false\" ]; then\n\t\treturn 0\n\tfi\n\tcodes=\n\tif [ \"$1\" = 'bold' ]; then\n\t\tcodes='1'\n\t\tshift\n\tfi\n\tif [ \"$#\" -gt 0 ]; then\n\t\tcode=\n\t\tcase \"$1\" in\n\t\t\t# see https://en.wikipedia.org/wiki/ANSI_escape_code#Colors\n\t\t\tblack) code=30 ;;\n\t\t\tred) code=31 ;;\n\t\t\tgreen) code=32 ;;\n\t\t\tyellow) code=33 ;;\n\t\t\tblue) code=34 ;;\n\t\t\tmagenta) code=35 ;;\n\t\t\tcyan) code=36 ;;\n\t\t\twhite) code=37 ;;\n\t\tesac\n\t\tif [ \"$code\" ]; then\n\t\t\tcodes=\"${codes:+$codes;}$code\"\n\t\tfi\n\tfi\n\tprintf '\\033[%sm' \"$codes\"\n}\nwrap_color() {\n\ttext=\"$1\"\n\tshift\n\tcolor \"$@\"\n\tprintf '%s' \"$text\"\n\tcolor reset\n\techo\n}\n\nwrap_good() {\n\techo \"$(wrap_color \"$1\" white): $(wrap_color \"$2\" green)\"\n}\nwrap_bad() {\n\techo \"$(wrap_color \"$1\" bold): $(wrap_color \"$2\" bold red)\"\n}\nwrap_warning() {\n\twrap_color >&2 \"$*\" red\n}\n\ncheck_flag() {\n\tif is_set_in_kernel \"$1\"; then\n\t\twrap_good \"CONFIG_$1\" 'enabled'\n\telif is_set_as_module \"$1\"; then\n\t\twrap_good \"CONFIG_$1\" 'enabled (as module)'\n\telse\n\t\twrap_bad \"CONFIG_$1\" 'missing'\n\t\tEXITCODE=1\n\tfi\n}\n\ncheck_flags() {\n\tfor flag in \"$@\"; do\n\t\tprintf -- '- '\n\t\tcheck_flag \"$flag\"\n\tdone\n}\n\ncheck_command() {\n\tif command -v \"$1\" > /dev/null 2>&1; then\n\t\twrap_good \"$1 command\" 'available'\n\telse\n\t\twrap_bad \"$1 command\" 'missing'\n\t\tEXITCODE=1\n\tfi\n}\n\ncheck_device() {\n\tif [ -c \"$1\" ]; then\n\t\twrap_good \"$1\" 'present'\n\telse\n\t\twrap_bad \"$1\" 'missing'\n\t\tEXITCODE=1\n\tfi\n}\n\nif [ ! -e \"$CONFIG\" ]; then\n\twrap_warning \"warning: $CONFIG does not exist, searching other paths for kernel config ...\"\n\tfor tryConfig in $possibleConfigs; do\n\t\tif [ -e \"$tryConfig\" ]; then\n\t\t\tCONFIG=\"$tryConfig\"\n\t\t\tbreak\n\t\tfi\n\tdone\n\tif [ ! -e \"$CONFIG\" ]; then\n\t\twrap_warning \"error: cannot find kernel config\"\n\t\twrap_warning \"  try running this script again, specifying the kernel config:\"\n\t\twrap_warning \"    CONFIG=/path/to/kernel/.config $0 or $0 /path/to/kernel/.config\"\n\t\texit 1\n\tfi\nfi\n\nwrap_color \"info: reading kernel config from $CONFIG ...\" white\necho\n\necho 'Generally Necessary:'\n\nprintf -- '- '\nif [ \"$(stat -f -c %t /sys/fs/cgroup 2> /dev/null)\" = '63677270' ]; then\n\twrap_good 'cgroup hierarchy' 'cgroupv2'\n\tcgroupv2ControllerFile='/sys/fs/cgroup/cgroup.controllers'\n\tif [ -f \"$cgroupv2ControllerFile\" ]; then\n\t\techo '  Controllers:'\n\t\tfor controller in cpu cpuset io memory pids; do\n\t\t\tif grep -qE '(^| )'\"$controller\"'($| )' \"$cgroupv2ControllerFile\"; then\n\t\t\t\techo \"  - $(wrap_good \"$controller\" 'available')\"\n\t\t\telse\n\t\t\t\techo \"  - $(wrap_bad \"$controller\" 'missing')\"\n\t\t\tfi\n\t\tdone\n\telse\n\t\twrap_bad \"$cgroupv2ControllerFile\" 'nonexistent??'\n\tfi\n\t# TODO find an efficient way to check if cgroup.freeze exists in subdir\nelse\n\tcgroupSubsystemDir=\"$(sed -rne '/^[^ ]+ ([^ ]+) cgroup ([^ ]*,)?(cpu|cpuacct|cpuset|devices|freezer|memory)[, ].*$/ { s//\\1/p; q }' /proc/mounts)\"\n\tcgroupDir=\"$(dirname \"$cgroupSubsystemDir\")\"\n\tif [ -d \"$cgroupDir/cpu\" ] || [ -d \"$cgroupDir/cpuacct\" ] || [ -d \"$cgroupDir/cpuset\" ] || [ -d \"$cgroupDir/devices\" ] || [ -d \"$cgroupDir/freezer\" ] || [ -d \"$cgroupDir/memory\" ]; then\n\t\techo \"$(wrap_good 'cgroup hierarchy' 'properly mounted') [$cgroupDir]\"\n\telse\n\t\tif [ \"$cgroupSubsystemDir\" ]; then\n\t\t\techo \"$(wrap_bad 'cgroup hierarchy' 'single mountpoint!') [$cgroupSubsystemDir]\"\n\t\telse\n\t\t\twrap_bad 'cgroup hierarchy' 'nonexistent??'\n\t\tfi\n\t\tEXITCODE=1\n\t\techo \"    $(wrap_color '(see https://github.com/tianon/cgroupfs-mount)' yellow)\"\n\tfi\nfi\n\nif [ \"$(cat /sys/module/apparmor/parameters/enabled 2> /dev/null)\" = 'Y' ]; then\n\tprintf -- '- '\n\tif command -v apparmor_parser > /dev/null 2>&1; then\n\t\twrap_good 'apparmor' 'enabled and tools installed'\n\telse\n\t\twrap_bad 'apparmor' 'enabled, but apparmor_parser missing'\n\t\tprintf '    '\n\t\tif command -v apt-get > /dev/null 2>&1; then\n\t\t\twrap_color '(use \"apt-get install apparmor\" to fix this)'\n\t\telif command -v yum > /dev/null 2>&1; then\n\t\t\twrap_color '(your best bet is \"yum install apparmor-parser\")'\n\t\telse\n\t\t\twrap_color '(look for an \"apparmor\" package for your distribution)'\n\t\tfi\n\t\tEXITCODE=1\n\tfi\nfi\n\ncheck_flags \\\n\tNAMESPACES NET_NS PID_NS IPC_NS UTS_NS \\\n\tCGROUPS CGROUP_CPUACCT CGROUP_DEVICE CGROUP_FREEZER CGROUP_SCHED CPUSETS MEMCG \\\n\tKEYS \\\n\tVETH BRIDGE BRIDGE_NETFILTER \\\n\tIP_NF_FILTER IP_NF_MANGLE IP_NF_TARGET_MASQUERADE \\\n\tIP6_NF_FILTER IP6_NF_MANGLE IP6_NF_TARGET_MASQUERADE \\\n\tNETFILTER_XT_MATCH_ADDRTYPE \\\n\tNETFILTER_XT_MATCH_CONNTRACK \\\n\tNETFILTER_XT_MATCH_IPVS \\\n\tNETFILTER_XT_MARK \\\n\tIP_NF_RAW IP_NF_NAT NF_NAT \\\n\tIP6_NF_RAW IP6_NF_NAT NF_NAT \\\n\tPOSIX_MQUEUE\n# (POSIX_MQUEUE is required for bind-mounting /dev/mqueue into containers)\n\nif [ \"$kernelMajor\" -lt 4 ] || ([ \"$kernelMajor\" -eq 4 ] && [ \"$kernelMinor\" -lt 8 ]); then\n\tcheck_flags DEVPTS_MULTIPLE_INSTANCES\nfi\n\nif [ \"$kernelMajor\" -lt 5 ] || [ \"$kernelMajor\" -eq 5 -a \"$kernelMinor\" -le 1 ]; then\n\tcheck_flags NF_NAT_IPV4\nfi\n\nif [ \"$kernelMajor\" -lt 5 ] || [ \"$kernelMajor\" -eq 5 -a \"$kernelMinor\" -le 2 ]; then\n\tcheck_flags NF_NAT_NEEDED\nfi\n# check availability of BPF_CGROUP_DEVICE support\nif [ \"$kernelMajor\" -ge 5 ] || ([ \"$kernelMajor\" -eq 4 ] && [ \"$kernelMinor\" -ge 15 ]); then\n\tcheck_flags CGROUP_BPF\nfi\n\necho\n\necho 'Optional Features:'\n{\n\tcheck_flags USER_NS\n}\n{\n\tcheck_flags SECCOMP\n\tcheck_flags SECCOMP_FILTER\n}\n{\n\tcheck_flags CGROUP_PIDS\n}\n{\n\tcheck_flags MEMCG_SWAP\n\t# Kernel v5.8+ removes MEMCG_SWAP_ENABLED.\n\tif [ \"$kernelMajor\" -lt 5 ] || [ \"$kernelMajor\" -eq 5 -a \"$kernelMinor\" -le 8 ]; then\n\t\tCODE=${EXITCODE}\n\t\tcheck_flags MEMCG_SWAP_ENABLED\n\t\t# FIXME this check is cgroupv1-specific\n\t\tif [ -e /sys/fs/cgroup/memory/memory.memsw.limit_in_bytes ]; then\n\t\t\techo \"    $(wrap_color '(cgroup swap accounting is currently enabled)' bold black)\"\n\t\t\tEXITCODE=${CODE}\n\t\telif is_set MEMCG_SWAP && ! is_set MEMCG_SWAP_ENABLED; then\n\t\t\techo \"    $(wrap_color '(cgroup swap accounting is currently not enabled, you can enable it by setting boot option \"swapaccount=1\")' bold black)\"\n\t\tfi\n\telse\n\t\t# Kernel v5.8+ enables swap accounting by default.\n\t\techo \"    $(wrap_color '(cgroup swap accounting is currently enabled)' bold black)\"\n\tfi\n}\n{\n\tif is_set LEGACY_VSYSCALL_NATIVE; then\n\t\tprintf -- '- '\n\t\twrap_bad \"CONFIG_LEGACY_VSYSCALL_NATIVE\" 'enabled'\n\t\techo \"    $(wrap_color '(dangerous, provides an ASLR-bypassing target with usable ROP gadgets.)' bold black)\"\n\telif is_set LEGACY_VSYSCALL_EMULATE; then\n\t\tprintf -- '- '\n\t\twrap_good \"CONFIG_LEGACY_VSYSCALL_EMULATE\" 'enabled'\n\telif is_set LEGACY_VSYSCALL_NONE; then\n\t\tprintf -- '- '\n\t\twrap_bad \"CONFIG_LEGACY_VSYSCALL_NONE\" 'enabled'\n\t\techo \"    $(wrap_color '(containers using eglibc <= 2.13 will not work. Switch to' bold black)\"\n\t\techo \"    $(wrap_color ' \"CONFIG_VSYSCALL_[NATIVE|EMULATE]\" or use \"vsyscall=[native|emulate]\"' bold black)\"\n\t\techo \"    $(wrap_color ' on kernel command line. Note that this will disable ASLR for the,' bold black)\"\n\t\techo \"    $(wrap_color ' VDSO which may assist in exploiting security vulnerabilities.)' bold black)\"\n\t# else Older kernels (prior to 3dc33bd30f3e, released in v4.40-rc1) do\n\t#      not have these LEGACY_VSYSCALL options and are effectively\n\t#      LEGACY_VSYSCALL_EMULATE. Even older kernels are presumably\n\t#      effectively LEGACY_VSYSCALL_NATIVE.\n\tfi\n}\n\nif [ \"$kernelMajor\" -lt 4 ] || ([ \"$kernelMajor\" -eq 4 ] && [ \"$kernelMinor\" -le 5 ]); then\n\tcheck_flags MEMCG_KMEM\nfi\n\nif [ \"$kernelMajor\" -lt 3 ] || ([ \"$kernelMajor\" -eq 3 ] && [ \"$kernelMinor\" -le 18 ]); then\n\tcheck_flags RESOURCE_COUNTERS\nfi\n\nif [ \"$kernelMajor\" -lt 3 ] || ([ \"$kernelMajor\" -eq 3 ] && [ \"$kernelMinor\" -le 13 ]); then\n\tnetprio=NETPRIO_CGROUP\nelse\n\tnetprio=CGROUP_NET_PRIO\nfi\n\nif [ \"$kernelMajor\" -lt 5 ]; then\n\tcheck_flags IOSCHED_CFQ CFQ_GROUP_IOSCHED\nfi\n\ncheck_flags \\\n\tBLK_CGROUP BLK_DEV_THROTTLING \\\n\tCGROUP_PERF \\\n\tCGROUP_HUGETLB \\\n\tNET_CLS_CGROUP $netprio \\\n\tCFS_BANDWIDTH FAIR_GROUP_SCHED \\\n\tIP_NF_TARGET_REDIRECT \\\n\tIP_VS \\\n\tIP_VS_NFCT \\\n\tIP_VS_PROTO_TCP \\\n\tIP_VS_PROTO_UDP \\\n\tIP_VS_RR \\\n\tSECURITY_SELINUX \\\n\tSECURITY_APPARMOR\n\nif ! is_set EXT4_USE_FOR_EXT2; then\n\tcheck_flags EXT3_FS EXT3_FS_XATTR EXT3_FS_POSIX_ACL EXT3_FS_SECURITY\n\tif ! is_set EXT3_FS || ! is_set EXT3_FS_XATTR || ! is_set EXT3_FS_POSIX_ACL || ! is_set EXT3_FS_SECURITY; then\n\t\techo \"    $(wrap_color '(enable these ext3 configs if you are using ext3 as backing filesystem)' bold black)\"\n\tfi\nfi\n\ncheck_flags EXT4_FS EXT4_FS_POSIX_ACL EXT4_FS_SECURITY\nif ! is_set EXT4_FS || ! is_set EXT4_FS_POSIX_ACL || ! is_set EXT4_FS_SECURITY; then\n\tif is_set EXT4_USE_FOR_EXT2; then\n\t\techo \"    $(wrap_color 'enable these ext4 configs if you are using ext3 or ext4 as backing filesystem' bold black)\"\n\telse\n\t\techo \"    $(wrap_color 'enable these ext4 configs if you are using ext4 as backing filesystem' bold black)\"\n\tfi\nfi\n\necho '- Network Drivers:'\necho \"  - \\\"$(wrap_color 'overlay' blue)\\\":\"\ncheck_flags VXLAN BRIDGE_VLAN_FILTERING | sed 's/^/    /'\necho '      Optional (for encrypted networks):'\ncheck_flags CRYPTO CRYPTO_AEAD CRYPTO_GCM CRYPTO_SEQIV CRYPTO_GHASH \\\n\tXFRM XFRM_USER XFRM_ALGO INET_ESP NETFILTER_XT_MATCH_BPF | sed 's/^/      /'\nif [ \"$kernelMajor\" -lt 5 ] || [ \"$kernelMajor\" -eq 5 -a \"$kernelMinor\" -le 3 ]; then\n\tcheck_flags INET_XFRM_MODE_TRANSPORT | sed 's/^/      /'\nfi\necho \"  - \\\"$(wrap_color 'ipvlan' blue)\\\":\"\ncheck_flags IPVLAN | sed 's/^/    /'\necho \"  - \\\"$(wrap_color 'macvlan' blue)\\\":\"\ncheck_flags MACVLAN DUMMY | sed 's/^/    /'\necho \"  - \\\"$(wrap_color 'ftp,tftp client in container' blue)\\\":\"\ncheck_flags NF_NAT_FTP NF_CONNTRACK_FTP NF_NAT_TFTP NF_CONNTRACK_TFTP | sed 's/^/    /'\n\n# only fail if no storage drivers available\nCODE=${EXITCODE}\nEXITCODE=0\nSTORAGE=1\n\necho '- Storage Drivers:'\necho \"  - \\\"$(wrap_color 'btrfs' blue)\\\":\"\ncheck_flags BTRFS_FS | sed 's/^/    /'\ncheck_flags BTRFS_FS_POSIX_ACL | sed 's/^/    /'\n[ \"$EXITCODE\" = 0 ] && STORAGE=0\nEXITCODE=0\n\necho \"  - \\\"$(wrap_color 'overlay' blue)\\\":\"\ncheck_flags OVERLAY_FS | sed 's/^/    /'\n[ \"$EXITCODE\" = 0 ] && STORAGE=0\nEXITCODE=0\n\necho \"  - \\\"$(wrap_color 'zfs' blue)\\\":\"\nprintf '    - '\ncheck_device /dev/zfs\nprintf '    - '\ncheck_command zfs\nprintf '    - '\ncheck_command zpool\n[ \"$EXITCODE\" = 0 ] && STORAGE=0\nEXITCODE=0\n\nEXITCODE=$CODE\n[ \"$STORAGE\" = 1 ] && EXITCODE=1\n\necho\n\ncheck_limit_over() {\n\tif [ \"$(cat \"$1\")\" -le \"$2\" ]; then\n\t\twrap_bad \"- $1\" \"$(cat \"$1\")\"\n\t\twrap_color \"    This should be set to at least $2, for example set: sysctl -w kernel/keys/root_maxkeys=1000000\" bold black\n\t\tEXITCODE=1\n\telse\n\t\twrap_good \"- $1\" \"$(cat \"$1\")\"\n\tfi\n}\n\necho 'Limits:'\ncheck_limit_over /proc/sys/kernel/keys/root_maxkeys 10000\necho\n\nexit $EXITCODE\n```", "metadata": {"source": "github_repository", "repository": "docker/docker", "file_path": "check-config.sh", "category": "automation", "authentic": true}}
{"prompt": "Create a shell script for Docker image building and deployment", "completion": "```bash\n#!/usr/bin/env bash\nset -e\n\n# This script builds various binary artifacts from a checkout of the docker\n# source code.\n#\n# Requirements:\n# - The current directory should be a checkout of the docker source code\n#   (https://github.com/docker/docker). Whatever version is checked out\n#   will be built.\n# - The VERSION file, at the root of the repository, should exist, and\n#   will be used as Docker binary version and package version.\n# - The hash of the git commit will also be included in the Docker binary,\n#   with the suffix -unsupported if the repository isn't clean.\n# - The script is intended to be run inside the docker container specified\n#   in the Dockerfile at the root of the source. In other words:\n#   DO NOT CALL THIS SCRIPT DIRECTLY.\n# - The right way to call this script is to invoke \"make\" from\n#   your checkout of the Docker repository.\n#   the Makefile will do a \"docker build -t docker .\" and then\n#   \"docker run hack/make.sh\" in the resulting image.\n#\n\nset -o pipefail\n\nexport DOCKER_PKG='github.com/docker/docker'\nexport SCRIPTDIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nexport MAKEDIR=\"$SCRIPTDIR/make\"\nexport PKG_CONFIG=${PKG_CONFIG:-pkg-config}\n\necho\n\n# List of bundles to create when no argument is passed\nDEFAULT_BUNDLES=(\n\tbinary-daemon\n\tdynbinary\n\ttest-integration\n\ttest-docker-py\n)\n\nVERSION=${VERSION:-dev}\ncase \"$VERSION\" in\n\trefs/tags/v*) VERSION=${VERSION#refs/tags/v} ;;\n\trefs/tags/*) VERSION=${VERSION#refs/tags/} ;;\n\trefs/heads/*) VERSION=$(echo \"${VERSION#refs/heads/}\" | sed -r 's#/+#-#g') ;;\n\trefs/pull/*) VERSION=pr-$(echo \"$VERSION\" | grep -o '[0-9]\\+') ;;\nesac\n\n! BUILDTIME=$(date -u -d \"@${SOURCE_DATE_EPOCH:-$(date +%s)}\" --rfc-3339 ns 2> /dev/null | sed -e 's/ /T/')\nif [ \"$DOCKER_GITCOMMIT\" ]; then\n\tGITCOMMIT=\"$DOCKER_GITCOMMIT\"\nelif command -v git &> /dev/null && [ -e .git ] && git rev-parse &> /dev/null; then\n\tGITCOMMIT=$(git rev-parse HEAD)\n\tif [ -n \"$(git status --porcelain --untracked-files=no)\" ]; then\n\t\tGITCOMMIT=\"$GITCOMMIT-unsupported\"\n\t\techo \"#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\t\techo \"# GITCOMMIT = $GITCOMMIT\"\n\t\techo \"# The version you are building is listed as unsupported because\"\n\t\techo \"# there are some files in the git repository that are in an uncommitted state.\"\n\t\techo \"# Commit these changes, or add to .gitignore to remove the -unsupported from the version.\"\n\t\techo \"# Here is the current list:\"\n\t\tgit status --porcelain --untracked-files=no\n\t\techo \"#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\tfi\nelse\n\techo >&2 'error: .git directory missing and DOCKER_GITCOMMIT not specified'\n\techo >&2 '  Please either build with the .git directory accessible, or specify the'\n\techo >&2 '  exact commit hash you are building using DOCKER_GITCOMMIT for future'\n\techo >&2 '  accountability in diagnosing build issues.  Thanks!'\n\texit 1\nfi\n\nif [ \"$AUTO_GOPATH\" ]; then\n\trm -rf .gopath\n\tmkdir -p .gopath/src/\"$(dirname \"${DOCKER_PKG}\")\"\n\tln -sf ../../../.. .gopath/src/\"${DOCKER_PKG}\"\n\texport GOPATH=\"${PWD}/.gopath\"\nfi\n\nif [ -z \"${EXCLUDE_AUTO_BUILDTAG_JOURNALD:-}\" ] && ${PKG_CONFIG} 'libsystemd' 2> /dev/null; then\n\tDOCKER_BUILDTAGS+=\" journald\"\nfi\n\n# Use these flags when compiling the tests and final binary\n\nif [ -z \"$DOCKER_DEBUG\" ]; then\n\tLDFLAGS='-w'\nfi\n\nBUILDFLAGS=(${BUILDFLAGS} -tags \"netgo osusergo static_build $DOCKER_BUILDTAGS\")\nLDFLAGS_STATIC=\"-extldflags -static\"\n\nif [ \"$(uname -s)\" = 'FreeBSD' ]; then\n\t# Tell cgo the compiler is Clang, not GCC\n\t# https://code.google.com/p/go/source/browse/src/cmd/cgo/gcc.go?spec=svne77e74371f2340ee08622ce602e9f7b15f29d8d3&r=<TOKEN>#752\n\texport CC=clang\n\n\t# \"-extld clang\" is a workaround for\n\t# https://code.google.com/p/go/issues/detail?id=6845\n\tLDFLAGS=\"$LDFLAGS -extld clang\"\nfi\n\nbundle() {\n\tlocal bundle=\"$1\"\n\tshift\n\techo \"---> Making bundle: $(basename \"$bundle\") (in $DEST)\"\n\tsource \"$SCRIPTDIR/make/$bundle\" \"$@\"\n}\n\nmain() {\n\tbundle_dir=\"bundles\"\n\tif [ -n \"${PREFIX}\" ]; then\n\t\tbundle_dir=\"${PREFIX}/${bundle_dir}\"\n\tfi\n\n\tif [ -z \"${KEEPBUNDLE-}\" ]; then\n\t\techo \"Removing ${bundle_dir}/\"\n\t\trm -rf \"${bundle_dir}\"/*\n\t\techo\n\tfi\n\tmkdir -p \"${bundle_dir}\"\n\n\tif [ $# -lt 1 ]; then\n\t\tbundles=(${DEFAULT_BUNDLES[@]})\n\telse\n\t\tbundles=($@)\n\tfi\n\tfor bundle in ${bundles[@]}; do\n\t\texport DEST=\"${bundle_dir}/$(basename \"$bundle\")\"\n\t\t# Cygdrive paths don't play well with go build -o.\n\t\tif [[ \"$(uname -s)\" == CYGWIN* ]]; then\n\t\t\texport DEST=\"$(cygpath -mw \"$DEST\")\"\n\t\tfi\n\t\tmkdir -p \"$DEST\"\n\t\tABS_DEST=\"$(cd \"$DEST\" && pwd -P)\"\n\t\tbundle \"$bundle\"\n\t\techo\n\tdone\n}\n\nmain \"$@\"\n```", "metadata": {"source": "github_repository", "repository": "docker/docker", "file_path": "make.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for Docker container automation", "completion": "```bash\n#   Copyright 2020 Docker Compose CLI authors\n\n#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n\n#       http://www.apache.org/licenses/LICENSE-2.0\n\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n\n>&2 echo \"log to stderr\"\necho \"log to stdout\"\n```", "metadata": {"source": "github_repository", "repository": "docker/compose", "file_path": "log_to_stderr.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for  automation", "completion": "```bash\n#!/bin/sh\n\n# try to fetch the latest version from github\nwget -O support.sh.new https://raw.githubusercontent.com/docker/libnetwork/master/support/support.sh\n\nif [ \"$?\" -eq \"0\" ]; then\n\tmv support.sh.new support.sh\n\tchmod +x support.sh\nelse\n\techo \"issue fetching the latest support.sh, will use the container version\"\nfi\n\necho \"run the support script\"\n./support.sh\n```", "metadata": {"source": "github_repository", "repository": "moby/moby", "file_path": "run.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for  testing automation", "completion": "```bash\n#!/bin/bash\nset -eu\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd -P)\"\n\nOUT_DIR=\"${SCRIPT_DIR}/../integration-cli/fixtures/https\"\n\n# generate CA\necho 01 > \"${OUT_DIR}/ca-rogue.srl\"\nopenssl genrsa -out \"${OUT_DIR}/ca-rogue-key.pem\"\n\nopenssl req \\\n\t-new \\\n\t-x509 \\\n\t-days 3652 \\\n\t-subj \"/C=US/ST=CA/L=SanFrancisco/O=Evil Inc/OU=changeme/CN=changeme/name=changeme/emailAddress=<EMAIL>\" \\\n\t-nameopt compat \\\n\t-text \\\n\t-key \"${OUT_DIR}/ca-rogue-key.pem\" \\\n\t-out \"${OUT_DIR}/ca-rogue.pem\"\n\n# Now that we have a CA, create a server key and certificate signing request.\n# Make sure that `\"Common Name (e.g. server FQDN or YOUR name)\"` matches the hostname you will use\n# to connect or just use '*' for a certificate valid for any hostname:\n\nopenssl genrsa -out \"${OUT_DIR}/server-rogue-key.pem\"\nopenssl req -new \\\n\t-subj \"/C=US/ST=CA/L=SanFrancisco/O=Evil Inc/OU=changeme/CN=changeme/name=changeme/emailAddress=<EMAIL>\" \\\n\t-text \\\n\t-key \"${OUT_DIR}/server-rogue-key.pem\" \\\n\t-out \"${OUT_DIR}/server-rogue.csr\"\n\n# Options for server certificate\ncat > \"${OUT_DIR}/server-rogue-options.cfg\" << 'EOF'\nbasicConstraints=CA:FALSE\nsubjectKeyIdentifier=hash\nauthorityKeyIdentifier=keyid,issuer\nextendedKeyUsage=serverAuth\nsubjectAltName=DNS:*,DNS:localhost,IP:127.0.0.1,IP:::1\nEOF\n\n# Generate the certificate and sign with our CA\nopenssl x509 \\\n\t-req \\\n\t-days 3652 \\\n\t-extfile \"${OUT_DIR}/server-rogue-options.cfg\" \\\n\t-CA \"${OUT_DIR}/ca-rogue.pem\" \\\n\t-CAkey \"${OUT_DIR}/ca-rogue-key.pem\" \\\n\t-nameopt compat \\\n\t-text \\\n\t-in \"${OUT_DIR}/server-rogue.csr\" \\\n\t-out \"${OUT_DIR}/server-rogue-cert.pem\"\n\n# For client authentication, create a client key and certificate signing request\nopenssl genrsa -out \"${OUT_DIR}/client-rogue-key.pem\"\nopenssl req -new \\\n\t-subj \"/C=US/ST=CA/L=SanFrancisco/O=Evil Inc/OU=changeme/CN=changeme/name=changeme/emailAddress=<EMAIL>\" \\\n\t-text \\\n\t-key \"${OUT_DIR}/client-rogue-key.pem\" \\\n\t-out \"${OUT_DIR}/client-rogue.csr\"\n\n# Options for client certificate\ncat > \"${OUT_DIR}/client-rogue-options.cfg\" << 'EOF'\nbasicConstraints=CA:FALSE\nsubjectKeyIdentifier=hash\nauthorityKeyIdentifier=keyid,issuer\nextendedKeyUsage=clientAuth\nsubjectAltName=DNS:*,DNS:localhost,IP:127.0.0.1,IP:::1\nEOF\n\n# Generate the certificate and sign with our CA:\nopenssl x509 \\\n\t-req \\\n\t-days 3652 \\\n\t-extfile \"${OUT_DIR}/client-rogue-options.cfg\" \\\n\t-CA \"${OUT_DIR}/ca-rogue.pem\" \\\n\t-CAkey \"${OUT_DIR}/ca-rogue-key.pem\" \\\n\t-nameopt compat \\\n\t-text \\\n\t-in \"${OUT_DIR}/client-rogue.csr\" \\\n\t-out \"${OUT_DIR}/client-rogue-cert.pem\"\n\nrm \"${OUT_DIR}/ca-rogue.srl\"\nrm \"${OUT_DIR}/ca-rogue-key.pem\"\nrm \"${OUT_DIR}\"/*.cfg\nrm \"${OUT_DIR}\"/*.csr\n```", "metadata": {"source": "github_repository", "repository": "moby/moby", "file_path": "generate-test-rogue-certs.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for  automation", "completion": "```bash\n#!/bin/sh\n# dockerd-rootless.sh executes dockerd in rootless mode.\n#\n# Usage: dockerd-rootless.sh [DOCKERD_OPTIONS]\n#\n# External dependencies:\n# * newuidmap and newgidmap needs to be installed.\n# * /etc/subuid and /etc/subgid needs to be configured for the current user.\n# * Either one of slirp4netns (>= v0.4.0), VPNKit, lxc-user-nic needs to be installed.\n#\n# Recognized environment variables:\n# * DOCKERD_ROOTLESS_ROOTLESSKIT_STATE_DIR=DIR: the rootlesskit state dir. Defaults to \"$XDG_RUNTIME_DIR/dockerd-rootless\".\n# * DOCKERD_ROOTLESS_ROOTLESSKIT_NET=(slirp4netns|vpnkit|pasta|lxc-user-nic): the rootlesskit network driver. Defaults to \"slirp4netns\" if slirp4netns (>= v0.4.0) is installed. Otherwise defaults to \"vpnkit\".\n# * DOCKERD_ROOTLESS_ROOTLESSKIT_MTU=NUM: the MTU value for the rootlesskit network driver. Defaults to 65520 for slirp4netns, 1500 for other drivers.\n# * DOCKERD_ROOTLESS_ROOTLESSKIT_PORT_DRIVER=(builtin|slirp4netns|implicit): the rootlesskit port driver. Defaults to \"builtin\".\n# * DOCKERD_ROOTLESS_ROOTLESSKIT_SLIRP4NETNS_SANDBOX=(auto|true|false): whether to protect slirp4netns with a dedicated mount namespace. Defaults to \"auto\".\n# * DOCKERD_ROOTLESS_ROOTLESSKIT_SLIRP4NETNS_SECCOMP=(auto|true|false): whether to protect slirp4netns with seccomp. Defaults to \"auto\".\n# * DOCKERD_ROOTLESS_ROOTLESSKIT_DISABLE_HOST_LOOPBACK=(true|false): prohibit connections to 127.0.0.1 on the host (including via 10.0.2.2, in the case of slirp4netns). Defaults to \"true\".\n\n# To apply an environment variable via systemd, create ~/.config/systemd/user/docker.service.d/override.conf as follows,\n# and run `systemctl --user daemon-reload && systemctl --user restart docker`:\n# --- BEGIN ---\n# [Service]\n# Environment=\"DOCKERD_ROOTLESS_ROOTLESSKIT_NET=pasta\"\n# Environment=\"DOCKERD_ROOTLESS_ROOTLESSKIT_PORT_DRIVER=implicit\"\n# ---  END  ---\n\n# Guide to choose the network driver and the port driver:\n#\n#  Network driver | Port driver    | Net throughput | Port throughput | Src IP | No SUID | Note\n#  ---------------|----------------|----------------|-----------------|--------|---------|---------------------------------------------------------\n#  slirp4netns    | builtin        | Slow           | Fast ✅         | ❌     | ✅      | Default in typical setup\n#  vpnkit         | builtin        | Slow           | Fast ✅         | ❌     | ✅      | Default when slirp4netns is not installed\n#  slirp4netns    | slirp4netns    | Slow           | Slow            | ✅     | ✅      |\n#  pasta          | implicit       | Slow           | Fast ✅         | ✅     | ✅      | Experimental; Needs recent version of pasta (2023_12_04)\n#  lxc-user-nic   | builtin        | Fast ✅        | Fast ✅         | ❌     | ❌      | Experimental\n#  (bypass4netns) | (bypass4netns) | Fast ✅        | Fast ✅         | ✅     | ✅      | (Not integrated to RootlessKit)\n\n# See the documentation for the further information: https://docs.docker.com/go/rootless/\n\nset -e -x\ncase \"$1\" in\n\t\"check\" | \"install\" | \"uninstall\")\n\t\techo \"Did you mean 'dockerd-rootless-setuptool.sh $@' ?\"\n\t\texit 1\n\t\t;;\nesac\nif ! [ -w \"$XDG_RUNTIME_DIR\" ]; then\n\techo \"XDG_RUNTIME_DIR needs to be set and writable\"\n\texit 1\nfi\nif ! [ -d \"$HOME\" ]; then\n\techo \"HOME needs to be set and exist.\"\n\texit 1\nfi\n\nmount_directory() {\n\tif [ -z \"$_DOCKERD_ROOTLESS_CHILD\" ]; then\n\t\techo \"mount_directory should be called from the child context. Otherwise data loss is at risk\" >&2\n\t\texit 1\n\tfi\n\n\tDIRECTORY=\"$1\"\n\tif [ ! -d \"$DIRECTORY\" ]; then\n\t\treturn\n\tfi\n\n\t# Bind mount directory: this makes this directory visible to\n\t# Dockerd, even if it is originally a symlink, given Dockerd does\n\t# not always follow symlinks. Some directories might also be\n\t# \"copied-up\", meaning that they will also be writable on the child\n\t# namespace; this will be the case only if they are provided as\n\t# --copy-up to the rootlesskit.\n\tDIRECTORY_REALPATH=$(realpath \"$DIRECTORY\")\n\tMOUNT_OPTIONS=\"${2:---bind}\"\n\trm -rf \"$DIRECTORY\"\n\tmkdir -p \"$DIRECTORY\"\n\tmount $MOUNT_OPTIONS \"$DIRECTORY_REALPATH\" \"$DIRECTORY\"\n}\n\nrootlesskit=\"\"\nfor f in docker-rootlesskit rootlesskit; do\n\tif command -v $f > /dev/null 2>&1; then\n\t\trootlesskit=$f\n\t\tbreak\n\tfi\ndone\nif [ -z \"$rootlesskit\" ]; then\n\techo \"rootlesskit needs to be installed\"\n\texit 1\nfi\n\n: \"${DOCKERD_ROOTLESS_ROOTLESSKIT_STATE_DIR:=$XDG_RUNTIME_DIR/dockerd-rootless}\"\n: \"${DOCKERD_ROOTLESS_ROOTLESSKIT_NET:=}\"\n: \"${DOCKERD_ROOTLESS_ROOTLESSKIT_MTU:=}\"\n: \"${DOCKERD_ROOTLESS_ROOTLESSKIT_PORT_DRIVER:=builtin}\"\n: \"${DOCKERD_ROOTLESS_ROOTLESSKIT_SLIRP4NETNS_SANDBOX:=auto}\"\n: \"${DOCKERD_ROOTLESS_ROOTLESSKIT_SLIRP4NETNS_SECCOMP:=auto}\"\n: \"${DOCKERD_ROOTLESS_ROOTLESSKIT_DISABLE_HOST_LOOPBACK:=}\"\nnet=$DOCKERD_ROOTLESS_ROOTLESSKIT_NET\nmtu=$DOCKERD_ROOTLESS_ROOTLESSKIT_MTU\nif [ -z \"$net\" ]; then\n\tif command -v slirp4netns > /dev/null 2>&1; then\n\t\t# If --netns-type is present in --help, slirp4netns is >= v0.4.0.\n\t\tif slirp4netns --help | grep -qw -- --netns-type; then\n\t\t\tnet=slirp4netns\n\t\t\tif [ -z \"$mtu\" ]; then\n\t\t\t\tmtu=65520\n\t\t\tfi\n\t\telse\n\t\t\techo \"slirp4netns found but seems older than v0.4.0. Falling back to VPNKit.\"\n\t\tfi\n\tfi\n\tif [ -z \"$net\" ]; then\n\t\tif command -v vpnkit > /dev/null 2>&1; then\n\t\t\tnet=vpnkit\n\t\telse\n\t\t\techo \"Either slirp4netns (>= v0.4.0) or vpnkit needs to be installed\"\n\t\t\texit 1\n\t\tfi\n\tfi\nfi\nif [ -z \"$mtu\" ]; then\n\tmtu=1500\nfi\n\nhost_loopback=\"--disable-host-loopback\"\nif [ \"$DOCKERD_ROOTLESS_ROOTLESSKIT_DISABLE_HOST_LOOPBACK\" = \"false\" ]; then\n\thost_loopback=\"\"\nfi\n\ndockerd=\"${DOCKERD:-dockerd}\"\n\nif [ -z \"$_DOCKERD_ROOTLESS_CHILD\" ]; then\n\t_DOCKERD_ROOTLESS_CHILD=1\n\texport _DOCKERD_ROOTLESS_CHILD\n\tif [ \"$(id -u)\" = \"0\" ]; then\n\t\techo \"This script must be executed as a non-privileged user\"\n\t\texit 1\n\tfi\n\t# `selinuxenabled` always returns false in RootlessKit child, so we execute `selinuxenabled` in the parent.\n\t# https://github.com/rootless-containers/rootlesskit/issues/94\n\tif command -v selinuxenabled > /dev/null 2>&1 && selinuxenabled; then\n\t\t_DOCKERD_ROOTLESS_SELINUX=1\n\t\texport _DOCKERD_ROOTLESS_SELINUX\n\tfi\n\t# Re-exec the script via RootlessKit, so as to create unprivileged {user,mount,network} namespaces.\n\t#\n\t# --copy-up allows removing/creating files in the directories by creating tmpfs and symlinks\n\t# * /etc: copy-up is required so as to prevent `/etc/resolv.conf` in the\n\t#         namespace from being unexpectedly unmounted when `/etc/resolv.conf` is recreated on the host\n\t#         (by either systemd-networkd or NetworkManager)\n\t# * /run: copy-up is required so that we can create /run/docker (hardcoded for plugins) in our namespace\n\texec $rootlesskit \\\n\t\t--state-dir=$DOCKERD_ROOTLESS_ROOTLESSKIT_STATE_DIR \\\n\t\t--net=$net --mtu=$mtu \\\n\t\t--slirp4netns-sandbox=$DOCKERD_ROOTLESS_ROOTLESSKIT_SLIRP4NETNS_SANDBOX \\\n\t\t--slirp4netns-seccomp=$DOCKERD_ROOTLESS_ROOTLESSKIT_SLIRP4NETNS_SECCOMP \\\n\t\t$host_loopback --port-driver=$DOCKERD_ROOTLESS_ROOTLESSKIT_PORT_DRIVER \\\n\t\t--copy-up=/etc --copy-up=/run \\\n\t\t--propagation=rslave \\\n\t\t$DOCKERD_ROOTLESS_ROOTLESSKIT_FLAGS \\\n\t\t\"$0\" \"$@\"\nelse\n\t[ \"$_DOCKERD_ROOTLESS_CHILD\" = 1 ]\n\n\t# The Container Device Interface (CDI) specs can be found by default\n\t# under {/etc,/var/run}/cdi. More information at:\n\t# https://github.com/cncf-tags/container-device-interface\n\t#\n\t# In order to use the Container Device Interface (CDI) integration,\n\t# the CDI paths need to exist before the Docker daemon is started in\n\t# order for it to read the CDI specification files. Otherwise, a\n\t# Docker daemon restart will be required for the daemon to discover\n\t# them.\n\t#\n\t# If another set of CDI paths (other than the default /etc/cdi and\n\t# /var/run/cdi) are configured through the Docker configuration file\n\t# (using \"cdi-spec-dirs\"), they need to be bind mounted in rootless\n\t# mode; otherwise the Docker daemon won't have access to the CDI\n\t# specification files.\n\tmount_directory /etc/cdi\n\tmount_directory /var/run/cdi\n\n\t# remove the symlinks for the existing files in the parent namespace if any,\n\t# so that we can create our own files in our mount namespace.\n\trm -f /run/docker /run/containerd /run/xtables.lock\n\n\tif [ -n \"$_DOCKERD_ROOTLESS_SELINUX\" ]; then\n\t\t# iptables requires /run in the child to be relabeled. The actual /run in the parent is unaffected.\n\t\t# https://github.com/containers/podman/blob/<TOKEN>/libpod/networking_linux.go#L396-L401\n\t\t# https://github.com/moby/moby/issues/41230\n\t\tchcon system_u:object_r:iptables_var_run_t:s0 /run\n\tfi\n\n\tif [ \"$(stat -c %T -f /etc)\" = \"tmpfs\" ] && [ -L \"/etc/ssl\" ]; then\n\t\t# Workaround for \"x509: certificate signed by unknown authority\" on openSUSE Tumbleweed.\n\t\t# https://github.com/rootless-containers/rootlesskit/issues/225\n\t\tmount_directory /etc/ssl \"--rbind\"\n\tfi\n\n\texec \"$dockerd\" \"$@\"\nfi\n```", "metadata": {"source": "github_repository", "repository": "moby/moby", "file_path": "dockerd-rootless.sh", "category": "containerization", "authentic": true}}
{"prompt": "Create a shell script for Kubernetes cluster automation", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2014 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# GoFmt apparently is changing @ head...\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\nKUBE_ROOT=$(dirname \"${BASH_SOURCE[0]}\")/..\nsource \"${KUBE_ROOT}/hack/lib/init.sh\"\n\nkube::golang::setup_env\n\ncd \"${KUBE_ROOT}\"\n\nfunction git_find() {\n    # Similar to find but faster and easier to understand.  We want to include\n    # modified and untracked files because this might be running against code\n    # which is not tracked by git yet.\n    git ls-files -cmo --exclude-standard \\\n        ':!:vendor/*'        `# catches vendor/...` \\\n        ':!:*/vendor/*'      `# catches any subdir/vendor/...` \\\n        ':!:third_party/*'   `# catches third_party/...` \\\n        ':!:*/third_party/*' `# catches third_party/...` \\\n        ':!:*/testdata/*'    `# catches any subdir/testdata/...` \\\n        ':(glob)**/*.go' \\\n        \"$@\"\n}\n\ngit_find -z | xargs -0 gofmt -s -w\n```", "metadata": {"source": "github_repository", "repository": "kubernetes/kubernetes", "file_path": "update-gofmt.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for Kubernetes resource management", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2014 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This script builds some binaries and then the conformance image.\n# REGISTRY and VERSION must be set.\n# Example usage:\n#   $ export REGISTRY=gcr.io/someone\n#   $ export VERSION=v1.4.0-testfix\n#   ./hack/dev-push-conformance.sh\n# That will build and push gcr.io/someone/conformance-amd64:v1.4.0-testfix\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\nKUBE_ROOT=\"$(dirname \"${BASH_SOURCE[0]}\")/..\"\nsource \"${KUBE_ROOT}/build/common.sh\"\n\nif [[ -z \"${REGISTRY:-}\" ]]; then\n\techo \"REGISTRY must be set\"\n\texit 1\nfi\nif [[ -z \"${VERSION:-}\" ]]; then\n\techo \"VERSION must be set\"\n\texit 1\nfi\n\nIMAGE=\"${REGISTRY}/conformance-amd64:${VERSION}\"\n\nkube::build::verify_prereqs\nkube::build::build_image\nkube::build::run_build_command make WHAT=\"github.com/onsi/ginkgo/v2/ginkgo test/e2e/e2e.test cmd/kubectl test/conformance/image/go-runner\"\nkube::build::copy_output\n\nmake -C \"${KUBE_ROOT}/test/conformance/image\" build\ndocker push \"${IMAGE}\"\n```", "metadata": {"source": "github_repository", "repository": "kubernetes/kubernetes", "file_path": "dev-push-conformance.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for Kubernetes cluster automation", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright 2016 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Script to fetch latest openapi spec.\n# Puts the updated spec at api/openapi-spec/\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\nKUBE_ROOT=$(dirname \"${BASH_SOURCE[0]}\")/..\nDISCOVERY_ROOT_DIR=\"${KUBE_ROOT}/api/discovery\"\nOPENAPI_ROOT_DIR=\"${KUBE_ROOT}/api/openapi-spec\"\nsource \"${KUBE_ROOT}/hack/lib/init.sh\"\n\nkube::util::require-jq\nkube::golang::setup_env\nkube::etcd::install\n\n# We need to call `make` here because that includes all of the compile and link\n# flags that we use for a production build, which we need for this script.\nmake -C \"${KUBE_ROOT}\" WHAT=cmd/kube-apiserver\n\nfunction cleanup()\n{\n    if [[ -n ${APISERVER_PID-} ]]; then\n      kill \"${APISERVER_PID}\" 1>&2 2>/dev/null\n      wait \"${APISERVER_PID}\" || true\n    fi\n    unset APISERVER_PID\n\n    kube::etcd::cleanup\n\n    kube::log::status \"Clean up complete\"\n}\n\ntrap cleanup EXIT SIGINT\n\nTMP_DIR=${TMP_DIR:-$(kube::realpath \"$(mktemp -d -t \"$(basename \"$0\").XXXXXX\")\")}\nETCD_HOST=${ETCD_HOST:-127.0.0.1}\nETCD_PORT=${ETCD_PORT:-2379}\nAPI_PORT=${API_PORT:-8050}\nAPI_HOST=${API_HOST:-127.0.0.1}\nAPI_LOGFILE=${API_LOGFILE:-${TMP_DIR}/openapi-api-server.log}\n\nkube::etcd::start\n\necho \"dummy_token,admin,admin\" > \"${TMP_DIR}/tokenauth.csv\"\n\n# setup envs for TokenRequest required flags\nSERVICE_ACCOUNT_LOOKUP=${SERVICE_ACCOUNT_LOOKUP:-true}\nSERVICE_ACCOUNT_KEY=${SERVICE_ACCOUNT_KEY:-${TMP_DIR}/kube-serviceaccount.key}\n# Generate ServiceAccount key if needed\nif [[ ! -f \"${SERVICE_ACCOUNT_KEY}\" ]]; then\n  mkdir -p \"$(dirname \"${SERVICE_ACCOUNT_KEY}\")\"\n  openssl genrsa -out \"${SERVICE_ACCOUNT_KEY}\" 2048 2>/dev/null\nfi\n\n# Start kube-apiserver\n# omit enums from static openapi snapshots used to generate clients until #109177 is resolved\nkube::log::status \"Starting kube-apiserver\"\n# KUBE_APISERVER_STRICT_REMOVED_API_HANDLING_IN_ALPHA ensures that the OpenAPI is updated with all APIs\n# that are intended to be removed at a particular release during alpha.\n# If a new version tag was just created and you are seeing an unrelated diff when adding\n# a new API, run `KUBE_APISERVER_STRICT_REMOVED_API_HANDLING_IN_ALPHA=false ./hack/update-openapi-spec.sh`.\nKUBE_APISERVER_STRICT_REMOVED_API_HANDLING_IN_ALPHA=${KUBE_APISERVER_STRICT_REMOVED_API_HANDLING_IN_ALPHA:-true} kube-apiserver \\\n  --bind-address=\"${API_HOST}\" \\\n  --secure-port=\"${API_PORT}\" \\\n  --etcd-servers=\"http://${ETCD_HOST}:${ETCD_PORT}\" \\\n  --advertise-address=\"10.10.10.10\" \\\n  --cert-dir=\"${TMP_DIR}/certs\" \\\n  --feature-gates=AllAlpha=true,AllBeta=true,OpenAPIEnums=false \\\n  --runtime-config=\"api/all=true\" \\\n  --token-auth-file=\"${TMP_DIR}/tokenauth.csv\" \\\n  --authorization-mode=RBAC \\\n  --service-account-key-file=\"${SERVICE_ACCOUNT_KEY}\" \\\n  --service-account-lookup=\"${SERVICE_ACCOUNT_LOOKUP}\" \\\n  --service-account-issuer=\"https://kubernetes.default.svc\" \\\n  --service-account-signing-key-file=\"${SERVICE_ACCOUNT_KEY}\" \\\n  --enable-logs-handler=true \\\n  --v=2 \\\n  --service-cluster-ip-range=\"10.0.0.0/24\" >\"${API_LOGFILE}\" 2>&1 &\nAPISERVER_PID=$!\n\nif ! kube::util::wait_for_url \"https://${API_HOST}:${API_PORT}/healthz\" \"apiserver: \"; then\n  kube::log::error \"Here are the last 10 lines from kube-apiserver (${API_LOGFILE})\"\n  kube::log::error \"=== BEGIN OF LOG ===\"\n  tail -10 \"${API_LOGFILE}\" >&2 || :\n  kube::log::error \"=== END OF LOG ===\"\n  exit 1\nfi\n\nkube::log::status \"Updating aggregated discovery\"\n\nrm -fr \"${DISCOVERY_ROOT_DIR}\"\nmkdir -p \"${DISCOVERY_ROOT_DIR}\"\ncurl -kfsS -H 'Authorization: Bearer dummy_token' -H 'Accept: application/json;g=apidiscovery.k8s.io;v=v2;as=APIGroupDiscoveryList' \"https://${API_HOST}:${API_PORT}/apis\" | jq -S . > \"${DISCOVERY_ROOT_DIR}/aggregated_v2.json\"\n\nkube::log::status \"Updating \" \"${OPENAPI_ROOT_DIR} for OpenAPI v2\"\n\nrm -f \"${OPENAPI_ROOT_DIR}/swagger.json\"\ncurl -w \"\\n\" -kfsS -H 'Authorization: Bearer dummy_token' \\\n  \"https://${API_HOST}:${API_PORT}/openapi/v2\" \\\n  | jq -S '.info.version=\"unversioned\"' \\\n  > \"${OPENAPI_ROOT_DIR}/swagger.json\"\n\nkube::log::status \"Updating \" \"${OPENAPI_ROOT_DIR}/v3 for OpenAPI v3\"\n\nmkdir -p \"${OPENAPI_ROOT_DIR}/v3\"\n# clean up folder, note that some files start with dot like\n# \".well-known__openid-configuration_openapi.json\"\nrm -r \"${OPENAPI_ROOT_DIR}\"/v3/{*,.*} || true\n\nrm -rf \"${OPENAPI_ROOT_DIR}/v3/*\"\ncurl -w \"\\n\" -kfsS -H 'Authorization: Bearer dummy_token' \\\n  \"https://${API_HOST}:${API_PORT}/openapi/v3\" \\\n  | jq -r '.paths | to_entries | .[].key' \\\n  | while read -r group; do\n    kube::log::status \"Updating OpenAPI spec and discovery for group ${group}\"\n    OPENAPI_FILENAME=\"${group}_openapi.json\"\n    OPENAPI_FILENAME_ESCAPED=\"${OPENAPI_FILENAME//\\//__}\"\n    OPENAPI_PATH=\"${OPENAPI_ROOT_DIR}/v3/${OPENAPI_FILENAME_ESCAPED}\"\n    curl -w \"\\n\" -kfsS -H 'Authorization: Bearer dummy_token' \\\n      \"https://${API_HOST}:${API_PORT}/openapi/v3/{$group}\" \\\n      | jq -S '.info.version=\"unversioned\"' \\\n      > \"$OPENAPI_PATH\"\n\n    if [[ \"${group}\" == \"api\"* ]]; then\n      DISCOVERY_FILENAME=\"${group}.json\"\n      DISCOVERY_FILENAME_ESCAPED=\"${DISCOVERY_FILENAME//\\//__}\"\n      DISCOVERY_PATH=\"${DISCOVERY_ROOT_DIR}/${DISCOVERY_FILENAME_ESCAPED}\"\n      curl -kfsS -H 'Authorization: Bearer dummy_token' \"https://${API_HOST}:${API_PORT}/{$group}\" | jq -S . > \"$DISCOVERY_PATH\"\n    fi\ndone\n\nkube::log::status \"SUCCESS\"\n\n# ex: ts=2 sw=2 et filetype=sh\n```", "metadata": {"source": "github_repository", "repository": "kubernetes/kubernetes", "file_path": "update-openapi-spec.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script to install and setup Kubernetes cluster", "completion": "```bash\n#!/bin/bash\n\n# Copyright 2021 The Kubernetes Authors All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -eux -o pipefail\n\nfunction install_gotestsum() {\n  rm -f $(which gotestsum)\n  GOBIN=\"$GOROOT/bin\" go install gotest.tools/gotestsum@v1.12.3\n}\n\nwhich gotestsum || install_gotestsum\n```", "metadata": {"source": "github_repository", "repository": "kubernetes/minikube", "file_path": "check_install_gotestsum.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script to build Kubernetes cluster components", "completion": "```bash\n#!/bin/bash\n\n# Copyright 2022 The Kubernetes Authors All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -eux -o pipefail\n\nif [ \"$#\" -ne 1 ]; then\n  echo \"Usage: build_auto_pause.sh <archlist>\" >&2\n  exit 1\nfi\n\narchlist=$1\nIFS=, read -a archarray <<< \"$archlist\"\n\npushd cmd/auto-pause\n\nfor (( i=0; i < ${#archarray[*]}; i++ ))\ndo\n\tarch=${archarray[i]#\"linux/\"}\n\tenv GOOS=linux GOARCH=$arch CGO_ENABLED=0 go build -o auto-pause-$arch\ndone\npopd\n```", "metadata": {"source": "github_repository", "repository": "kubernetes/minikube", "file_path": "build_auto_pause.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for Kubernetes resource management", "completion": "```bash\n#!/bin/bash\n\n# Copyright 2021 The Kubernetes Authors All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Gather data comparing the overhead of multiple local Kubernetes (macOS and linux)\nreadonly TESTS=$1\n\n# How many iterations to cycle through\nreadonly TEST_ITERATIONS=10\n\n# How long to poll CPU usage for (each point is an average over this period)\nreadonly POLL_DURATION=5s\n\n# How long to measure background usage for. 5 minutes too short, 10 minutes too long\nreadonly TOTAL_DURATION=5m\n\n# How all tests will be identified\nreadonly SESSION_ID=\"$(date +%Y%m%d-%H%M%S)-$$\"\n\n# OS Type\nreadonly OS=$(uname)\n\nmeasure() {\n  local name=$1\n  local iteration=$2\n  local filename=\"benchmark-results/${SESSION_ID}/cstat.${name}.$$-${iteration}\"\n\n  echo \"\"\n  echo \"  >> Current top processes by CPU:\"\n  if [[ \"${OS}\" == \"Darwin\" ]]; then\n    top -n 3 -l 2 -s 2 -o cpu  | tail -n4 | awk '{ print $1 \" \" $2 \" \" $3 \" \" $4 }'\n  elif [[ \"${OS}\" == \"Linux\" ]]; then\n    top -b -n 3 -o %CPU | head -n 9\n  fi\n\n  if [[ \"${iteration}\" == 0 ]]; then\n    echo \"NOTE: dry-run iteration: will not record measurements\"\n    cstat --poll \"${POLL_DURATION}\" --for \"${POLL_DURATION}\" --busy\n    return\n  fi\n\n  echo \"\"\n  echo \"  >> Measuring ${name} and saving to out/${filename} ...\"\n  cstat --poll \"${POLL_DURATION}\" --for \"${TOTAL_DURATION}\" --busy --header=false | tee \"$(pwd)/out/${filename}\"\n}\n\n\ncleanup() {\n  echo \"  >> Deleting local clusters and Docker containers ...\"\n  out/minikube delete --all 2>/dev/null >/dev/null\n  k3d cluster delete 2>/dev/null >/dev/null\n  kind delete cluster 2>/dev/null >/dev/null\n  docker stop $(docker ps -q) 2>/dev/null\n  docker kill $(docker ps -q) 2>/dev/null\n  docker rm $(docker ps -a -q) 2>/dev/null\n  sleep 2\n}\n\npause_if_running_apps() {\n  while true; do\n    local apps=$(osascript -e 'tell application \"System Events\" to get name of (processes where background only is false)'  | tr ',' '\\n' | sed s/\"^ \"//g)\n    local quiet=0\n\n    for app in $apps; do\n      quiet=1\n      if [[ \"${app}\" != \"Terminal\" && \"${app}\" != \"Finder\" ]]; then\n        echo \"Unexpected application running: \\\"${app}\\\" - will sleep\"\n        quiet=0\n      fi\n    done\n\n    pmset -g batt | grep 'AC Power'\n    if [[ \"$?\" != 0 ]]; then\n      echo \"waiting to be plugged in ...\"\n      sleep 5\n      continue\n    fi\n\n    if [[ \"${quiet}\" == 1 ]]; then\n      break\n    else\n      echo \"waiting for apps to be closed ...\"\n      sleep 5\n    fi\n\n  done\n}\n\nfail() {\n  local name=$1\n  local iteration=$2\n\n  echo '***********************************************************************'\n  echo \"${name} failed on iteration ${iteration} - will not record measurement\"\n  echo '***********************************************************************'\n\n  if [[ \"${iteration}\" == 0 ]]; then\n    echo \"test environment appears invalid, exiting\"\n    exit 90\n  fi\n}\n\nstart_docker() {\n    local docker_up=0\n    local started=0\n\n    while [[ \"${docker_up}\" == 0 ]]; do\n      docker info >/dev/null && docker_up=1 || docker_up=0\n\n      if [[ \"${docker_up}\" == 0 && \"${started}\" == 0 ]]; then\n          if [[ \"${OS}\" == \"Darwin\" ]]; then\n            echo \"\"\n            echo \"  >> Starting Docker for Desktop ...\"\n            open -a Docker\n            started=1\n          elif [[ \"${OS}\" == \"Linux\" ]]; then\n            echo \"\"\n            echo \"  >> Starting Docker Engine ...\"\n            sudo systemctl start docker\n            started=1\n          fi\n      fi\n\n      sleep 1\n    done\n\n    # Give time for d4d Kubernetes to begin, if it's around\n    if [[ \"${started}\" == 1 ]]; then\n      sleep 60\n    fi\n}\n\n\nmain() {\n  # check if cstat is installed\n  CSTAT=$(which cstat)\n  if [[ \"$?\" != 0 ]]; then\n    echo \"cstat in not installed. Install cstat at https://github.com/tstromberg/cstat\"\n    exit 1\n  fi\n\n  echo \"----[ versions ]------------------------------------\"\n  k3d version || { echo \"k3d version failed. Please install latest k3d\"; exit 1; }\n  kind version || { echo \"kind version failed. Please install latest kind\"; exit 1; }\n  out/minikube version || { echo \"minikube version failed\"; exit 1; }\n  docker version\n  echo \"----------------------------------------------------\"\n  echo \"\"\n\n  echo \"Session ID: ${SESSION_ID}\"\n  mkdir -p \"out/benchmark-results/${SESSION_ID}\"\n\n  echo \"\"\n\n  if [[ \"${OS}\" == \"Darwin\" ]]; then\n    echo \"Turning on Wi-Fi for initial downloads\"\n    networksetup -setairportpower Wi-Fi on\n  fi\n\n  for i in $(seq 0 ${TEST_ITERATIONS}); do\n    echo \"\"\n    echo \"==> session ${SESSION_ID}, iteration $i\"\n\n    cleanup\n\n    if [[ \"$i\" = 0 ]]; then\n      echo \"NOTE: The 0 iteration is an unmeasured dry run!\"\n    else\n      if [[ \"${OS}\" == \"Darwin\" ]]; then\n        pause_if_running_apps\n        echo \"Turning off Wi-Fi to remove background noise\"\n        networksetup -setairportpower Wi-Fi off\n\n        echo \"  >> Killing Docker for Desktop ...\"\n        osascript -e 'quit app \"Docker\"'\n      elif [[ \"${OS}\" == \"Linux\" ]]; then\n        echo \"  >> Killing Docker Engine ...\"\n        sudo systemctl stop docker\n      fi\n\n      # Measure the background noise on this system\n      sleep 15\n      measure idle $i\n    fi\n\n    # Run cleanup once we can assert that Docker is up\n    start_docker\n    cleanup\n\n    docker_k8s=0\n    # depending on whether Docker for Mac Kubernetes is enabled\n    if [[ \"${OS}\" == \"Darwin\" ]]; then\n      # wait kubernetes system pods for Docker for Mac, if it is enabled\n      sleep 60\n      kubectl --context docker-desktop version\n\n      # measure Docker for Mac Kubernetes\n      if  [[ $? == 0 ]]; then\n        echo \"Kubernetes is running in Docker for Desktop - adjusting tests\"\n        docker_k8s=1\n        measure docker_k8s $i\n      # measure Docker idle\n      else\n        measure docker $i\n      fi\n    # measure Docker idle only\n    elif [[ \"${OS}\" == \"Linux\" ]]; then\n      measure docker $i\n    fi\n\n    # measure k3d and kind\n    echo \"\"\n    echo \"-> k3d\"\n    time k3d cluster create && measure k3d $i || fail k3d $i\n    cleanup\n\n    echo \"\"\n    echo \"-> kind\"\n    time kind create cluster && measure kind $i || fail kind $i\n    cleanup\n\n    # test different drivers\n    if [[ \"${OS}\" == \"Darwin\" ]]; then\n      drivers=(docker hyperkit virtualbox)\n    elif [[ \"${OS}\" == \"Linux\" ]]; then\n      drivers=(docker kvm2 virtualbox)\n    fi\n\n    for driver in \"${drivers[@]}\"; do\n      echo \"\"\n      echo \"-> out/minikube --driver=${driver}\"\n      time out/minikube start --driver \"${driver}\" && measure \"minikube.${driver}\" $i || fail \"minikube.${driver}\" $i\n      cleanup\n\n      # We won't be needing docker for the remaining tests this iteration\n      if [[ \"${OS}\" == \"Darwin\" && \"${driver}\" == \"docker\" ]]; then\n        echo \"  >> Quitting Docker for Desktop ...\"\n        osascript -e 'quit app \"Docker\"'\n      elif [[ \"${OS}\" == \"Linux\" && ${driver} == \"docker\" ]]; then\n        echo \"  >> Quitting Docker Engine ...\"\n        sudo systemctl stop docker\n      fi\n    done ## driver\n  done ## iteration\n}\n\nmain \"$@\"\n# update benchmark result into docs contents\n./hack/benchmark/cpu_usage/idle_only/update_summary.sh \"${SESSION_ID}\"\ngo run ./hack/benchmark/cpu_usage/idle_only/chart.go \"${SESSION_ID}\"\n```", "metadata": {"source": "github_repository", "repository": "kubernetes/minikube", "file_path": "benchmark_local_k8s.sh", "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for Kubernetes cluster testing automation", "completion": "```bash\n#!/bin/bash\n\n# Copyright 2019 The Kubernetes Authors All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# This script runs the integration tests on a Linux machine for the KVM Driver\n\n# The script expects the following env variables:\n# MINIKUBE_LOCATION: GIT_COMMIT from upstream build.\n# COMMIT: Actual commit ID from upstream build\n# EXTRA_BUILD_ARGS (optional): Extra args to be passed into the minikube integrations tests\n# access_token: The GitHub API access token. Injected by the Jenkins credential provider.\n\nset -e\n\nOS=\"linux\"\nARCH=\"amd64\"\nDRIVER=\"kvm2\"\nJOB_NAME=\"KVM_Linux_crio\"\nCONTAINER_RUNTIME=\"crio\"\n\nsudo apt-get update\nsudo apt-get -y install qemu-system libvirt-clients libvirt-daemon-system ebtables iptables dnsmasq\nsudo adduser jenkins libvirt || true\n\nsource ./common.sh\n```", "metadata": {"source": "github_repository", "repository": "kubernetes/minikube", "file_path": "linux_integration_tests_kvm_crio.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for Kubernetes cluster testing automation", "completion": "```bash\n#!/bin/bash\n\n# Copyright 2018 The Kubernetes Authors All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfor pkg in $(go list ./pkg/minikube/...); do\n    #we are assuming that the runner has NOPASSWD sudoer\n    go test -v $pkg -tags integration\ndone\n```", "metadata": {"source": "github_repository", "repository": "kubernetes/minikube", "file_path": "unix_white_box_integration_tests.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for  release automation", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright The Helm Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nRELEASE=${RELEASE:-$2}\nPREVIOUS_RELEASE=${PREVIOUS_RELEASE:-$1}\n\n## Ensure Correct Usage\nif [[ -z \"${PREVIOUS_RELEASE}\" || -z \"${RELEASE}\" ]]; then\n  echo Usage:\n  echo ./scripts/release-notes.sh v3.0.0 v3.1.0\n  echo or\n  echo PREVIOUS_RELEASE=v3.0.0\n  echo RELEASE=v3.1.0\n  echo ./scripts/release-notes.sh\n  exit 1\nfi\n\n## validate git tags\nfor tag in $RELEASE $PREVIOUS_RELEASE; do\n  OK=$(git tag -l ${tag} | wc -l)\n  if [[ \"$OK\" == \"0\" ]]; then\n    echo ${tag} is not a valid release version\n    exit 1\n  fi\ndone\n\n## Check for hints that checksum files were downloaded\n## from `make fetch-dist`\nif [[ ! -e \"./_dist/helm-${RELEASE}-darwin-amd64.tar.gz.sha256sum\" ]]; then\n  echo \"checksum file ./_dist/helm-${RELEASE}-darwin-amd64.tar.gz.sha256sum not found in ./_dist/\"\n  echo \"Did you forget to run \\`make fetch-dist\\` first ?\"\n  exit 1\nfi\n\n## Generate CHANGELOG from git log\nCHANGELOG=$(git log --no-merges --pretty=format:'- %s %H (%aN)' ${PREVIOUS_RELEASE}..${RELEASE})\nif [[ ! $? -eq 0 ]]; then\n  echo \"Error creating changelog\"\n  echo \"try running \\`git log --no-merges --pretty=format:'- %s %H (%aN)' ${PREVIOUS_RELEASE}..${RELEASE}\\`\"\n  exit 1\nfi\n\n## guess at MAJOR / MINOR / PATCH versions\nMAJOR=$(echo ${RELEASE} | sed 's/^v//' | cut -f1 -d.)\nMINOR=$(echo ${RELEASE} | sed 's/^v//' | cut -f2 -d.)\nPATCH=$(echo ${RELEASE} | sed 's/^v//' | cut -f3 -d.)\n\n## Print release notes to stdout\ncat <<EOF\n## ${RELEASE}\n\nHelm ${RELEASE} is a feature release. This release, we focused on <insert focal point>. Users are encouraged to upgrade for the best experience.\n\nThe community keeps growing, and we'd love to see you there!\n\n- Join the discussion in [Kubernetes Slack](https://kubernetes.slack.com):\n  - `#helm-users` for questions and just to hang out\n  - `#helm-dev` for discussing PRs, code, and bugs\n- Hang out at the Public Developer Call: Thursday, 9:30 Pacific via [Zoom](https://zoom.us/j/696660622)\n- Test, debug, and contribute charts: [ArtifactHub/packages](https://artifacthub.io/packages/search?kind=0)\n\n## Notable Changes\n\n- Add list of\n- notable changes here\n\n## Installation and Upgrading\n\nDownload Helm ${RELEASE}. The common platform binaries are here:\n\n- [MacOS amd64](https://get.helm.sh/helm-${RELEASE}-darwin-amd64.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-darwin-amd64.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-darwin-amd64.tar.gz.sha256))\n- [MacOS arm64](https://get.helm.sh/helm-${RELEASE}-darwin-arm64.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-darwin-arm64.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-darwin-arm64.tar.gz.sha256))\n- [Linux amd64](https://get.helm.sh/helm-${RELEASE}-linux-amd64.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-linux-amd64.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-linux-amd64.tar.gz.sha256))\n- [Linux arm](https://get.helm.sh/helm-${RELEASE}-linux-arm.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-linux-arm.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-linux-arm.tar.gz.sha256))\n- [Linux arm64](https://get.helm.sh/helm-${RELEASE}-linux-arm64.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-linux-arm64.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-linux-arm64.tar.gz.sha256))\n- [Linux i386](https://get.helm.sh/helm-${RELEASE}-linux-386.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-linux-386.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-linux-386.tar.gz.sha256))\n- [Linux ppc64le](https://get.helm.sh/helm-${RELEASE}-linux-ppc64le.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-linux-ppc64le.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-linux-ppc64le.tar.gz.sha256))\n- [Linux s390x](https://get.helm.sh/helm-${RELEASE}-linux-s390x.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-linux-s390x.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-linux-s390x.tar.gz.sha256))\n- [Linux riscv64](https://get.helm.sh/helm-${RELEASE}-linux-riscv64.tar.gz) ([checksum](https://get.helm.sh/helm-${RELEASE}-linux-riscv64.tar.gz.sha256sum) / $(cat _dist/helm-${RELEASE}-linux-riscv64.tar.gz.sha256))\n- [Windows amd64](https://get.helm.sh/helm-${RELEASE}-windows-amd64.zip) ([checksum](https://get.helm.sh/helm-${RELEASE}-windows-amd64.zip.sha256sum) / $(cat _dist/helm-${RELEASE}-windows-amd64.zip.sha256))\n- [Windows arm64](https://get.helm.sh/helm-${RELEASE}-windows-arm64.zip) ([checksum](https://get.helm.sh/helm-${RELEASE}-windows-arm64.zip.sha256sum) / $(cat _dist/helm-${RELEASE}-windows-arm64.zip.sha256))\n\n\n## What's Next\n\n- ${MAJOR}.${MINOR}.$(expr ${PATCH} + 1) will contain only bug fixes.\n- ${MAJOR}.$(expr ${MINOR} + 1).${PATCH} is the next feature release. This release will focus on ...\n\n## Changelog\n\n${CHANGELOG}\nEOF\n```", "metadata": {"source": "github_repository", "repository": "helm/helm", "file_path": "release-notes.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for  automation", "completion": "```bash\n#!/usr/bin/env bash\n\n# Copyright The Helm Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Bash 'Strict Mode'\n# http://redsymbol.net/articles/unofficial-bash-strict-mode\nset -euo pipefail\nIFS=$'\\n\\t'\n\n# Helper Functions -------------------------------------------------------------\n\n# Display error message and exit\nerror_exit() {\n  echo \"error: ${1:-\"unknown error\"}\" 1>&2\n  exit 1\n}\n\n# Checks if a command exists.  Returns 1 or 0\ncommand_exists() {\n  hash \"${1}\" 2>/dev/null\n}\n\n# Program Functions ------------------------------------------------------------\n\nverify_prereqs() {\n  echo \"Verifying Prerequisites....\"\n  if command_exists gsutil; then\n    echo \"Thumbs up! Looks like you have gsutil. Let's continue.\"\n  else\n    error_exit \"Couldn't find gsutil. Bailing out.\"\n  fi\n}\n\nconfirm() {\n  case $response in\n    [yY][eE][sS]|[yY])\n      true\n      ;;\n    *)\n      false\n      ;;\n  esac\n}\n\n# Main -------------------------------------------------------------------------\n\nmain() {\n  if [ \"$#\" -ne 2 ]; then\n    error_exit \"Illegal number of parameters. You must pass in local directory path and a GCS bucket name\"\n  fi\n\n  echo \"Getting ready to sync your local directory ($1) to a remote repository at gs://$2\"\n\n  verify_prereqs\n\n  # dry run of the command\n  gsutil rsync -d -n $1 gs://$2\n\n  read -p \"Are you sure you would like to continue with these changes? [y/N]} \" confirm\n  if [[ $confirm =~ [yY](es)* ]]; then\n    gsutil rsync -d $1 gs://$2\n  else\n    error_exit \"Discontinuing sync process.\"\n  fi\n\n  echo \"Your remote chart repository now matches the contents of the $1 directory!\"\n\n}\n\nmain \"${@:-}\"\n```", "metadata": {"source": "github_repository", "repository": "helm/helm", "file_path": "sync-repo.sh", "category": "automation", "authentic": true}}
{"prompt": "Create a shell script for  automation", "completion": "```bash\n#!/bin/bash\n\n# WARNING: DO NOT EDIT, THIS FILE IS PROBABLY A COPY\n#\n# The original version of this file is located in the https://github.com/istio/common-files repo.\n# If you're looking at this file in a different repo and want to make a change, please go to the\n# common-files repo, make the change there and check it in. Then come back to this repo and run\n# \"make update-common\".\n\n# Copyright Istio Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Usage: tracing::extract_prow_trace.\n# If running in a prow job, this sets the parent trace to the same value Prow tracing will use, as defined in https://github.com/kubernetes/test-infra/issues/30010\nfunction tracing::extract_prow_trace() {\n  if [[ \"${PROW_JOB_ID:-}\" != \"\" ]]; then\n    local trace\n    trace=\"$(<<< \"$PROW_JOB_ID\" tr -d '\\-')\"\n    local span\n    span=\"${trace:0:16}\"\n    export TRACEPARENT=\"01-${trace}-${span}-00\"\n  fi\n}\n\nfunction _genattrs() {\n  # No upstream standard, so copy from https://github.com/jenkinsci/opentelemetry-plugin/blob/master/docs/job-traces.md\n  if [[ -n \"${PULL_NUMBER:=}\" ]]\n  then\n    # Presubmit\n    url=\"https://prow.istio.io/view/gs/istio-prow/pr-logs/pull/${REPO_OWNER}_${REPO_NAME}/${PULL_NUMBER}/${JOB_NAME}/${BUILD_ID},\"\n  else\n    # Postsubmit or periodic\n    url=\"https://prow.istio.io/view/gs/istio-prow/pr-logs/${JOB_NAME}/${BUILD_ID},\"\n  fi\n  # Use printf instead of echo to avoid spaces between args\n  printf '%s' \"ci.pipeline.id=${JOB_NAME},\"\\\n    \"ci.pipeline.type=${JOB_TYPE},\"\\\n    \"ci.pipeline.run.url=${url}\"\\\n    \"ci.pipeline.run.number=${BUILD_ID},\"\\\n    \"ci.pipeline.run.id=${PROW_JOB_ID},\"\\\n    \"ci.pipeline.run.repo=${REPO_OWNER:-unknown}/${REPO_NAME:-unknown},\"\\\n    \"ci.pipeline.run.base=${PULL_BASE_REF:-none},\"\\\n    \"ci.pipeline.run.pull_number=${PULL_NUMBER:-none},\"\\\n    \"ci.pipeline.run.pull_sha=${PULL_PULL_SHA:-${PULL_BASE_SHA:-none}}\"\n}\n\n# Usage: tracing::run <span name> [command ...]\nfunction tracing::run() {\n  # If not running in a prow job or otel-cli is not available (e.g. build system without otel-cli) just run the command\n  if [ -z \"${JOB_NAME:-}\" ] || ! command -v otel-cli &> /dev/null\n  then\n    \"${@:2}\"\n    return \"$?\"\n  fi\n\n  # Disable execution tracing to avoid noise\n  { [[ $- = *x* ]] && was_execution_trace=1 || was_execution_trace=0; } 2>/dev/null\n  { set +x; } 2>/dev/null\n  # Throughout, \"local\" usage is critical to avoid nested calls overwriting things\n  local start\n  start=\"$(date -u +%s.%N)\"\n  # First, get a trace and span ID. We need to get one now so we can propagate it to the child\n  # Get trace ID from TRACEPARENT, if present\n  local tid\n  tid=\"$(<<<\"${TRACEPARENT:-}\" cut -d- -f2)\"\n  tid=\"${tid:-\"$(tr -dc 'a-f0-9' < /dev/urandom | head -c 32)\"}\"\n  # Always generate a new span ID\n  local sid\n  sid=\"$(tr -dc 'a-f0-9' < /dev/urandom | head -c 16)\"\n\n  # Execute the command they wanted with the propagation through TRACEPARENT\n  if [[ $was_execution_trace == 1 ]]; then\n    { set -x; } 2>/dev/null\n  fi\n\n  TRACEPARENT=\"00-${tid}-${sid}-01\" \"${@:2}\"\n  local result=\"$?\"\n  { set +x; } 2>/dev/null\n\n  local end\n  end=\"$(date -u +%s.%N)\"\n\n  # Now report this span. We override the IDs to the ones we set before.\n  otel-cli span \\\n    --service \"${BASH_SOURCE[-1]}\" \\\n    --name \"$1\" \\\n    --start \"$start\" \\\n    --end \"$end\" \\\n    --force-trace-id \"$tid\" \\\n    --force-span-id \"$sid\" \\\n    --attrs \"$(_genattrs)\"\n  if [[ $was_execution_trace == 1 ]]; then\n    { set -x; } 2>/dev/null\n  fi\n  return \"$result\"\n}\n\n# Usage: tracing::decorate <function>\n# Automatically makes a function traced.\nfunction tracing::decorate() {\neval \"\\\nfunction $1() {\n_$(typeset -f \"$1\")\ntracing::run '$1' _$1\n}\n\"\n}\n```", "metadata": {"source": "github_repository", "repository": "istio/istio", "file_path": "tracing.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script to build  components", "completion": "```bash\n#!/bin/bash\n#\n# Copyright Istio Authors\n#\n#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n\nset -ox errexit\n\n# Get to the root directory of the repo...\nSCRIPTDIR=$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\ncd \"$SCRIPTDIR/../../..\"\n\nh=\"${BOOKINFO_HUB:?BOOKINFO_HUB must be set}\"\nt=\"${BOOKINFO_TAG:?BOOKINFO_TAG must be set}\"\nif [[ (\"${h}\" == \"istio\" || \"${h}\" == \"docker.io/istio\") && -z \"$CI\" && \"$*\" =~ \"--push\" ]]; then\n  echo \"Can only push to prod registry in CI\"\n  exit 1\nfi\n\nif [[ \"${BOOKINFO_LATEST}\" == \"true\" ]]; then\n  BOOKINFO_TAG=\"${BOOKINFO_TAG},latest\"\nfi\n\n# Pass input args to the command. This allows using --push, --load, etc\nenv TAGS=\"${BOOKINFO_TAG}\" HUB=\"${BOOKINFO_HUB}\" \\\n  docker buildx bake -f samples/bookinfo/src/docker-bake.hcl \"$@\"\n\nif [[ \"${BOOKINFO_UPDATE}\" == \"true\" ]]; then\n# Update image references in the yaml files\n  find ./samples/bookinfo/platform -name \"*bookinfo*.yaml\" -exec sed -i.bak \"s#image:.*\\\\(\\\\/examples-bookinfo-.*\\\\):.*#image: ${h//\\//\\\\/}\\\\1:$t#g\" {} +\nfi\n```", "metadata": {"source": "github_repository", "repository": "istio/istio", "file_path": "build-services.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for Kubernetes resource management", "completion": "```bash\n#!/bin/bash\n\n# Copyright 2019 Istio Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# Usage: ./integ-suite-kind.sh TARGET\n# Example: ./integ-suite-kind.sh test.integration.pilot.kube.presubmit\n\nWD=$(dirname \"$0\")\nWD=$(cd \"$WD\"; pwd)\nROOT=$(dirname \"$WD\")\n\n# Exit immediately for non zero status\nset -e\n# Check unset variables\nset -u\n# Print commands\nset -x\n\n# shellcheck source=prow/lib.sh\nsource \"${ROOT}/prow/lib.sh\"\nsetup_and_export_git_sha\n\n# shellcheck source=common/scripts/kind_provisioner.sh\nsource \"${ROOT}/common/scripts/kind_provisioner.sh\"\n\nTOPOLOGY=SINGLE_CLUSTER\nNODE_IMAGE=\"gcr.io/istio-testing/kind-node:v1.32.0\"\nKIND_CONFIG=\"\"\nCLUSTER_TOPOLOGY_CONFIG_FILE=\"${ROOT}/prow/config/topology/multicluster.json\"\nCLUSTER_NAME=\"${CLUSTER_NAME:-istio-testing}\"\n\nexport FAST_VM_BUILDS=true\nexport ISTIO_DOCKER_BUILDER=\"${ISTIO_DOCKER_BUILDER:-crane}\"\n# DEVCONTAINER controls a set of features that allow this script to be run from\n# within a dev container using ghcr.io/devcontainers/features/docker-outside-of-docker\nexport DEVCONTAINER=\"${DEVCONTAINER:-}\"\nif [[ \"${DEVCONTAINER}\" ]]; then\n  export ISTIO_DOCKER_BUILDER=docker\nfi\n\nPARAMS=()\n\nwhile (( \"$#\" )); do\n  case \"$1\" in\n    # Node images can be found at https://github.com/kubernetes-sigs/kind/releases\n    # For example, kindest/node:v1.14.0\n    --node-image)\n      NODE_IMAGE=$2\n      shift 2\n    ;;\n    # Config for enabling different Kubernetes features in KinD (see prow/config{endpointslice.yaml,trustworthy-jwt.yaml}).\n    --kind-config)\n    KIND_CONFIG=$2\n    shift 2\n    ;;\n    --skip-setup)\n      SKIP_SETUP=true\n      shift\n    ;;\n    --skip-cleanup)\n      SKIP_CLEANUP=true\n      shift\n    ;;\n    --skip-build)\n      SKIP_BUILD=true\n      shift\n    ;;\n    --manual)\n      MANUAL=true\n      shift\n    ;;\n    --topology)\n      case $2 in\n        # TODO(landow) get rid of MULTICLUSTER_SINGLE_NETWORK after updating Prow job\n        SINGLE_CLUSTER | MULTICLUSTER_SINGLE_NETWORK | MULTICLUSTER | AMBIENT_MULTICLUSTER )\n          TOPOLOGY=$2\n          echo \"Running with topology ${TOPOLOGY}\"\n          ;;\n        *)\n          echo \"Error: Unsupported topology ${TOPOLOGY}\" >&2\n          exit 1\n          ;;\n      esac\n      shift 2\n    ;;\n    --topology-config)\n      CLUSTER_TOPOLOGY_CONFIG_FILE=\"${ROOT}/${2}\"\n      shift 2\n    ;;\n    -*)\n      echo \"Error: Unsupported flag $1\" >&2\n      exit 1\n      ;;\n    *) # preserve positional arguments\n      PARAMS+=(\"$1\")\n      shift\n      ;;\n  esac\ndone\n\nif [ -f /proc/cpuinfo ]; then\n  echo \"Checking CPU...\"\n  grep 'model' /proc/cpuinfo || true\nfi\n\n# Default IP family of the cluster is IPv4\nKIND_IP_FAMILY=\"ipv4\"\nexport IP_FAMILIES=\"${IP_FAMILIES:-IPv4}\"\nif [[ \"$IP_FAMILIES\" == \"IPv6\" ]]; then\n   KIND_IP_FAMILY=\"ipv6\"\nelif [[ \"$IP_FAMILIES\" =~ \"IPv6\" ]] && [[ \"$IP_FAMILIES\" =~ \"IPv4\" ]]; then\n   KIND_IP_FAMILY=\"dual\"\nfi\nexport KIND_IP_FAMILY\n\n# LoadBalancer in Kind is supported using metallb\nexport TEST_ENV=kind-metallb\n\n# See https://kind.sigs.k8s.io/docs/user/quick-start/#loading-an-image-into-your-cluster\nexport PULL_POLICY=IfNotPresent\n\n# We run a local-registry in a docker container that KinD nodes pull from\n# These values are must match what is in config/trustworthy-jwt.yaml\nexport KIND_REGISTRY_NAME=\"kind-registry\"\nexport KIND_REGISTRY_PORT=\"5000\"\nexport KIND_REGISTRY=\"localhost:${KIND_REGISTRY_PORT}\"\nexport KIND_REGISTRY_DIR=\"/etc/containerd/certs.d/localhost:${KIND_REGISTRY_PORT}\"\n\nexport HUB=${HUB:-\"istio-testing\"}\nexport TAG=\"${TAG:-\"istio-testing\"}\"\nexport VARIANT\n\n# If we're not intending to pull from an actual remote registry, use the local kind registry\nif [[ -z \"${SKIP_BUILD:-}\" ]]; then\n  HUB=\"${KIND_REGISTRY}\"\n  export HUB\nfi\n\n# Setup junit report and verbose logging\nexport T=\"${T:-\"-v -count=1\"}\"\nexport CI=\"true\"\n\nexport ARTIFACTS=\"${ARTIFACTS:-$(mktemp -d)}\"\ntrace \"init\" make init\n\nif [[ -z \"${SKIP_SETUP:-}\" ]]; then\n  export DEFAULT_CLUSTER_YAML=\"./prow/config/default.yaml\"\n  export METRICS_SERVER_CONFIG_DIR='./prow/config/metrics'\n\n  if [[ \"${TOPOLOGY}\" == \"SINGLE_CLUSTER\" ]]; then\n    trace \"setup kind cluster\" setup_kind_cluster_retry \"${CLUSTER_NAME}\" \"${NODE_IMAGE}\" \"${KIND_CONFIG}\"\n  else\n    trace \"load cluster topology\" load_cluster_topology \"${CLUSTER_TOPOLOGY_CONFIG_FILE}\"\n    trace \"setup kind clusters\" setup_kind_clusters \"${NODE_IMAGE}\" \"${KIND_IP_FAMILY}\"\n\n    TOPOLOGY_JSON=$(cat \"${CLUSTER_TOPOLOGY_CONFIG_FILE}\")\n    for i in $(seq 0 $((${#CLUSTER_NAMES[@]} - 1))); do\n      CLUSTER=\"${CLUSTER_NAMES[i]}\"\n      KCONFIG=\"${KUBECONFIGS[i]}\"\n      TOPOLOGY_JSON=$(set_topology_value \"${TOPOLOGY_JSON}\" \"${CLUSTER}\" \"meta.kubeconfig\" \"${KCONFIG}\")\n    done\n    RUNTIME_TOPOLOGY_CONFIG_FILE=\"${ARTIFACTS}/topology-config.json\"\n    echo \"${TOPOLOGY_JSON}\" > \"${RUNTIME_TOPOLOGY_CONFIG_FILE}\"\n\n    export INTEGRATION_TEST_TOPOLOGY_FILE\n    INTEGRATION_TEST_TOPOLOGY_FILE=\"${RUNTIME_TOPOLOGY_CONFIG_FILE}\"\n\n    export INTEGRATION_TEST_KUBECONFIG\n    INTEGRATION_TEST_KUBECONFIG=NONE\n  fi\nfi\n\nif [[ -z \"${SKIP_BUILD:-}\" ]]; then\n  trace \"setup kind registry\" setup_kind_registry\n  trace \"build images\" build_images \"${PARAMS[*]}\"\n\n  # upload WASM plugins to kind-registry\n  registry_url=$(if [ -z \"$DEVCONTAINER\" ]; then echo \"localhost\"; else echo $KIND_REGISTRY_NAME; fi):$KIND_REGISTRY_PORT\n  crane copy gcr.io/istio-testing/wasm/attributegen:<TOKEN> \"$registry_url/istio-testing/wasm/attributegen:0.0.1\" --insecure\n  crane copy gcr.io/istio-testing/wasm/header-injector:0.0.1 \"$registry_url/istio-testing/wasm/header-injector:0.0.1\" --insecure\n  crane copy gcr.io/istio-testing/wasm/header-injector:0.0.2 \"$registry_url/istio-testing/wasm/header-injector:0.0.2\" --insecure\n\n  # Make \"kind-registry\" resolvable in IPv6 cluster\n  if [[ \"$KIND_IP_FAMILY\" == \"ipv6\" ]]; then\n    kind_registry_ip=$(docker inspect -f '{{range $k, $v := .NetworkSettings.Networks}}{{if eq $k \"kind\"}}{{.GlobalIPv6Address}}{{end}}{{end}}' kind-registry)\n    coredns_config=$(kubectl get -oyaml -n=kube-system configmap/coredns)\n    echo \"Current CoreDNS config:\"\n    echo \"${coredns_config}\"\n    patched_coredns_config=$(kubectl get -oyaml -n=kube-system configmap/coredns | sed -e '/^ *ready/i\\\n        hosts {\\\n            '\"$kind_registry_ip\"' kind-registry.lan\\\n            '\"$kind_registry_ip\"' kind-registry.\\\n            fallthrough\\\n        }')\n    echo \"Patched CoreDNS config:\"\n    echo \"${patched_coredns_config}\"\n    printf '%s' \"${patched_coredns_config}\" | kubectl apply -f -\n  fi\n  # CoreDNS by default caches Kubernetes objects for 30s. This leads to problematic timing issues when we tear down + re-install\n  # in our tests. We will negative-cache the object, adding up to 30s on each test suite.\n  # See https://github.com/coredns/coredns/pull/2348\n  kubectl get -oyaml -n=kube-system configmap/coredns | sed 's/ttl 30/ttl 0/g' | kubectl apply -f -\nfi\n\n# Run the test target if provided.\nif [[ -n \"${PARAMS:-}\" ]]; then\n  trace \"test\" make \"${PARAMS[*]}\"\nfi\n\n# Check if the user is running the clusters in manual mode.\nif [[ -n \"${MANUAL:-}\" ]]; then\n  echo \"Running cluster(s) in manual mode. Press any key to shutdown and exit...\"\n  read -rsn1\n  exit 0\nfi\n```", "metadata": {"source": "github_repository", "repository": "istio/istio", "file_path": "integ-suite-kind.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for  testing automation", "completion": "```bash\n#!/bin/bash\n\n# Copyright Istio Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nWD=$(dirname \"$0\")\nWD=$(cd \"$WD\"; pwd)\nROOT=$(dirname \"$WD\")\n\n# shellcheck source=prow/lib.sh\nsource \"${ROOT}/prow/lib.sh\"\nsetup_and_export_git_sha\n\nset -eux\n\nGCS_BENCHMARK_DIR=\"${GCS_BENCHMARK_DIR:-istio-prow/benchmarks}\"\n\nBENCHMARK_COUNT=\"${BENCHMARK_COUNT:-5}\"\nBENCHMARK_CPUS=\"${BENCHMARK_CPUS:-8}\"\n\nREPORT_JUNIT=\"${REPORT_JUNIT:-${ARTIFACTS}/junit_benchmarks.xml}\"\nREPORT_PLAINTEXT=\"${REPORT_PLAINTEXT:-${ARTIFACTS}/benchmark-log.txt}\"\n\n# Sha we should compare against. Defaults to the PULL_BASE_SHA, which is the last commit on the branch we are on.\n# For example, a PR on master will compare to the HEAD of master.\nCOMPARE_GIT_SHA=\"${COMPARE_GIT_SHA:-${PULL_BASE_SHA:-${GIT_SHA}}}\"\n\ncase \"${1}\" in\n  run)\n    shift\n    benchmarkjunit \"$@\" -l \"${REPORT_PLAINTEXT}\" --output=\"${REPORT_JUNIT}\" \\\n      --test-arg \"--benchmem\" \\\n      --test-arg \"--count=${BENCHMARK_COUNT}\" \\\n      --test-arg \"--cpu=${BENCHMARK_CPUS}\" \\\n      --test-arg \"--test.timeout=60m\" \\\n      --test-arg \"-tags=vtprotobuf\"\n    # Print out the results as well for ease of debugging, so they are in the logs instead of just output\n    cat \"${REPORT_PLAINTEXT}\"\n    ;;\n  report)\n    # Upload the reports to a well known path based on git SHA\n    gsutil cp \"${REPORT_JUNIT}\" \"gs://${GCS_BENCHMARK_DIR}/${GIT_SHA}.xml\"\n    gsutil cp \"${REPORT_PLAINTEXT}\" \"gs://${GCS_BENCHMARK_DIR}/${GIT_SHA}.txt\"\n    ;;\n  compare)\n    # Fetch previous results, and compare them.\n    curl \"https://storage.googleapis.com/${GCS_BENCHMARK_DIR}/${COMPARE_GIT_SHA}.txt\" > \"${ARTIFACTS}/baseline-benchmark-log.txt\"\n    benchstat \"${ARTIFACTS}/baseline-benchmark-log.txt\" \"${REPORT_PLAINTEXT}\"\n    ;;\n  *)\n    echo \"unknown command, expect report, run, or compare.\"\n    ;;\nesac\n```", "metadata": {"source": "github_repository", "repository": "istio/istio", "file_path": "benchtest.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for  automation", "completion": "```bash\n#!/bin/bash\n\n# Copyright 2019 Istio Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -eu\n\nif [ -z ${CI+x} ]; then\n  # When not in CI, do nothing\n  exit 0;\nfi\n\necho \"Fetching docker container status\"\ndocker ps || true\necho \"Fetching buildx logs\"\ndocker logs buildx_buildkit_container-builder0 || true\necho \"Fetching docker logs\"\ncat /var/log/docker.log || true\necho \"Fetching local registry logs\"\ndocker logs kind-registry || true\n```", "metadata": {"source": "github_repository", "repository": "istio/istio", "file_path": "dump-docker-logs.sh", "category": "build", "authentic": true}}
{"prompt": "Create a shell script for  automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\nfail() {\n  echo \"$1\" 1>&2\n  exit 1\n}\n\n[[ -z \"$VAULT_ADDR\" ]] && fail \"VAULT_ADDR env variable has not been set\"\nbinpath=${VAULT_INSTALL_DIR}/vault\ntest -x \"$binpath\" || fail \"unable to locate vault binary at $binpath\"\n\nif ! out=$(sudo systemctl stop vault 2>&1); then\n  fail \"failed to stop vault: $out: $(sudo systemctl status vault)\"\nfi\n\nif ! out=$(sudo systemctl daemon-reload 2>&1); then\n  fail \"failed to daemon-reload systemd: $out\" 1>&2\nfi\n\nif ! out=$(sudo systemctl start vault 2>&1); then\n  fail \"failed to start vault: $out: $(sudo systemctl status vault)\"\nfi\n\ncount=0\nretries=5\nwhile :; do\n  # Check the Vault seal status\n  status=$($binpath status)\n  code=$?\n\n  if [ $code == 0 ] || [ $code == 2 ]; then\n    # 0 is unsealed and 2 is running but sealed\n    echo \"$status\"\n    exit 0\n  fi\n\n  printf \"Waiting for Vault cluster to be ready: status code: %s, status:\\n%s\\n\" \"$code\" \"$status\" 2>&1\n\n  wait=$((3 ** count))\n  count=$((count + 1))\n  if [ \"$count\" -lt \"$retries\" ]; then\n      sleep \"$wait\"\n  else\n      fail \"Timed out waiting for Vault node to be ready after restart\"\n  fi\ndone\n```", "metadata": {"source": "github_repository", "repository": "hashicorp/vault", "file_path": "restart-vault.sh", "category": "testing", "authentic": true}}
{"prompt": "Create a shell script for  automation", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\nset -e\n\nfail() {\n  echo \"$1\" 1>&2\n  exit 1\n}\n\n[[ -z \"$AES_LABEL\" ]] && fail \"AES_LABEL env variable has not been set\"\n[[ -z \"$HMAC_LABEL\" ]] && fail \"HMAC_LABEL env variable has not been set\"\n[[ -z \"$PIN\" ]] && fail \"PIN env variable has not been set\"\n[[ -z \"$SO_PIN\" ]] && fail \"SO_PIN env variable has not been set\"\n[[ -z \"$TOKEN_LABEL\" ]] && fail \"TOKEN_LABEL env variable has not been set\"\n[[ -z \"$TOKEN_DIR\" ]] && fail \"TOKEN_DIR env variable has not been set\"\n\nif ! type softhsm2-util &> /dev/null; then\n  fail \"unable to locate softhsm2-util in PATH. Have you installed softhsm?\"\nfi\n\nif ! type pkcs11-tool &> /dev/null; then\n  fail \"unable to locate pkcs11-tool in PATH. Have you installed opensc?\"\nfi\n\n# Create an HSM slot and return the slot number in decimal value.\ncreate_slot() {\n  sudo softhsm2-util --init-token --free --so-pin=\"$SO_PIN\" --pin=\"$PIN\" --label=\"$TOKEN_LABEL\" | grep -oE '[0-9]+$'\n}\n\n# Find the location of our softhsm shared object.\nfind_softhsm_so() {\n  sudo find /usr -type f -name libsofthsm2.so -print -quit\n}\n\n# Create key a key in the slot. Args: module, key label, id number, key type\nkeygen() {\n  sudo pkcs11-tool --keygen --usage-sign --private --sensitive --usage-wrap \\\n    --module \"$1\" \\\n    -p \"$PIN\" \\\n    --token-label \"$TOKEN_LABEL\" \\\n    --label \"$2\" \\\n    --id \"$3\" \\\n    --key-type \"$4\"\n}\n\n# Create our softhsm slot and keys\nmain() {\n  local slot\n  if ! slot=$(create_slot); then\n    fail \"failed to create softhsm token slot\"\n  fi\n\n  local so\n  if ! so=$(find_softhsm_so); then\n    fail \"unable to locate libsofthsm2.so shared object\"\n  fi\n\n  if ! keygen \"$so\" \"$AES_LABEL\" 1 'AES:32' 1>&2; then\n    fail \"failed to create AES key\"\n  fi\n\n  if ! keygen \"$so\" \"$HMAC_LABEL\" 2 'GENERIC:32' 1>&2; then\n    fail \"failed to create HMAC key\"\n  fi\n\n  # Return our seal configuration attributes as JSON\n  cat << EOF\n{\n  \"lib\": \"${so}\",\n  \"slot\": \"${slot}\",\n  \"pin\": \"${PIN}\",\n  \"key_label\": \"${AES_LABEL}\",\n  \"hmac_key_label\": \"${HMAC_LABEL}\",\n  \"generate_key\": \"false\"\n}\nEOF\n  exit 0\n}\n\nmain\n```", "metadata": {"source": "github_repository", "repository": "hashicorp/vault", "file_path": "create-keys.sh", "category": "automation", "authentic": true}}
{"prompt": "Write a shell script to install and setup ", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\nset -e\n\nfail() {\n  echo \"$1\" 1>&2\n  exit 1\n}\n\n[[ -z \"${RETRY_INTERVAL}\" ]] && fail \"RETRY_INTERVAL env variable has not been set\"\n[[ -z \"${TIMEOUT_SECONDS}\" ]] && fail \"TIMEOUT_SECONDS env variable has not been set\"\n[[ -z \"${PACKAGES}\" ]] && fail \"PACKAGES env variable has not been set\"\n[[ -z \"${PACKAGE_MANAGER}\" ]] && fail \"PACKAGE_MANAGER env variable has not been set\"\n\n# Install packages based on the provided packages and package manager. We assume that the repositories\n# have already been synchronized by the repo setup that is a prerequisite for this script.\ninstall_packages() {\n  if [[ \"${PACKAGES}\" = \"__skip\" ]]; then\n    return 0\n  fi\n\n  set -x\n  echo \"Installing Dependencies: ${PACKAGES}\"\n\n  # Use the default package manager of the current Linux distro to install packages\n  case $PACKAGE_MANAGER in\n    apt)\n      for package in ${PACKAGES}; do\n        if dpkg -s \"${package}\"; then\n          echo \"Skipping installation of ${package} because it is already installed\"\n          continue\n        else\n          echo \"Installing ${package}\"\n          local output\n          if ! output=$(sudo apt install -y \"${package}\" 2>&1); then\n            echo \"Failed to install ${package}: ${output}\" 1>&2\n            return 1\n          fi\n        fi\n      done\n      ;;\n    dnf)\n      for package in ${PACKAGES}; do\n        if rpm -q \"${package}\"; then\n          echo \"Skipping installation of ${package} because it is already installed\"\n          continue\n        else\n          echo \"Installing ${package}\"\n          local output\n          if ! output=$(sudo dnf -y install \"${package}\" 2>&1); then\n            echo \"Failed to install ${package}: ${output}\" 1>&2\n            return 1\n          fi\n        fi\n      done\n      ;;\n    yum)\n      for package in ${PACKAGES}; do\n        if rpm -q \"${package}\"; then\n          echo \"Skipping installation of ${package} because it is already installed\"\n          continue\n        else\n          echo \"Installing ${package}\"\n          local output\n          if ! output=$(sudo yum -y install \"${package}\" 2>&1); then\n            echo \"Failed to install ${package}: ${output}\" 1>&2\n            return 1\n          fi\n        fi\n      done\n      ;;\n    zypper)\n      for package in ${PACKAGES}; do\n        if rpm -q \"${package}\"; then\n          echo \"Skipping installation of ${package} because it is already installed\"\n          continue\n        else\n          echo \"Installing ${package}\"\n          local output\n          if ! output=$(sudo zypper --non-interactive install -y -l --force-resolution \"${package}\" 2>&1); then\n            echo \"Failed to install ${package}: ${output}\" 1>&2\n            return 1\n          fi\n        fi\n      done\n      ;;\n    *)\n      fail \"No matching package manager provided.\"\n      ;;\n  esac\n}\n\nbegin_time=$(date +%s)\nend_time=$((begin_time + TIMEOUT_SECONDS))\nwhile [[ \"$(date +%s)\" -lt \"${end_time}\" ]]; do\n  if install_packages; then\n    exit 0\n  fi\n\n  sleep \"${RETRY_INTERVAL}\"\ndone\n\nfail \"Timed out waiting for packages to install\"\n```", "metadata": {"source": "github_repository", "repository": "hashicorp/vault", "file_path": "install-packages.sh", "category": "infrastructure", "authentic": true}}
{"prompt": "Create a shell script for Docker image building and deployment", "completion": "```bash\n#!/bin/bash\n\nset -ex\n\n./script/clean\n\nDOCKER_COMPOSE_GITSHA=\"$(script/build/write-git-sha)\"\n\ndocker build . \\\n       --target bin \\\n       --build-arg DISTRO=debian \\\n       --build-arg GIT_COMMIT=\"${DOCKER_COMPOSE_GITSHA}\" \\\n       --output dist/\nARCH=$(uname -m)\n# Ensure that we output the binary with the same name as we did before\nmv dist/docker-compose-linux-amd64 \"dist/docker-compose-Linux-${ARCH}\"\n```", "metadata": {"source": "github_raw", "repository": "docker/compose", "file_path": "script/build/linux", "category": "build", "authentic": true}}
{"prompt": "Write a shell script to build  components", "completion": "```bash\n#!/usr/bin/env bash\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: BUSL-1.1\n\n#\n# This script builds the application from source for multiple platforms.\nset -e\n\nGO_CMD=${GO_CMD:-go}\n\n# Get the parent directory of where this script is.\nSOURCE=\"${BASH_SOURCE[0]}\"\nSOURCE_DIR=$( dirname \"$SOURCE\" )\nwhile [ -h \"$SOURCE\" ] ; do SOURCE=\"$(readlink \"$SOURCE\")\"; done\nDIR=\"$( cd -P \"$SOURCE_DIR/..\" && pwd )\"\n\n# Change into that directory\ncd \"$DIR\"\n\n# Set build tags\nBUILD_TAGS=\"${BUILD_TAGS:-\"vault\"}\"\n\n# Get the git commit\nGIT_COMMIT=\"$(\"$SOURCE_DIR\"/ci-helper.sh revision)\"\nGIT_DIRTY=\"$(test -n \"`git status --porcelain`\" && echo \"+CHANGES\" || true)\"\n\nBUILD_DATE=\"$(\"$SOURCE_DIR\"/ci-helper.sh date)\"\n\nGOPATH=${GOPATH:-$(${GO_CMD} env GOPATH)}\ncase $(uname) in\n    CYGWIN*)\n        GOPATH=\"$(cygpath $GOPATH)\"\n        ;;\nesac\n\n# Delete the old dir\necho \"==> Removing old directory...\"\nrm -f bin/*\nrm -rf pkg/*\nmkdir -p bin/\n\n# Build!\necho \"==> Building...\"\n${GO_CMD} build \\\n    -gcflags \"${GCFLAGS}\" \\\n    -ldflags \"${LD_FLAGS} -X github.com/hashicorp/vault/version.GitCommit='${GIT_COMMIT}${GIT_DIRTY}' -X github.com/hashicorp/vault/version.BuildDate=${BUILD_DATE}\" \\\n    -o \"bin/vault\" \\\n    -tags \"${BUILD_TAGS}\" \\\n    .\n\n# Move all the compiled things to the $GOPATH/bin\nOLDIFS=$IFS\nIFS=: FIRST=($GOPATH) BIN_PATH=${GOBIN:-${FIRST}/bin}\nIFS=$OLDIFS\n\n# Ensure the go bin folder exists\nmkdir -p ${BIN_PATH}\nrm -f ${BIN_PATH}/vault\ncp bin/vault ${BIN_PATH}\n\n# Done!\necho\necho \"==> Results:\"\nls -hl bin/\n```", "metadata": {"source": "github_raw", "repository": "hashicorp/vault", "file_path": "scripts/build.sh", "category": "build", "authentic": true}}
{"prompt": "Write a shell script for deployment automation", "completion": "```bash\npackages:\n  yum:\n    gcc: []\n    make: []\n    openssl-devel: []\n    libxml2: []\n    libxml2-devel: []\nfiles:\n  \"/opt/elasticbeanstalk/hooks/appdeploy/pre/50npm.sh\" :\n    mode: \"000775\"\n    owner: root\n    group: root\n    content: |\n      #!/bin/bash\n      function error_exit\n      {\n      eventHelper.py --msg \"$1\" --severity ERROR\n      exit $2\n      }\n\n      export HOME=/home/ec2-user # ADDED EXPORT COMMAND\n      echo \"export home\" # JUST FOR REMARK\n\n      OUT=$(/opt/elasticbeanstalk/containerfiles/ebnode.py --action npm- install 2>&1) || error_exit \"Failed to run npm install. $OUT\" $?\n      echo $OUT\n```", "metadata": {"source": "stackoverflow", "question_id": 34084814, "title": "NPM error when deploying NodeJS to Elastic Beanstalk", "score": 13, "category": "deployment", "authentic": true}}
{"prompt": "Create a shell script for AWS infrastructure management", "completion": "```bash\n2014-02-10 19:07:17,234 [DEBUG] Running command 02_createadmin\n2014-02-10 19:07:17,235 [DEBUG] Generating defaults for command 02_createadmin\n<<<\n\n2014-02-10 19:07:17,319 [DEBUG] Running test for command 02_createadmin\n2014-02-10 19:07:17,330 [DEBUG] Test command output:\n2014-02-10 19:07:17,331 [DEBUG] Test for command 02_createadmin passed\n2014-02-10 19:07:17,340 [ERROR] Command 02_createadmin (scripts/createadmin.py) failed\n2014-02-10 19:07:17,341 [DEBUG] Command 02_createadmin output: /bin/sh: scripts/createadmin.py: Permission denied\n\n2014-02-10 19:07:17,341 [ERROR] Error encountered during build of postbuild_0_legi_track_prod: Command 02_createadmin failed\nTraceback (most recent call last):\n  File \"/usr/lib/python2.6/site-packages/cfnbootstrap/construction.py\", line 511, in run_config\n    CloudFormationCarpenter(config, self._auth_config).build(worklog)\n  File \"/usr/lib/python2.6/site-packages/cfnbootstrap/construction.py\", line 247, in build\n    changes['commands'] = CommandTool().apply(self._config.commands)\n  File \"/usr/lib/python2.6/site-packages/cfnbootstrap/command_tool.py\", line 113, in apply\n    raise ToolError(u\"Command %s failed\" % name)\nToolError: Command 02_createadmin failed\n2014-02-10 19:07:17,342 [ERROR] Unhandled exception during build: Command 02_createadmin failed\nTraceback (most recent call last):\n  File \"/opt/aws/bin/cfn-init\", line 122, in <module>\n    worklog.build(detail.metadata, configSets)\n  File \"/usr/lib/python2.6/site-packages/cfnbootstrap/construction.py\", line 117, in build\n    Contractor(metadata).build(configSets, self)\n  File \"/usr/lib/python2.6/site-packages/cfnbootstrap/construction.py\", line 502, in build\n    self.run_config(config, worklog)\n  File \"/usr/lib/python2.6/site-packages/cfnbootstrap/construction.py\", line 511, in run_config\n    CloudFormationCarpenter(config, self._auth_config).build(worklog)\n  File \"/usr/lib/python2.6/site-packages/cfnbootstrap/construction.py\", line 247, in build\n    changes['commands'] = CommandTool().apply(self._config.commands)\n  File \"/usr/lib/python2.6/site-packages/cfnbootstrap/command_tool.py\", line 113, in apply\n    raise ToolError(u\"Command %s failed\" % name)\nToolError: Command 02_createadmin failed\n```", "metadata": {"source": "stackoverflow", "question_id": 21686439, "title": "Django on AWS Elasticbeanstalk: Command 02_createadmin failed", "score": 6, "category": "build", "authentic": true}}
{"prompt": "Write a shell script for CI/CD pipeline", "completion": "```bash\n$ sudo gitlab-runner register\nRuntime platform                                    arch=amd64 os=linux pid=8665 revision=3afdaba6 version=11.5.0\nRunning in system-mode.\n\nPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):\nhttp://example.com/\nPlease enter the gitlab-ci token for this runner:\nru7i9G9R-3BJn2RXKdtv\nPlease enter the gitlab-ci description for this runner:\n[ubuntu-s-1vcpu-1gb-fra1-01]: warehouse\nPlease enter the gitlab-ci tags for this runner (comma separated):\nwarehouse\nRegistering runner... succeeded                     runner=ru7i9G9R\nPlease enter the executor: parallels, ssh, virtualbox, docker+machine, kubernetes, docker, docker-ssh, shell, docker-ssh+machine:\ndocker\nPlease enter the default Docker image (e.g. ruby:2.1):\nwarehouse:latest\nRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!\n```", "metadata": {"source": "stackoverflow", "question_id": 53571539, "title": "gitlab ci/cd runner stuck", "score": 9, "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for CI/CD pipeline", "completion": "```bash\n$ sudo cat /etc/gitlab-runner/config.toml\nconcurrent = 1\ncheck_interval = 0\n\n[session_server]\n  session_timeout = 1800\n\n[[runners]]\n  name = \"warehouse\"\n  url = \"http://example.com/\"\n  token = \"f5b8036463e2f97d2ab4bc721b6a91\"\n  executor = \"docker\"\n  [runners.docker]\n    tls_verify = false\n    image = \"warehouse:latest\"\n    privileged = false\n    disable_entrypoint_overwrite = false\n    oom_kill_disable = false\n    disable_cache = false\n    volumes = [\"/cache\"]\n    shm_size = 0\n  [runners.cache]\n    [runners.cache.s3]\n    [runners.cache.gcs]\n```", "metadata": {"source": "stackoverflow", "question_id": 53571539, "title": "gitlab ci/cd runner stuck", "score": 9, "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for CI/CD pipeline", "completion": "```bash\n$ sudo gitlab-runner run\nRuntime platform                                    arch=amd64 os=linux pid=9678 revision=3afdaba6 version=11.5.0\nStarting multi-runner from /etc/gitlab-runner/config.toml ...  builds=0\nRunning in system-mode.\n\nConfiguration loaded                                builds=0\nListen address not defined, metrics server disabled  builds=0\nListen address not defined, session server disabled  builds=0\n```", "metadata": {"source": "stackoverflow", "question_id": 53571539, "title": "gitlab ci/cd runner stuck", "score": 9, "category": "build", "authentic": true}}
{"prompt": "Write a shell script for CI/CD pipeline", "completion": "```bash\nroot@debian:~# gitlab-ci-multi-runner register\nRunning in system-mode.\nPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):\n  http://127.0.0.1\nPlease enter the gitlab-ci token for this runner:\n  XXX\nPlease enter the gitlab-ci description for this runner:\n  [debian]: p1\nPlease enter the gitlab-ci tags for this runner (comma separated):\n  dev\nRegistering runner... succeeded                     runner=XXX\nPlease enter the executor: kubernetes, docker, parallels, ssh, docker+machine, docker-ssh, shell, virtualbox, docker-ssh+machine:\n  shell\nRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!\nroot@debian:~# gitlab-ci-multi-runner verify\nRunning in system -mode.\n\nVerifying runner... is alive                        runner=XXX\n```", "metadata": {"source": "stackoverflow", "question_id": 41545349, "title": "GitLab CI Why this runner isn&#39;t doing the build?", "score": 6, "category": "containerization", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\n{'elements': [{'id': 1615,\n   'slug': 'engineering-manager-ios-blockchain',\n   'title': 'Engineering Manager, iOS - Blockchain',\n   'seniority': 'expert',\n   'role': 'engineeringOthers',\n   'primaryLanguage': 'java',\n   'primaryPlatform': None,\n   'secondaryLanguage': None,\n   'secondaryPlatform': None,\n   'mainDatabase': None,\n   'productDescription': '',\n   'postedAt': 1662976098357,\n   'companyId': 1,\n   'salaryCurrency': 'BGN',\n   'salaryMin': 11500,\n   'salaryMax': 15000,\n   'salaryPeriod': 'MONTH',\n   'jobType': 'FULL_TIME',\n   'jobTypeComment': None,\n   'businessTravelComment': None,\n   'homeOfficeDays': 0,\n   'homeOfficePer': 'WEEK',\n   'teamSizeMin': 500,\n   'teamSizeMax': 1000,\n   'teamLead': '',\n   'teamLeadName': '',\n   'teamLeadRole': '',\n   'teamLeadImage': None,\n   'locations': [{'id': 1,\n     'teamSize': None,\n     'founded': 2018,\n     'comment': None}],\n   'productImages': [{'id': 5078,\n     'collection': 'product',\n     'name': 'prod/1/product/zm49c..'},\n    {'id': 5079, 'collection': 'product', 'name': 'prod/1/product/mhqkiw.'},\n    {'id': 5081, 'collection': 'product', 'name': 'prod/1/product/c.jtpo.'},\n    {'id': 5080, 'collection': 'product', 'name': 'prod/1/product/u0847l.'},\n    {'id': 5082, 'collection': 'product', 'name': 'prod/1/product/yrpy99.'}],\n   'requirements': [{'icon': 'fas fa-check-square',\n     'title': '1+ years of experience leading a team of 4+ people'},\n    {'icon': 'fas fa-check-square',\n     'title': '3+ years of experience with Swift'},\n    {'icon': 'fas fa-check-square',\n     'title': 'Experience with multithreaded apps, offline storage and performance optimizations'},\n    {'icon': 'fas fa-check-square', 'title': 'Experience using RESTful APIs'},\n    {'icon': 'fas fa-check-square',\n     'title': \"Familiar with Apple's Human Interface Guidelines and concepts for good UX\"},\n    {'icon': 'fas fa-check-square',\n     'title': 'Experience setting up CI/CD processes'},\n    {'icon': 'fas fa-check-square',\n     'title': 'Good understanding of design patterns and software architecture principles'},\n    {'icon': 'fas fa-check-square',\n     'title': 'Understanding of software development lifecycle (SDLC)'},\n    {'icon': 'fas fa-check-square',\n     'title': 'Superior interpersonal communication skills'},\n    {'icon': 'fas fa-check-square',\n     'title': 'A technical mindset with great attention to detail'},\n    {'icon': 'fas fa-check-square',\n     'title': 'Self-starter, comfortable in a fast-paced startup environment'},\n    {'icon': 'fas fa-check-square',\n     'title': 'Familiar with crypto-economic protocol design including governance and incentive structures'},\n    {'icon': 'fas fa-check-square',\n     'title': 'Familiar with Web3 Stack: Web3, Ethers, Hardhat'}],\n   'responsibilities': [{'icon': 'fas fa-hand-point-right',\n     'title': 'Take part in designing, scoping, developing, and maintaining disruptive Web3 applications'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'You Write It – You Own It: Develop, test, release, maintain, and improve – own the full life-cycle of your code'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'Provide technical guidance and coaching'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'Possess a strong sense of ownership and accountability with a commitment to deliver quality timely outcomes\\n'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'Assist in management, including hiring, onboarding, training, and keeping management updated on team performance'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'Proactively propose improvement plans and best practices'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'Contribute and maintain the thorough documentation'}],\n   'benefits': [{'icon': 'fas fa-star',\n     'title': 'Attractive remuneration package'},\n    {'icon': 'fas fa-star', 'title': 'Annual bonuses '},\n    {'icon': 'fas fa-star', 'title': 'Learning Hub'},\n    {'icon': 'fas fa-star', 'title': 'Hybrid way of work and work from home '},\n    {'icon': 'fas fa-star',\n     'title': 'Inspiring atmosphere and innovative projects'},\n    {'icon': 'fas fa-star',\n     'title': 'Future career development in a global company leading the innovative blockchain space'},\n    {'icon': 'fas fa-star',\n     'title': 'Tailor-made personal benefits package — you want it, you get it'},\n    {'icon': 'fas fa-star',\n     'title': 'Wellness program including additional health insurance, Multisport card, sports activities, standing desks & protective glasses and many more'},\n    {'icon': 'fas fa-star',\n     'title': 'Free assorted healthy snacks and fresh fruits in the office'},\n    {'icon': 'fas fa-star', 'title': 'Weekly gourmet breakfast meet-ups'},\n    {'icon': 'fas fa-star',\n     'title': 'Free parking with a designated space, free electric bikes & public transport'},\n    {'icon': 'fas fa-star',\n     'title': 'Epic regular team buildings and parties'}],\n   'activities': [],\n   'hiringProcessSteps': [],\n   'tools': [],\n   'company': {'id': 1,\n    'slug': 'nexo',\n    'brand': 'Nexo',\n    'product': '',\n    'images': [{'id': 2,\n      'collection': 'main',\n      'name': 'prod/1/main/yzxiiu.jpg'},\n     {'id': 5071, 'collection': 'main', 'name': 'prod/1/main/c3smv4.'},\n     {'id': 5072, 'collection': 'main', 'name': 'prod/1/main/baofyo.'},\n     {'id': 1, 'collection': 'logo', 'name': 'prod/1/logo/b25jcy.png'},\n     {'id': 5078, 'collection': 'product', 'name': 'prod/1/product/zm49c..'},\n     {'id': 5079, 'collection': 'product', 'name': 'prod/1/product/mhqkiw.'},\n     {'id': 5081, 'collection': 'product', 'name': 'prod/1/product/c.jtpo.'},\n     {'id': 5080, 'collection': 'product', 'name': 'prod/1/product/u0847l.'},\n     {'id': 5082, 'collection': 'product', 'name': 'prod/1/product/yrpy99.'},\n     {'id': 21, 'collection': 'clients', 'name': 'prod/1/clients/cw-ck4.jpg'},\n     {'id': 22, 'collection': 'clients', 'name': 'prod/1/clients/wpezkk.jpg'},\n     {'id': 23, 'collection': 'clients', 'name': 'prod/1/clients/01ngdh.jpg'},\n     {'id': 24, 'collection': 'clients', 'name': 'prod/1/clients/yh1pgp.jpg'},\n     {'id': 25, 'collection': 'clients', 'name': 'prod/1/clients/gli-f8.jpg'},\n     {'id': 5073, 'collection': 'photos', 'name': 'prod/1/photos/zunc4z.'},\n     {'id': 5074, 'collection': 'photos', 'name': 'prod/1/photos/q-bklt.'},\n     {'id': 5075, 'collection': 'photos', 'name': 'prod/1/photos/tgiq9i.'},\n     {'id': 5077, 'collection': 'photos', 'name': 'prod/1/photos/dguwy5.'},\n     {'id': 5076, 'collection': 'photos', 'name': 'prod/1/photos/tx0fdl.'},\n     {'id': 3871, 'collection': 'photos', 'name': 'prod/1/photos/c0nnnz.'},\n     {'id': 3869, 'collection': 'photos', 'name': 'prod/1/photos/6x4jxe.'},\n     {'id': 3874, 'collection': 'photos', 'name': 'prod/1/photos/e0bfnd.'},\n     {'id': 3872, 'collection': 'photos', 'name': 'prod/1/photos/k5q7hf.'}],\n    'locations': [{'id': 1,\n      'teamSize': None,\n      'founded': 2018,\n      'comment': None}],\n    'awards': [{'icon': 'heart',\n      'title': 'Finance Company of The Year by Forbes Business Awards 2021'},\n     {'icon': 'heart',\n      'title': 'Bronze Stevie® Award In 2021 International Business Awards®'},\n     {'icon': 'fas fa-trophy',\n      'title': 'Top 50 List of Crypto Valley Companies'}],\n    'perks': [{'icon': 'fas fa-gem',\n      'title': 'Monthly evening events',\n      'text': 'At Nexo, we do monthly get-togethers after work to have a drink, enjoy some company and relax. No rules, no expectations.'},\n     {'icon': 'fas fa-gem',\n      'title': 'Teambuildings',\n      'text': 'Twice a year our team travels out of the big city to cozy locations where we can relax, have fun, sing karaoke, and do sports.'},\n     {'icon': 'fas fa-gem',\n      'title': 'Lunchtime',\n      'text': 'This is the easiest opportunity to get connected with colleagues outside of your immediate team. Learn about them personally and professionally.'},\n     {'icon': 'fas fa-gem',\n      'title': 'Ad hoc',\n      'text': 'Going in the park, the gym, an event, or elsewhere is always welcome. Share with your colleagues and you will likely find enthusiasts.'}],\n    'values': [{'icon': 'fas fa-gem',\n      'title': 'Give Your Best',\n      'text': 'Always. When every team member gives his/her best in their domain, we as a team move mountains.'},\n     {'icon': 'fas fa-gem',\n      'title': 'Results Matter the Most',\n      'text': 'We analyze what is best for the company and how can we invest our time in the most productive way to generate the most impactful results.'},\n     {'icon': 'fas fa-gem',\n      'title': 'Bring Positivity',\n      'text': 'We smile, have fun, and enjoy ourselves.'},\n     {'icon': 'fas fa-gem',\n      'title': 'Be Proactive',\n      'text': 'We are independent, forward-thinking and we act.'},\n     {'icon': 'fas fa-gem',\n      'title': 'Always Learn. Always Question.',\n      'text': 'Our industry changes 10X faster than most other industries. Hence, we are always learning and looking for ways to stay ahead of the competition.'}],\n    'public': True},\n   'public': True,\n   'customerFacing': False,\n   'businessTraveling': False,\n   'offeringStock': False,\n   'fullyRemote': False},\n  {'id': 1606,\n   'slug': 'devops-engineer',\n   'title': 'DevOps Engineer',\n   'seniority': 'senior',\n   'role': 'devops',\n   'primaryLanguage': 'bashShellPowershell',\n   'primaryPlatform': 'linux',\n   'secondaryLanguage': 'python',\n   'secondaryPlatform': None,\n   'mainDatabase': 'postgresql',\n   'productDescription': '<p><a href=\"https://solveva.com/#projects\" rel=\"nofollow\"><em>Actus</em></a></p>',\n   'postedAt': 1662111811347,\n   'companyId': 198,\n   'salaryCurrency': 'BGN',\n   'salaryMin': 4000,\n   'salaryMax': 0,\n   'salaryPeriod': 'MONTH',\n   'jobType': 'FULL_TIME',\n   'jobTypeComment': None,\n   'businessTravelComment': None,\n   'homeOfficeDays': 0,\n   'homeOfficePer': 'WEEK',\n   'teamSizeMin': 1,\n   'teamSizeMax': 5,\n   'teamLead': '',\n   'teamLeadName': '',\n   'teamLeadRole': '',\n   'teamLeadImage': None,\n   'locations': [{'id': 1425,\n     'teamSize': None,\n     'founded': None,\n     'comment': None}],\n   'productImages': [],\n   'requirements': [{'icon': 'fas fa-check-square',\n     'title': 'You have 2+ years of experience in a systems engineering/DevOps role\\n\\n\\n'}],\n   'responsibilities': [{'icon': 'fas fa-hand-point-right',\n     'title': 'You will actively interface with software developers, security operations engineers, product managers, operations managers on projects\\n'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'You will provide on-call support for the platform.\\nYou will collaborate with the cyber security team to integrate security measures into all aspects of the platform'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'You will develop and deploy a control plane for all platform services to guarantee observability, monitoring, analytics, and alerting'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': 'You will develop and maintain the continuous integration and continuous delivery pipeline'},\n    {'icon': 'fas fa-hand-point-right',\n     'title': ' You will perform capacity planning, automation, testing, performance tuning, and tools development'}],\n   'benefits': [{'icon': 'fas fa-star',\n     'title': 'We have a friendly team, which is nice to work in - people have always been our strong point. Solveva has a flat structure, little bureaucracy, no managers (any scrum-master, first of all, the developer);\\n'},\n    {'icon': 'fas fa-star',\n     'title': 'We provide you with a choice of hardware: Windows (Dell, Lenovo) or Mac (Pro, Air);'},\n    {'icon': 'fas fa-star',\n     'title': \"Remote, office or mixed work. If you do not feel comfortable working from home, we'll take for you a coworking space;\"},\n    {'icon': 'fas fa-star',\n     'title': 'We provide you with a choice of hardware: Windows (Dell, Lenovo) or Mac (Pro, Air);'},\n    {'icon': 'fas fa-star',\n     'title': 'An individual budget for the development of knowledge (books, conferences, courses), additional equipment and putting the body in order after hard work;'},\n    {'icon': 'fas fa-star', 'title': 'Additional benefits and incentives;'}],\n   'activities': [],\n   'hiringProcessSteps': ['CV review\\n',\n    'HR Interview',\n    'Technical Interview',\n    'Task ( this is optional - we do it if is needed )',\n    'Team Interview'],\n   'tools': [],\n   'company': {'id': 198,\n    'slug': 'solveva',\n    'brand': 'Solveva ',\n    'product': '<p><a href=\"https://solveva.com/#projects\" rel=\"nofollow\"><em>Actus</em></a></p>',\n    'images': [{'id': 5709,\n      'collection': 'main',\n      'name': 'prod/198/main/plhttq.'},\n     {'id': 5710, 'collection': 'logo', 'name': 'prod/198/logo/ywhgct.'},\n     {'id': 5711, 'collection': 'logo', 'name': 'prod/198/logo/mhpi0w.'},\n     {'id': 5718, 'collection': 'photos', 'name': 'prod/198/photos/h.mk-f.'},\n     {'id': 5717, 'collection': 'photos', 'name': 'prod/198/photos/y4xgtc.'},\n     {'id': 5715, 'collection': 'photos', 'name': 'prod/198/photos/zukwmr.'},\n     {'id': 5719, 'collection': 'photos', 'name': 'prod/198/photos/tshc3z.'}],\n    'locations': [{'id': 1425,\n      'teamSize': None,\n      'founded': None,\n      'comment': None},\n     {'id': 1426,\n      'teamSize': None,\n      'founded': None,\n      'comment': None},\n     {'id': 1427,\n      'teamSize': None,\n      'founded': None,\n      'comment': None},\n     {'id': 1428,\n      'teamSize': None,\n      'founded': None,\n      'comment': None}],\n    'awards': [],\n    'perks': [{'icon': 'heart',\n      'title': 'Internal trainings',\n      'text': 'As our main value are the people, at Solveva we regularly organise different  trainings to help our colleagues achieve their career and personal goals.'},\n     {'icon': 'heart',\n      'title': 'Good social benefit system',\n      'text': 'You are given an individual budget for the development of knowledge (books, conferences, courses), additional equipment and putting the body in order after hard work.'},\n     {'icon': 'heart',\n      'title': 'Regular Planing meetings and team buildings',\n      'text': 'Every 3 months we organise a planing meetings and team building event and gather all our colleagues for a 5-day  where we can spend quality time together.'},\n     {'icon': 'heart',\n      'title': 'Flexible working time',\n      'text': \"No fixed schedules, ability for remote working days.\\nRemote, office or mixed work. If you do not feel comfortable working from home, we'll take for you a coworking space.\"},\n    'public': True},\n   'public': True,\n   'customerFacing': False,\n   'businessTraveling': False,\n   'offeringStock': False,\n   'fullyRemote': False}],\n 'totalPages': 10,\n 'page': 0,\n 'totalElements': 481}\n```", "metadata": {"source": "stackoverflow", "question_id": 73693783, "title": "Flatten complex nested JSON structure in Pyspark", "score": 0, "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\n@echo off\n:: ============================================================================\n::  Windows batch script to take a .zip backup of configured directories\n:: ----------------------------------------------------------------------------\ncall :getDateTimeISO8601 ISO8601_DateTime\nSET EXECUTION_START_TIME=%ISO8601_DateTime:~0,13%.%ISO8601_DateTime:~14,2%.%ISO8601_DateTime:~17,2%\n\nSET LOG_FILE=%~n0 [%EXECUTION_START_TIME%].log\n\n:: ----------------------------------------------------------------------------\n::  Configure backup directory and associated backup locations here\n:: ----------------------------------------------------------------------------\nSET BACK_UP_DIRS[1].SourceDir=\"%USERPROFILE%\\Documents\\My Received Files\"\nSET BACK_UP_DIRS[1].BackupLocation=\".\\backup\"\nSET BACK_UP_DIRS[2].SourceDir=\"%USERPROFILE%\\Documents\"\nSET BACK_UP_DIRS[2].BackupLocation=\".\\backup\"\n\nSET MAIL_NOTIFICATION_TO=<EMAIL>\nSET MAIL_SUBJECT=Backup Script Execution Report From %COMPUTERNAME%\\%USERNAME% at %EXECUTION_START_TIME%\nSET MAIL_SIGNATURE=^<b^>^<br/^>Thanks,^<br/^> Test Automation Team.^</b^>\n\n\n:: ----------------------------------------------------------------------------\n:: -- Executable Code                           [Note: Don't touch below here]\n:: ----------------------------------------------------------------------------\n\nsetlocal EnableDelayedExpansion\n    call :log Execution started at %EXECUTION_START_TIME%\n    SET MailMessageHTML=^<p^>Hi,^</p^>\n    SET MailMessageHTML=!MailMessageHTML!^<p^>The backup script execution summary from %COMPUTERNAME%\\%USERNAME% is below. Please find the detailed log attached.^</p^>\n    SET MailMessageHTML=!MailMessageHTML!^<ul^>\n\n    SET SCRIPT_DIR=%~dp0\n\n    call :len BACK_UP_DIRS length\n\n    for /l %%i in (1,1,%length%) do (\n        call :log Processing... %%i of %length%\n        if defined BACK_UP_DIRS[%%i] do (\n            call :absolute_path_from_relative !BACK_UP_DIRS[%%i].SourceDir! sourceDir\n            call :absolute_path_from_relative !BACK_UP_DIRS[%%i].BackupLocation! backupLocation\n            call :get_name_only \"!sourceDir!\" sourceDirName\n\n            set backupZipFile=!backupLocation!\\!sourceDirName! [!EXECUTION_START_TIME!].zip\n\n            ::call :runZip \"!sourceDir!\" \"!backupZipFile!\" 1>>\"%LOG_FILE%\"\n\n            SET MailMessageHTML=!MailMessageHTML!^<li^>[%date% %time%] The directory '^<em^>!sourceDir!^</em^>' is backed up as '^<em^>!backupZipFile!^</em^>'.^</li^>\n\n        )\n    )\n    SET MailMessageHTML=!MailMessageHTML!^</ul^>\n\n    cd %SCRIPT_DIR%\n    SET BACK_UP_DIRS=\n    call :log Execution completed at %date% %time%\n\n    ::call :sendEmail \"!MailMessageHTML!\"\n    del \"%LOG_FILE%\"\nendlocal\ngoto :EOF\n\n::-----------------------------------------------------------------------------\n::-- Function section starts here\n::-----------------------------------------------------------------------------\n\n:len <inputArrayName> <outputLength>\nSETLOCAL\n    set arrayName=%1\n    set arrayIndex=0\n    for /f \"delims=[=] tokens=2\" %%a in ('set %arrayName%[') do (\n        set arrayIndex=%%a\n    )\n( ENDLOCAL\n    SET \"%~2=%arrayIndex%\"\n)\ngoto :EOF\n\n:absolute_path_from_relative <inputRelativePath> <outputAbsolutePath>\nSETLOCAL\n    set absolutePath=%~f1\n( ENDLOCAL\n    set \"%~2=%absolutePath%\"\n)\ngoto :EOF\n\n:get_directory_path <inputFilePath> <outputDirectoryPath>\nSETLOCAL\n    set dirPath=%~dp1\n( ENDLOCAL\n    set %~2=%dirPath%\n)\ngoto :EOF\n\n:get_name_only <inputPath> <outputName>\nSETLOCAL\n    set name=%~nx1\n( ENDLOCAL\n    set %~2=%name%\n)\ngoto :EOF\n\n:runZip <sourceDir> <backupZipFile>\nSETLOCAL\n    call :log Taking backup of '%~1' to '%~2'\n    if not exist \"%~dp2\" mkdir \"%~dp2\"\n    cd /d \"%~1\"\n    call %ZIP_EXE% -dcR9 \"%~2\" *\n    cd /d %~dp0\n    call :log Completed backup of '%~1' to '%~2'\n    echo.\nENDLOCAL\ngoto :EOF\n\n:sendEmail <message>\nSETLOCAL\n    echo Sending Email..\n    ::echo Message: %~1\n    call %BLAT_EXE% -server %SMTP_MAIL_SERVER% -port %SMTP_PORT% -f %MAIL_SENDER% -from %MAIL_SENDER% -to %MAIL_NOTIFICATION_TO% -html -subject \"%MAIL_SUBJECT%\" -body \"%~1 %MAIL_SIGNATURE%\" -attach \"%LOG_FILE%\"\n    echo Email Sent.\nENDLOCAL\ngoto :EOF\n\n:getDateTimeISO8601 <outputValue>\nSETLOCAL\n    :: Check WMIC is available\n    WMIC.EXE Alias /? >NUL 2>&1 || GOTO :no_wmic\n\n    :: Use WMIC to retrieve date and time\n    FOR /F \"skip=1 tokens=1-6\" %%G IN ('WMIC Path Win32_LocalTime Get Day^,Hour^,Minute^,Month^,Second^,Year /Format:table') DO (\n       IF \"%%~L\"==\"\" goto s_done\n          SET _yyyy=%%L\n          SET _mm=00%%J\n          SET _dd=00%%G\n          SET _hour=00%%H\n          SET _minute=00%%I\n          SET _second=00%%K\n    )\n    :s_done\n\n    :: Pad digits with leading zeros\n          SET _mm=%_mm:~-2%\n          SET _dd=%_dd:~-2%\n          SET _hour=%_hour:~-2%\n          SET _minute=%_minute:~-2%\n          SET _second=%_second:~-2%\n\n    :: Display the date/time in ISO 8601 format:\n    SET _isodate=%_yyyy%-%_mm%-%_dd% %_hour%:%_minute%:%_second%\n    goto :functionDone\n\n    :no_wmic\n    echo WMIC not available on this machine.\n    Set _isodate=%date% %time%\n    :functionDone\n( ENDLOCAL\n    SET \"%~1=%_isodate%\"\n)\ngoto :EOF\n\n:log <message>\nSETLOCAL\n    set message=%~n0 [%date% %time%] %*\n    if \"%LOG_FILE%\"==\"\" goto :console\n        echo %message% >> \"%LOG_FILE%\"\n    :console\n    echo %message%\nENDLOCAL\ngoto :EOF\n```", "metadata": {"source": "stackoverflow", "question_id": 45650915, "title": "Why am I getting this error? - &quot;The syntax of the command is incorrect.&quot;", "score": 0, "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\nvagrant up\nsh: 1: netsh: not found\nsh: 1: cscript: not found\nIt seems that you don't have the privileges to change the firewall rules. NFS will not work without that firewall\nchanges. Execute the following commands via cmd as administrator:\nnetsh advfirewall firewall add rule name=\"VagrantWinNFSd-1.1.0\" dir=\"in\" action=allow protocol=any program=\"\\home\\grek\\.vagrant.d\\gems\\gems\\vagrant-winnfsd-1.1.0\\bin\\winnfsd.exe\" profile=any\nnetsh advfirewall firewall add rule name=\"VagrantWinNFSd-1.1.0\" dir=\"out\" action=allow protocol=any program=\"\\home\\grek\\.vagrant.d\\gems\\gems\\vagrant-winnfsd-1.1.0\\bin\\winnfsd.exe\" profile=any\nIf you are an Windows XP user run the following command instead:\nnetsh firewall add allowedprogram \"\\home\\grek\\.vagrant.d\\gems\\gems\\vagrant-winnfsd-1.1.0\\bin\\winnfsd.exe\" VagrantWinNFSd-1.1.0 ENABLE\nBringing machine 'default' up with 'virtualbox' provider...\n==> default: Importing base box 'puphpet/ubuntu1404-x64'...\n==> default: Matching MAC address for NAT networking...\n==> default: Checking if box 'puphpet/ubuntu1404-x64' is up to date...\n==> default: Setting the name of the VM: J4oxiT_default_1440513805447_78063\n==> default: Pruning invalid NFS exports. Administrator privileges will be required...\n==> default: Clearing any previously set network interfaces...\n==> default: Preparing network interfaces based on configuration...\n    default: Adapter 1: nat\n    default: Adapter 2: hostonly\n==> default: Forwarding ports...\n    default: 22 => 6905 (adapter 1)\n    default: 22 => 2222 (adapter 1)\n==> default: Running 'pre-boot' VM customizations...\n==> default: Booting VM...\n==> default: Waiting for machine to boot. This may take a few minutes...\n    default: SSH address: 127.0.0.1:2222\n    default: SSH username: vagrant\n    default: SSH auth method: private key\n    default: Warning: Connection timeout. Retrying...\n    default:\n    default: Vagrant insecure key detected. Vagrant will automatically replace\n    default: this with a newly generated keypair for better security.\n    default:\n    default: Inserting generated public key within guest...\n    default: Removing insecure key from the guest if it's present...\n    default: Key inserted! Disconnecting and reconnecting using new SSH key...\n==> default: Machine booted and ready!\n==> default: Checking for guest additions in VM...\n==> default: Setting hostname...\n==> default: Configuring and enabling network interfaces...\n==> default: Installing NFS client...\n==> default: Exporting NFS shared folders...\n==> default: Preparing to edit /etc/exports. Administrator privileges will be required...\nnfsd running\nexportfs: duplicated export entries:\nexportfs:       192.168.56.107:/home/grek/Downloads/J4oxiT\nexportfs:       192.168.56.107:/home/grek/Downloads/J4oxiT\n==> default: Mounting NFS shared folders...\n==> default: Running provisioner: shell...\n    default: Running: inline script\n==> default: stdin: is not a tty\n==> default: Running provisioner: shell...\n    default: Running: /tmp/vagrant-shell20150825-10700-espnt2.sh\n==> default: stdin: is not a tty\n==> default:\n==> default:  ____        ____  _   _ ____      _      generated using\n==> default: |  _ \\ _   _|  _ \\| | | |  _ \\ ___| |_   ___ ___  _ __ ___\n==> default: | |_) | | | | |_) | |_| | |_) / _ \\ __| / __/ _ \\| '_ ` _ \\\n==> default: |  __/| |_| |  __/|  _  |  __/  __/ |_ | (_| (_) | | | | | |\n==> default: |_|    \\__,_|_|   |_| |_|_|   \\___|\\__(_)___\\___/|_| |_| |_|\n==> default:\n==> default: Running initial-setup apt-get update\n==> default: Finished running initial-setup apt-get update\n==> default: Running provisioner: shell...\n    default: Running: /tmp/vagrant-shell20150825-10700-dijdg1.sh\n==> default: stdin: is not a tty\n==> default: Generating public/private rsa key pair.\n==> default: Your identification has been saved in /vagrant/puphpet/files/dot/ssh/root_id_rsa.\n==> default: Your public key has been saved in /vagrant/puphpet/files/dot/ssh/root_id_rsa.pub.\n==> default: The key fingerprint is:\n==> default: 47:ed:6d:21:16:2d:64:e3:8a:c5:7a:41:4f:36:20:d8 root@miejsce\n==> default: The key's randomart image is:\n==> default: +--[ RSA 2048]----+\n==> default: |       o. ooO.   |\n==> default: |      . E+ B.+.  |\n==> default: |          = *..  |\n==> default: |         = = o . |\n==> default: |        S + . o  |\n==> default: |         o   .   |\n==> default: |                 |\n==> default: |                 |\n==> default: |                 |\n==> default: +-----------------+\n==> default: dpkg-preconfigure: unable to re-open stdin: No such file or directory\n==> default: Your private key for SSH-based authentication has been saved to 'puphpet/files/dot/ssh/root_id_rsa'!\n==> default: Generating public/private rsa key pair.\n==> default: Your identification has been saved in /vagrant/puphpet/files/dot/ssh/id_rsa.\n==> default: Your public key has been saved in /vagrant/puphpet/files/dot/ssh/id_rsa.pub.\n==> default: The key fingerprint is:\n==> default: fd:15:9a:cb:04:db:49:cf:47:2c:71:24:18:05:94:a4 root@miejsce\n==> default: The key's randomart image is:\n==> default: +--[ RSA 2048]----+\n==> default: |           o=*+.o|\n==> default: |           .o  = |\n==> default: |          E . o o|\n==> default: |         . = * + |\n==> default: |        S o * + .|\n==> default: |           + o . |\n==> default: |            +    |\n==> default: |                 |\n==> default: |                 |\n==> default: +-----------------+\n==> default: Your private key for SSH-based authentication has been saved to 'puphpet/files/dot/ssh/id_rsa'!\n==> default: Adding generated root key to /root/.ssh/id_rsa\n==> default: Adding generated root key to /root/.ssh/id_rsa.pub\n==> default: Adding generated root key to /root/.ssh/authorized_keys\n==> default: Adding generated key to /home/vagrant/.ssh/id_rsa\n==> default: Adding generated key to /home/vagrant/.ssh/id_rsa.pub\n==> default: Adding generated key to /home/vagrant/.ssh/authorized_keys\n==> default: Running provisioner: shell...\n    default: Running: /tmp/vagrant-shell20150825-10700-1yg483r.sh\n==> default: stdin: is not a tty\n==> default: Running provisioner: shell...\n    default: Running: /tmp/vagrant-shell20150825-10700-rzxlnu.sh\n==> default: stdin: is not a tty\n==> default: Running provisioner: shell...\n    default: Running: /tmp/vagrant-shell20150825-10700-qq98jx.sh\n==> default: stdin: is not a tty\n==> default: Successfully installed deep_merge-1.0.1\n==> default: 1 gem installed\n==> default: Successfully installed thread_safe-0.3.5\n==> default: Successfully installed minitest-5.8.0\n==> default: Successfully installed tzinfo-1.2.2\n==> default: Successfully installed i18n-0.7.0\n==> default: Successfully installed activesupport-4.2.4\n==> default: 5 gems installed\n==> default: Successfully installed vine-0.2\n==> default: 1 gem installed\n==> default: Running provisioner: puppet...\n==> default: Running Puppet with site.pp...\n==> default: stdin: is not a tty\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/java/lib/facter/java_patch_level.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/java/lib/facter/java_major_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/java/lib/facter/java_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/composer/lib/facter/composer_home.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/stdlib/lib/facter/puppet_vardir.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/stdlib/lib/facter/root_home.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/stdlib/lib/facter/pe_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/stdlib/lib/facter/facter_dot_d.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/git/lib/facter/git_exec_path.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/git/lib/facter/git_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/php/lib/facter/php_fact_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/php/lib/facter/php_fact_extension_dir.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/rvm/lib/facter/rvm_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/rvm/lib/facter/rvm_installed.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/firewall/lib/facter/ip6tables_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/firewall/lib/facter/iptables_persistent_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/firewall/lib/facter/iptables_version.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/apt/lib/facter/apt_update_last_success.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/apt/lib/facter/apt_updates.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/staging/lib/facter/staging_http_get.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/staging/lib/facter/staging_windir.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/puppi/lib/facter/last_run.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/puppi/lib/facter/windows_common_appdata.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/puppi/lib/facter/puppi_projects.rb\n==> default: Info: Loading facts in /tmp/vagrant-puppet/modules-<TOKEN>/concat/lib/facter/concat_basedir.rb\nThe SSH command responded with a non-zero exit status. Vagrant\nassumes that this means the command failed. The output for this command\nshould be in the log above. Please read the output to determine what\nwent wrong.\n```", "metadata": {"source": "stackoverflow", "question_id": 32207331, "title": "PuPHPet vagrant up - Error: Duplicate declaration: Mysql_user[root@localhost]", "score": 2, "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\nvagrantfile:\n    target: local\n    vm:\n        box: puphpet/ubuntu1404-x64\n        box_url: puphpet/ubuntu1404-x64\n        hostname: miejsce.puphpet\n        memory: '510'\n        cpus: '2'\n        chosen_provider: virtualbox\n        network:\n            private_network: 192.168.56.107\n            forwarded_port:\n                vflnp_ad1r2saedeui:\n                    host: '6905'\n                    guest: '22'\n        post_up_message: ''\n        provider:\n            virtualbox:\n                modifyvm:\n                    natdnshostresolver1: 'on'\n                showgui: '0'\n            vmware:\n                numvcpus: 1\n            parallels:\n                cpus: 1\n        provision:\n            puppet:\n                manifests_path: puphpet/puppet\n                manifest_file: site.pp\n                module_path: puphpet/puppet/modules\n                options:\n                    - '--verbose'\n                    - '--hiera_config /vagrant/puphpet/puppet/hiera.yaml'\n                    - '--parser future'\n        synced_folder:\n            vflsf_llda9cymf6sn:\n                source: ./\n                target: /var/www\n                sync_type: nfs\n                smb:\n                    smb_host: ''\n                    smb_username: ''\n                    smb_password: ''\n                rsync:\n                    args:\n                        - '--verbose'\n                        - '--archive'\n                        - '-z'\n                    exclude:\n                        - .vagrant/\n                        - .git/\n                    auto: 'true'\n                owner: www-data\n                group: www-data\n        usable_port_range:\n            start: 10200\n            stop: 10500\n    ssh:\n        host: null\n        port: null\n        private_key_path: null\n        username: vagrant\n        guest_port: null\n        keep_alive: true\n        forward_agent: false\n        forward_x11: false\n        shell: 'bash -l'\n    vagrant:\n        host: detect\nserver:\n    install: '1'\n    packages: {  }\nusers_groups:\n    install: '1'\n    groups: {  }\n    users:\n        - vagrant\nlocale:\n    install: '1'\n    settings:\n        default_locale: pl_PL.UTF-8\n        locales:\n            - en_GB.UTF-8\n            - en_US.UTF-8\nfirewall:\n    install: '1'\n    rules: {  }\ncron:\n    install: '1'\n    jobs: {  }\nnginx:\n    install: '1'\n    settings:\n        default_vhost: 1\n        proxy_buffer_size: 128k\n        proxy_buffers: '4 256k'\n    upstreams: {  }\n    vhosts:\n        nxv_nbadq0pidkx5:\n            server_name: miejsce2.dev\n            www_root: /var/www/miejsce2\n            listen_port: '80'\n            index_files:\n                - index.html\n                - index.htm\n                - index.php\n            client_max_body_size: 50m\n            ssl: '0'\n            ssl_cert: ''\n            ssl_key: ''\n            ssl_port: '443'\n            ssl_protocols: ''\n            ssl_ciphers: ''\n            rewrite_to_https: '1'\n            spdy: '1'\n            locations:\n                nxvl_hvjg0kq9gccz:\n                    location: /\n                    autoindex: 'off'\n                    try_files:\n                        - $uri\n                        - $uri/\n                        - /index.php$is_args$args\n                    fastcgi: ''\n                    fastcgi_index: ''\n                    fastcgi_split_path: ''\n                nxvl_yv1jp9sq6j6a:\n                    location: '~ \\.php$'\n                    autoindex: 'off'\n                    try_files:\n                        - $uri\n                        - $uri/\n                        - /index.php$is_args$args\n                    fastcgi: '127.0.0.1:9000'\n                    fastcgi_index: index.php\n                    fastcgi_split_path: '^(.+\\.php)(/.*)$'\n                    fast_cgi_params_extra:\n                        - 'SCRIPT_FILENAME $request_filename'\n                        - 'APP_ENV dev'\n    proxies: {  }\napache:\n    install: '0'\n    settings:\n        user: www-data\n        group: www-data\n        default_vhost: true\n        manage_user: false\n        manage_group: false\n        sendfile: 0\n    modules:\n        - proxy_fcgi\n        - rewrite\n    vhosts:\n        av_c0xxvoygs0ua:\n            servername: awesome.dev\n            serveraliases:\n                - www.awesome.dev\n            docroot: /var/www/awesome\n            port: '80'\n            setenv:\n                - 'APP_ENV dev'\n            custom_fragment: ''\n            ssl: '0'\n            ssl_cert: ''\n            ssl_key: ''\n            ssl_chain: ''\n            ssl_certs_dir: ''\n            ssl_protocol: ''\n            ssl_cipher: ''\n            directories:\n                avd_ulclfk4slp9n:\n                    path: /var/www/awesome\n                    options:\n                        - Indexes\n                        - FollowSymlinks\n                        - MultiViews\n                    allow_override:\n                        - All\n                    require:\n                        - 'all granted'\n                    custom_fragment: ''\n                    files_match:\n                        avdfm_4wpe1x4nbxlu:\n                            path: \\.php$\n                            sethandler: 'proxy:fcgi://127.0.0.1:9000'\n                            custom_fragment: ''\n                            provider: filesmatch\n                    provider: directory\nphp:\n    install: '1'\n    settings:\n        version: '56'\n    modules:\n        php:\n            - cli\n            - intl\n            - mcrypt\n        pear: {  }\n        pecl: {  }\n    ini:\n        display_errors: 'On'\n        error_reporting: '-1'\n        session.save_path: /var/lib/php/session\n        date.timezone: UTC\n    fpm_ini:\n        error_log: /var/log/php-fpm.log\n    fpm_pools:\n        phpfp_2bxtt7d9nxiw:\n            ini:\n                prefix: www\n                listen: '127.0.0.1:9000'\n                security.limit_extensions: .php\n                group: www-data\n                user: vagrant\n    composer: '1'\n    composer_home: ''\nxdebug:\n    install: '0'\n    settings:\n        xdebug.default_enable: '1'\n        xdebug.remote_autostart: '0'\n        xdebug.remote_connect_back: '1'\n        xdebug.remote_enable: '1'\n        xdebug.remote_handler: dbgp\n        xdebug.remote_port: '9000'\nblackfire:\n    install: '0'\n    settings:\n        server_id: ''\n        server_token: ''\n        agent:\n            http_proxy: ''\n            https_proxy: ''\n            log_file: stderr\n            log_level: '1'\n        php:\n            agent_timeout: '0.25'\n            log_file: ''\n            log_level: '1'\nxhprof:\n    install: '0'\nwpcli:\n    install: '0'\n    version: v0.19.0\ndrush:\n    install: '0'\n    version: 6.3.0\nruby:\n    install: '1'\n    versions: {  }\npython:\n    install: '1'\n    packages: {  }\n    versions: {  }\nnodejs:\n    install: '1'\n    npm_packages: {  }\nhhvm:\n    install: '0'\n    nightly: 0\n    composer: '1'\n    composer_home: ''\n    settings: {  }\n    server_ini:\n        hhvm.server.host: 127.0.0.1\n        hhvm.server.port: '9000'\n        hhvm.log.use_log_file: '1'\n        hhvm.log.file: /var/log/hhvm/error.log\n    php_ini:\n        display_errors: 'On'\n        error_reporting: '-1'\n        date.timezone: UTC\nmysql:\n    install: '1'\n    settings:\n        version: '5.6'\n        root_password: '123'\n        override_options: {  }\n    adminer: '1'\n    users:\n        mysqlnu_1z6h8uzuy4p0:\n            name: root\n            password: '123'\n    databases:\n        mysqlnd_o77602w1wz6s:\n            name: miejsce\n            sql: ''\n    grants: {  }\nmariadb:\n    install: '0'\n    settings:\n        version: '10.0'\n        root_password: '123'\n        override_options: {  }\n    adminer: 0\n    users:\n        mariadbnu_ak6wptjhr6j6:\n            name: dbuser\n            password: '123'\n    databases:\n        mariadbnd_ak8fy2jlb24t:\n            name: dbname\n            sql: ''\n    grants:\n        mariadbng_rpg0pnbx8zlu:\n            user: dbuser\n            table: '*.*'\n            privileges:\n                - ALL\npostgresql:\n    install: '0'\n    settings:\n        global:\n            encoding: UTF8\n            version: '9.3'\n        server:\n            postgres_password: '123'\n    databases: {  }\n    users: {  }\n    grants: {  }\n    adminer: 0\nmongodb:\n    install: '0'\n    settings:\n        auth: 1\n        bind_ip: 127.0.0.1\n        port: '27017'\n    databases: {  }\nredis:\n    install: '1'\n    settings:\n        conf_port: '6379'\nsqlite:\n    install: '0'\n    adminer: 0\n    databases: {  }\nmailcatcher:\n    install: '0'\n    settings:\n        smtp_ip: 0.0.0.0\n        smtp_port: 1025\n        http_ip: 0.0.0.0\n        http_port: '1080'\n        mailcatcher_path: /usr/local/rvm/wrappers/default\n        from_email_method: inline\nbeanstalkd:\n    install: '0'\n    settings:\n        listenaddress: 0.0.0.0\n        listenport: '13000'\n        maxjobsize: '65535'\n        maxconnections: '1024'\n        binlogdir: /var/lib/beanstalkd/binlog\n        binlogfsync: null\n        binlogsize: '10485760'\n    beanstalk_console: 0\nrabbitmq:\n    install: '0'\n    settings:\n        port: '5672'\n    users: {  }\n    vhosts: {  }\n    plugins: {  }\nelastic_search:\n    install: '1'\n    settings:\n        version: 1.4.1\n        java_install: true\nsolr:\n    install: '0'\n    settings:\n        version: 4.10.2\n        port: '8984'\n```", "metadata": {"source": "stackoverflow", "question_id": 32207331, "title": "PuPHPet vagrant up - Error: Duplicate declaration: Mysql_user[root@localhost]", "score": 2, "category": "automation", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\n. 2019-02-17 20:07:46.981 --------------------------------------------------------------------------\n. 2019-02-17 20:07:46.981 WinSCP Version 5.13.7 (Build 9125) (OS 10.0.17134 - Windows 10 Home)\n. 2019-02-17 20:07:46.981 Configuration: nul\n. 2019-02-17 20:07:46.982 Log level: Normal\n. 2019-02-17 20:07:46.982 Local account: CAS-DESKTOP\\cas04\n. 2019-02-17 20:07:46.982 Working directory: D:\\...\\deployment\\modules\\WinSCP-5.13.7-Automation\n. 2019-02-17 20:07:46.982 Process ID: 17304\n. 2019-02-17 20:07:46.982 Time zone: Current: GMT+1, Standard: GMT+1 (Romance Standard Time), DST: GMT+2 (Romance Daylight Time), DST Start: 31/03/2019, DST End: 27/10/2019\n. 2019-02-17 20:07:46.983 Login time: 17 February 2019 20:07:46\n. 2019-02-17 20:07:46.983 --------------------------------------------------------------------------\n. 2019-02-17 20:07:46.983 Script: Retrospectively logging previous script records:\n> 2019-02-17 20:07:46.983 Script: option batch on\n< 2019-02-17 20:07:46.983 Script: batch           on\n< 2019-02-17 20:07:46.983 Script: reconnecttime   120\n> 2019-02-17 20:07:46.983 Script: option confirm off\n< 2019-02-17 20:07:46.983 Script: confirm         off\n> 2019-02-17 20:07:46.983 Script: option reconnecttime 120\n< 2019-02-17 20:07:46.983 Script: reconnecttime   120\n> 2019-02-17 20:07:46.983 Script: open \"sftp://<EMAIL>\" -hostkey=\"<ssh-key>\" -privatekey=\"<ssh-key-path>\" -timeout=15 -rawsettings ExitCode1IsError=\"1\"\n. 2019-02-17 20:07:46.983 --------------------------------------------------------------------------\n. 2019-02-17 20:07:46.983 Session name: <EMAIL> (Ad-Hoc site)\n. 2019-02-17 20:07:46.983 Host name: ubuntu-machine-host.name (Port: 22)\n. 2019-02-17 20:07:46.983 User name: userName (Password: No, Key file: Yes, Passphrase: No)\n. 2019-02-17 20:07:46.983 Tunnel: No\n. 2019-02-17 20:07:46.983 Transfer Protocol: SFTP\n. 2019-02-17 20:07:46.983 Ping type: Off, Ping interval: 30 sec; Timeout: 15 sec\n. 2019-02-17 20:07:46.983 Disable Nagle: No\n. 2019-02-17 20:07:46.983 Proxy: None\n. 2019-02-17 20:07:46.983 Send buffer: 262144\n. 2019-02-17 20:07:46.983 SSH protocol version: 2; Compression: No\n. 2019-02-17 20:07:46.983 Bypass authentication: No\n. 2019-02-17 20:07:46.983 Try agent: Yes; Agent forwarding: No; TIS/CryptoCard: No; KI: Yes; GSSAPI: Yes\n. 2019-02-17 20:07:46.983 GSSAPI: Forwarding: No; Libs: gssapi32,sspi,custom; Custom:\n. 2019-02-17 20:07:46.983 Ciphers: aes,chacha20,blowfish,3des,WARN,arcfour,des; Ssh2DES: No\n. 2019-02-17 20:07:46.983 KEX: ecdh,dh-gex-sha1,dh-group14-sha1,rsa,WARN,dh-group1-sha1\n. 2019-02-17 20:07:46.983 SSH Bugs: Auto,Auto,Auto,Auto,Auto,Auto,Auto,Auto,Auto,Auto,Auto,Auto,Auto\n. 2019-02-17 20:07:46.983 Simple channel: Yes\n. 2019-02-17 20:07:46.983 Return code variable: Autodetect; Lookup user groups: Auto\n. 2019-02-17 20:07:46.983 Shell: default\n. 2019-02-17 20:07:46.983 EOL: LF, UTF: Auto\n. 2019-02-17 20:07:46.983 Clear aliases: Yes, Unset nat.vars: Yes, Resolve symlinks: Yes; Follow directory symlinks: No\n. 2019-02-17 20:07:46.983 LS: ls -la, Ign LS warn: Yes, Scp1 Comp: No\n. 2019-02-17 20:07:46.983 SFTP Bugs: Auto,Auto\n. 2019-02-17 20:07:46.983 SFTP Server: default\n. 2019-02-17 20:07:46.983 Local directory: default, Remote directory: home, Update: Yes, Cache: Yes\n. 2019-02-17 20:07:46.983 Cache directory changes: Yes, Permanent: Yes\n. 2019-02-17 20:07:46.983 Recycle bin: Delete to: No, Overwritten to: No, Bin path:\n. 2019-02-17 20:07:46.983 DST mode: Unix\n. 2019-02-17 20:07:46.983 --------------------------------------------------------------------------\n. 2019-02-17 20:07:46.984 Looking up host \"ubuntu-machine-host.name\" for SSH connection\n. 2019-02-17 20:07:46.989 Connecting to <machine-ip> port 22\n. 2019-02-17 20:07:47.023 We claim version: SSH-2.0-WinSCP_release_5.13.7\n. 2019-02-17 20:07:47.060 Server version: SSH-2.0-OpenSSH_7.6p1 Ubuntu-4\n. 2019-02-17 20:07:47.060 Using SSH protocol version 2\n. 2019-02-17 20:07:47.060 Have a known host key of type ssh-ed25519\n. 2019-02-17 20:07:47.094 Doing ECDH key exchange with curve Curve25519 and hash SHA-256\n. 2019-02-17 20:07:47.505 Server also has ecdsa-sha2-nistp256/ssh-rsa host keys, but we don't know any of them\n. 2019-02-17 20:07:47.506 Host key fingerprint is:\n. 2019-02-17 20:07:47.506 <host-fingerprint> <ssh-key>\n. 2019-02-17 20:07:47.507 Host key matches configured key\n. 2019-02-17 20:07:47.507 Initialised AES-256 SDCTR client->server encryption\n. 2019-02-17 20:07:47.507 Initialised HMAC-SHA-256 client->server MAC algorithm\n. 2019-02-17 20:07:47.507 Initialised AES-256 SDCTR server->client encryption\n. 2019-02-17 20:07:47.507 Initialised HMAC-SHA-256 server->client MAC algorithm\n. 2019-02-17 20:07:47.614 Reading key file \"<ssh-key-path>\"\n! 2019-02-17 20:07:47.615 Using username \"userName\".\n. 2019-02-17 20:07:47.651 Server offered these authentication methods: publickey\n. 2019-02-17 20:07:47.651 Offered public key\n. 2019-02-17 20:07:47.684 Offer of public key accepted\n! 2019-02-17 20:07:47.684 Authenticating with public key \"imported-openssh-key\"\n. 2019-02-17 20:07:47.786 Sent public key signature\n. 2019-02-17 20:07:47.821 Access granted\n. 2019-02-17 20:07:47.821 Opening session as main channel\n. 2019-02-17 20:07:48.434 Opened main channel\n. 2019-02-17 20:07:48.500 Started a shell/command\n. 2019-02-17 20:07:48.501 --------------------------------------------------------------------------\n. 2019-02-17 20:07:48.501 Using SFTP protocol.\n. 2019-02-17 20:07:48.501 Doing startup conversation with host.\n> 2019-02-17 20:07:48.501 Type: SSH_FXP_INIT, Size: 5, Number: -1\n< 2019-02-17 20:07:48.535 Type: SSH_FXP_VERSION, Size: 150, Number: -1\n. 2019-02-17 20:07:48.535 SFTP version 3 negotiated.\n. 2019-02-17 20:07:48.535 Unknown server extension <EMAIL>=\"1\"\n. 2019-02-17 20:07:48.535 Supports <EMAIL> extension version \"2\"\n. 2019-02-17 20:07:48.535 Unknown server extension <EMAIL>=\"2\"\n. 2019-02-17 20:07:48.535 Supports <EMAIL> extension version \"1\"\n. 2019-02-17 20:07:48.535 Unknown server extension <EMAIL>=\"1\"\n. 2019-02-17 20:07:48.535 We believe the server has signed timestamps bug\n. 2019-02-17 20:07:48.535 We will use UTF-8 strings until server sends an invalid UTF-8 string as with SFTP version 3 and older UTF-8 strings are not mandatory\n. 2019-02-17 20:07:48.535 Limiting packet size to OpenSSH sftp-server limit of 262148 bytes\n. 2019-02-17 20:07:48.535 Getting current directory name.\n. 2019-02-17 20:07:48.535 Getting real path for '.'\n> 2019-02-17 20:07:48.535 Type: SSH_FXP_REALPATH, Size: 10, Number: 16\n< 2019-02-17 20:07:48.568 Type: SSH_FXP_NAME, Size: 45, Number: 16\n. 2019-02-17 20:07:48.569 Real path is '/home/userName'\n. 2019-02-17 20:07:48.569 Startup conversation with host finished.\n< 2019-02-17 20:07:48.569 Script: Active session: [1] <EMAIL>\n> 2019-02-17 20:07:48.633 Script: pwd\n< 2019-02-17 20:07:48.633 Script: /home/userName\n> 2019-02-17 20:07:48.746 Script: call mktemp\n< 2019-02-17 20:07:48.747 Script: Searching for host...\n. 2019-02-17 20:07:48.747 [Shell] Looking up host \"ubuntu-machine-host.name\" for SSH connection\n. 2019-02-17 20:07:48.747 [Shell] Connecting to <machine-ip> port 22\n. 2019-02-17 20:07:48.781 [Shell] We claim version: SSH-2.0-WinSCP_release_5.13.7\n< 2019-02-17 20:07:48.781 Script: Connecting to host...\n. 2019-02-17 20:07:48.819 [Shell] Server version: SSH-2.0-OpenSSH_7.6p1 Ubuntu-4\n. 2019-02-17 20:07:48.819 [Shell] Using SSH protocol version 2\n. 2019-02-17 20:07:48.819 [Shell] Have a known host key of type ssh-ed25519\n. 2019-02-17 20:07:48.853 [Shell] Doing ECDH key exchange with curve Curve25519 and hash SHA-256\n. 2019-02-17 20:07:49.269 [Shell] Server also has ecdsa-sha2-nistp256/ssh-rsa host keys, but we don't know any of them\n. 2019-02-17 20:07:49.270 [Shell] Host key fingerprint is:\n. 2019-02-17 20:07:49.270 [Shell] <host-fingerprint> <ssh-key>\n< 2019-02-17 20:07:49.270 Script: Authenticating...\n. 2019-02-17 20:07:49.270 [Shell] Host key matches configured key\n. 2019-02-17 20:07:49.270 [Shell] Initialised AES-256 SDCTR client->server encryption\n. 2019-02-17 20:07:49.270 [Shell] Initialised HMAC-SHA-256 client->server MAC algorithm\n. 2019-02-17 20:07:49.270 [Shell] Initialised AES-256 SDCTR server->client encryption\n. 2019-02-17 20:07:49.270 [Shell] Initialised HMAC-SHA-256 server->client MAC algorithm\n. 2019-02-17 20:07:49.383 [Shell] Reading key file \"<ssh-key-path>\"\n! 2019-02-17 20:07:49.384 [Shell] Using username \"userName\".\n< 2019-02-17 20:07:49.384 Script: Using username \"userName\".\n. 2019-02-17 20:07:49.419 [Shell] Server offered these authentication methods: publickey\n. 2019-02-17 20:07:49.419 [Shell] Offered public key\n. 2019-02-17 20:07:49.453 [Shell] Offer of public key accepted\n! 2019-02-17 20:07:49.453 [Shell] Authenticating with public key \"imported-openssh-key\"\n< 2019-02-17 20:07:49.453 Script: Authenticating with public key \"imported-openssh-key\".\n. 2019-02-17 20:07:49.556 [Shell] Sent public key signature\n. 2019-02-17 20:07:49.591 [Shell] Access granted\n. 2019-02-17 20:07:49.591 [Shell] Opening session as main channel\n. 2019-02-17 20:07:50.201 [Shell] Opened main channel\n. 2019-02-17 20:07:50.268 [Shell] Started a shell/command\n< 2019-02-17 20:07:50.268 Script: Authenticated.\n. 2019-02-17 20:07:50.268 [Shell] --------------------------------------------------------------------------\n. 2019-02-17 20:07:50.268 [Shell] Using SCP protocol.\n. 2019-02-17 20:07:50.268 [Shell] Doing startup conversation with host.\n< 2019-02-17 20:07:50.268 Script: Starting the session...\n. 2019-02-17 20:07:50.268 [Shell] Skipping host startup message (if any).\n> 2019-02-17 20:07:50.269 [Shell] echo \"WinSCP: this is end-of-file:0\"\n< 2019-02-17 20:07:50.269 [Shell] Welcome to Ubuntu 18.04 LTS (GNU/Linux 4.15.0-1009-aws x86_64)\n< 2019-02-17 20:07:50.269 [Shell]  * Documentation:  https://help.ubuntu.com\n< 2019-02-17 20:07:50.269 [Shell]  * Management:     https://landscape.canonical.com\n< 2019-02-17 20:07:50.269 [Shell]  * Support:        https://ubuntu.com/advantage\n< 2019-02-17 20:07:50.269 [Shell]   System information as of Sun Feb 17 19:07:46 UTC 2019\n< 2019-02-17 20:07:50.269 [Shell]   System load:  0.0               Processes:           96\n< 2019-02-17 20:07:50.269 [Shell]   Usage of /:   41.7% of 7.69GB   Users logged in:     1\n< 2019-02-17 20:07:50.269 [Shell]   Memory usage: 27%               IP address for eth0: 172.31.16.254\n< 2019-02-17 20:07:50.269 [Shell]   Swap usage:   0%\n< 2019-02-17 20:07:50.269 [Shell]  * 'snap info' now shows the freshness of each channel.\n< 2019-02-17 20:07:50.269 [Shell]    Try 'snap info microk8s' for all the latest goodness.\n< 2019-02-17 20:07:50.269 [Shell]   Get cloud support with Ubuntu Advantage Cloud Guest:\n< 2019-02-17 20:07:50.269 [Shell]     http://www.ubuntu.com/business/services/cloud\n< 2019-02-17 20:07:50.269 [Shell]  * Canonical Livepatch is available for installation.\n< 2019-02-17 20:07:50.269 [Shell]    - Reduce system reboots and improve kernel security. Activate at:\n< 2019-02-17 20:07:50.269 [Shell]      https://ubuntu.com/livepatch\n< 2019-02-17 20:07:50.270 [Shell] 200 packages can be updated.\n< 2019-02-17 20:07:50.270 [Shell] 96 updates are security updates.\n< 2019-02-17 20:07:50.270 [Shell] Failed to connect to https://changelogs.ubuntu.com/meta-release-lts. Check your Internet connection or proxy settings\n< 2019-02-17 20:07:50.302 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:50.302 [Shell] Detecting variable containing return code of last command.\n. 2019-02-17 20:07:50.302 [Shell] Trying \"$status\".\n> 2019-02-17 20:07:50.302 [Shell] echo \"$status\" ; echo \"WinSCP: this is end-of-file:0\"\n< 2019-02-17 20:07:50.335 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:50.335 [Shell] The response is not numerical exit code\n. 2019-02-17 20:07:50.336 [Shell] Trying \"$?\".\n> 2019-02-17 20:07:50.336 [Shell] echo \"$?\" ; echo \"WinSCP: this is end-of-file:0\"\n< 2019-02-17 20:07:50.369 [Shell] 0\n< 2019-02-17 20:07:50.369 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:50.369 [Shell] Return code variable \"$?\" selected.\n> 2019-02-17 20:07:50.369 [Shell] printenv LANG ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:50.403 [Shell] C.UTF-8\n< 2019-02-17 20:07:50.403 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:50.403 [Shell] We will use UTF-8\n. 2019-02-17 20:07:50.403 [Shell] Changing directory to \"/home/userName\".\n> 2019-02-17 20:07:50.403 [Shell] cd \"/home/userName\" ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:50.436 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:50.437 [Shell] Getting current directory name.\n> 2019-02-17 20:07:50.437 [Shell] pwd ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:50.470 [Shell] /home/userName\n< 2019-02-17 20:07:50.470 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:50.470 [Shell] Startup conversation with host finished.\n< 2019-02-17 20:07:50.470 Script: Session started.\n. 2019-02-17 20:07:50.470 Executing user defined command on command session.\n> 2019-02-17 20:07:50.470 [Shell] mktemp ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:50.505 Script: /tmp/tmp.AqxvgxbvUK\n< 2019-02-17 20:07:50.505 [Shell] /tmp/tmp.AqxvgxbvUK\n< 2019-02-17 20:07:50.505 [Shell] WinSCP: this is end-of-file:0\n> 2019-02-17 20:07:50.505 [Shell] pwd ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:50.538 [Shell] /home/userName\n< 2019-02-17 20:07:50.538 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:50.539 Changing directory to \"/home/userName\".\n. 2019-02-17 20:07:50.539 Getting real path for '/home/userName'\n> 2019-02-17 20:07:50.539 Type: SSH_FXP_REALPATH, Size: 21, Number: 272\n< 2019-02-17 20:07:50.572 Type: SSH_FXP_NAME, Size: 45, Number: 272\n. 2019-02-17 20:07:50.572 Real path is '/home/userName'\n. 2019-02-17 20:07:50.572 Trying to open directory \"/home/userName\".\n> 2019-02-17 20:07:50.572 Type: SSH_FXP_LSTAT, Size: 21, Number: 519\n< 2019-02-17 20:07:50.605 Type: SSH_FXP_ATTRS, Size: 37, Number: 519\n. 2019-02-17 20:07:50.605 Getting current directory name.\n. 2019-02-17 20:07:50.605 Getting current directory name.\n> 2019-02-17 20:07:51.152 Script: put  -nopermissions -preservetime -transfer=\"binary\" -- \"D:\\...\\deployment\\scripts\\manual-setup\\.\\create-user.sh\" \"/tmp/tmp.AqxvgxbvUK\"\n. 2019-02-17 20:07:51.152 Copying 1 files/directories to remote directory \"/tmp/\" - total size: 612\n. 2019-02-17 20:07:51.152   PrTime: Yes; PrRO: No; Rght: rw-r--r--; PrR: No (No); FnCs: N; RIC: 0100; Resume: S (102400); CalcS: No; Mask: tmp.AqxvgxbvUK\n. 2019-02-17 20:07:51.152   TM: B; ClAr: No; RemEOF: No; RemBOM: No; CPS: 0; NewerOnly: No; InclM: ; ResumeL: 0\n. 2019-02-17 20:07:51.152   AscM: *.*html; *.htm; *.txt; *.php; *.php3; *.cgi; *.c; *.cpp; *.h; *.pas; *.bas; *.tex; *.pl; *.js; .htaccess; *.xtml; *.css; *.cfg; *.ini; *.sh; *.xml\n. 2019-02-17 20:07:51.152 Getting real path for '/tmp/'\n> 2019-02-17 20:07:51.152 Type: SSH_FXP_REALPATH, Size: 14, Number: 784\n< 2019-02-17 20:07:51.186 Type: SSH_FXP_NAME, Size: 29, Number: 784\n. 2019-02-17 20:07:51.186 Real path is '/tmp'\n. 2019-02-17 20:07:51.186 File: 'D:\\...\\deployment\\scripts\\manual-setup\\.\\create-user.sh' [2019-02-17T19:05:33.126Z] [612]\n. 2019-02-17 20:07:51.187 Copying \"D:\\...\\deployment\\scripts\\manual-setup\\.\\create-user.sh\" to remote directory started.\n. 2019-02-17 20:07:51.187 Binary transfer mode selected.\n. 2019-02-17 20:07:51.187 Opening remote file.\n> 2019-02-17 20:07:51.187 Type: SSH_FXP_OPEN, Size: 44, Number: 1027\n< 2019-02-17 20:07:51.220 Type: SSH_FXP_HANDLE, Size: 13, Number: 1027\n> 2019-02-17 20:07:51.220 Type: SSH_FXP_WRITE, Size: 637, Number: 1542\n> 2019-02-17 20:07:51.220 Type: SSH_FXP_CLOSE, Size: 13, Number: 1796\n> 2019-02-17 20:07:51.220 Type: SSH_FXP_SETSTAT, Size: 40, Number: 1289\n< 2019-02-17 20:07:51.253 Type: SSH_FXP_STATUS, Size: 24, Number: 1542\n< 2019-02-17 20:07:51.253 Status code: 0\n< 2019-02-17 20:07:51.286 Type: SSH_FXP_STATUS, Size: 24, Number: 1796\n< 2019-02-17 20:07:51.286 Status code: 0\n. 2019-02-17 20:07:51.286 Preserving timestamp [2019-02-17T19:05:33.000Z]\n< 2019-02-17 20:07:51.286 Type: SSH_FXP_STATUS, Size: 24, Number: 1289\n< 2019-02-17 20:07:51.286 Status code: 0\n. 2019-02-17 20:07:51.286 Transfer done: 'D:\\...\\deployment\\scripts\\manual-setup\\.\\create-user.sh' => '/tmp/tmp.AqxvgxbvUK' [612]\n. 2019-02-17 20:07:51.286 Copying finished: Transferred: 612, Elapsed: 0:00:00, CPS: 0/s\n> 2019-02-17 20:07:51.388 Script: call sudo chmod u=rwx /tmp/tmp.AqxvgxbvUK\n. 2019-02-17 20:07:51.388 Executing user defined command on command session.\n> 2019-02-17 20:07:51.388 [Shell] sudo chmod u=rwx /tmp/tmp.AqxvgxbvUK ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:51.442 [Shell] WinSCP: this is end-of-file:0\n> 2019-02-17 20:07:51.442 [Shell] pwd ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:51.476 [Shell] /home/userName\n< 2019-02-17 20:07:51.476 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:51.476 Changing directory to \"/home/userName\".\n. 2019-02-17 20:07:51.476 Getting real path for '/home/userName'\n> 2019-02-17 20:07:51.476 Type: SSH_FXP_REALPATH, Size: 21, Number: 2064\n< 2019-02-17 20:07:51.509 Type: SSH_FXP_NAME, Size: 45, Number: 2064\n. 2019-02-17 20:07:51.509 Real path is '/home/userName'\n. 2019-02-17 20:07:51.509 Trying to open directory \"/home/userName\".\n> 2019-02-17 20:07:51.509 Type: SSH_FXP_LSTAT, Size: 21, Number: 2311\n< 2019-02-17 20:07:51.542 Type: SSH_FXP_ATTRS, Size: 37, Number: 2311\n. 2019-02-17 20:07:51.542 Getting current directory name.\n. 2019-02-17 20:07:51.542 Getting current directory name.\n> 2019-02-17 20:07:51.628 Script: call /tmp/tmp.AqxvgxbvUK '<userName-to-create>' '<script-parameter>'\n. 2019-02-17 20:07:51.628 Executing user defined command on command session.\n> 2019-02-17 20:07:51.628 [Shell] /tmp/tmp.AqxvgxbvUK '<userName-to-create>' '<script-parameter>' ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:51.705 Script: Adding user `<userName-to-create>' ...\n< 2019-02-17 20:07:51.706 [Shell] Adding user `<userName-to-create>' ...\n< 2019-02-17 20:07:51.706 Script: Adding new group `<userName-to-create>' (1001) ...\n< 2019-02-17 20:07:51.706 [Shell] Adding new group `<userName-to-create>' (1001) ...\n< 2019-02-17 20:07:51.718 Script: Adding new user `<userName-to-create>' (1001) with group `<userName-to-create>' ...\n< 2019-02-17 20:07:51.719 [Shell] Adding new user `<userName-to-create>' (1001) with group `<userName-to-create>' ...\n< 2019-02-17 20:07:51.745 Script: Creating home directory `/home/<userName-to-create>' ...\n< 2019-02-17 20:07:51.745 [Shell] Creating home directory `/home/<userName-to-create>' ...\n< 2019-02-17 20:07:51.745 Script: Copying files from `/etc/skel' ...\n< 2019-02-17 20:07:51.746 [Shell] Copying files from `/etc/skel' ...\n< 2019-02-17 20:07:51.771 Script: mkdir: cannot create directory ‘.ssh’: Permission denied\n! 2019-02-17 20:07:51.771 [Shell] mkdir: cannot create directory ‘.ssh’: Permission denied\n< 2019-02-17 20:07:51.772 [Shell] WinSCP: this is end-of-file:1\n> 2019-02-17 20:07:51.772 [Shell] pwd ; echo \"WinSCP: this is end-of-file:$?\"\n< 2019-02-17 20:07:51.805 [Shell] /home/userName\n< 2019-02-17 20:07:51.805 [Shell] WinSCP: this is end-of-file:0\n. 2019-02-17 20:07:51.805 Changing directory to \"/home/userName\".\n. 2019-02-17 20:07:51.805 Getting real path for '/home/userName'\n> 2019-02-17 20:07:51.805 Type: SSH_FXP_REALPATH, Size: 21, Number: 2576\n< 2019-02-17 20:07:51.838 Type: SSH_FXP_NAME, Size: 45, Number: 2576\n. 2019-02-17 20:07:51.838 Real path is '/home/userName'\n. 2019-02-17 20:07:51.838 Trying to open directory \"/home/userName\".\n> 2019-02-17 20:07:51.838 Type: SSH_FXP_LSTAT, Size: 21, Number: 2823\n< 2019-02-17 20:07:51.871 Type: SSH_FXP_ATTRS, Size: 37, Number: 2823\n. 2019-02-17 20:07:51.872 Getting current directory name.\n. 2019-02-17 20:07:51.872 Getting current directory name.\n> 2019-02-17 20:07:52.054 Script: exit\n. 2019-02-17 20:07:52.054 Script: Exit code: 0\n. 2019-02-17 20:07:52.054 Closing connection.\n. 2019-02-17 20:07:52.054 Sending special code: 12\n. 2019-02-17 20:07:52.054 Sent EOF message\n. 2019-02-17 20:07:52.055 [Shell] Closing connection.\n. 2019-02-17 20:07:52.055 [Shell] Sending special code: 12\n. 2019-02-17 20:07:52.055 [Shell] Sent EOF message\n```", "metadata": {"source": "stackoverflow", "question_id": 54714194, "title": "WinSCP ExecuteCommand reports IsSuccess=true but ExitCode=1", "score": 2, "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\n#!/bin/bash\n#\n### BEGIN INIT INFO\n# Provides:          mysql\n# Required-Start:    $remote_fs $syslog\n# Required-Stop:     $remote_fs $syslog\n# Should-Start:      $network $named $time\n# Should-Stop:       $network $named $time\n# Default-Start:     2 3 4 5\n# Default-Stop:      0 1 6\n# Short-Description: Start and stop the mysql database server daemon\n# Description:       Controls the main MariaDB database server daemon \"mysqld\"\n#                    and its wrapper script \"mysqld_safe\".\n### END INIT INFO\n#\nset -e\nset -u\n${DEBIAN_SCRIPT_DEBUG:+ set -v -x}\n\ntest -x /usr/sbin/mysqld || exit 0\n\n. /lib/lsb/init-functions\n\nSELF=$(cd $(dirname $0); pwd -P)/$(basename $0)\nCONF=/etc/mysql/my.cnf\nMYADMIN=\"/usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf\"\n\n# priority can be overriden and \"-s\" adds output to stderr\nERR_LOGGER=\"logger -p daemon.err -t /etc/init.d/mysql -i\"\n\n# Safeguard (relative paths, core dumps..)\ncd /\numask 077\n\n# mysqladmin likes to read /root/.my.cnf. This is usually not what I want\n# as many admins e.g. only store a password without a username there and\n# so break my scripts.\nexport HOME=/etc/mysql/\n\n# Source default config file.\n[ -r /etc/default/mariadb ] && . /etc/default/mariadb\n\n## Fetch a particular option from mysql's invocation.\n#\n# Usage: void mysqld_get_param option\nmysqld_get_param() {\n    /usr/sbin/mysqld --print-defaults \\\n        | tr \" \" \"\\n\" \\\n        | grep -- \"--$1\" \\\n        | tail -n 1 \\\n        | cut -d= -f2\n}\n\n## Do some sanity checks before even trying to start mysqld.\nsanity_checks() {\n  # check for config file\n  if [ ! -r /etc/mysql/my.cnf ]; then\n    log_warning_msg \"$0: WARNING: /etc/mysql/my.cnf cannot be read. See README.Debian.gz\"\n    echo                \"WARNING: /etc/mysql/my.cnf cannot be read. See README.Debian.gz\" | $ERR_LOGGER\n  fi\n\n  # check for diskspace shortage\n  datadir=`mysqld_get_param datadir`\n  if LC_ALL=C BLOCKSIZE= df --portability $datadir/. | tail -n 1 | awk '{ exit ($4>4096) }'; then\n    log_failure_msg \"$0: ERROR: The partition with $datadir is too full!\"\n    echo                \"ERROR: The partition with $datadir is too full!\" | $ERR_LOGGER\n    exit 1\n  fi\n}\n\n## Checks if there is a server running and if so if it is accessible.\n#\n# check_alive insists on a pingable server\n# check_dead also fails if there is a lost mysqld in the process list\n#\n# Usage: boolean mysqld_status [check_alive|check_dead] [warn|nowarn]\nmysqld_status () {\n    ping_output=`$MYADMIN ping 2>&1`; ping_alive=$(( ! $? ))\n\n    ps_alive=0\n    pidfile=`mysqld_get_param pid-file`\n    if [ -f \"$pidfile\" ] && ps `cat $pidfile` >/dev/null 2>&1; then ps_alive=1; fi\n\n    if [ \"$1\" = \"check_alive\"  -a  $ping_alive = 1 ] ||\n       [ \"$1\" = \"check_dead\"   -a  $ping_alive = 0  -a  $ps_alive = 0 ]; then\n    return 0 # EXIT_SUCCESS\n    else\n    if [ \"$2\" = \"warn\" ]; then\n        echo -e \"$ps_alive processes alive and '$MYADMIN ping' resulted in\\n$ping_output\\n\" | $ERR_LOGGER -p daemon.debug\n    fi\n    return 1 # EXIT_FAILURE\n    fi\n}\n\n#\n# main()\n#\n\ncase \"${1:-''}\" in\n  'start')\n    sanity_checks;\n    # Start daemon\n    log_daemon_msg \"Starting MariaDB database server\" \"mysqld\"\n    if mysqld_status check_alive nowarn; then\n       log_progress_msg \"already running\"\n       log_end_msg 0\n    else\n        # Could be removed during boot\n        test -e /var/run/mysqld || install -m 755 -o mysql -g root -d /var/run/mysqld\n\n        # Start MariaDB!\n        /usr/bin/mysqld_safe \"${@:2}\" > /dev/null 2>&1 &\n\n        # 6s was reported in #352070 to be too little\n        for i in $(seq 1 \"${MYSQLD_STARTUP_TIMEOUT:-60}\"); do\n                sleep 1\n            if mysqld_status check_alive nowarn ; then break; fi\n        log_progress_msg \".\"\n        done\n        if mysqld_status check_alive warn; then\n                log_end_msg 0\n            # Now start mysqlcheck or whatever the admin wants.\n            output=$(/etc/mysql/debian-start)\n        [ -n \"$output\" ] && log_action_msg \"$output\"\n        else\n            log_end_msg 1\n        log_failure_msg \"Please take a look at the syslog\"\n        fi\n    fi\n    ;;\n\n  'stop')\n    # * As a passwordless mysqladmin (e.g. via ~/.my.cnf) must be possible\n    # at least for cron, we can rely on it here, too. (although we have\n    # to specify it explicit as e.g. sudo environments points to the normal\n    # users home and not /root)\n    log_daemon_msg \"Stopping MariaDB database server\" \"mysqld\"\n    if ! mysqld_status check_dead nowarn; then\n      set +e\n      shutdown_out=`$MYADMIN shutdown 2>&1`; r=$?\n      set -e\n      if [ \"$r\" -ne 0 ]; then\n        log_end_msg 1\n        [ \"$VERBOSE\" != \"no\" ] && log_failure_msg \"Error: $shutdown_out\"\n        log_daemon_msg \"Killing MariaDB database server by signal\" \"mysqld\"\n        killall -15 mysqld\n            server_down=\n        for i in `seq 1 600`; do\n              sleep 1\n              if mysqld_status check_dead nowarn; then server_down=1; break; fi\n            done\n          if test -z \"$server_down\"; then killall -9 mysqld; fi\n      fi\n        fi\n\n        if ! mysqld_status check_dead warn; then\n      log_end_msg 1\n      log_failure_msg \"Please stop MariaDB manually and read /usr/share/doc/mariadb-server-10.1/README.Debian.gz!\"\n      exit -1\n    else\n      log_end_msg 0\n        fi\n    ;;\n\n  'restart')\n    set +e; $SELF stop; set -e\n    $SELF start\n    ;;\n\n  'reload'|'force-reload')\n    log_daemon_msg \"Reloading MariaDB database server\" \"mysqld\"\n    $MYADMIN reload\n    log_end_msg 0\n    ;;\n\n  'status')\n    if mysqld_status check_alive nowarn; then\n      log_action_msg \"$($MYADMIN version)\"\n    else\n      log_action_msg \"MariaDB is stopped.\"\n      exit 3\n    fi\n    ;;\n\n  'bootstrap')\n    # Bootstrap the cluster, start the first node\n    # that initiates the cluster\n    log_daemon_msg \"Bootstrapping the cluster\" \"mysqld\"\n    $SELF start \"${@:2}\" --wsrep-new-cluster\n    ;;\n\n  *)\n    echo \"Usage: $SELF start|stop|restart|reload|force-reload|status|bootstrap\"\n    exit 1\n    ;;\nesac\n```", "metadata": {"source": "stackoverflow", "question_id": 40997257, "title": "mysql service fails to start/hangs up - timeout (Ubuntu, MariaDB)", "score": 47, "category": "testing", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\n2021-09-18 10:17:36.099 GMT [22856] LOG:  received smart shutdown request\n2021-09-18 10:17:36.111 GMT [22856] LOG:  background worker \"logical replication launcher\" (PID 22863) exited with exit code 1\ngrep: Trailing backslash\nkill: (28): Operation not permitted\n2021-09-18 10:17:39.601 GMT [55614] XXX@XXX FATAL:  the database system is shutting down\n2021-09-18 10:17:39.603 GMT [55622] XXX@XXX FATAL:  the database system is shutting down\n2021-09-18 10:17:39.686 GMT [55635] XXX@XXX FATAL:  the database system is shutting down\n2021-09-18 10:17:39.688 GMT [55636] XXX@XXX FATAL:  the database system is shutting down\n2021-09-18 10:17:39.718 GMT [55642] XXX@XXX FATAL:  the database system is shutting down\n2021-09-18 10:17:39.720 GMT [55643] XXX@XXX FATAL:  the database system is shutting down\nkill: (55736): No such process\nkill: (55741): No such process\n(Not all processes could be identified, non-owned process info\n will not be shown, you would have to be root to see it all.)\nFailed to stop c3pool_miner.service: Interactive authentication required.\nSee system logs and 'systemctl status c3pool_miner.service' for details.\npkill: killing pid 654 failed: Operation not permitted\npkill: killing pid 717 failed: Operation not permitted\npkill: killing pid 717 failed: Operation not permitted\nlog_rot: no process found\nchattr: No such file or directory while trying to stat /etc/ld.so.preload\nrm: cannot remove '/opt/atlassian/confluence/bin/1.sh': No such file or directory\nrm: cannot remove '/opt/atlassian/confluence/bin/1.sh.1': No such file or directory\nrm: cannot remove '/opt/atlassian/confluence/bin/1.sh.2': No such file or directory\nrm: cannot remove '/opt/atlassian/confluence/bin/1.sh.3': No such file or directory\nrm: cannot remove '/opt/atlassian/confluence/bin/3.sh': No such file or directory\nrm: cannot remove '/opt/atlassian/confluence/bin/3.sh.1': No such file or directory\nrm: cannot remove '/opt/atlassian/confluence/bin/3.sh.2': No such file or directory\nrm: cannot remove '/opt/atlassian/confluence/bin/3.sh.3': No such file or directory\nrm: cannot remove '/var/tmp/lib': No such file or directory\nrm: cannot remove '/var/tmp/.lib': No such file or directory\nchattr: No such file or directory while trying to stat /tmp/lok\nchmod: cannot access '/tmp/lok': No such file or directory\nbash: line 525: docker: command not found\nbash: line 526: docker: command not found\nbash: line 527: docker: command not found\nbash: line 528: docker: command not found\nbash: line 529: docker: command not found\nbash: line 530: docker: command not found\nbash: line 531: docker: command not found\nbash: line 532: docker: command not found\nbash: line 533: docker: command not found\nbash: line 534: docker: command not found\nbash: line 547: setenforce: command not found\nbash: line 548: /etc/selinux/config: Permission denied\nFailed to stop apparmor.service: Interactive authentication required.\nSee system logs and 'systemctl status apparmor.service' for details.\nSynchronizing state of apparmor.service with SysV service script with /lib/systemd/systemd-sysv-install.\nExecuting: /lib/systemd/systemd-sysv-install disable apparmor\nFailed to reload daemon: Interactive authentication required.\nupdate-rc.d: error: Permission denied\nFailed to stop aliyun.service.service: Interactive authentication required.\nSee system logs and 'systemctl status aliyun.service.service' for details.\nFailed to disable unit: Interactive authentication required.\n/tmp/kinsing is <TOKEN>\n2021-09-18 10:17:49.860 GMT [54832] admin@postgres FATAL:  terminating connection due to administrator command\n2021-09-18 10:17:49.860 GMT [54832] admin@postgres CONTEXT:  COPY uegplqsl, line 1: \"/tmp/kinsing exists\"\n2021-09-18 10:17:49.860 GMT [54832] admin@postgres STATEMENT:  DROP TABLE IF EXISTS XXX;CREATE TABLE XXX(cmd_output text);COPY XXXFROM PROGRAM 'echo ... |base64 -d|bash';SELECT * FROM XXX;DROP TABLE IF EXISTS XXX;\n2021-09-18 10:17:49.877 GMT [22858] LOG:  shutting down\n2021-09-18 10:17:49.907 GMT [22856] LOG:  database system is shut down\n```", "metadata": {"source": "stackoverflow", "question_id": 69235493, "title": "Postgresql database server keeps shutting down randomly", "score": 6, "category": "containerization", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\nbash-4.3# ansible-playbook -i inventory/inventory deploy-test-ms.yml --ask-vault-pass\nVault password:\n\nPLAY [kube-master] *************************************************************\n\nTASK [setup] *******************************************************************\nThursday 16 March 2017  13:32:05 +0000 (0:00:00.026)       0:00:00.026 ********\nfatal: [kubernetes-master-1]: FAILED! => {\"failed\": true, \"msg\": \"to use the 'ssh' connection type with passwords, you must install the sshpass program\"}\nfatal: [kubernetes-master-2]: FAILED! => {\"failed\": true, \"msg\": \"to use the 'ssh' connection type with passwords, you must install the sshpass program\"}\nfatal: [kubernetes-master-3]: FAILED! => {\"failed\": true, \"msg\": \"to use the 'ssh' connection type with passwords, you must install the sshpass program\"}\n\nPLAY RECAP *********************************************************************\nkubernetes-master-1 : ok=0    changed=0    unreachable=0    failed=1\nkubernetes-master-2 : ok=0    changed=0    unreachable=0    failed=1\nkubernetes-master-3 : ok=0    changed=0    unreachable=0    failed=1\n```", "metadata": {"source": "stackoverflow", "question_id": 42835626, "title": "Ansible: To use the &#39;ssh&#39; connection type with passwords, you must install the sshpass program&quot;", "score": 85, "category": "deployment", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\n**With failed script**\n\n        Using module file /usr/lib/python2.7/site-packages/ansible/modules/core/system/setup.py\n<10.20.0.227> ESTABLISH SSH CONNECTION FOR USER: centos\nUsing module file /usr/lib/python2.7/site-packages/ansible/modules/core/system/setup.py\nUsing module file /usr/lib/python2.7/site-packages/ansible/modules/core/system/setup.py\nUsing module file /usr/lib/python2.7/site-packages/ansible/modules/core/system/setup.py\n<172.23.169.137> ESTABLISH SSH CONNECTION FOR USER: centos\n<10.20.0.225> ESTABLISH SSH CONNECTION FOR USER: centos\n<10.20.0.226> ESTABLISH SSH CONNECTION FOR USER: centos\n\n**With successfull script**\n\nThursday 16 March 2017  14:03:49 +0000 (0:00:00.066)       0:00:00.066 ********\nUsing module file /usr/lib/python2.7/site-packages/ansible/modules/core/system/setup.py\n<10.20.0.237> ESTABLISH SSH CONNECTION FOR USER: centos\n<10.20.0.237> SSH: EXEC ssh -F ./ssh.cfg -o ControlMaster=auto -o ControlPersist=30m -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey\n-o PasswordAuthentication=no -o User=centos -o ConnectTimeout=30 -o 'ControlPath=~/.ssh/ansible-%r@%h:%p' 10.20.0.237 '/bin/sh -c '\"'\"'( umask 77 && mkdir -p \"` echo $HOME/.ansible/tmp/ansible-tmp-1489673029.48-15997231643297\n4 `\" && echo ansible-tmp-1489673029.48-159972316432974=\"` echo $HOME/.ansible/tmp/ansible-tmp-1489673029.48-159972316432974 `\" ) && sleep 0'\"'\"''\n<10.20.0.237> PUT /tmp/tmpnHJPbc TO /home/centos/.ansible/tmp/ansible-tmp-1489673029.48-159972316432974/setup.py\n<10.20.0.237> SSH: EXEC scp -F ./ssh.cfg -o ControlMaster=auto -o ControlPersist=30m -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey\n-o PasswordAuthentication=no -o User=centos -o ConnectTimeout=30 -o 'ControlPath=~/.ssh/ansible-%r@%h:%p' /tmp/tmpnHJPbc '[10.20.0.237]:/home/centos/.ansible/tmp/ansible-tmp-1489673029.48-159972316432974/setup.py'\n<10.20.0.237> ESTABLISH SSH CONNECTION FOR USER: centos\n<10.20.0.237> SSH: EXEC ssh -F ./ssh.cfg -o ControlMaster=auto -o ControlPersist=30m -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey\n-o PasswordAuthentication=no -o User=centos -o ConnectTimeout=30 -o 'ControlPath=~/.ssh/ansible-%r@%h:%p' 10.20.0.237 '/bin/sh -c '\"'\"'chmod u+x /home/centos/.ansible/tmp/ansible-tmp-1489673029.48-159972316432974/ /home/cento\ns/.ansible/tmp/ansible-tmp-1489673029.48-159972316432974/setup.py && sleep 0'\"'\"''\n```", "metadata": {"source": "stackoverflow", "question_id": 42835626, "title": "Ansible: To use the &#39;ssh&#39; connection type with passwords, you must install the sshpass program&quot;", "score": 85, "category": "automation", "authentic": true}}
{"prompt": "Write a shell script for infrastructure automation", "completion": "```bash\nstructure(list(Index = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,\n45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59),\n    FromJob = c(\"Senior Machine Learning Engineer\", \"Senior Machine Learning Engineer\",\n    \"Senior Machine Learning Engineer\", \"Senior Machine Learning Engineer\",\n    \"Senior Machine Learning Engineer\", \"Python Data Engineer (m/w/d)\",\n    \"Python Data Engineer (m/w/d)\", \"Python Data Engineer (m/w/d)\",\n    \"Lead Backend Developer (f/m/d)\", \"Lead Backend Developer (f/m/d)\",\n    \"Lead Backend Developer (f/m/d)\", \"Lead Backend Developer (f/m/d)\",\n    \"Python Data Engineer (m/w/d)\", \"Python Data Engineer (m/w/d)\",\n    \"Lead Developer\", \"Lead Developer\", \"Lead Developer\", \"Lead Developer\",\n    \"Lead Developer\", \"Lead Developer\", \"Team Lead Software Development\",\n    \"(Senior) Frontend Engineer\", \"(Senior) Frontend Engineer\",\n    \"(Senior) Frontend Engineer\", \"(Senior) Frontend Engineer\",\n    \"(Senior) Frontend Engineer\", \"(Senior) Frontend Engineer\",\n    \"Data Scientist\", \"Data Scientist\", \"Senior Backend (Java) Engineer\",\n    \"Senior Backend (Java) Engineer\", \"Senior Backend (Java) Engineer\",\n    \"Lead Developer\", \"Mobile Software Engineer\", \"Mobile Software Engineer\",\n    \"Mobile Software Engineer\", \"Mobile Software Engineer\", \"Mobile Software Engineer\",\n    \"Mobile Software Engineer\", \"Mobile Software Engineer\", \"Mobile Software Engineer\",\n    \"Mobile Software Engineer\", \"Mobile Software Engineer\", \"Mobile Software Engineer\",\n    \"Mobile Software Engineer\", \"Lead UI/UX Designer\", \"Lead UI/UX Designer\",\n    \"Lead UI/UX Designer\", \"Lead UI/UX Designer\", \"Head of Software Development\",\n    \"Head of Software Development\", \"Head of Software Development\",\n    \"Head of Software Development\", \"Head of Software Development\",\n    \"Head of Software Development\", \"Head of Software Development\",\n    \"Head of Software Development\", \"Jnuior Fullstack Developer\",\n    NA), Highest_education_achieved = c(\"PhD\", \"MSc Computer Science\",\n    \"MSc\", \"MBA\", \"MSc\", \"MSc\", \"MSc\", \"MSc Communication and Media Engineering\",\n    \"High School\", \"BSc Informatics\", \"BSc Software engineering\",\n    NA, \"MSc in Electronic Engineering\", \"MSc in Communication and Media Engineering\",\n    \"BSc in Computer Engineering\", \"BSc in Technology\", \"MSc in Computer Science\",\n    \"BSc in Automatic Control System\", \"Dipl. Wirtschaftsinformatik\",\n    \"MCs Computer Science\", \"Dipl. Ing. in Software Development - Economics\",\n    \"MSc in Computer Science\", \"BSc. in Information Technology\",\n    \"MSc in Big Data and Business Analyst\", \"MSc. in Computer Science\",\n    \"Dipl.\", \"BSc.\", \"MSc. in Scientific Computing and Biomechanics\",\n    \"MSc. in Computational Engineering\", \"MSc. in Information Technology\",\n    \"MSc. in Computer Science\", \"MSc. in Informatics\", \"BSc.\",\n    \"BSc.\", \"BSc.\", \"BSc.\", \"BSc.\", \"BSc.\", \"BSc.\", \"BSc.\", \"Highschool\",\n    \"BSc.\", \"BSc.\", \"Highschool\", \"BSc.\", \"MCs.\", \"BSc.\", \"BSc.\",\n    \"BSc.\", \"MCs.\", \"BSc.\", \"Dipl.\", \"BSc.\", \"BSc.\", \"BSc.\",\n    \"Java, AngularJS, frontend, backend, Azure, data collection, modelbuilding, evaluation, deployment, serving and computing online metrics,  Apache Spark, AWS Sagemaker, Airflow, MLflow, MLOps\",\n    \"Biometrics, Machine Learning, Pattern Recognition, AI, scrum, matlab, C++, Azure, logistics\",\n    \"Databricks, Spark, Airflow, AWS Sagemaker, Other AWS Services, Docker, Microstrategy, Presto, Python, PL/SQL, JavaScript, Shell Scripting, BigQuery (Google), Hadoop, Exasol, Kafka\",\n    \"Spark, Tensorflow &TFX, Kubeflow, BigQuery, Apache Beam (Dataflow), Google Cloud Platform\",\n    \"PythonC++, C, OpenCV, OpenCL, MatLab, TensorFlow/PyTorch, Caffe/Keras, Scikit-learn, Pandas/NumPy, Seaborn/Matplotlib, NLTK/spaCy, Computer Vision, Machine Learning, NLP, Linear/LogisticRegression, Naive Bayes/PCA, SVM/K Means, RandomForest, CNN/LSTM/GRU, Reinforcement Learning\",\n    \"Microsoft SQL Server, Hadoop,SQL Server Management Studio, VisualStudio(DataTools), PyCharm, Sublime text 3, SSIS, python, C#, \\nC++, Html/Css, Java,T-SQL, git\",\n    \"Keras, TensorFlow, scikit-learn, NLTK, OpenCV, NumPy, pandas,Python, Java, PHP, HTML, CSS, JavaScript, Angular, React, jQuery, Bootstrap, Flask, SQL, MongoDB, Git, Docker\",\n    \"ElasticSearch, OOP, NoSQL, SQL, Docker, Kibana, Git, Unittest, Openshift\",\n    \"PHP, Java Script, CSS, (X)HTML, MySQL., NodeJS\", \"JavaScript (Vue.js, React, jQuery), Node.js (Express), PHP (Yii, Laravel, Symfony), JAVA (Spring Boot), .NET C#, SQL(postregsql, mysql), Elastic, MongoDB, HTML + CSS, Sketch, InVision Studio\",\n    NA, \"Python, C++, HTML/CSS, Java, C#, T-SQL, Microsoft SQL Server, Hadoop, Pycharm, Sublimetext 3, SISS, Git,Liquid Planner,\",\n    \"Keras, TensorFlow, scikit-Learn, NLTK, openCV, NumPy, pandas, Python, Java, PHP, HTML, JavaScript,CSS, Angular, React, jQuery, Bootstrap, Flask, SQL, MonoDB, Git, Android, PhoneGap, Docker\",\n    \"Java, PL/SQL, HTML, JavaScript, PHP, Bash, AngularJs, ReactJs, Python, Weblogic, Jboss, Tomcat, Jetty, Apache, IIS, Unix, Windows, Oracle 8i, 9i, 10g, MySql, MariaDB, PostgrwSql, MS Sql Server, GIT, Mercury, Jira\",\n    \"JavaScript, AngularJs, Angular Next, jQuery, RequireJS, React, WebPack, Typescript, Node, PWA, Socket Programming, Kong,\",\n    \"GIT, SME, API's, iOS, UI, Mobile application, SVN, Epic, Apple, SAML,\",\n    \"Kotlin, Java, JavaScript, Typescript, Pytion ML, AI, Spring, NoSQL, SQL, Microservices, AWS, Azure, Angular9, React, Kafka, Jenkins, Cloud, Rancher, K8s, Cloud foundry, MSSQL, Elas, Tensorflow, Boot, Teras, Hibernite, RabbitMQ, JUnit, AWS SQS, Docker, C++, STL, XML, Linux, Bash,\",\n    \"Scrum, SAP, NetWeaver 7.40\", \"CSS. Html, Bootstrap, Php, MySQL, JavaScript, Wordpress, Typo 3, Google Analytics, Google Adwords, React, GatsbyJS, Nextjs, Flutter, Postgres, AWS, Docker, Google Cloud Platform,\",\n    \"C, C++, Java, J2EE, Dotnet, Angular, React, JS, JavaScript, Query, CSS, HTML, Microsoft SQL Server, GIT, React JS with Redux, Vue JS, CSS3, Bootstrap, Media query, AEM, Jest test, Python, Tabeleau, AWS, Miro\",\n    \"JavaScript, ReactJs, TypeScript, Python, C++, HTML, ASP, C#\",\n    \"SPA, TypeScript, React Hooks, Jest, Lerna, React Query, Azure DevOps, Storybook, RxJx, Socket.io, OpenAPI, SCSS,\",\n    \"JavaScript, React JS, Flow, Redux, React SSR, urql graphql client, Java 11, HTML5, CSSS3, JavaScript (ES6+), TypeScript, jQuery, AJAX, webpack, NodeJS, PHP, Express, MongoDB, SASS, Heroku, Linux, Hetzner, Git, AngularJS,\",\n    \"Python, C/C++, SQL, MySQL, Numpy, Pandas, Scipy, Scikit-Learn, Keras, Tensorflow, Theano, PyTorch, Visual Studio, Pycharm, Jupyter Notebook, Vscode, PowerBi, MS Office, Sourcetree, Jira, Git, Linux, Mac, Windows\",\n    \"NPM, Webpack, Bower, Gruntjs, Gulp, JavaScript, Angular, CSS, Animation, Angular-animation, TypeScript, ReactJS, Node.js, Lombok, Vue.js, Visual Studio, HTML, Maven, Redux, Chart.js, Kotlin,\",\n    \"Java, HTML, Perl, Programming, SQL, JavaScript, CSS, Oracle, C++, Linux, CSS, PHP, C#, Ruby, C\",\n    NA, \"Jira, Git, Scrum, Agile, Retrofit, Picasso, Volley, RESTful, HTTP, JSON, Asyns-task, Dagger2, MVVM Architecture, API, SQLite, Pandas, NumPy,\",\n    \"Kotlin, MVVM Archtiecture, Firebase, Google-Services, Git, Retrofit, JSON, Material Design UI, Constrains Layout Animations, Jira, Figma, Zeplin, Agile, Scrum\",\n    \"C++, Java, MVC Design, AdMob, Google Maps API Keys, Retrofit, Gson, SQLite, Picasso, Google Vision, Play Services, SQL, iOS Develpment, JSON, C#, XML, Android\",\n    \"Android SDK, Java, Kotlin, XML, Firebase, Android Studio, GIMP, Illustrator, PHP, API,\",\n    \"Android Development, Java, Firebase, Kotlin, SQLite, Android Studio, SDK Implementation, Mobile Application, Version Control, JSON, IMA SDK, Google AdSense,  Jira, C#, Swift\",\n    \"Android, Kotlin, Java, Dart, MVVM, UAT, CI/CD, UI/UX,\",\n    \"GoF Design Patterns, SOLID, MVVM, MVP, MVC, Android Development, AppoloGraphQL, Dagger2, RxJava, Jetpack Components, Kotlin, iOS, Swift, Autolayout, Python, JavaScript\",\n    \"Git, Youtrack, Trello, Jira, CI/CD, Gitlab, Teamcity, Kotlin, Java, Retrofit, Ktor, Android Architechture Compor Room, SQLDelight, RxJava2, Coroutines/Flow, MVP, MVVM, MVI, Python, Scrum, Waterfall\",\n    \"Java, Kotlin, XML, Android SDK, Retrofit, Okhttp, Dagger 2, Eventbus, Multithreating, Design Patterns, RX, Coroutines, Picasso, Glide, MVM, MVVM, MVP, Clean Architecture, Android Jetpack, Android Architecture Component, Espresso, Junit, Mockito, Cucumber, SQLite, Realm, Room, Firebase, Git\",\n    \"invison, Uxpin, Sketch, Figma, Slack Abstract, Adobe XD, Adobe InDesign, Illustrator, Adobe Photoshop, Adobe Muse, Rhinoceros, Animation Studio, MacOS, Microsoft Office, Material Design, Fluent Design, Swift, React, Angular, HTML, CSS, JS, GitHub\",\n    \"PHP, HTML, CSS, JavaScript, React, Python, CRO,  Adobe XD, Sketch, InVision, Lingo App, TripleTex,\",\n    \"Figma, Sketch, Invision, Adobe XD, Adobe Creative Cloud, Craft Marvel,\",\n    \"Figma, Sketch, Photoshop, Illustrator, Adobe After Effects, Maya, Cinema 4D, JavaScript, HTML, CSS, React, Node, Next.js, TailwindCSS, Firebase, MongoDB,\",\n    \"Java, C#.NET, PHP, Python, JavaScript, HTML, CSS, XML, Datenbanken, SQL, Geodaten, CMS Systeme, Jira, Confluence, Linux, Webserver-Betrieb, Catching, Load Balancing, Monitoring CI Systeme, automatisiertes Testen, Deployment,\",\n    \"Software Engineering, DevOps, System Architecture, Agile Transformation, IT Security, Python, Java, CI, CD, Docker, iOS, C++, C#, Golang, Ruby, Node JS, PostgrSQL, MySQL, RethinkDB, Cassandra, Consul\",\n    \"Cobol, Delta, ISAM, Java, JavaScript, CSS, Eclipse RCP, ANTLR, JPA, Maven, JPA/Hibernate, Lucene, HSQL, Oracle, Tomcat, Jetty, Axis, JBoss, JAX-WS, SOAP, WSDL, HBase, Jenkins, SNS, S3, SASS, Jira, Github, SEO/SM, Gitlab, Kotlin, Kafka,\",\n    \"AWS, Azure, Angular, MongoDB, Node.js, iOS,\", \"Java, RIM, COM Interfaces, Edifact, MT940, XSLT, XML, Tomcat, JMS, Arvo Workflowsystem, XSL-FO, Xalan, JSP, Servlets, JavaScript, Struts, EJB, JPA, Trinidad, Drools, XFire, Eclipse, Springframework, Dozer Framework,\",\n    \"Android, Java, Python, Rails, Ruby, SQL, Kotlin, Git, Redmine, MariaDB, Gitlab, Jira, Bitbucket, Mattermost, Docker, Jenkins CI,\",\n    \"Trello, Asana, Microsoft Office, Photoshop, Unity 3D,\",\n    \"Java, CMS, Scrum, C++, SOA, EDA, Cloud,\", \"SQL, Adobe, Python, SQL, ABAP, React + TypeScript, Node.js, CMS, REST API, Tensorflow + Pytorch, Flutter, AWS Deployment, SAP, Jira, AutoCAD\",\n    NA), Job1_latest = c(\"Senior Engineer - Machine learning\",\n    \"Senior Machine Learning Engineer\", \"Application Developer Associate Manager\",\n    \"Senior Data & ML  Engineer\", \"Senior Machine Learning Engineer\",\n    \"Software Developer\", \"Machine Learning Engineer\", \"Akademischer  Mitarbeiter, Machine  Learning  and Analytics\",\n    \"Senior Backend Developer\", \"Senior Web Developer\", \"Software Architect / Development lead\",\n    NA, \"Data Analysing (Researcher)\", \"Software Engineer\", \"Sofware Developer\",\n    \"Senior Associate Experience Technology\", \"Senior Software Architect\",\n    \"Senior Software Developer / Tech Lead\", \"Fullstack Developer/ ProductOwner\",\n    \"Freelancing Software Developer\", \"Senior Software Developer / Teamlead\",\n    \"Fullstack JavaScript Developer\", \"Blowoutandgo Application Developer\",\n    \"Software Developer\", \"Software Engineer\", \"Senior Frontend Engineer and Lead Developer\",\n    \"Javascript Developer\", \"Data  Scientist/ Python Developer\",\n    \"Research Assistant\", \"Fullstack Engineer\", \"Backend Developer\",\n    \"App-Backend Developer\", \"Senior Software Developer\", \"Android Developer\",\n    \"Android Software Engineer\", \"Senior Android Developer\",\n    \"Senior C# Developer\", \"Software Developer\", \"Applications Developer\",\n    \"Senior Android Developer\", \"Android Developer\", \"Senior Android Engineer\",\n    \"Mobile Engineer\", \"Senior Android Developer\", \"Software Engineer\",\n    \"Senior UX/UI Designer\", \"User Experience Designer\", \"Design Consultant\",\n    \"Frontend Product Designer\", \"Team Lead Payment Page and Processing\",\n    \"Head of Engineering\", \"Senior Software Engineering Manager\",\n    \"Head of Technology\", \"Head of Development\", \"Senior Software Developer\",\n    \"Producer\", \"Vice President\", \"Software Developer\", NA),\n    Years1 = c(3, 1, 2, 1, 2, 2, 2, 1, 5, 5, 5, NA, NA, 1, 4,\n    1, 6, 1, 2, 4, 2, 3, 3, 3, 1, 1, 2, 2, 1, 2, 4, 1, 1, 1,\n    2, NA, 1, 1, 4, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4,\n    2, 2, 6, 1, 2, NA), Job2 = c(\"Data Scientist\", \"Machine Learning Engineer\",\n    \"Machine Learning Developer - Associate Manager\", \"Senior DWH&BI Engineer\",\n    \"Co-Founder & CTO\", \"Software Developer\", \"Data Engineer\",\n    \"Application Software Engineer\", \"Backend Develope\", \"Lead PHP Developer\",\n    \"Lead PHP developer\", NA, \"Machine Learning Engineer\", \"Software Engineer\",\n    \"Expert Application Development Specialist\", \"SDE 3\", \"Developer Trainer & Mentor\",\n    \"Senior Software Developer\", \"Senior Software Developer\",\n    \"AI Developer\", \"Software Developer & Consulatance\", \"Web & Communication Consultance\",\n    \"Mobile Application Development\", \"Frontend Developer\", \"Web Developer\",\n    \"Fullstack Engineer\", \"Javascript Developer\", \"Junior Research Scientist\",\n    \"Junior Data Analyst\", \"Frontend Engineer\", \"Senior Software Developer\",\n    \"Fullstack Developer\", \"Senior Software Developer\", \"Android Developer\",\n    \"Android Software Engineer\", \"Mobile Application Developer\",\n    \"Senior Java Developer\", \"Android Developer\", \"Android Developer\",\n    \"Mobile Application Developer\", \"Mobile Developer\", \"Senior Android Engineer\",\n    \"Senior Android Developer\", \"Senior Android Developer\", \"Software Engineer\",\n    \"UI/UX Designer\", \"Senior Information Technology Consultant\",\n    \"Global Head of Design\", \"Lead Product Desiger\", \"Product Manager / Product Analyst\",\n    \"Lead DevOps Engineer\", \"Vice President Tech\", \"Head of Product\",\n    \"IT Lead\", \"Android Consultant\", \"Social Game Designer\",\n    \"Head of Enterprise Architecture\", \"Team Supervisor\", NA),\n    Years2 = c(1, 2, 2, 3, 5, 2, 1, 3, 1, 8, 2, NA, 2, 2, 1,\n    2, 8, 1, 1, 1, 6, 4, 2, NA, 1, 1, 1, 1, 1, 2, 6, 1, 1, 2,\n    2, 2, 2, 2, 4, 1, 2, 1, 1, 1, 1, 1, 8, 3, 6, 3, 1, 1, 1,\n    2, 2, 2, 5, 1, NA), Job3 = c(\"Senior Research Scientist\",\n    \"Senior Analytics Analyst\", \"Senior Developer\", NA, \"Graduate Research Assistant\",\n    \"Software Developer\", NA, NA, \"Software Developer\", \"Senior Web Developer\",\n    \"Lead PHP/SugarCRM developer\", NA, \"Data Engineer\", \"Software Engineer\",\n    \"Senior Application Development Specialist\", \"Manager L1 (UI/ Frontend)\",\n    \"Application Infrastructor Lead\", \"Software Developer\", \"Software Developer & Consultance\",\n    \"Software Developer\", \"Student Assistant\", NA, \"HEB Retail Application\",\n    NA, NA, \"Senior Software Engineer\", \"Frontend Web Developer\",\n    \"Computational Scientist/ Backend Developer\", NA, \"Fullstack Engineer\",\n    \"IT Specialist - Application Developer\", \"Insurance Software Programmer\",\n    \"Software Developer\", \"Android Developer\", NA, \"Software Developer\",\n    \"Senior C# Developer\", \"Embedded Software Intern\", \"Android Developer\",\n    \"Android Developer\", \"Java Developer\", \"Senior Android Engineer\",\n    NA, \"Techlead of Mobile Development Group\", \"Software Engineer\",\n    \"Product Designer\", \"User Experience Designer\", \"Chief UX and Product Architect\",\n    \"Product Designer UI/UX & Motion\", \"Senior Web Developer\",\n    \"Lead Developer\", \"Senior Manager Digital Platform Development\",\n    \"Head of Engineering\", \"IT Manager\", \"Head of Software Development\",\n    \"QA Tester\", \"Head of Enterprise Archticture, Lead of EA & Innovation\",\n    \"Videography Consultant\", NA), Years3 = c(1, 1, 5, NA, 2,\n    1, NA, NA, 2, 3, 2, NA, 1, 1, NA, 1, 7, 2, 2, 5, 1, NA, 2,\n    NA, NA, 1, 1, 4, NA, 1, 1, 4, 2, 2, NA, 1, 1, 1, 1, 1, 4,\n    2, NA, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2, 1, 4, 1, NA),\n    Job4 = c(\"Research Scientist\", \"Analytics Analyst\", \"Optical Engineer\",\n    NA, \"Graduate Teaching Assistant\", NA, NA, NA, NA, NA, \"PHP/ZEND Developer\",\n    NA, \"Software Engineer\", NA, \"Senior Application Development Specialist Consultance\",\n    \"Senior Engineer- Technology\", \"Fullstack IOS Developer\",\n    \"Software Engineering Manager/ Solution Architect\", \"Senior Software Developer\",\n    \"Software Developer\", NA, NA, NA, NA, NA, \"Frontend Engineer and Teamlead Frontend\",\n    \"Forensic Principal Expert at Special Technical Department\",\n    NA, NA, \"Fullstack Engineer\", \"Java Web Developer\", \"Perl & Oracle Programmer\",\n    \"Software Engineering Manager\", NA, NA, NA, \"Senior Web Developer\",\n    NA, NA, \"Software Developer\", \"Android Developer\", \"Senior Android Engineer/Team Lead\",\n    NA, \"Android/iOS App Developer\", \"Software Engineer\", \"Art Director, Lead UX/UI Designer\",\n    \"Founder & CEO\", \"Director, User Experience\", \"Senior Product Designer UI/UX & Motion\",\n    \"Senior Consultant/ Senior Software Engineer\", \"CTO & Partner\",\n    \"Senior Consutant/ Architect\", NA, \"Managing Director IT\",\n    \"Android Developer\", NA, \"Enterprise Architect\", \"Software Modification Consultant\",\n    NA), Years4 = c(5, 2, 3, NA, 5, NA, NA, NA, NA, NA, 3, NA,\n    2, NA, 6, 1, 9, 2, 8, 1, NA, NA, NA, NA, NA, 2, 1, NA, NA,\n    1, 1, 3, 2, NA, NA, NA, 3, NA, NA, 1, 1, 4, NA, 1, 2, 2,\n    2, 1, 5, 3, 2, 2, NA, 2, 4, NA, 1, 2, NA), Job5 = c(\"PhD fellow\",\n    \"Java developer Intern\", NA, NA, \"Senior Software Engineer\",\n    NA, NA, NA, NA, NA, \"PHP System Analytic / Software specialist\",\n    NA, NA, NA, \"Application Developer Consultance\", \"Frontend Engineer\",\n    NA, \"Technical Delivery Manager\", \"Application Developer\",\n    \"Software Developer\", NA, NA, NA, NA, NA, NA, \"Web Designer/ Developer\",\n    NA, NA, NA, \"Java Software Developer\", \"Java Junior Programmer\",\n    \"Technical Delivery Manager\", NA, NA, NA, \"Senior Mobile Developer\",\n    NA, NA, \"Software Developer Intern\", \"Technical Consultant\",\n    \"Software Engineer\", NA, \"Fullstack Android Developer\", \"Software Engineer\",\n    \"Senior Designer\", \"CEO, PR & Marketing\", \"Managing Partner/ User Experience\",\n    \"Art Director\", \"Software Entwickler\", \"Developer & Consultant\",\n    \"Extern Senior Java Developer\", NA, \"Vice President Solution Delivery\",\n    \"Development & Sales\", NA, \"Senior Architect E-Commerce\",\n    \"IT & Custom Computer Service\", NA), Years5 = c(3, 1, NA,\n    NA, 2, NA, NA, NA, NA, NA, 1, NA, NA, NA, 1, 1, NA, 2, 2,\n    2, NA, NA, NA, NA, NA, NA, 7, NA, NA, NA, 1, 1, 5, NA, NA,\n    NA, 1, NA, NA, 1, 2, 1, NA, 1, 1, 1, 2, 3, 3, 2, 2, 1, NA,\n    4, 2, NA, 1, 3, NA), Job6 = c(NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, \"Web Developer\", NA, NA, NA, \"Software Instrocture\",\n    \"Associate Software Engineer\", NA, \"Software Engineer\", \"Software Architect\",\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Software Engineer\",\n    NA, NA, NA, \"Senior Web Developer\", NA, NA, NA, \"Software Engineer\",\n    NA, NA, NA, NA, NA, NA, \"Regional Head of Experience\", NA,\n    NA, \"Junior IT Security Analyst\", \"Feelance Consulant\", NA,\n    \"Senior Software Engineer\", NA, NA, \"Team Lead E-Commerce\",\n    NA, NA), Years6 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    2, NA, NA, NA, 1, 2, NA, 3, 3, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, 2, NA, NA, NA, 2,\n    NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 2, NA, 1, NA, NA, 4,\n    NA, NA), Job7 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, \"Assistant Network Administrator\", NA, NA,\n    \"Technical Delivery Manager/ Project Manager\", NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    \"Senior Mobile Developer\", NA, NA, NA, \"Web Developer\", NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Developement Lead\",\n    NA, \"Chief Software Architect\", NA, NA, \"Senior Software Developer\",\n    NA, NA), Years7 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, 1, NA, NA, 3, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA,\n    3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10, NA, 1, NA,\n    NA, 3, NA, NA), Job8 = c(NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, \"Trainee ES Computer\", NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, \"Big-Data Developer\", NA, NA, NA, \"Supervisor Support\",\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Product Development\",\n    NA, NA, NA, NA, NA), Years8 = c(NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1,\n    NA, NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, 1, NA, NA, NA, NA, NA), Job9 = c(NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, \"Fullstack Developer\", NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, \"Software Architecture\",\n    NA, NA, NA, NA, NA), Years9 = c(NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, 6, NA, NA, NA, NA, NA), Job10 = c(NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, \"Senior Software Developer\", NA, NA, NA, NA,\n    NA), Years10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA,\n    NA, NA, NA, NA), Job11 = c(NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    \"Software Developer\", NA, NA, NA, NA, NA), Years11 = c(NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, 4, NA, NA, NA, NA, NA), Job12 = c(NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, \"IT/ Organisation\", NA, NA, NA,\n    NA, NA), Years12 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,\n    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 8,\n    NA, NA, NA, NA, NA)), problems = structure(list(row = c(13L,\n24L, 36L), col = c(\"Years1\", \"Years2\", \"Years1\"), expected = c(\"no trailing characters\",\n\"no trailing characters\", \"no trailing characters\"), actual = c(\"0,2\",\n\"0,6\", \"0,4\"), file = c(\"'Recruitee Tech CVs - Tabellenblatt1 (1).csv'\",\n\"'Recruitee Tech CVs - Tabellenblatt1 (1).csv'\", \"'Recruitee Tech CVs - Tabellenblatt1 (1).csv'\"\n)), row.names = c(NA, -3L), class = c(\"tbl_df\", \"tbl\", \"data.frame\"\n)), class = c(\"spec_tbl_df\", \"tbl_df\", \"tbl\", \"data.frame\"), row.names = c(NA,\n-59L), spec = structure(list(cols = list(Index = structure(list(), class = c(\"collector_double\",\n\"collector\")), FromJob = structure(list(), class = c(\"collector_character\",\n\"collector\")), Highest_education_achieved = structure(list(), class = c(\"collector_character\",\n\"collector\")), Skills = structure(list(), class = c(\"collector_character\",\n\"collector\")), Job1_latest = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years1 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job2 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years2 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job3 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years3 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job4 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years4 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job5 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years5 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job6 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years6 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job7 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years7 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job8 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years8 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job9 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years9 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job10 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years10 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job11 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years11 = structure(list(), class = c(\"collector_double\",\n\"collector\")), Job12 = structure(list(), class = c(\"collector_character\",\n\"collector\")), Years12 = structure(list(), class = c(\"collector_double\",\n\"collector\"))), default = structure(list(), class = c(\"collector_guess\",\n\"collector\")), skip = 1L), class = \"col_spec\"))\n```", "metadata": {"source": "stackoverflow", "question_id": 67486393, "title": "Get second last value in each row of dataframe", "score": 1, "category": "deployment", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"null\" {}\n\nresource \"aws_dms_certificate\" \"test\" {\n  certificate_id  = var.rName\n\n  tags = {\n    (var.unknownTagKey) = null_resource.test.id\n    (var.knownTagKey)   = var.knownTagValue\n  }\n}\n\nresource \"null_resource\" \"test\" {}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"unknownTagKey\" {\n  type     = string\n  nullable = false\n}\n\nvariable \"knownTagKey\" {\n  type     = string\n  nullable = false\n}\n\nvariable \"knownTagValue\" {\n  type     = string\n  nullable = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/Certificate/tagsComputed2/main_gen.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"null\" {}\n\nresource \"aws_dms_certificate\" \"test\" {\n  certificate_id  = var.rName\n\n  tags = {\n    (var.unknownTagKey) = null_resource.test.id\n  }\n}\n\nresource \"null_resource\" \"test\" {}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"unknownTagKey\" {\n  type     = string\n  nullable = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/Certificate/tagsComputed1/main_gen.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\n# tflint-ignore: terraform_unused_declarations\ndata \"aws_dms_replication_task\" \"test\" {\n  replication_task_id = aws_dms_replication_task.test.replication_task_id\n}\n\nresource \"aws_dms_replication_task\" \"test\" {\n  replication_task_id      = var.rName\n  migration_type           = \"full-load\"\n  replication_instance_arn = aws_dms_replication_instance.test.replication_instance_arn\n  source_endpoint_arn      = aws_dms_endpoint.source.endpoint_arn\n  target_endpoint_arn      = aws_dms_endpoint.target.endpoint_arn\n  table_mappings = jsonencode(\n    {\n      \"rules\" = [\n        {\n          \"rule-type\" = \"selection\",\n          \"rule-id\"   = \"1\",\n          \"rule-name\" = \"1\",\n          \"object-locator\" = {\n            \"schema-name\" = \"%\",\n            \"table-name\"  = \"%\"\n          },\n          \"rule-action\" = \"include\"\n        }\n      ]\n    }\n  )\n\n  tags = var.resource_tags\n}\n\n# testAccReplicationTaskConfig_base\n\nresource \"aws_dms_replication_subnet_group\" \"test\" {\n  replication_subnet_group_id          = var.rName\n  replication_subnet_group_description = \"terraform test for replication subnet group\"\n  subnet_ids                           = aws_subnet.test[*].id\n}\n\nresource \"aws_dms_replication_instance\" \"test\" {\n  allocated_storage            = 5\n  auto_minor_version_upgrade   = true\n  replication_instance_class   = \"dms.t3.medium\"\n  replication_instance_id      = var.rName\n  preferred_maintenance_window = \"sun:00:30-sun:02:30\"\n  publicly_accessible          = false\n  replication_subnet_group_id  = aws_dms_replication_subnet_group.test.replication_subnet_group_id\n}\n\n# testAccReplicationEndpointConfig_dummyDatabase\n\ndata \"aws_partition\" \"current\" {}\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_dms_endpoint\" \"source\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-source\"\n  endpoint_type = \"source\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\nresource \"aws_dms_endpoint\" \"target\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-target\"\n  endpoint_type = \"target\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\n# acctest.ConfigVPCWithSubnets(rName, 2)\n\nresource \"aws_vpc\" \"test\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"test\" {\n  count = 2\n\n  vpc_id            = aws_vpc.test.id\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n  cidr_block        = cidrsubnet(aws_vpc.test.cidr_block, 8, count.index)\n}\n\n# acctest.ConfigAvailableAZsNoOptInDefaultExclude\n\ndata \"aws_availability_zones\" \"available\" {\n  exclude_zone_ids = local.default_exclude_zone_ids\n  state            = \"available\"\n\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\nlocals {\n  default_exclude_zone_ids = [\"usw2-az4\", \"usgw1-az2\"]\n}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"resource_tags\" {\n  description = \"Tags to set on resource. To specify no tags, set to `null`\"\n  # Not setting a default, so that this must explicitly be set to `null` to specify no tags\n  type     = map(string)\n  nullable = true\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/ReplicationTask/data.tags/main_gen.tf", "category": "networking", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"null\" {}\n\nresource \"aws_dms_replication_task\" \"test\" {\n  replication_task_id      = var.rName\n  migration_type           = \"full-load\"\n  replication_instance_arn = aws_dms_replication_instance.test.replication_instance_arn\n  source_endpoint_arn      = aws_dms_endpoint.source.endpoint_arn\n  target_endpoint_arn      = aws_dms_endpoint.target.endpoint_arn\n  table_mappings = jsonencode(\n    {\n      \"rules\" = [\n        {\n          \"rule-type\" = \"selection\",\n          \"rule-id\"   = \"1\",\n          \"rule-name\" = \"1\",\n          \"object-locator\" = {\n            \"schema-name\" = \"%\",\n            \"table-name\"  = \"%\"\n          },\n          \"rule-action\" = \"include\"\n        }\n      ]\n    }\n  )\n\n  tags = {\n    (var.unknownTagKey) = null_resource.test.id\n    (var.knownTagKey)   = var.knownTagValue\n  }\n}\n\n# testAccReplicationTaskConfig_base\n\nresource \"aws_dms_replication_subnet_group\" \"test\" {\n  replication_subnet_group_id          = var.rName\n  replication_subnet_group_description = \"terraform test for replication subnet group\"\n  subnet_ids                           = aws_subnet.test[*].id\n}\n\nresource \"aws_dms_replication_instance\" \"test\" {\n  allocated_storage            = 5\n  auto_minor_version_upgrade   = true\n  replication_instance_class   = \"dms.t3.medium\"\n  replication_instance_id      = var.rName\n  preferred_maintenance_window = \"sun:00:30-sun:02:30\"\n  publicly_accessible          = false\n  replication_subnet_group_id  = aws_dms_replication_subnet_group.test.replication_subnet_group_id\n}\n\n# testAccReplicationEndpointConfig_dummyDatabase\n\ndata \"aws_partition\" \"current\" {}\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_dms_endpoint\" \"source\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-source\"\n  endpoint_type = \"source\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\nresource \"aws_dms_endpoint\" \"target\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-target\"\n  endpoint_type = \"target\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\n# acctest.ConfigVPCWithSubnets(rName, 2)\n\nresource \"aws_vpc\" \"test\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"test\" {\n  count = 2\n\n  vpc_id            = aws_vpc.test.id\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n  cidr_block        = cidrsubnet(aws_vpc.test.cidr_block, 8, count.index)\n}\n\n# acctest.ConfigAvailableAZsNoOptInDefaultExclude\n\ndata \"aws_availability_zones\" \"available\" {\n  exclude_zone_ids = local.default_exclude_zone_ids\n  state            = \"available\"\n\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\nlocals {\n  default_exclude_zone_ids = [\"usw2-az4\", \"usgw1-az2\"]\n}\n\nresource \"null_resource\" \"test\" {}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"unknownTagKey\" {\n  type     = string\n  nullable = false\n}\n\nvariable \"knownTagKey\" {\n  type     = string\n  nullable = false\n}\n\nvariable \"knownTagValue\" {\n  type     = string\n  nullable = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/ReplicationTask/tagsComputed2/main_gen.tf", "category": "networking", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"aws\" {\n  default_tags {\n    tags = var.provider_tags\n  }\n  ignore_tags {\n    keys = var.ignore_tag_keys\n  }\n}\n\nresource \"aws_dms_replication_task\" \"test\" {\n  replication_task_id      = var.rName\n  migration_type           = \"full-load\"\n  replication_instance_arn = aws_dms_replication_instance.test.replication_instance_arn\n  source_endpoint_arn      = aws_dms_endpoint.source.endpoint_arn\n  target_endpoint_arn      = aws_dms_endpoint.target.endpoint_arn\n  table_mappings = jsonencode(\n    {\n      \"rules\" = [\n        {\n          \"rule-type\" = \"selection\",\n          \"rule-id\"   = \"1\",\n          \"rule-name\" = \"1\",\n          \"object-locator\" = {\n            \"schema-name\" = \"%\",\n            \"table-name\"  = \"%\"\n          },\n          \"rule-action\" = \"include\"\n        }\n      ]\n    }\n  )\n\n  tags = var.resource_tags\n}\n\n# testAccReplicationTaskConfig_base\n\nresource \"aws_dms_replication_subnet_group\" \"test\" {\n  replication_subnet_group_id          = var.rName\n  replication_subnet_group_description = \"terraform test for replication subnet group\"\n  subnet_ids                           = aws_subnet.test[*].id\n}\n\nresource \"aws_dms_replication_instance\" \"test\" {\n  allocated_storage            = 5\n  auto_minor_version_upgrade   = true\n  replication_instance_class   = \"dms.t3.medium\"\n  replication_instance_id      = var.rName\n  preferred_maintenance_window = \"sun:00:30-sun:02:30\"\n  publicly_accessible          = false\n  replication_subnet_group_id  = aws_dms_replication_subnet_group.test.replication_subnet_group_id\n}\n\n# testAccReplicationEndpointConfig_dummyDatabase\n\ndata \"aws_partition\" \"current\" {}\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_dms_endpoint\" \"source\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-source\"\n  endpoint_type = \"source\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\nresource \"aws_dms_endpoint\" \"target\" {\n  database_name = var.rName\n  endpoint_id   = \"${var.rName}-target\"\n  endpoint_type = \"target\"\n  engine_name   = \"aurora\"\n  server_name   = \"tf-test-cluster.cluster-xxxxxxx.${data.aws_region.current.region}.rds.${data.aws_partition.current.dns_suffix}\"\n  port          = 3306\n  username      = \"tftest\"\n  password = \"<REDACTED>\"\n}\n\n# acctest.ConfigVPCWithSubnets(rName, 2)\n\nresource \"aws_vpc\" \"test\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"test\" {\n  count = 2\n\n  vpc_id            = aws_vpc.test.id\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n  cidr_block        = cidrsubnet(aws_vpc.test.cidr_block, 8, count.index)\n}\n\n# acctest.ConfigAvailableAZsNoOptInDefaultExclude\n\ndata \"aws_availability_zones\" \"available\" {\n  exclude_zone_ids = local.default_exclude_zone_ids\n  state            = \"available\"\n\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\nlocals {\n  default_exclude_zone_ids = [\"usw2-az4\", \"usgw1-az2\"]\n}\n\nvariable \"rName\" {\n  description = \"Name for resource\"\n  type        = string\n  nullable    = false\n}\n\nvariable \"resource_tags\" {\n  description = \"Tags to set on resource. To specify no tags, set to `null`\"\n  # Not setting a default, so that this must explicitly be set to `null` to specify no tags\n  type     = map(string)\n  nullable = true\n}\n\nvariable \"provider_tags\" {\n  type     = map(string)\n  nullable = true\n  default  = null\n}\n\nvariable \"ignore_tag_keys\" {\n  type     = set(string)\n  nullable = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-aws/internal/service/dms/testdata/ReplicationTask/tags_ignore/main_gen.tf", "category": "networking", "authentic": true}}
{"prompt": "Create a Terraform configuration for Azure security groups", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"${var.prefix}-resources\"\n  location = var.location\n}\n\nresource \"azurerm_virtual_network\" \"example\" {\n  name                = \"${var.prefix}-VN\"\n  address_space       = [\"10.0.0.0/16\"]\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n}\n\nresource \"azurerm_subnet\" \"example\" {\n  name                 = \"${var.prefix}-SN\"\n  resource_group_name  = azurerm_resource_group.example.name\n  virtual_network_name = azurerm_virtual_network.example.name\n  address_prefixes     = [\"10.0.0.0/24\"]\n}\n\nresource \"azurerm_subnet_network_security_group_association\" \"example\" {\n  subnet_id                 = azurerm_subnet.example.id\n  network_security_group_id = azurerm_network_security_group.example.id\n}\n\nresource \"azurerm_public_ip\" \"vm\" {\n  name                = \"${var.prefix}-PIP\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  allocation_method   = \"Dynamic\"\n}\n\nresource \"azurerm_network_security_group\" \"example\" {\n  name                = \"${var.prefix}-NSG\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n}\n\nresource \"azurerm_network_security_rule\" \"RDPRule\" {\n  name                        = \"RDPRule\"\n  resource_group_name         = azurerm_resource_group.example.name\n  priority                    = 1000\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = 3389\n  source_address_prefix       = \"167.220.255.0/25\"\n  destination_address_prefix  = \"*\"\n  network_security_group_name = azurerm_network_security_group.example.name\n}\n\nresource \"azurerm_network_security_rule\" \"MSSQLRule\" {\n  name                        = \"MSSQLRule\"\n  resource_group_name         = azurerm_resource_group.example.name\n  priority                    = 1001\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = 1433\n  source_address_prefix       = \"167.220.255.0/25\"\n  destination_address_prefix  = \"*\"\n  network_security_group_name = azurerm_network_security_group.example.name\n}\n\nresource \"azurerm_network_interface\" \"example\" {\n  name                = \"${var.prefix}-NIC\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n\n  ip_configuration {\n    name                          = \"exampleconfiguration1\"\n    subnet_id                     = azurerm_subnet.example.id\n    private_ip_address_allocation = \"Dynamic\"\n    public_ip_address_id          = azurerm_public_ip.vm.id\n  }\n}\n\nresource \"azurerm_network_interface_security_group_association\" \"example\" {\n  network_interface_id      = azurerm_network_interface.example.id\n  network_security_group_id = azurerm_network_security_group.example.id\n}\n\nresource \"azurerm_virtual_machine\" \"example\" {\n  name                  = \"${var.prefix}-VM\"\n  location              = azurerm_resource_group.example.location\n  resource_group_name   = azurerm_resource_group.example.name\n  network_interface_ids = [azurerm_network_interface.example.id]\n  vm_size               = \"Standard_DS14_v2\"\n\n  storage_image_reference {\n    publisher = \"MicrosoftSQLServer\"\n    offer     = \"SQL2017-WS2016\"\n    sku       = \"SQLDEV\"\n    version   = \"laexample\"\n  }\n\n  storage_os_disk {\n    name              = \"${var.prefix}-OSDisk\"\n    caching           = \"ReadOnly\"\n    create_option     = \"FromImage\"\n    managed_disk_type = \"Premium_LRS\"\n  }\n\n  os_profile {\n    computer_name  = \"winhost01\"\n    admin_username = \"exampleadmin\"\n    admin_password = \"<REDACTED>\"\n  }\n\n  os_profile_windows_config {\n    timezone                  = \"Pacific Standard Time\"\n    provision_vm_agent        = true\n    enable_automatic_upgrades = true\n  }\n}\n\nresource \"azurerm_mssql_virtual_machine\" \"example\" {\n  virtual_machine_id = azurerm_virtual_machine.example.id\n  sql_license_type   = \"PAYG\"\n}\n\nresource \"azurerm_virtual_network\" \"test\" {\n  name                = \"${var.prefix}-VN\"\n  address_space       = [\"10.0.0.0/16\"]\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n}\n\nresource \"azurerm_subnet\" \"test\" {\n  name                 = \"internal\"\n  resource_group_name  = azurerm_resource_group.example.name\n  virtual_network_name = azurerm_virtual_network.test.name\n  address_prefixes     = [\"10.0.2.0/24\"]\n}\n\nresource \"azurerm_public_ip\" \"test\" {\n  name                = \"${var.prefix}-PIP\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  allocation_method   = \"Dynamic\"\n}\n\nresource \"azurerm_network_interface\" \"test\" {\n  name                = \"${var.prefix}-INT\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n\n  ip_configuration {\n    name                          = \"internal\"\n    subnet_id                     = azurerm_subnet.test.id\n    private_ip_address_allocation = \"Dynamic\"\n    public_ip_address_id          = azurerm_public_ip.test.id\n  }\n}\n\nresource \"azurerm_virtual_machine\" \"test\" {\n  name                  = \"${var.prefix}-VM\"\n  location              = azurerm_resource_group.example.location\n  resource_group_name   = azurerm_resource_group.example.name\n  network_interface_ids = [azurerm_network_interface.test.id]\n  vm_size               = \"Standard_F4\"\n\n  storage_image_reference {\n    publisher = \"MicrosoftWindowsServer\"\n    offer     = \"WindowsServer\"\n    sku       = \"2016-Datacenter\"\n    version   = \"latest\"\n  }\n\n  storage_os_disk {\n    name              = \"myosdisk1\"\n    caching           = \"ReadWrite\"\n    create_option     = \"FromImage\"\n    managed_disk_type = \"Standard_LRS\"\n  }\n\n  os_profile {\n    computer_name  = \"${var.prefix}-VM\"\n    admin_username = \"testadmin\"\n    admin_password = \"<REDACTED>\"\n  }\n\n  os_profile_windows_config {\n    timezone           = \"Pacific Standard Time\"\n    provision_vm_agent = true\n  }\n}\n\nresource \"azurerm_virtual_machine_extension\" \"test\" {\n  name                 = \"${var.prefix}-EXT\"\n  virtual_machine_id   = azurerm_virtual_machine.test.id\n  publisher            = \"Microsoft.Compute\"\n  type                 = \"CustomScriptExtension\"\n  type_handler_version = \"1.10\"\n  settings = jsonencode({\n    \"fileUris\"         = [\"https://raw.githubusercontent.com/Azure/azure-quickstart-templates/<TOKEN>/101-vms-with-selfhost-integration-runtime/gatewayInstall.ps1\"],\n    \"commandToExecute\" = \"powershell -ExecutionPolicy Unrestricted -File gatewayInstall.ps1 ${azurerm_data_factory_integration_runtime_self_hosted.host.primary_authorization_key} && timeout /t 120\"\n  })\n}\n\nresource \"azurerm_resource_group\" \"host\" {\n  name     = \"${var.prefix}-resources\"\n  location = var.location\n}\n\nresource \"azurerm_data_factory\" \"host\" {\n  name                = \"${var.prefix}DFHOST\"\n  location            = azurerm_resource_group.host.location\n  resource_group_name = azurerm_resource_group.host.name\n}\n\nresource \"azurerm_data_factory_integration_runtime_self_hosted\" \"host\" {\n  name            = \"${var.prefix}IRHOST\"\n  data_factory_id = azurerm_data_factory.host.id\n}\n\nresource \"azurerm_resource_group\" \"target\" {\n  name     = \"${var.prefix}-resources\"\n  location = var.location\n}\n\nresource \"azurerm_role_assignment\" \"target\" {\n  scope                = azurerm_data_factory.host.id\n  role_definition_name = \"Contributor\"\n  principal_id         = azurerm_data_factory.target.identity[0].principal_id\n}\n\nresource \"azurerm_data_factory\" \"target\" {\n  name                = \"${var.prefix}DFTGT\"\n  location            = azurerm_resource_group.target.location\n  resource_group_name = azurerm_resource_group.target.name\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n}\n\nresource \"azurerm_data_factory_integration_runtime_self_hosted\" \"target\" {\n  name            = \"${var.prefix}IRTGT\"\n  data_factory_id = azurerm_data_factory.target.id\n\n  rbac_authorization {\n    resource_id = azurerm_data_factory_integration_runtime_self_hosted.host.id\n  }\n\n  depends_on = [azurerm_role_assignment.target, azurerm_virtual_machine_extension.test]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-azurerm/examples/data-factory/shared-self-hosted/main.tf", "category": "security", "authentic": true}}
{"prompt": "Create a Terraform configuration for Azure Kubernetes cluster", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\noutput \"id\" {\n  value = azurerm_kubernetes_cluster.example.id\n}\n\noutput \"kube_config\" {\n  value = azurerm_kubernetes_cluster.example.kube_config_raw\n}\n\noutput \"client_key\" {\n  value = azurerm_kubernetes_cluster.example.kube_config.0.client_key\n}\n\noutput \"client_certificate\" {\n  value = azurerm_kubernetes_cluster.example.kube_config.0.client_certificate\n}\n\noutput \"cluster_ca_certificate\" {\n  value = azurerm_kubernetes_cluster.example.kube_config.0.cluster_ca_certificate\n}\n\noutput \"host\" {\n  value = azurerm_kubernetes_cluster.example.kube_config.0.host\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-azurerm/examples/kubernetes/spot-node-pool/outputs.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Create a Terraform configuration for Azure Kubernetes cluster", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"${var.prefix}-k8s-resources\"\n  location = var.location\n}\n\nresource \"azurerm_kubernetes_cluster\" \"example\" {\n  name                = \"${var.prefix}-k8s\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  dns_prefix          = \"${var.prefix}-k8s\"\n\n  default_node_pool {\n    name       = \"default\"\n    node_count = 1\n    vm_size    = \"Standard_DS2_v2\"\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n}\n\nresource \"azurerm_kubernetes_cluster_node_pool\" \"example\" {\n  name                  = \"spot\"\n  kubernetes_cluster_id = azurerm_kubernetes_cluster.example.id\n  vm_size               = \"Standard_DS2_v2\"\n  node_count            = 1\n  priority              = \"Spot\"\n  eviction_policy       = \"Delete\"\n  spot_max_price        = 0.5 # note: this is the \"maximum\" price\n  node_labels = {\n    \"kubernetes.azure.com/scalesetpriority\" = \"spot\"\n  }\n  node_taints = [\n    \"kubernetes.azure.com/scalesetpriority=spot:NoSchedule\"\n  ]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-azurerm/examples/kubernetes/spot-node-pool/main.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Create a Terraform configuration for Azure Kubernetes cluster", "completion": "```hcl\n# Copyright (c) HashiCorp, Inc.\n# SPDX-License-Identifier: MPL-2.0\n\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"${var.prefix}-k8s-resources\"\n  location = var.location\n}\n\nresource \"azurerm_virtual_network\" \"example\" {\n  name                = \"${var.prefix}-network\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  address_space       = [\"10.1.0.0/16\"]\n}\n\nresource \"azurerm_subnet\" \"internal\" {\n  name                 = \"internal\"\n  virtual_network_name = azurerm_virtual_network.example.name\n  resource_group_name  = azurerm_resource_group.example.name\n  address_prefixes     = [\"10.1.0.0/22\"]\n}\n\nresource \"azurerm_kubernetes_cluster\" \"example\" {\n  name                = \"${var.prefix}-k8s\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  dns_prefix          = \"${var.prefix}-k8s\"\n\n  default_node_pool {\n    name           = \"system\"\n    node_count     = 1\n    vm_size        = \"Standard_DS2_v2\"\n    vnet_subnet_id = azurerm_subnet.internal.id\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n}\n\nresource \"azurerm_kubernetes_cluster_node_pool\" \"user\" {\n  name                  = \"user\"\n  kubernetes_cluster_id = azurerm_kubernetes_cluster.example.id\n  vm_size               = \"Standard_DS2_v2\"\n  node_count            = 1\n  vnet_subnet_id        = azurerm_subnet.internal.id\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-azurerm/examples/kubernetes/nodes-on-internal-network/main.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\n# https://cloud.google.com/vpc/docs/shared-vpc\n\nprovider \"google\" {\n  region      = var.region\n  credentials = file(var.credentials_file_path)\n}\n\nprovider \"random\" {\n}\n\nresource \"random_id\" \"host_project_name\" {\n  byte_length = 8\n}\n\nresource \"random_id\" \"service_project_1_name\" {\n  byte_length = 8\n}\n\nresource \"random_id\" \"service_project_2_name\" {\n  byte_length = 8\n}\n\nresource \"random_id\" \"standalone_project_name\" {\n  byte_length = 8\n}\n\n# The project which owns the VPC.\nresource \"google_project\" \"host_project\" {\n  name            = \"Host Project\"\n  project_id      = \"tf-vpc-${random_id.host_project_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\n# One project which will use the VPC.\nresource \"google_project\" \"service_project_1\" {\n  name            = \"Service Project 1\"\n  project_id      = \"tf-vpc-${random_id.service_project_1_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\n# The other project which will use the VPC.\nresource \"google_project\" \"service_project_2\" {\n  name            = \"Service Project 2\"\n  project_id      = \"tf-vpc-${random_id.service_project_2_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\n# A project which will not use the VPC, for the sake of demonstration.\nresource \"google_project\" \"standalone_project\" {\n  name            = \"Standalone Project\"\n  project_id      = \"tf-vpc-${random_id.standalone_project_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\n# Compute service needs to be enabled for all four new projects.\nresource \"google_project_service\" \"host_project\" {\n  project = google_project.host_project.project_id\n  service = \"compute.googleapis.com\"\n}\n\nresource \"google_project_service\" \"service_project_1\" {\n  project = google_project.service_project_1.project_id\n  service = \"compute.googleapis.com\"\n}\n\nresource \"google_project_service\" \"service_project_2\" {\n  project = google_project.service_project_2.project_id\n  service = \"compute.googleapis.com\"\n}\n\nresource \"google_project_service\" \"standalone_project\" {\n  project = google_project.standalone_project.project_id\n  service = \"compute.googleapis.com\"\n}\n\n# Enable shared VPC hosting in the host project.\nresource \"google_compute_shared_vpc_host_project\" \"host_project\" {\n  project    = google_project.host_project.project_id\n  depends_on = [google_project_service.host_project]\n}\n\n# Enable shared VPC in the two service projects - explicitly depend on the host\n# project enabling it, because enabling shared VPC will fail if the host project\n# is not yet hosting.\nresource \"google_compute_shared_vpc_service_project\" \"service_project_1\" {\n  host_project    = google_project.host_project.project_id\n  service_project = google_project.service_project_1.project_id\n\n  depends_on = [\n    google_compute_shared_vpc_host_project.host_project,\n    google_project_service.service_project_1,\n  ]\n}\n\nresource \"google_compute_shared_vpc_service_project\" \"service_project_2\" {\n  host_project    = google_project.host_project.project_id\n  service_project = google_project.service_project_2.project_id\n\n  depends_on = [\n    google_compute_shared_vpc_host_project.host_project,\n    google_project_service.service_project_2,\n  ]\n}\n\n# Create the hosted network.\nresource \"google_compute_network\" \"shared_network\" {\n  name                    = \"shared-network\"\n  auto_create_subnetworks = \"true\"\n  project                 = google_compute_shared_vpc_host_project.host_project.project\n\n  depends_on = [\n    google_compute_shared_vpc_service_project.service_project_1,\n    google_compute_shared_vpc_service_project.service_project_2,\n  ]\n}\n\n# Allow the hosted network to be hit over ICMP, SSH, and HTTP.\nresource \"google_compute_firewall\" \"shared_network\" {\n  name    = \"allow-ssh-and-icmp\"\n  network = google_compute_network.shared_network.self_link\n  project = google_compute_network.shared_network.project\n\n  allow {\n    protocol = \"icmp\"\n  }\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\", \"80\"]\n  }\n}\n\n# Create a standalone network with the same firewall rules.\nresource \"google_compute_network\" \"standalone_network\" {\n  name                    = \"standalone-network\"\n  auto_create_subnetworks = \"true\"\n  project                 = google_project.standalone_project.project_id\n  depends_on              = [google_project_service.standalone_project]\n}\n\nresource \"google_compute_firewall\" \"standalone_network\" {\n  name    = \"allow-ssh-and-icmp\"\n  network = google_compute_network.standalone_network.self_link\n\n  allow {\n    protocol = \"icmp\"\n  }\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\", \"80\"]\n  }\n\n  project = google_project.standalone_project.project_id\n}\n\n# Create a VM which hosts a web page stating its identity (\"VM1\")\nresource \"google_compute_instance\" \"project_1_vm\" {\n  name         = \"tf-project-1-vm\"\n  project      = google_project.service_project_1.project_id\n  machine_type = \"f1-micro\"\n  zone         = var.region_zone\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  metadata_startup_script = \"VM_NAME=VM1\\n${file(\"scripts/install-vm.sh\")}\"\n\n  network_interface {\n    network = google_compute_network.shared_network.self_link\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n\n  depends_on = [google_project_service.service_project_1]\n}\n\n# Create a VM which hosts a web page demonstrating the example networking.\nresource \"google_compute_instance\" \"project_2_vm\" {\n  name         = \"tf-project-2-vm\"\n  machine_type = \"f1-micro\"\n  project      = google_project.service_project_2.project_id\n  zone         = var.region_zone\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  metadata_startup_script = <<EOF\nVM1_EXT_IP=${google_compute_instance.project_1_vm.network_interface[0].access_config[0].nat_ip}\nST_VM_EXT_IP=${google_compute_instance.standalone_project_vm.network_interface[0].access_config[0].nat_ip}\nVM1_INT_IP=${google_compute_instance.project_1_vm.network_interface[0].address}\nST_VM_INT_IP=${google_compute_instance.standalone_project_vm.network_interface[0].address}\n${file(\"scripts/install-network-page.sh\")}\nEOF\n\n\n  network_interface {\n    network = google_compute_network.shared_network.self_link\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n\n  depends_on = [google_project_service.service_project_2]\n}\n\n# Create a VM which hosts a web page stating its identity (\"standalone\").\nresource \"google_compute_instance\" \"standalone_project_vm\" {\n  name         = \"tf-standalone-vm\"\n  machine_type = \"f1-micro\"\n  project      = google_project.standalone_project.project_id\n  zone         = var.region_zone\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  metadata_startup_script = \"VM_NAME=standalone\\n${file(\"scripts/install-vm.sh\")}\"\n\n  network_interface {\n    network = google_compute_network.standalone_network.self_link\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n\n  depends_on = [google_project_service.standalone_project]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/shared-vpc/main.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\n# Example for using Cloud Armor https://cloud.google.com/armor/\n#\n\nresource \"random_id\" \"instance_id\" {\n  byte_length = 4\n}\n\n# Configure the Google Cloud provider\nprovider \"google\" {\n  credentials = file(var.credentials_file_path)\n  project     = var.project_name\n  region      = var.region\n  zone        = var.region_zone\n}\n\n# Set up a backend to be proxied to:\n# A single instance in a pool running nginx with port 80 open will allow end to end network testing\nresource \"google_compute_instance\" \"cluster1\" {\n  name         = \"armor-gce-${random_id.instance_id.hex}\"\n  machine_type = \"f1-micro\"\n\n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-9\"\n    }\n  }\n\n  network_interface {\n    network = \"default\"\n    access_config {\n      # Ephemeral IP\n    }\n  }\n\n  metadata_startup_script = \"sudo apt-get update; sudo apt-get install -yq nginx; sudo service nginx restart\"\n}\n\nresource \"google_compute_firewall\" \"cluster1\" {\n  name    = \"armor-firewall\"\n  network = \"default\"\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"80\", \"43\"]\n  }\n}\n\nresource \"google_compute_instance_group\" \"webservers\" {\n  name        = \"instance-group-all\"\n  description = \"An instance group for the single GCE instance\"\n\n  instances = [\n    google_compute_instance.cluster1.self_link,\n  ]\n\n  named_port {\n    name = \"http\"\n    port = \"80\"\n  }\n}\n\nresource \"google_compute_target_pool\" \"example\" {\n  name = \"armor-pool\"\n\n  instances = [\n    google_compute_instance.cluster1.self_link,\n  ]\n\n  health_checks = [\n    google_compute_http_health_check.health.name,\n  ]\n}\n\nresource \"google_compute_http_health_check\" \"health\" {\n  name               = \"armor-healthcheck\"\n  request_path       = \"/\"\n  check_interval_sec = 1\n  timeout_sec        = 1\n}\n\nresource \"google_compute_backend_service\" \"website\" {\n  name        = \"armor-backend\"\n  description = \"Our company website\"\n  port_name   = \"http\"\n  protocol    = \"HTTP\"\n  timeout_sec = 10\n  enable_cdn  = false\n\n  backend {\n    group = google_compute_instance_group.webservers.self_link\n  }\n\n  security_policy = google_compute_security_policy.security-policy-1.self_link\n\n  health_checks = [google_compute_http_health_check.health.self_link]\n}\n\n# Cloud Armor Security policies\nresource \"google_compute_security_policy\" \"security-policy-1\" {\n  name        = \"armor-security-policy\"\n  description = \"example security policy\"\n\n  # Reject all traffic that hasn't been whitelisted.\n  rule {\n    action   = \"deny(403)\"\n    priority = \"2147483647\"\n\n    match {\n      versioned_expr = \"SRC_IPS_V1\"\n\n      config {\n        src_ip_ranges = [\"*\"]\n      }\n    }\n\n    description = \"Default rule, higher priority overrides it\"\n  }\n\n  # Whitelist traffic from certain ip address\n  rule {\n    action   = \"allow\"\n    priority = \"1000\"\n\n    match {\n      versioned_expr = \"SRC_IPS_V1\"\n\n      config {\n        src_ip_ranges = var.ip_white_list\n      }\n    }\n\n    description = \"allow traffic from 192.0.2.0/24\"\n  }\n}\n\n# Front end of the load balancer\nresource \"google_compute_global_forwarding_rule\" \"default\" {\n  name       = \"armor-rule\"\n  target     = google_compute_target_http_proxy.default.self_link\n  port_range = \"80\"\n}\n\nresource \"google_compute_target_http_proxy\" \"default\" {\n  name    = \"armor-proxy\"\n  url_map = google_compute_url_map.default.self_link\n}\n\nresource \"google_compute_url_map\" \"default\" {\n  name            = \"armor-url-map\"\n  default_service = google_compute_backend_service.website.self_link\n\n  host_rule {\n    hosts        = [\"mysite.com\"]\n    path_matcher = \"allpaths\"\n  }\n\n  path_matcher {\n    name            = \"allpaths\"\n    default_service = google_compute_backend_service.website.self_link\n\n    path_rule {\n      paths   = [\"/*\"]\n      service = google_compute_backend_service.website.self_link\n    }\n  }\n}\n\noutput \"ip\" {\n  value = google_compute_global_forwarding_rule.default.ip_address\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/cloud-armor/main.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\n# https://cloud.google.com/compute/docs/load-balancing/http/content-based-example\n\nprovider \"google\" {\n  region      = var.region\n  project     = var.project_name\n  credentials = file(var.credentials_file_path)\n  zone        = var.region_zone\n}\n\nresource \"google_compute_instance\" \"www\" {\n  name         = \"tf-www-compute\"\n  machine_type = \"f1-micro\"\n  tags         = [\"http-tag\"]\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  network_interface {\n    network = \"default\"\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  metadata_startup_script = file(\"scripts/install-www.sh\")\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n}\n\nresource \"google_compute_instance\" \"www-video\" {\n  name         = \"tf-www-video-compute\"\n  machine_type = \"f1-micro\"\n  tags         = [\"http-tag\"]\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  network_interface {\n    network = \"default\"\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  metadata_startup_script = file(\"scripts/install-video.sh\")\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/compute.readonly\"]\n  }\n}\n\nresource \"google_compute_global_address\" \"external-address\" {\n  name = \"tf-external-address\"\n}\n\nresource \"google_compute_instance_group\" \"www-resources\" {\n  name = \"tf-www-resources\"\n\n  instances = [google_compute_instance.www.self_link]\n\n  named_port {\n    name = \"http\"\n    port = \"80\"\n  }\n}\n\nresource \"google_compute_instance_group\" \"video-resources\" {\n  name = \"tf-video-resources\"\n\n  instances = [google_compute_instance.www-video.self_link]\n\n  named_port {\n    name = \"http\"\n    port = \"80\"\n  }\n}\n\nresource \"google_compute_health_check\" \"health-check\" {\n  name = \"tf-health-check\"\n\n  http_health_check {\n  }\n}\n\nresource \"google_compute_backend_service\" \"www-service\" {\n  name     = \"tf-www-service\"\n  protocol = \"HTTP\"\n\n  backend {\n    group = google_compute_instance_group.www-resources.self_link\n  }\n\n  health_checks = [google_compute_health_check.health-check.self_link]\n}\n\nresource \"google_compute_backend_service\" \"video-service\" {\n  name     = \"tf-video-service\"\n  protocol = \"HTTP\"\n\n  backend {\n    group = google_compute_instance_group.video-resources.self_link\n  }\n\n  health_checks = [google_compute_health_check.health-check.self_link]\n}\n\nresource \"google_compute_url_map\" \"web-map\" {\n  name            = \"tf-web-map\"\n  default_service = google_compute_backend_service.www-service.self_link\n\n  host_rule {\n    hosts        = [\"*\"]\n    path_matcher = \"tf-allpaths\"\n  }\n\n  path_matcher {\n    name            = \"tf-allpaths\"\n    default_service = google_compute_backend_service.www-service.self_link\n\n    path_rule {\n      paths   = [\"/video\", \"/video/*\"]\n      service = google_compute_backend_service.video-service.self_link\n    }\n  }\n}\n\nresource \"google_compute_target_http_proxy\" \"http-lb-proxy\" {\n  name    = \"tf-http-lb-proxy\"\n  url_map = google_compute_url_map.web-map.self_link\n}\n\nresource \"google_compute_global_forwarding_rule\" \"default\" {\n  name       = \"tf-http-content-gfr\"\n  target     = google_compute_target_http_proxy.http-lb-proxy.self_link\n  ip_address = google_compute_global_address.external-address.address\n  port_range = \"80\"\n}\n\nresource \"google_compute_firewall\" \"default\" {\n  name    = \"tf-www-firewall-allow-internal-only\"\n  network = \"default\"\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"80\"]\n  }\n\n  source_ranges = [\"130.211.0.0/22\", \"35.191.0.0/16\"]\n  target_tags   = [\"http-tag\"]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/content-based-load-balancing/main.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\nprovider \"google\" {\n  region      = var.region\n  credentials = file(var.credentials_file_path)\n}\n\nprovider \"random\" {\n}\n\nresource \"random_id\" \"project_name\" {\n  byte_length = 8\n}\n\nresource \"google_project\" \"endpoints_project\" {\n  name            = \"Endpoints Project\"\n  project_id      = \"tf-ep-${random_id.project_name.hex}\"\n  org_id          = var.org_id\n  billing_account = var.billing_account_id\n}\n\nresource \"google_project_service\" \"endpoints_project\" {\n  project = google_project.endpoints_project.project_id\n  service = \"compute.googleapis.com\"\n}\n\nresource \"google_project_service\" \"endpoints_project_sm\" {\n  project = google_project.endpoints_project.project_id\n  service = \"servicemanagement.googleapis.com\"\n}\n\nresource \"google_endpoints_service\" \"endpoints_service\" {\n  service_name = \"echo-api.endpoints.${google_project.endpoints_project.project_id}.cloud.goog\"\n  project      = google_project.endpoints_project.project_id\n\n  openapi_config = <<EOF\nswagger: \"2.0\"\ninfo:\n  description: \"A simple Google Cloud Endpoints API example.\"\n  title: \"Endpoints Example\"\n  version: \"1.0.0\"\nhost: \"echo-api.endpoints.${google_project.endpoints_project.project_id}.cloud.goog\"\nbasePath: \"/\"\nconsumes:\n- \"application/json\"\nproduces:\n- \"application/json\"\nschemes:\n- \"https\"\npaths:\n  \"/echo\":\n    post:\n      description: \"Echo back a given message.\"\n      operationId: \"echo\"\n      produces:\n      - \"application/json\"\n      responses:\n        200:\n          description: \"Echo\"\n          schema:\n            $ref: \"#/definitions/echoMessage\"\n      parameters:\n      - description: \"Message to echo\"\n        in: body\n        name: message\n        required: true\n        schema:\n          $ref: \"#/definitions/echoMessage\"\n      security:\n      - api_key: []\ndefinitions:\n  echoMessage:\n    properties:\n      message:\n        type: \"string\"\nEOF\n\n\n  depends_on = [google_project_service.endpoints_project_sm]\n}\n\nresource \"google_compute_network\" \"network\" {\n  name                    = \"ep-network\"\n  auto_create_subnetworks = \"true\"\n  project                 = google_project.endpoints_project.project_id\n  depends_on              = [google_project_service.endpoints_project]\n}\n\n# Allow the hosted network to be hit over ICMP, SSH, and HTTP.\nresource \"google_compute_firewall\" \"network\" {\n  name    = \"allow-ssh-and-icmp\"\n  network = google_compute_network.network.self_link\n  project = google_compute_network.network.project\n\n  allow {\n    protocol = \"icmp\"\n  }\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\", \"80\"]\n  }\n}\n\nresource \"google_compute_instance\" \"project_1_vm\" {\n  name         = \"tf-ep-vm\"\n  project      = google_project.endpoints_project.project_id\n  machine_type = \"f1-micro\"\n  zone         = var.region_zone\n\n  boot_disk {\n    initialize_params {\n      image = \"projects/debian-cloud/global/images/family/debian-8\"\n    }\n  }\n\n  metadata = {\n    endpoints-service-name      = google_endpoints_service.endpoints_service.service_name\n    endpoints-service-config-id = google_endpoints_service.endpoints_service.config_id\n    startup-script              = file(\"scripts/install-vm.sh\")\n  }\n\n  network_interface {\n    network = google_compute_firewall.network.network\n\n    access_config {\n      // Ephemeral IP\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/cloud-platform\"]\n  }\n\n  depends_on = [\n    google_project_service.endpoints_project_sm,\n    google_project_service.endpoints_project,\n  ]\n}\n\noutput \"ip\" {\n  value = google_compute_instance.project_1_vm.network_interface[0].access_config[0].nat_ip\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/endpoints-on-compute-engine/main.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\n# An example of how to connect two GCE networks with a VPN\nprovider \"google\" {\n  credentials = file(\"~/gce/account.json\")\n  project     = var.project\n  region      = var.region1\n}\n\n# Create the two networks we want to join. They must have separate, internal\n# ranges.\nresource \"google_compute_network\" \"network1\" {\n  name       = \"network1\"\n  ipv4_range = \"10.120.0.0/16\"\n}\n\nresource \"google_compute_network\" \"network2\" {\n  name       = \"network2\"\n  ipv4_range = \"10.121.0.0/16\"\n}\n\n# Attach a VPN gateway to each network.\nresource \"google_compute_vpn_gateway\" \"target_gateway1\" {\n  name    = \"vpn1\"\n  network = google_compute_network.network1.self_link\n  region  = var.region1\n}\n\nresource \"google_compute_vpn_gateway\" \"target_gateway2\" {\n  name    = \"vpn2\"\n  network = google_compute_network.network2.self_link\n  region  = var.region2\n}\n\n# Create an outward facing static IP for each VPN that will be used by the\n# other VPN to connect.\nresource \"google_compute_address\" \"vpn_static_ip1\" {\n  name   = \"vpn-static-ip1\"\n  region = var.region1\n}\n\nresource \"google_compute_address\" \"vpn_static_ip2\" {\n  name   = \"vpn-static-ip2\"\n  region = var.region2\n}\n\n# Forward IPSec traffic coming into our static IP to our VPN gateway.\nresource \"google_compute_forwarding_rule\" \"fr1_esp\" {\n  name        = \"fr1-esp\"\n  region      = var.region1\n  ip_protocol = \"ESP\"\n  ip_address  = google_compute_address.vpn_static_ip1.address\n  target      = google_compute_vpn_gateway.target_gateway1.self_link\n}\n\nresource \"google_compute_forwarding_rule\" \"fr2_esp\" {\n  name        = \"fr2-esp\"\n  region      = var.region2\n  ip_protocol = \"ESP\"\n  ip_address  = google_compute_address.vpn_static_ip2.address\n  target      = google_compute_vpn_gateway.target_gateway2.self_link\n}\n\n# The following two sets of forwarding rules are used as a part of the IPSec\n# protocol\nresource \"google_compute_forwarding_rule\" \"fr1_udp500\" {\n  name        = \"fr1-udp500\"\n  region      = var.region1\n  ip_protocol = \"UDP\"\n  port_range  = \"500\"\n  ip_address  = google_compute_address.vpn_static_ip1.address\n  target      = google_compute_vpn_gateway.target_gateway1.self_link\n}\n\nresource \"google_compute_forwarding_rule\" \"fr2_udp500\" {\n  name        = \"fr2-udp500\"\n  region      = var.region2\n  ip_protocol = \"UDP\"\n  port_range  = \"500\"\n  ip_address  = google_compute_address.vpn_static_ip2.address\n  target      = google_compute_vpn_gateway.target_gateway2.self_link\n}\n\nresource \"google_compute_forwarding_rule\" \"fr1_udp4500\" {\n  name        = \"fr1-udp4500\"\n  region      = var.region1\n  ip_protocol = \"UDP\"\n  port_range  = \"4500\"\n  ip_address  = google_compute_address.vpn_static_ip1.address\n  target      = google_compute_vpn_gateway.target_gateway1.self_link\n}\n\nresource \"google_compute_forwarding_rule\" \"fr2_udp4500\" {\n  name        = \"fr2-udp4500\"\n  region      = var.region2\n  ip_protocol = \"UDP\"\n  port_range  = \"4500\"\n  ip_address  = google_compute_address.vpn_static_ip2.address\n  target      = google_compute_vpn_gateway.target_gateway2.self_link\n}\n\n# Each tunnel is responsible for encrypting and decrypting traffic exiting\n# and leaving its associated gateway\nresource \"google_compute_vpn_tunnel\" \"tunnel1\" {\n  name               = \"tunnel1\"\n  region             = var.region1\n  peer_ip            = google_compute_address.vpn_static_ip2.address\n  shared_secret = \"<REDACTED>\"\n  target_vpn_gateway = google_compute_vpn_gateway.target_gateway1.self_link\n\n  depends_on = [\n    google_compute_forwarding_rule.fr1_udp500,\n    google_compute_forwarding_rule.fr1_udp4500,\n    google_compute_forwarding_rule.fr1_esp,\n  ]\n}\n\nresource \"google_compute_vpn_tunnel\" \"tunnel2\" {\n  name               = \"tunnel2\"\n  region             = var.region2\n  peer_ip            = google_compute_address.vpn_static_ip1.address\n  shared_secret = \"<REDACTED>\"\n  target_vpn_gateway = google_compute_vpn_gateway.target_gateway2.self_link\n\n  depends_on = [\n    google_compute_forwarding_rule.fr2_udp500,\n    google_compute_forwarding_rule.fr2_udp4500,\n    google_compute_forwarding_rule.fr2_esp,\n  ]\n}\n\n# Each route tells the associated network to send all traffic in the dest_range\n# through the VPN tunnel\nresource \"google_compute_route\" \"route1\" {\n  name                = \"route1\"\n  network             = google_compute_network.network1.name\n  next_hop_vpn_tunnel = google_compute_vpn_tunnel.tunnel1.self_link\n  dest_range          = google_compute_network.network2.ipv4_range\n  priority            = 1000\n}\n\nresource \"google_compute_route\" \"route2\" {\n  name                = \"route2\"\n  network             = google_compute_network.network2.name\n  next_hop_vpn_tunnel = google_compute_vpn_tunnel.tunnel2.self_link\n  dest_range          = google_compute_network.network1.ipv4_range\n  priority            = 1000\n}\n\n# We want to allow the two networks to communicate, so we need to unblock\n# them in the firewall\nresource \"google_compute_firewall\" \"network1-allow-network1\" {\n  name          = \"network1-allow-network1\"\n  network       = google_compute_network.network1.name\n  source_ranges = [google_compute_network.network1.ipv4_range]\n\n  allow {\n    protocol = \"tcp\"\n  }\n\n  allow {\n    protocol = \"udp\"\n  }\n\n  allow {\n    protocol = \"icmp\"\n  }\n}\n\nresource \"google_compute_firewall\" \"network1-allow-network2\" {\n  name          = \"network1-allow-network2\"\n  network       = google_compute_network.network1.name\n  source_ranges = [google_compute_network.network2.ipv4_range]\n\n  allow {\n    protocol = \"tcp\"\n  }\n\n  allow {\n    protocol = \"udp\"\n  }\n\n  allow {\n    protocol = \"icmp\"\n  }\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-provider-google/examples/vpn/vpn.tf", "category": "provider", "authentic": true}}
{"prompt": "Write a Terraform configuration for Kubernetes compute instances", "completion": "```hcl\nterraform {\n  required_version = \">= 0.11.7\"\n}\n\ndata \"terraform_remote_state\" \"k8s_cluster\" {\n  backend = \"atlas\"\n  config {\n    name = \"${var.tfe_organization}/${var.k8s_cluster_workspace}\"\n  }\n}\n\nprovider \"kubernetes\" {\n  load_config_file = false\n  host = \"${data.terraform_remote_state.k8s_cluster.k8s_endpoint}\"\n  client_certificate = \"${base64decode(data.terraform_remote_state.k8s_cluster.k8s_master_auth_client_certificate)}\"\n  client_key = \"<REDACTED>\"\n  cluster_ca_certificate = \"${base64decode(data.terraform_remote_state.k8s_cluster.k8s_master_auth_cluster_ca_certificate)}\"\n}\n\nresource \"null_resource\" \"service_account\" {\n\n  provisioner \"file\" {\n    source = \"cats-and-dogs.yaml\"\n    destination = \"~/cats-and-dogs.yaml\"\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"oc new-project cats-and-dogs --description=\\\"cats and dogs project\\\" --display-name=\\\"cats-and-dogs\\\"\",\n      \"kubectl create -f cats-and-dogs.yaml\",\n      \"kubectl get serviceaccount cats-and-dogs -o yaml > cats-and-dogs-service.yaml\",\n      \"grep \\\"cats-and-dogs-token\\\" cats-and-dogs-service.yaml | cut -d ':' -f 2 | sed 's/ //' > cats-and-dogs-secret-name\"\n    ]\n  }\n\n  connection {\n    host = \"${data.terraform_remote_state.k8s_cluster.master_public_dns}\"\n    type = \"ssh\"\n    agent = false\n    user = \"ec2-user\"\n    private_key = \"<REDACTED>\"\n    bastion_host = \"${data.terraform_remote_state.k8s_cluster.bastion_public_dns}\"\n  }\n}\n\nresource \"null_resource\" \"get_secret_name\" {\n  provisioner \"remote-exec\" {\n    inline = [\n      \"scp -o StrictHostKeyChecking=no -i ~/.ssh/private-key.pem ec2-user@${data.terraform_remote_state.k8s_cluster.master_public_dns}:~/cats-and-dogs-secret-name cats-and-dogs-secret-name\"\n    ]\n\n    connection {\n      host = \"${data.terraform_remote_state.k8s_cluster.bastion_public_dns}\"\n      type = \"ssh\"\n      agent = false\n      user = \"ec2-user\"\n      private_key = \"<REDACTED>\"\n    }\n  }\n\n  provisioner \"local-exec\" {\n    command = \"echo \\\"${var.private_key_data}\\\" > private-key.pem\"\n  }\n\n  provisioner \"local-exec\" {\n    command = \"chmod 400 private-key.pem\"\n  }\n\n  provisioner \"local-exec\" {\n    command = \"scp -o StrictHostKeyChecking=no -i private-key.pem  ec2-user@${data.terraform_remote_state.k8s_cluster.bastion_public_dns}:~/cats-and-dogs-secret-name cats-and-dogs-secret-name\"\n  }\n\n  depends_on = [\"null_resource.service_account\"]\n}\n\ndata \"null_data_source\" \"retrieve_secret_name_from_file\" {\n  inputs = {\n    secret_name = \"${chomp(file(\"cats-and-dogs-secret-name\"))}\"\n  }\n  depends_on = [\"null_resource.get_secret_name\"]\n}\n\nresource \"kubernetes_pod\" \"cats-and-dogs-backend\" {\n  metadata {\n    name = \"cats-and-dogs-backend\"\n    namespace = \"cats-and-dogs\"\n    labels {\n      App = \"cats-and-dogs-backend\"\n    }\n  }\n  spec {\n    service_account_name = \"cats-and-dogs\"\n    container {\n      image = \"rberlind/cats-and-dogs-backend:k8s-auth\"\n      image_pull_policy = \"Always\"\n      name  = \"cats-and-dogs-backend\"\n      command = [\"/app/start_redis.sh\"]\n      env = {\n        name = \"VAULT_ADDR\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_addr}\"\n      }\n      env = {\n        name = \"VAULT_K8S_BACKEND\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_k8s_auth_backend}\"\n      }\n      env = {\n        name = \"VAULT_USER\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_user}\"\n      }\n      env = {\n        name = \"K8S_TOKEN\"\n        value_from {\n          secret_key_ref {\n            name = \"${data.null_data_source.retrieve_secret_name_from_file.outputs[\"secret_name\"]}\"\n            key = \"<REDACTED>\"\n          }\n        }\n      }\n      port {\n        container_port = 6379\n      }\n    }\n  }\n}\n\nresource \"kubernetes_service\" \"cats-and-dogs-backend\" {\n  metadata {\n    name = \"cats-and-dogs-backend\"\n    namespace = \"cats-and-dogs\"\n  }\n  spec {\n    selector {\n      App = \"${kubernetes_pod.cats-and-dogs-backend.metadata.0.labels.App}\"\n    }\n    port {\n      port = 6379\n      target_port = 6379\n    }\n  }\n}\n\nresource \"kubernetes_pod\" \"cats-and-dogs-frontend\" {\n  metadata {\n    name = \"cats-and-dogs-frontend\"\n    namespace = \"cats-and-dogs\"\n    labels {\n      App = \"cats-and-dogs-frontend\"\n    }\n  }\n  spec {\n    service_account_name = \"cats-and-dogs\"\n    container {\n      image = \"rberlind/cats-and-dogs-frontend:k8s-auth\"\n      image_pull_policy = \"Always\"\n      name  = \"cats-and-dogs-frontend\"\n      env = {\n        name = \"REDIS\"\n        value = \"cats-and-dogs-backend\"\n      }\n      env = {\n        name = \"VAULT_ADDR\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_addr}\"\n      }\n      env = {\n        name = \"VAULT_K8S_BACKEND\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_k8s_auth_backend}\"\n      }\n      env = {\n        name = \"VAULT_USER\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_user}\"\n      }\n      env = {\n        name = \"K8S_TOKEN\"\n        value_from {\n          secret_key_ref {\n            name = \"${data.null_data_source.retrieve_secret_name_from_file.outputs[\"secret_name\"]}\"\n            key = \"<REDACTED>\"\n          }\n        }\n      }\n      port {\n        container_port = 80\n      }\n    }\n  }\n\n  depends_on = [\"kubernetes_service.cats-and-dogs-backend\"]\n}\n\nresource \"kubernetes_service\" \"cats-and-dogs-frontend\" {\n  metadata {\n    name = \"cats-and-dogs-frontend\"\n    namespace = \"cats-and-dogs\"\n  }\n  spec {\n    selector {\n      App = \"${kubernetes_pod.cats-and-dogs-frontend.metadata.0.labels.App}\"\n    }\n    port {\n      port = 80\n      target_port = 80\n    }\n    type = \"LoadBalancer\"\n  }\n}\n\nresource \"null_resource\" \"expose_route\" {\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"oc expose service cats-and-dogs-frontend --hostname=cats-and-dogs-frontend.${data.terraform_remote_state.k8s_cluster.master_public_ip}.xip.io\"\n    ]\n  }\n\n  connection {\n    host = \"${data.terraform_remote_state.k8s_cluster.master_public_dns}\"\n    type = \"ssh\"\n    agent = false\n    user = \"ec2-user\"\n    private_key = \"<REDACTED>\"\n    bastion_host = \"${data.terraform_remote_state.k8s_cluster.bastion_public_dns}\"\n  }\n\n  depends_on = [\"kubernetes_service.cats-and-dogs-frontend\"]\n\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/k8s-services-openshift/main.tf", "category": "compute", "authentic": true}}
{"prompt": "Create a Terraform configuration for Kubernetes Kubernetes cluster", "completion": "```hcl\nterraform {\n  required_version = \">= 0.11.11\"\n}\n\ndata \"terraform_remote_state\" \"k8s_cluster\" {\n  backend = \"atlas\"\n  config {\n    name = \"${var.tfe_organization}/${var.k8s_cluster_workspace}\"\n  }\n}\n\ndata \"terraform_remote_state\" \"k8s_vault_config\" {\n  backend = \"atlas\"\n  config {\n    name = \"${var.tfe_organization}/${var.k8s_vault_config_workspace}\"\n  }\n}\n\nprovider \"kubernetes\" {\n  host = \"${data.terraform_remote_state.k8s_cluster.k8s_endpoint}\"\n  client_certificate = \"${base64decode(data.terraform_remote_state.k8s_cluster.k8s_master_auth_client_certificate)}\"\n  client_key = \"<REDACTED>\"\n  cluster_ca_certificate = \"${base64decode(data.terraform_remote_state.k8s_cluster.k8s_master_auth_cluster_ca_certificate)}\"\n}\n\nresource \"kubernetes_namespace\" \"cats-and-dogs\" {\n  metadata {\n    name = \"cats-and-dogs\"\n  }\n}\n\nresource \"kubernetes_service_account\" \"cats-and-dogs\" {\n  metadata {\n    name = \"cats-and-dogs\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n  }\n}\n\nresource \"kubernetes_pod\" \"cats-and-dogs-backend\" {\n  metadata {\n    name = \"cats-and-dogs-backend\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n    labels {\n      App = \"cats-and-dogs-backend\"\n    }\n  }\n  spec {\n    service_account_name = \"${kubernetes_service_account.cats-and-dogs.metadata.0.name}\"\n    container {\n      image = \"${var.backend_image}\"\n      image_pull_policy = \"Always\"\n      name  = \"cats-and-dogs-backend\"\n      command = [\"/app/start_redis.sh\"]\n      env = {\n        name = \"VAULT_ADDR\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_addr}\"\n      }\n      env = {\n        name = \"VAULT_K8S_BACKEND\"\n        value = \"${data.terraform_remote_state.k8s_vault_config.vault_k8s_auth_backend}\"\n      }\n      env = {\n        name = \"VAULT_USER\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_user}\"\n      }\n      env = {\n        name = \"K8S_TOKEN\"\n        value_from {\n          secret_key_ref {\n            name = \"${kubernetes_service_account.cats-and-dogs.default_secret_name}\"\n            key = \"<REDACTED>\"\n          }\n        }\n      }\n      port {\n        container_port = 6379\n      }\n    }\n  }\n}\n\nresource \"kubernetes_service\" \"cats-and-dogs-backend\" {\n  metadata {\n    name = \"cats-and-dogs-backend\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n  }\n  spec {\n    selector {\n      App = \"${kubernetes_pod.cats-and-dogs-backend.metadata.0.labels.App}\"\n    }\n    port {\n      port = 6379\n      target_port = 6379\n    }\n  }\n}\n\nresource \"kubernetes_pod\" \"cats-and-dogs-frontend\" {\n  metadata {\n    name = \"cats-and-dogs-frontend\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n    labels {\n      App = \"cats-and-dogs-frontend\"\n    }\n  }\n  spec {\n    service_account_name = \"${kubernetes_service_account.cats-and-dogs.metadata.0.name}\"\n    container {\n      image = \"${var.frontend_image}\"\n      image_pull_policy = \"Always\"\n      name  = \"cats-and-dogs-frontend\"\n      env = {\n        name = \"REDIS\"\n        value = \"cats-and-dogs-backend\"\n      }\n      env = {\n        name = \"VAULT_ADDR\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_addr}\"\n      }\n      env = {\n        name = \"VAULT_K8S_BACKEND\"\n        value = \"${data.terraform_remote_state.k8s_vault_config.vault_k8s_auth_backend}\"\n      }\n      env = {\n        name = \"VAULT_USER\"\n        value = \"${data.terraform_remote_state.k8s_cluster.vault_user}\"\n      }\n      env = {\n        name = \"K8S_TOKEN\"\n        value_from {\n          secret_key_ref {\n            name = \"${kubernetes_service_account.cats-and-dogs.default_secret_name}\"\n            key = \"<REDACTED>\"\n          }\n        }\n      }\n      port {\n        container_port = 80\n      }\n    }\n  }\n\n  depends_on = [\"kubernetes_service.cats-and-dogs-backend\"]\n}\n\nresource \"kubernetes_service\" \"cats-and-dogs-frontend\" {\n  metadata {\n    name = \"cats-and-dogs-frontend\"\n    namespace = \"${kubernetes_namespace.cats-and-dogs.metadata.0.name}\"\n  }\n  spec {\n    selector {\n      App = \"${kubernetes_pod.cats-and-dogs-frontend.metadata.0.labels.App}\"\n    }\n    port {\n      port = 80\n      target_port = 80\n    }\n    type = \"LoadBalancer\"\n  }\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/k8s-services/main.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure infrastructure deployment", "completion": "```hcl\nvariable \"tfe_organization\" {\n  description = \"TFE organization\"\n  default = \"RogerBerlind\"\n}\n\nvariable \"k8s_cluster_workspace\" {\n  description = \"workspace to use for the k8s cluster\"\n}\n\nvariable \"k8s_vault_config_workspace\" {\n  description = \"workspace to use for the vault configuration\"\n}\n\nvariable \"frontend_image\" {\n  default = \"rberlind/cats-and-dogs-frontend:k8s-auth\"\n  description = \"Docker image location of the frontend app\"\n}\n\n variable \"backend_image\" {\n  default = \"rberlind/cats-and-dogs-backend:k8s-auth\"\n  description = \"Docker image location of the frontend app\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/k8s-services/variables.tf", "category": "variables", "authentic": true}}
{"prompt": "Write a Terraform configuration for Google Cloud infrastructure deployment", "completion": "```hcl\noutput \"compute_network_consumable\" {\n  value       = \"${google_compute_network.demo_network.name}\"\n  description = \"The Network Name\"\n}\n\noutput \"subnetwork_consumable_name\" {\n  value       = \"${google_compute_subnetwork.demo_subnetwork.name}\"\n  description = \"The Subnet Name\"\n}\n\noutput \"subnetwork_consumable_ip_cidr_range\" {\n  value       = \"${google_compute_subnetwork.demo_subnetwork.ip_cidr_range}\"\n  description = \"The default Cidr Range\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/getting-started/terraform-gcp/outputs.tf", "category": "outputs", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure infrastructure deployment", "completion": "```hcl\nvariable \"gn_name\" {\n  default     = \"\"\n  description = \"The default name for the Compute Network\"\n}\n\nvariable \"sn_name\" {\n  default     = \"\"\n  description = \"The default name for the subnet\"\n}\n\nvariable \"sn_region\" {\n  default     = \"\"\n  description = \"The default region for the subnet\"\n}\n\nvariable \"sn_cidr_range\" {\n  default     = \"\"\n  description = \"The default Subnet Cidr Range\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/hashicorp_terraform-guides/self-serve-infrastructure/getting-started/terraform-gcp/_interface.tf", "category": "infrastructure", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\ndata \"aws_region\" \"current\" {\n  # Call this API only if create_vpc and enable_flow_log are true\n  count = var.create_vpc && var.enable_flow_log ? 1 : 0\n}\n\ndata \"aws_caller_identity\" \"current\" {\n  # Call this API only if create_vpc and enable_flow_log are true\n  count = var.create_vpc && var.enable_flow_log ? 1 : 0\n}\n\ndata \"aws_partition\" \"current\" {\n  # Call this API only if create_vpc and enable_flow_log are true\n  count = var.create_vpc && var.enable_flow_log ? 1 : 0\n}\n\nlocals {\n  # Only create flow log if user selected to create a VPC as well\n  enable_flow_log = var.create_vpc && var.enable_flow_log\n\n  create_flow_log_cloudwatch_iam_role  = local.enable_flow_log && var.flow_log_destination_type != \"s3\" && var.create_flow_log_cloudwatch_iam_role\n  create_flow_log_cloudwatch_log_group = local.enable_flow_log && var.flow_log_destination_type != \"s3\" && var.create_flow_log_cloudwatch_log_group\n\n  flow_log_destination_arn                  = local.create_flow_log_cloudwatch_log_group ? try(aws_cloudwatch_log_group.flow_log[0].arn, null) : var.flow_log_destination_arn\n  flow_log_iam_role_arn                     = var.flow_log_destination_type != \"s3\" && local.create_flow_log_cloudwatch_iam_role ? try(aws_iam_role.vpc_flow_log_cloudwatch[0].arn, null) : var.flow_log_cloudwatch_iam_role_arn\n  flow_log_cloudwatch_log_group_name_suffix = var.flow_log_cloudwatch_log_group_name_suffix == \"\" ? local.vpc_id : var.flow_log_cloudwatch_log_group_name_suffix\n  flow_log_group_arns = [\n    for log_group in aws_cloudwatch_log_group.flow_log :\n    \"arn:${data.aws_partition.current[0].partition}:logs:${data.aws_region.current[0].region}:${data.aws_caller_identity.current[0].account_id}:log-group:${log_group.name}:*\"\n  ]\n}\n\n################################################################################\n# Flow Log\n################################################################################\n\nresource \"aws_flow_log\" \"this\" {\n  count = local.enable_flow_log ? 1 : 0\n\n  log_destination_type       = var.flow_log_destination_type\n  log_destination            = local.flow_log_destination_arn\n  log_format                 = var.flow_log_log_format\n  iam_role_arn               = local.flow_log_iam_role_arn\n  deliver_cross_account_role = var.flow_log_deliver_cross_account_role\n  traffic_type               = var.flow_log_traffic_type\n  vpc_id                     = local.vpc_id\n  max_aggregation_interval   = var.flow_log_max_aggregation_interval\n\n  dynamic \"destination_options\" {\n    for_each = var.flow_log_destination_type == \"s3\" ? [true] : []\n\n    content {\n      file_format                = var.flow_log_file_format\n      hive_compatible_partitions = var.flow_log_hive_compatible_partitions\n      per_hour_partition         = var.flow_log_per_hour_partition\n    }\n  }\n\n  tags = merge(var.tags, var.vpc_flow_log_tags)\n}\n\n################################################################################\n# Flow Log CloudWatch\n################################################################################\n\nresource \"aws_cloudwatch_log_group\" \"flow_log\" {\n  count = local.create_flow_log_cloudwatch_log_group ? 1 : 0\n\n  name              = \"${var.flow_log_cloudwatch_log_group_name_prefix}${local.flow_log_cloudwatch_log_group_name_suffix}\"\n  retention_in_days = var.flow_log_cloudwatch_log_group_retention_in_days\n  kms_key_id        = var.flow_log_cloudwatch_log_group_kms_key_id\n  skip_destroy      = var.flow_log_cloudwatch_log_group_skip_destroy\n  log_group_class   = var.flow_log_cloudwatch_log_group_class\n\n  tags = merge(var.tags, var.vpc_flow_log_tags)\n}\n\nresource \"aws_iam_role\" \"vpc_flow_log_cloudwatch\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  name        = var.vpc_flow_log_iam_role_use_name_prefix ? null : var.vpc_flow_log_iam_role_name\n  name_prefix = var.vpc_flow_log_iam_role_use_name_prefix ? \"${var.vpc_flow_log_iam_role_name}-\" : null\n\n  assume_role_policy   = data.aws_iam_policy_document.flow_log_cloudwatch_assume_role[0].json\n  permissions_boundary = var.vpc_flow_log_permissions_boundary\n\n  tags = merge(var.tags, var.vpc_flow_log_tags)\n}\n\ndata \"aws_iam_policy_document\" \"flow_log_cloudwatch_assume_role\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  statement {\n    sid = \"AWSVPCFlowLogsAssumeRole\"\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"vpc-flow-logs.amazonaws.com\"]\n    }\n\n    effect = \"Allow\"\n\n    actions = [\"sts:AssumeRole\"]\n\n    dynamic \"condition\" {\n      for_each = var.flow_log_cloudwatch_iam_role_conditions\n      content {\n        test     = condition.value.test\n        variable = condition.value.variable\n        values   = condition.value.values\n      }\n    }\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"vpc_flow_log_cloudwatch\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  role       = aws_iam_role.vpc_flow_log_cloudwatch[0].name\n  policy_arn = aws_iam_policy.vpc_flow_log_cloudwatch[0].arn\n}\n\nresource \"aws_iam_policy\" \"vpc_flow_log_cloudwatch\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  name        = var.vpc_flow_log_iam_policy_use_name_prefix ? null : var.vpc_flow_log_iam_policy_name\n  name_prefix = var.vpc_flow_log_iam_policy_use_name_prefix ? \"${var.vpc_flow_log_iam_policy_name}-\" : null\n  policy      = data.aws_iam_policy_document.vpc_flow_log_cloudwatch[0].json\n  tags        = merge(var.tags, var.vpc_flow_log_tags)\n}\n\ndata \"aws_iam_policy_document\" \"vpc_flow_log_cloudwatch\" {\n  count = local.create_flow_log_cloudwatch_iam_role ? 1 : 0\n\n  statement {\n    sid = \"AWSVPCFlowLogsPushToCloudWatch\"\n\n    effect = \"Allow\"\n\n    actions = [\n      \"logs:CreateLogStream\",\n      \"logs:PutLogEvents\",\n      \"logs:DescribeLogGroups\",\n      \"logs:DescribeLogStreams\",\n    ]\n\n    resources = local.flow_log_group_arns\n  }\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/vpc-flow-logs.tf", "category": "networking", "authentic": true}}
{"prompt": "Write a Terraform module for AWS infrastructure", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n\n  assume_role {\n    role_arn = \"arn:aws:iam::<ACCOUNT_ID>:role/outpost-shared-anton\"\n  }\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  name   = \"ex-${basename(path.cwd)}\"\n  region = \"eu-west-1\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Example    = local.name\n    GithubRepo = \"terraform-aws-vpc\"\n    GithubOrg  = \"terraform-aws-modules\"\n  }\n\n  network_acls = {\n    outpost_inbound = [\n      {\n        rule_number = 100\n        rule_action = \"allow\"\n        from_port   = 80\n        to_port     = 80\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 110\n        rule_action = \"allow\"\n        from_port   = 443\n        to_port     = 443\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 120\n        rule_action = \"allow\"\n        from_port   = 22\n        to_port     = 22\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 130\n        rule_action = \"allow\"\n        from_port   = 3389\n        to_port     = 3389\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number     = 140\n        rule_action     = \"allow\"\n        from_port       = 80\n        to_port         = 80\n        protocol        = \"tcp\"\n        ipv6_cidr_block = \"::/0\"\n      },\n    ]\n    outpost_outbound = [\n      {\n        rule_number = 100\n        rule_action = \"allow\"\n        from_port   = 80\n        to_port     = 80\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 110\n        rule_action = \"allow\"\n        from_port   = 443\n        to_port     = 443\n        protocol    = \"tcp\"\n        cidr_block  = \"0.0.0.0/0\"\n      },\n      {\n        rule_number = 120\n        rule_action = \"allow\"\n        from_port   = 1433\n        to_port     = 1433\n        protocol    = \"tcp\"\n        cidr_block  = \"10.0.100.0/22\"\n      },\n      {\n        rule_number = 130\n        rule_action = \"allow\"\n        from_port   = 22\n        to_port     = 22\n        protocol    = \"tcp\"\n        cidr_block  = \"10.0.100.0/22\"\n      },\n      {\n        rule_number = 140\n        rule_action = \"allow\"\n        icmp_code   = -1\n        icmp_type   = 8\n        protocol    = \"icmp\"\n        cidr_block  = \"10.0.0.0/22\"\n      },\n      {\n        rule_number     = 150\n        rule_action     = \"allow\"\n        from_port       = 90\n        to_port         = 90\n        protocol        = \"tcp\"\n        ipv6_cidr_block = \"::/0\"\n      },\n    ]\n  }\n}\n\n################################################################################\n# VPC Module\n################################################################################\n\nmodule \"vpc\" {\n  source = \"../../\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k)]\n  public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 4)]\n\n  # Outpost is using single AZ specified in `outpost_az`\n  outpost_subnets = [\"10.0.50.0/24\", \"10.0.51.0/24\"]\n  outpost_arn     = data.aws_outposts_outpost.shared.arn\n  outpost_az      = data.aws_outposts_outpost.shared.availability_zone\n\n  # IPv6\n  enable_ipv6                                    = true\n  outpost_subnet_assign_ipv6_address_on_creation = true\n  outpost_subnet_ipv6_prefixes                   = [2, 3, 4]\n\n  # NAT Gateway\n  enable_nat_gateway = true\n  single_nat_gateway = true\n\n  # Network ACLs\n  outpost_dedicated_network_acl = true\n  outpost_inbound_acl_rules     = local.network_acls[\"outpost_inbound\"]\n  outpost_outbound_acl_rules    = local.network_acls[\"outpost_outbound\"]\n\n  tags = local.tags\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\ndata \"aws_outposts_outpost\" \"shared\" {\n  name = \"SEA19.07\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/examples/outpost/main.tf", "category": "module", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS VPC networking", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  name   = \"ex-${basename(path.cwd)}\"\n  region = \"eu-west-1\"\n\n  azs               = slice(data.aws_availability_zones.available.names, 0, 3)\n  preview_partition = cidrsubnets(aws_vpc_ipam_preview_next_cidr.this.cidr, 2, 2, 2)\n\n  tags = {\n    Example    = local.name\n    GithubRepo = \"terraform-aws-vpc\"\n    GithubOrg  = \"terraform-aws-modules\"\n  }\n}\n\n################################################################################\n# VPC Module\n################################################################################\n\n# IPv4\nmodule \"vpc_ipam_set_netmask\" {\n  source = \"../..\"\n\n  name = \"${local.name}-set-netmask\"\n\n  use_ipam_pool       = true\n  ipv4_ipam_pool_id   = aws_vpc_ipam_pool.this.id\n  ipv4_netmask_length = 16\n  azs                 = local.azs\n\n  private_subnets = cidrsubnets(local.preview_partition[0], 2, 2, 2)\n  public_subnets  = cidrsubnets(local.preview_partition[1], 2, 2, 2)\n\n  tags = local.tags\n\n  depends_on = [\n    aws_vpc_ipam_pool_cidr.this\n  ]\n}\n\nmodule \"vpc_ipam_set_cidr\" {\n  source = \"../..\"\n\n  name = \"${local.name}-set-cidr\"\n\n  use_ipam_pool     = true\n  ipv4_ipam_pool_id = aws_vpc_ipam_pool.this.id\n  cidr              = \"10.1.0.0/16\"\n  azs               = local.azs\n\n  private_subnets = [\"10.1.1.0/24\", \"10.1.2.0/24\", \"10.1.3.0/24\"]\n  public_subnets  = [\"10.1.11.0/24\", \"10.1.12.0/24\", \"10.1.13.0/24\"]\n\n  tags = local.tags\n}\n\n# # IPv6 - Requires having a CIDR plus its message and signature (see below)\n# module \"vpc_ipv6_ipam_set_netmask\" {\n#   source = \"../..\"\n\n#   name = \"${local.name}-ipv6-set-netmask\"\n\n#   use_ipam_pool       = true\n#   ipv4_ipam_pool_id   = aws_vpc_ipam_pool.this.id\n#   ipv6_ipam_pool_id   = aws_vpc_ipam_pool.ipv6.id\n#   ipv6_netmask_length = 56\n#   azs                 = local.azs\n\n#   tags = local.tags\n# }\n\n################################################################################\n# Supporting Resources\n################################################################################\n\n/*\nNOTES ON IPAM USAGE:\n\nIn order to build subnets with your VPC Terraform must know subnet CIDRs to properly plan # of resources to build.\nSince CIDR is derived by IPAM by calling CreateVpc this is not possible within a module unless cidr is known ahead of time.\nWe can get around this by \"previewing\" the CIDR and then using that as the subnet values.\n\nIn the example above we use `cidrsubnets()` to calculate a public and private \"partitions\" (group of cidrs) then calculate the specific\nCIDRs for each subnet type.\n\nFor an explanation on prolonged delete times on IPAM pools see 2nd\n*note* in terraform docs: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_ipam_pool_cidr\n*/\n\nresource \"aws_vpc_ipam\" \"this\" {\n  operating_regions {\n    region_name = local.region\n  }\n\n  tags = local.tags\n}\n\n# IPv4\nresource \"aws_vpc_ipam_pool\" \"this\" {\n  description                       = \"IPv4 pool\"\n  address_family                    = \"ipv4\"\n  ipam_scope_id                     = aws_vpc_ipam.this.private_default_scope_id\n  locale                            = local.region\n  allocation_default_netmask_length = 16\n\n  tags = local.tags\n}\n\nresource \"aws_vpc_ipam_pool_cidr\" \"this\" {\n  ipam_pool_id = aws_vpc_ipam_pool.this.id\n  cidr         = \"10.0.0.0/8\"\n}\n\nresource \"aws_vpc_ipam_preview_next_cidr\" \"this\" {\n  ipam_pool_id = aws_vpc_ipam_pool.this.id\n\n  depends_on = [\n    aws_vpc_ipam_pool_cidr.this\n  ]\n}\n\n# IPv6\nresource \"aws_vpc_ipam_pool\" \"ipv6\" {\n  description                       = \"IPv6 pool\"\n  address_family                    = \"ipv6\"\n  ipam_scope_id                     = aws_vpc_ipam.this.public_default_scope_id\n  locale                            = local.region\n  allocation_default_netmask_length = 56\n  publicly_advertisable             = false\n  aws_service                       = \"ec2\"\n\n  tags = local.tags\n}\n\n# # Requires having a CIDR plus its message and signature\n# resource \"aws_vpc_ipam_pool_cidr\" \"ipv6\" {\n#   ipam_pool_id = aws_vpc_ipam_pool.ipv6.id\n#   cidr         = var.ipv6_cidr\n\n#   cidr_authorization_context {\n#     message   = var.message\n#     signature = var.signature\n#   }\n# }\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/examples/ipam/main.tf", "category": "networking", "authentic": true}}
{"prompt": "Write a Terraform module for AWS infrastructure", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  name   = \"ex-${basename(path.cwd)}\"\n  region = \"eu-west-1\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Example    = local.name\n    GithubRepo = \"terraform-aws-vpc\"\n    GithubOrg  = \"terraform-aws-modules\"\n  }\n}\n\n################################################################################\n# VPC Module\n################################################################################\n\nmodule \"vpc\" {\n  source = \"../../\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n\n  vpc_block_public_access_options = {\n    internet_gateway_block_mode = \"block-bidirectional\"\n  }\n\n  vpc_block_public_access_exclusions = {\n    exclude_vpc = {\n      exclude_vpc                     = true\n      internet_gateway_exclusion_mode = \"allow-bidirectional\"\n    }\n  }\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/examples/block-public-access/main.tf", "category": "module", "authentic": true}}
{"prompt": "Create a Terraform configuration for infrastructure storage bucket", "completion": "```hcl\n# VPC flow log - Cloudwatch logs (default)\noutput \"vpc_with_flow_logs_cloudwatch_logs_default_vpc_flow_log_id\" {\n  description = \"The ID of the Flow Log resource\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs_default.vpc_flow_log_id\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_default_vpc_flow_log_destination_arn\" {\n  description = \"The ARN of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs_default.vpc_flow_log_destination_arn\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_default_vpc_flow_log_destination_type\" {\n  description = \"The type of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs_default.vpc_flow_log_destination_type\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_default_vpc_flow_log_cloudwatch_iam_role_arn\" {\n  description = \"The ARN of the IAM role used when pushing logs to Cloudwatch log group\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs_default.vpc_flow_log_cloudwatch_iam_role_arn\n}\n\n# VPC flow log - Cloudwatch logs (created separately)\noutput \"vpc_with_flow_logs_cloudwatch_logs_vpc_flow_log_id\" {\n  description = \"The ID of the Flow Log resource\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs.vpc_flow_log_id\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_vpc_flow_log_destination_arn\" {\n  description = \"The ARN of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs.vpc_flow_log_destination_arn\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_vpc_flow_log_destination_type\" {\n  description = \"The type of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs.vpc_flow_log_destination_type\n}\n\noutput \"vpc_with_flow_logs_cloudwatch_logs_vpc_flow_log_cloudwatch_iam_role_arn\" {\n  description = \"The ARN of the IAM role used when pushing logs to Cloudwatch log group\"\n  value       = module.vpc_with_flow_logs_cloudwatch_logs.vpc_flow_log_cloudwatch_iam_role_arn\n}\n\n# VPC flow log - S3 bucket\noutput \"vpc_flow_logs_s3_bucket_vpc_flow_log_id\" {\n  description = \"The ID of the Flow Log resource\"\n  value       = module.vpc_with_flow_logs_s3_bucket.vpc_flow_log_id\n}\n\noutput \"vpc_flow_logs_s3_bucket_vpc_flow_log_destination_arn\" {\n  description = \"The ARN of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_s3_bucket.vpc_flow_log_destination_arn\n}\n\noutput \"vpc_flow_logs_s3_bucket_vpc_flow_log_destination_type\" {\n  description = \"The type of the destination for VPC Flow Logs\"\n  value       = module.vpc_with_flow_logs_s3_bucket.vpc_flow_log_destination_type\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-vpc/examples/vpc-flow-logs/outputs.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS Kubernetes cluster", "completion": "```hcl\nlocals {\n  dualstack_oidc_issuer_url = try(replace(replace(aws_eks_cluster.this[0].identity[0].oidc[0].issuer, \"https://oidc.eks.\", \"https://oidc-eks.\"), \".amazonaws.com/\", \".api.aws/\"), null)\n}\n\n################################################################################\n# Cluster\n################################################################################\n\noutput \"cluster_arn\" {\n  description = \"The Amazon Resource Name (ARN) of the cluster\"\n  value       = try(aws_eks_cluster.this[0].arn, null)\n\n  depends_on = [\n    aws_eks_access_entry.this,\n    aws_eks_access_policy_association.this,\n  ]\n}\n\noutput \"cluster_certificate_authority_data\" {\n  description = \"Base64 encoded certificate data required to communicate with the cluster\"\n  value       = try(aws_eks_cluster.this[0].certificate_authority[0].data, null)\n\n  depends_on = [\n    aws_eks_access_entry.this,\n    aws_eks_access_policy_association.this,\n  ]\n}\n\noutput \"cluster_endpoint\" {\n  description = \"Endpoint for your Kubernetes API server\"\n  value       = try(aws_eks_cluster.this[0].endpoint, null)\n\n  depends_on = [\n    aws_eks_access_entry.this,\n    aws_eks_access_policy_association.this,\n  ]\n}\n\noutput \"cluster_id\" {\n  description = \"The ID of the EKS cluster. Note: currently a value is returned only for local EKS clusters created on Outposts\"\n  value       = try(aws_eks_cluster.this[0].cluster_id, \"\")\n}\n\noutput \"cluster_name\" {\n  description = \"The name of the EKS cluster\"\n  value       = try(aws_eks_cluster.this[0].name, \"\")\n\n  depends_on = [\n    aws_eks_access_entry.this,\n    aws_eks_access_policy_association.this,\n  ]\n}\n\noutput \"cluster_oidc_issuer_url\" {\n  description = \"The URL on the EKS cluster for the OpenID Connect identity provider\"\n  value       = try(aws_eks_cluster.this[0].identity[0].oidc[0].issuer, null)\n}\n\noutput \"cluster_dualstack_oidc_issuer_url\" {\n  description = \"Dual-stack compatible URL on the EKS cluster for the OpenID Connect identity provider\"\n  value       = local.dualstack_oidc_issuer_url\n}\n\noutput \"cluster_version\" {\n  description = \"The Kubernetes version for the cluster\"\n  value       = try(aws_eks_cluster.this[0].version, null)\n}\n\noutput \"cluster_platform_version\" {\n  description = \"Platform version for the cluster\"\n  value       = try(aws_eks_cluster.this[0].platform_version, null)\n}\n\noutput \"cluster_status\" {\n  description = \"Status of the EKS cluster. One of `CREATING`, `ACTIVE`, `DELETING`, `FAILED`\"\n  value       = try(aws_eks_cluster.this[0].status, null)\n}\n\noutput \"cluster_primary_security_group_id\" {\n  description = \"Cluster security group that was created by Amazon EKS for the cluster. Managed node groups use this security group for control-plane-to-data-plane communication. Referred to as 'Cluster security group' in the EKS console\"\n  value       = try(aws_eks_cluster.this[0].vpc_config[0].cluster_security_group_id, null)\n}\n\noutput \"cluster_service_cidr\" {\n  description = \"The CIDR block where Kubernetes pod and service IP addresses are assigned from\"\n  value       = var.cluster_ip_family == \"ipv6\" ? try(aws_eks_cluster.this[0].kubernetes_network_config[0].service_ipv6_cidr, null) : try(aws_eks_cluster.this[0].kubernetes_network_config[0].service_ipv4_cidr, null)\n}\n\noutput \"cluster_ip_family\" {\n  description = \"The IP family used by the cluster (e.g. `ipv4` or `ipv6`)\"\n  value       = try(aws_eks_cluster.this[0].kubernetes_network_config[0].ip_family, null)\n}\n\n################################################################################\n# Access Entry\n################################################################################\n\noutput \"access_entries\" {\n  description = \"Map of access entries created and their attributes\"\n  value       = aws_eks_access_entry.this\n}\n\noutput \"access_policy_associations\" {\n  description = \"Map of eks cluster access policy associations created and their attributes\"\n  value       = aws_eks_access_policy_association.this\n}\n\n################################################################################\n# KMS Key\n################################################################################\n\noutput \"kms_key_arn\" {\n  description = \"The Amazon Resource Name (ARN) of the key\"\n  value       = module.kms.key_arn\n}\n\noutput \"kms_key_id\" {\n  description = \"The globally unique identifier for the key\"\n  value       = module.kms.key_id\n}\n\noutput \"kms_key_policy\" {\n  description = \"The IAM resource policy set on the key\"\n  value       = module.kms.key_policy\n}\n\n################################################################################\n# Cluster Security Group\n################################################################################\n\noutput \"cluster_security_group_arn\" {\n  description = \"Amazon Resource Name (ARN) of the cluster security group\"\n  value       = try(aws_security_group.cluster[0].arn, null)\n}\n\noutput \"cluster_security_group_id\" {\n  description = \"ID of the cluster security group\"\n  value       = try(aws_security_group.cluster[0].id, null)\n}\n\n################################################################################\n# Node Security Group\n################################################################################\n\noutput \"node_security_group_arn\" {\n  description = \"Amazon Resource Name (ARN) of the node shared security group\"\n  value       = try(aws_security_group.node[0].arn, null)\n}\n\noutput \"node_security_group_id\" {\n  description = \"ID of the node shared security group\"\n  value       = try(aws_security_group.node[0].id, null)\n}\n\n################################################################################\n# IRSA\n################################################################################\n\noutput \"oidc_provider\" {\n  description = \"The OpenID Connect identity provider (issuer URL without leading `https://`)\"\n  value       = try(replace(aws_eks_cluster.this[0].identity[0].oidc[0].issuer, \"https://\", \"\"), null)\n}\n\noutput \"oidc_provider_arn\" {\n  description = \"The ARN of the OIDC Provider if `enable_irsa = true`\"\n  value       = try(aws_iam_openid_connect_provider.oidc_provider[0].arn, null)\n}\n\noutput \"cluster_tls_certificate_sha1_fingerprint\" {\n  description = \"The SHA1 fingerprint of the public key of the cluster's certificate\"\n  value       = try(data.tls_certificate.this[0].certificates[0].sha1_fingerprint, null)\n}\n\n################################################################################\n# IAM Role\n################################################################################\n\noutput \"cluster_iam_role_name\" {\n  description = \"Cluster IAM role name\"\n  value       = try(aws_iam_role.this[0].name, null)\n}\n\noutput \"cluster_iam_role_arn\" {\n  description = \"Cluster IAM role ARN\"\n  value       = try(aws_iam_role.this[0].arn, null)\n}\n\noutput \"cluster_iam_role_unique_id\" {\n  description = \"Stable and unique string identifying the IAM role\"\n  value       = try(aws_iam_role.this[0].unique_id, null)\n}\n\n################################################################################\n# EKS Auto Node IAM Role\n################################################################################\n\noutput \"node_iam_role_name\" {\n  description = \"EKS Auto node IAM role name\"\n  value       = try(aws_iam_role.eks_auto[0].name, null)\n}\n\noutput \"node_iam_role_arn\" {\n  description = \"EKS Auto node IAM role ARN\"\n  value       = try(aws_iam_role.eks_auto[0].arn, null)\n}\n\noutput \"node_iam_role_unique_id\" {\n  description = \"Stable and unique string identifying the IAM role\"\n  value       = try(aws_iam_role.eks_auto[0].unique_id, null)\n}\n\n################################################################################\n# EKS Addons\n################################################################################\n\noutput \"cluster_addons\" {\n  description = \"Map of attribute maps for all EKS cluster addons enabled\"\n  value       = merge(aws_eks_addon.this, aws_eks_addon.before_compute)\n}\n\n################################################################################\n# EKS Identity Provider\n################################################################################\n\noutput \"cluster_identity_providers\" {\n  description = \"Map of attribute maps for all EKS identity providers enabled\"\n  value       = aws_eks_identity_provider_config.this\n}\n\n################################################################################\n# CloudWatch Log Group\n################################################################################\n\noutput \"cloudwatch_log_group_name\" {\n  description = \"Name of cloudwatch log group created\"\n  value       = try(aws_cloudwatch_log_group.this[0].name, null)\n}\n\noutput \"cloudwatch_log_group_arn\" {\n  description = \"Arn of cloudwatch log group created\"\n  value       = try(aws_cloudwatch_log_group.this[0].arn, null)\n}\n\n################################################################################\n# Fargate Profile\n################################################################################\n\noutput \"fargate_profiles\" {\n  description = \"Map of attribute maps for all EKS Fargate Profiles created\"\n  value       = module.fargate_profile\n}\n\n################################################################################\n# EKS Managed Node Group\n################################################################################\n\noutput \"eks_managed_node_groups\" {\n  description = \"Map of attribute maps for all EKS managed node groups created\"\n  value       = module.eks_managed_node_group\n}\n\noutput \"eks_managed_node_groups_autoscaling_group_names\" {\n  description = \"List of the autoscaling group names created by EKS managed node groups\"\n  value       = compact(flatten([for group in module.eks_managed_node_group : group.node_group_autoscaling_group_names]))\n}\n\n################################################################################\n# Self Managed Node Group\n################################################################################\n\noutput \"self_managed_node_groups\" {\n  description = \"Map of attribute maps for all self managed node groups created\"\n  value       = module.self_managed_node_group\n}\n\noutput \"self_managed_node_groups_autoscaling_group_names\" {\n  description = \"List of the autoscaling group names created by self-managed node groups\"\n  value       = compact([for group in module.self_managed_node_group : group.autoscaling_group_name])\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/outputs.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Create a Terraform configuration for infrastructure Kubernetes cluster", "completion": "```hcl\n################################################################################\n# Cluster\n################################################################################\n\noutput \"cluster_arn\" {\n  description = \"The Amazon Resource Name (ARN) of the cluster\"\n  value       = module.eks.cluster_arn\n}\n\noutput \"cluster_certificate_authority_data\" {\n  description = \"Base64 encoded certificate data required to communicate with the cluster\"\n  value       = module.eks.cluster_certificate_authority_data\n}\n\noutput \"cluster_endpoint\" {\n  description = \"Endpoint for your Kubernetes API server\"\n  value       = module.eks.cluster_endpoint\n}\n\noutput \"cluster_id\" {\n  description = \"The ID of the EKS cluster. Note: currently a value is returned only for local EKS clusters created on Outposts\"\n  value       = module.eks.cluster_id\n}\n\noutput \"cluster_name\" {\n  description = \"The name of the EKS cluster\"\n  value       = module.eks.cluster_name\n}\n\noutput \"cluster_oidc_issuer_url\" {\n  description = \"The URL on the EKS cluster for the OpenID Connect identity provider\"\n  value       = module.eks.cluster_oidc_issuer_url\n}\n\noutput \"cluster_dualstack_oidc_issuer_url\" {\n  description = \"Dual-stack compatible URL on the EKS cluster for the OpenID Connect identity provider\"\n  value       = module.eks.cluster_dualstack_oidc_issuer_url\n}\n\noutput \"cluster_platform_version\" {\n  description = \"Platform version for the cluster\"\n  value       = module.eks.cluster_platform_version\n}\n\noutput \"cluster_status\" {\n  description = \"Status of the EKS cluster. One of `CREATING`, `ACTIVE`, `DELETING`, `FAILED`\"\n  value       = module.eks.cluster_status\n}\n\noutput \"cluster_primary_security_group_id\" {\n  description = \"Cluster security group that was created by Amazon EKS for the cluster. Managed node groups use this security group for control-plane-to-data-plane communication. Referred to as 'Cluster security group' in the EKS console\"\n  value       = module.eks.cluster_primary_security_group_id\n}\n\noutput \"cluster_service_cidr\" {\n  description = \"The CIDR block where Kubernetes pod and service IP addresses are assigned from\"\n  value       = module.eks.cluster_service_cidr\n}\n\noutput \"cluster_ip_family\" {\n  description = \"The IP family used by the cluster (e.g. `ipv4` or `ipv6`)\"\n  value       = module.eks.cluster_ip_family\n}\n\n################################################################################\n# Access Entry\n################################################################################\n\noutput \"access_entries\" {\n  description = \"Map of access entries created and their attributes\"\n  value       = module.eks.access_entries\n}\n\n################################################################################\n# KMS Key\n################################################################################\n\noutput \"kms_key_arn\" {\n  description = \"The Amazon Resource Name (ARN) of the key\"\n  value       = module.eks.kms_key_arn\n}\n\noutput \"kms_key_id\" {\n  description = \"The globally unique identifier for the key\"\n  value       = module.eks.kms_key_id\n}\n\noutput \"kms_key_policy\" {\n  description = \"The IAM resource policy set on the key\"\n  value       = module.eks.kms_key_policy\n}\n\n################################################################################\n# Security Group\n################################################################################\n\noutput \"cluster_security_group_arn\" {\n  description = \"Amazon Resource Name (ARN) of the cluster security group\"\n  value       = module.eks.cluster_security_group_arn\n}\n\noutput \"cluster_security_group_id\" {\n  description = \"ID of the cluster security group\"\n  value       = module.eks.cluster_security_group_id\n}\n\n################################################################################\n# Node Security Group\n################################################################################\n\noutput \"node_security_group_arn\" {\n  description = \"Amazon Resource Name (ARN) of the node shared security group\"\n  value       = module.eks.node_security_group_arn\n}\n\noutput \"node_security_group_id\" {\n  description = \"ID of the node shared security group\"\n  value       = module.eks.node_security_group_id\n}\n\n################################################################################\n# IRSA\n################################################################################\n\noutput \"oidc_provider\" {\n  description = \"The OpenID Connect identity provider (issuer URL without leading `https://`)\"\n  value       = module.eks.oidc_provider\n}\n\noutput \"oidc_provider_arn\" {\n  description = \"The ARN of the OIDC Provider if `enable_irsa = true`\"\n  value       = module.eks.oidc_provider_arn\n}\n\noutput \"cluster_tls_certificate_sha1_fingerprint\" {\n  description = \"The SHA1 fingerprint of the public key of the cluster's certificate\"\n  value       = module.eks.cluster_tls_certificate_sha1_fingerprint\n}\n\n################################################################################\n# IAM Role\n################################################################################\n\noutput \"cluster_iam_role_name\" {\n  description = \"Cluster IAM role name\"\n  value       = module.eks.cluster_iam_role_name\n}\n\noutput \"cluster_iam_role_arn\" {\n  description = \"Cluster IAM role ARN\"\n  value       = module.eks.cluster_iam_role_arn\n}\n\noutput \"cluster_iam_role_unique_id\" {\n  description = \"Stable and unique string identifying the IAM role\"\n  value       = module.eks.cluster_iam_role_unique_id\n}\n\n################################################################################\n# EKS Auto Node IAM Role\n################################################################################\n\noutput \"node_iam_role_name\" {\n  description = \"EKS Auto node IAM role name\"\n  value       = module.eks.node_iam_role_name\n}\n\noutput \"node_iam_role_arn\" {\n  description = \"EKS Auto node IAM role ARN\"\n  value       = module.eks.node_iam_role_arn\n}\n\noutput \"node_iam_role_unique_id\" {\n  description = \"Stable and unique string identifying the IAM role\"\n  value       = module.eks.node_iam_role_unique_id\n}\n\n################################################################################\n# EKS Addons\n################################################################################\n\noutput \"cluster_addons\" {\n  description = \"Map of attribute maps for all EKS cluster addons enabled\"\n  value       = module.eks.cluster_addons\n}\n\n################################################################################\n# EKS Identity Provider\n################################################################################\n\noutput \"cluster_identity_providers\" {\n  description = \"Map of attribute maps for all EKS identity providers enabled\"\n  value       = module.eks.cluster_identity_providers\n}\n\n################################################################################\n# CloudWatch Log Group\n################################################################################\n\noutput \"cloudwatch_log_group_name\" {\n  description = \"Name of cloudwatch log group created\"\n  value       = module.eks.cloudwatch_log_group_name\n}\n\noutput \"cloudwatch_log_group_arn\" {\n  description = \"Arn of cloudwatch log group created\"\n  value       = module.eks.cloudwatch_log_group_arn\n}\n\n################################################################################\n# Fargate Profile\n################################################################################\n\noutput \"fargate_profiles\" {\n  description = \"Map of attribute maps for all EKS Fargate Profiles created\"\n  value       = module.eks.fargate_profiles\n}\n\n################################################################################\n# EKS Managed Node Group\n################################################################################\n\noutput \"eks_managed_node_groups\" {\n  description = \"Map of attribute maps for all EKS managed node groups created\"\n  value       = module.eks.eks_managed_node_groups\n}\n\noutput \"eks_managed_node_groups_autoscaling_group_names\" {\n  description = \"List of the autoscaling group names created by EKS managed node groups\"\n  value       = module.eks.eks_managed_node_groups_autoscaling_group_names\n}\n\n################################################################################\n# Self Managed Node Group\n################################################################################\n\noutput \"self_managed_node_groups\" {\n  description = \"Map of attribute maps for all self managed node groups created\"\n  value       = module.eks.self_managed_node_groups\n}\n\noutput \"self_managed_node_groups_autoscaling_group_names\" {\n  description = \"List of the autoscaling group names created by self-managed node groups\"\n  value       = module.eks.self_managed_node_groups_autoscaling_group_names\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/examples/eks-auto-mode/outputs.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS Kubernetes cluster", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {\n  # Exclude local zones\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\nlocals {\n  name            = \"ex-${basename(path.cwd)}\"\n  cluster_version = \"1.33\"\n  region          = \"us-west-2\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Test       = local.name\n    GithubRepo = \"terraform-aws-eks\"\n    GithubOrg  = \"terraform-aws-modules\"\n  }\n}\n\n################################################################################\n# EKS Module\n################################################################################\n\nmodule \"eks\" {\n  source = \"../..\"\n\n  cluster_name                   = local.name\n  cluster_version                = local.cluster_version\n  cluster_endpoint_public_access = true\n\n  enable_cluster_creator_admin_permissions = true\n\n  cluster_compute_config = {\n    enabled    = true\n    node_pools = [\"general-purpose\"]\n  }\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  tags = local.tags\n}\n\nmodule \"disabled_eks\" {\n  source = \"../..\"\n\n  create = false\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n  public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 48)]\n  intra_subnets   = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 52)]\n\n  enable_nat_gateway = true\n  single_nat_gateway = true\n\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = 1\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\" = 1\n  }\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/examples/eks-auto-mode/main.tf", "category": "orchestration", "authentic": true}}
{"prompt": "Write a Terraform module for infrastructure infrastructure", "completion": "```hcl\nmodule \"eks_al2023\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"~> 20.0\"\n\n  cluster_name    = \"${local.name}-al2023\"\n  cluster_version = \"1.33\"\n\n  # EKS Addons\n  cluster_addons = {\n    coredns                = {}\n    eks-pod-identity-agent = {}\n    kube-proxy             = {}\n    vpc-cni                = {}\n  }\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  self_managed_node_groups = {\n    example = {\n      ami_type      = \"AL2023_x86_64_STANDARD\"\n      instance_type = \"m6i.large\"\n\n      min_size = 2\n      max_size = 5\n      # This value is ignored after the initial creation\n      # https://github.com/bryantbiggs/eks-desired-size-hack\n      desired_size = 2\n\n      # This is not required - demonstrates how to pass additional configuration to nodeadm\n      # Ref https://awslabs.github.io/amazon-eks-ami/nodeadm/doc/api/\n      cloudinit_pre_nodeadm = [\n        {\n          content_type = \"application/node.eks.aws\"\n          content      = <<-EOT\n            ---\n            apiVersion: node.eks.aws/v1alpha1\n            kind: NodeConfig\n            spec:\n              kubelet:\n                config:\n                  shutdownGracePeriod: 30s\n                  featureGates:\n                    DisableKubeletCloudCredentialProviders: true\n          EOT\n        }\n      ]\n    }\n  }\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/examples/self-managed-node-group/eks-al2023.tf", "category": "module", "authentic": true}}
{"prompt": "Write a Terraform module for infrastructure infrastructure", "completion": "```hcl\nmodule \"eks_bottlerocket\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"~> 20.0\"\n\n  cluster_name    = \"${local.name}-bottlerocket\"\n  cluster_version = \"1.33\"\n\n  # EKS Addons\n  cluster_addons = {\n    coredns                = {}\n    eks-pod-identity-agent = {}\n    kube-proxy             = {}\n    vpc-cni                = {}\n  }\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  self_managed_node_groups = {\n    example = {\n      ami_type      = \"BOTTLEROCKET_x86_64\"\n      instance_type = \"m6i.large\"\n\n      min_size = 2\n      max_size = 5\n      # This value is ignored after the initial creation\n      # https://github.com/bryantbiggs/eks-desired-size-hack\n      desired_size = 2\n\n      # This is not required - demonstrates how to pass additional configuration\n      # Ref https://bottlerocket.dev/en/os/1.19.x/api/settings/\n      bootstrap_extra_args = <<-EOT\n        # The admin host container provides SSH access and runs with \"superpowers\".\n        # It is disabled by default, but can be disabled explicitly.\n        [settings.host-containers.admin]\n        enabled = false\n\n        # The control host container provides out-of-band access via SSM.\n        # It is enabled by default, and can be disabled if you do not expect to use SSM.\n        # This could leave you with no way to access the API and change settings on an existing node!\n        [settings.host-containers.control]\n        enabled = true\n\n        # extra args added\n        [settings.kernel]\n        lockdown = \"integrity\"\n      EOT\n    }\n  }\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-eks/examples/self-managed-node-group/eks-bottlerocket.tf", "category": "module", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure database", "completion": "```hcl\noutput \"enhanced_monitoring_iam_role_name\" {\n  description = \"The name of the monitoring role\"\n  value       = module.db_instance.enhanced_monitoring_iam_role_name\n}\n\noutput \"enhanced_monitoring_iam_role_arn\" {\n  description = \"The Amazon Resource Name (ARN) specifying the monitoring role\"\n  value       = module.db_instance.enhanced_monitoring_iam_role_arn\n}\n\noutput \"db_instance_address\" {\n  description = \"The address of the RDS instance\"\n  value       = module.db_instance.db_instance_address\n}\n\noutput \"db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = module.db_instance.db_instance_arn\n}\n\noutput \"db_instance_availability_zone\" {\n  description = \"The availability zone of the RDS instance\"\n  value       = module.db_instance.db_instance_availability_zone\n}\n\noutput \"db_instance_endpoint\" {\n  description = \"The connection endpoint\"\n  value       = module.db_instance.db_instance_endpoint\n}\n\noutput \"db_listener_endpoint\" {\n  description = \"Specifies the listener connection endpoint for SQL Server Always On\"\n  value       = module.db_instance.db_listener_endpoint\n}\n\noutput \"db_instance_engine\" {\n  description = \"The database engine\"\n  value       = module.db_instance.db_instance_engine\n}\n\noutput \"db_instance_engine_version_actual\" {\n  description = \"The running version of the database\"\n  value       = module.db_instance.db_instance_engine_version_actual\n}\n\noutput \"db_instance_hosted_zone_id\" {\n  description = \"The canonical hosted zone ID of the DB instance (to be used in a Route 53 Alias record)\"\n  value       = module.db_instance.db_instance_hosted_zone_id\n}\n\noutput \"db_instance_identifier\" {\n  description = \"The RDS instance identifier\"\n  value       = module.db_instance.db_instance_identifier\n}\n\noutput \"db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = module.db_instance.db_instance_resource_id\n}\n\noutput \"db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = module.db_instance.db_instance_status\n}\n\noutput \"db_instance_name\" {\n  description = \"The database name\"\n  value       = module.db_instance.db_instance_name\n}\n\noutput \"db_instance_username\" {\n  description = \"The master username for the database\"\n  value       = module.db_instance.db_instance_username\n  sensitive   = true\n}\n\noutput \"db_instance_domain\" {\n  description = \"The ID of the Directory Service Active Directory domain the instance is joined to\"\n  value       = module.db_instance.db_instance_domain\n}\n\noutput \"db_instance_domain_auth_secret_arn\" {\n  description = \"The ARN for the Secrets Manager secret with the self managed Active Directory credentials for the user joining the domain\"\n  value       = module.db_instance.db_instance_domain_auth_secret_arn\n}\n\noutput \"db_instance_domain_dns_ips\" {\n  description = \"The IPv4 DNS IP addresses of your primary and secondary self managed Active Directory domain controllers\"\n  value       = module.db_instance.db_instance_domain_dns_ips\n}\n\noutput \"db_instance_domain_fqdn\" {\n  description = \"The fully qualified domain name (FQDN) of an self managed Active Directory domain\"\n  value       = module.db_instance.db_instance_domain_fqdn\n}\n\noutput \"db_instance_domain_iam_role_name\" {\n  description = \"The name of the IAM role to be used when making API calls to the Directory Service\"\n  value       = module.db_instance.db_instance_domain_iam_role_name\n}\n\noutput \"db_instance_domain_ou\" {\n  description = \"The self managed Active Directory organizational unit for your DB instance to join\"\n  value       = module.db_instance.db_instance_domain_ou\n}\n\noutput \"db_instance_port\" {\n  description = \"The database port\"\n  value       = module.db_instance.db_instance_port\n}\n\noutput \"db_instance_ca_cert_identifier\" {\n  description = \"Specifies the identifier of the CA certificate for the DB instance\"\n  value       = module.db_instance.db_instance_ca_cert_identifier\n}\n\noutput \"db_instance_master_user_secret_arn\" {\n  description = \"The ARN of the master user secret (Only available when manage_master_user_password is set to true)\"\n  value       = module.db_instance.db_instance_master_user_secret_arn\n}\n\noutput \"db_subnet_group_id\" {\n  description = \"The db subnet group name\"\n  value       = module.db_subnet_group.db_subnet_group_id\n}\n\noutput \"db_subnet_group_arn\" {\n  description = \"The ARN of the db subnet group\"\n  value       = module.db_subnet_group.db_subnet_group_arn\n}\n\noutput \"db_parameter_group_id\" {\n  description = \"The db parameter group id\"\n  value       = module.db_parameter_group.db_parameter_group_id\n}\n\noutput \"db_parameter_group_arn\" {\n  description = \"The ARN of the db parameter group\"\n  value       = module.db_parameter_group.db_parameter_group_arn\n}\n\n# DB option group\noutput \"db_option_group_id\" {\n  description = \"The db option group id\"\n  value       = module.db_option_group.db_option_group_id\n}\n\noutput \"db_option_group_arn\" {\n  description = \"The ARN of the db option group\"\n  value       = module.db_option_group.db_option_group_arn\n}\n\n################################################################################\n# CloudWatch Log Group\n################################################################################\n\noutput \"db_instance_cloudwatch_log_groups\" {\n  description = \"Map of CloudWatch log groups created and their attributes\"\n  value       = module.db_instance.db_instance_cloudwatch_log_groups\n}\n\n################################################################################\n# DB Instance Role Association\n################################################################################\n\noutput \"db_instance_role_associations\" {\n  description = \"A map of DB Instance Identifiers and IAM Role ARNs separated by a comma\"\n  value       = module.db_instance_role_association\n}\n\n################################################################################\n# Managed Secret Rotation\n################################################################################\n\noutput \"db_instance_secretsmanager_secret_rotation_enabled\" {\n  description = \"Specifies whether automatic rotation is enabled for the secret\"\n  value       = module.db_instance.db_instance_secretsmanager_secret_rotation_enabled\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/outputs.tf", "category": "database", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure database", "completion": "```hcl\n# Master\noutput \"master_db_instance_address\" {\n  description = \"The address of the RDS instance\"\n  value       = module.master.db_instance_address\n}\n\noutput \"master_db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = module.master.db_instance_arn\n}\n\noutput \"master_db_instance_availability_zone\" {\n  description = \"The availability zone of the RDS instance\"\n  value       = module.master.db_instance_availability_zone\n}\n\noutput \"master_db_instance_endpoint\" {\n  description = \"The connection endpoint\"\n  value       = module.master.db_instance_endpoint\n}\n\noutput \"master_db_instance_engine\" {\n  description = \"The database engine\"\n  value       = module.master.db_instance_engine\n}\n\noutput \"master_db_instance_engine_version_actual\" {\n  description = \"The running version of the database\"\n  value       = module.master.db_instance_engine_version_actual\n}\n\noutput \"master_db_instance_hosted_zone_id\" {\n  description = \"The canonical hosted zone ID of the DB instance (to be used in a Route 53 Alias record)\"\n  value       = module.master.db_instance_hosted_zone_id\n}\n\noutput \"master_db_instance_identifier\" {\n  description = \"The RDS instance identifier\"\n  value       = module.master.db_instance_identifier\n}\n\noutput \"master_db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = module.master.db_instance_resource_id\n}\n\noutput \"master_db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = module.master.db_instance_status\n}\n\noutput \"master_db_instance_name\" {\n  description = \"The database name\"\n  value       = module.master.db_instance_name\n}\n\noutput \"master_db_instance_username\" {\n  description = \"The master username for the database\"\n  value       = module.master.db_instance_username\n  sensitive   = true\n}\n\noutput \"master_db_instance_port\" {\n  description = \"The database port\"\n  value       = module.master.db_instance_port\n}\n\noutput \"master_db_subnet_group_id\" {\n  description = \"The db subnet group name\"\n  value       = module.master.db_subnet_group_id\n}\n\noutput \"master_db_subnet_group_arn\" {\n  description = \"The ARN of the db subnet group\"\n  value       = module.master.db_subnet_group_arn\n}\n\noutput \"master_db_instance_cloudwatch_log_groups\" {\n  description = \"Map of CloudWatch log groups created and their attributes\"\n  value       = module.master.db_instance_cloudwatch_log_groups\n}\n\n# Replica\noutput \"replica_db_instance_address\" {\n  description = \"The address of the RDS instance\"\n  value       = module.replica.db_instance_address\n}\n\noutput \"replica_db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = module.replica.db_instance_arn\n}\n\noutput \"replica_db_instance_availability_zone\" {\n  description = \"The availability zone of the RDS instance\"\n  value       = module.replica.db_instance_availability_zone\n}\n\noutput \"replica_db_instance_endpoint\" {\n  description = \"The connection endpoint\"\n  value       = module.replica.db_instance_endpoint\n}\n\noutput \"replica_db_instance_engine\" {\n  description = \"The database engine\"\n  value       = module.replica.db_instance_engine\n}\n\noutput \"replica_db_instance_engine_version_actual\" {\n  description = \"The running version of the database\"\n  value       = module.replica.db_instance_engine_version_actual\n}\n\noutput \"replica_db_instance_hosted_zone_id\" {\n  description = \"The canonical hosted zone ID of the DB instance (to be used in a Route 53 Alias record)\"\n  value       = module.replica.db_instance_hosted_zone_id\n}\n\noutput \"replica_db_instance_identifier\" {\n  description = \"The RDS instance identifier\"\n  value       = module.replica.db_instance_identifier\n}\n\noutput \"replica_db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = module.replica.db_instance_resource_id\n}\n\noutput \"replica_db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = module.replica.db_instance_status\n}\n\noutput \"replica_db_instance_name\" {\n  description = \"The database name\"\n  value       = module.replica.db_instance_name\n}\n\noutput \"replica_db_instance_username\" {\n  description = \"The replica username for the database\"\n  value       = module.replica.db_instance_username\n  sensitive   = true\n}\n\noutput \"replica_db_instance_port\" {\n  description = \"The database port\"\n  value       = module.replica.db_instance_port\n}\n\noutput \"replica_db_instance_cloudwatch_log_groups\" {\n  description = \"Map of CloudWatch log groups created and their attributes\"\n  value       = module.replica.db_instance_cloudwatch_log_groups\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/examples/cross-region-replica-postgres/outputs.tf", "category": "database", "authentic": true}}
{"prompt": "Write a Terraform configuration for AWS database", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region1\n}\n\nprovider \"aws\" {\n  alias  = \"region2\"\n  region = local.region2\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\nlocals {\n  name    = \"replica-postgresql\"\n  region1 = \"eu-west-1\"\n  region2 = \"eu-central-1\"\n\n  tags = {\n    Name       = local.name\n    Example    = local.name\n    Repository = \"https://github.com/terraform-aws-modules/terraform-aws-rds\"\n  }\n\n  engine                = \"postgres\"\n  engine_version        = \"14\"\n  family                = \"postgres14\" # DB parameter group\n  major_engine_version  = \"14\"         # DB option group\n  instance_class        = \"db.t4g.large\"\n  allocated_storage     = 20\n  max_allocated_storage = 100\n  port                  = 5432\n}\n\n################################################################################\n# Master DB\n################################################################################\n\nmodule \"master\" {\n  source = \"../../\"\n\n  identifier = \"${local.name}-master\"\n\n  engine               = local.engine\n  engine_version       = local.engine_version\n  family               = local.family\n  major_engine_version = local.major_engine_version\n  instance_class       = local.instance_class\n\n  allocated_storage     = local.allocated_storage\n  max_allocated_storage = local.max_allocated_storage\n\n  db_name  = \"replicaPostgresql\"\n  username = \"replica_postgresql\"\n  port     = local.port\n\n  multi_az               = true\n  db_subnet_group_name   = module.vpc_region1.database_subnet_group_name\n  vpc_security_group_ids = [module.security_group_region1.security_group_id]\n\n  maintenance_window              = \"Mon:00:00-Mon:03:00\"\n  backup_window                   = \"03:00-06:00\"\n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n\n  # Backups are required in order to create a replica\n  backup_retention_period = 1\n  skip_final_snapshot     = true\n  deletion_protection     = false\n\n  tags = local.tags\n}\n\n################################################################################\n# Replica DB\n################################################################################\n\nmodule \"kms\" {\n  source      = \"terraform-aws-modules/kms/aws\"\n  version     = \"~> 1.0\"\n  description = \"KMS key for cross region replica DB\"\n\n  # Aliases\n  aliases                 = [local.name]\n  aliases_use_name_prefix = true\n\n  key_owners = [data.aws_caller_identity.current.id]\n\n  tags = local.tags\n\n  providers = {\n    aws = aws.region2\n  }\n}\n\nmodule \"replica\" {\n  source = \"../../\"\n\n  providers = {\n    aws = aws.region2\n  }\n\n  identifier = \"${local.name}-replica\"\n\n  # Source database. For cross-region use db_instance_arn\n  replicate_source_db = module.master.db_instance_arn\n\n  engine               = local.engine\n  engine_version       = local.engine_version\n  family               = local.family\n  major_engine_version = local.major_engine_version\n  instance_class       = local.instance_class\n  kms_key_id           = module.kms.key_arn\n\n  allocated_storage     = local.allocated_storage\n  max_allocated_storage = local.max_allocated_storage\n\n  # Not supported with replicas\n  manage_master_user_password = false\n\n  # Username and password should not be set for replicas\n  port = local.port\n\n  # parameter group for replica is inherited from the source database\n  create_db_parameter_group = false\n\n  multi_az               = false\n  vpc_security_group_ids = [module.security_group_region2.security_group_id]\n\n  maintenance_window              = \"Tue:00:00-Tue:03:00\"\n  backup_window                   = \"03:00-06:00\"\n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n\n  backup_retention_period = 0\n  skip_final_snapshot     = true\n  deletion_protection     = false\n\n  # Specify a subnet group created in the replica region\n  db_subnet_group_name = module.vpc_region2.database_subnet_group_name\n\n  tags = local.tags\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\nmodule \"vpc_region1\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = \"10.100.0.0/18\"\n\n  azs              = [\"${local.region1}a\", \"${local.region1}b\", \"${local.region1}c\"]\n  public_subnets   = [\"10.100.0.0/24\", \"10.100.1.0/24\", \"10.100.2.0/24\"]\n  private_subnets  = [\"10.100.3.0/24\", \"10.100.4.0/24\", \"10.100.5.0/24\"]\n  database_subnets = [\"10.100.7.0/24\", \"10.100.8.0/24\", \"10.100.9.0/24\"]\n\n  create_database_subnet_group = true\n\n  tags = local.tags\n}\n\nmodule \"security_group_region1\" {\n  source  = \"terraform-aws-modules/security-group/aws\"\n  version = \"~> 5.0\"\n\n  name        = local.name\n  description = \"Replica PostgreSQL example security group\"\n  vpc_id      = module.vpc_region1.vpc_id\n\n  # ingress\n  ingress_with_cidr_blocks = [\n    {\n      from_port   = 5432\n      to_port     = 5432\n      protocol    = \"tcp\"\n      description = \"PostgreSQL access from within VPC\"\n      cidr_blocks = module.vpc_region1.vpc_cidr_block\n    },\n  ]\n\n  tags = local.tags\n}\n\nmodule \"vpc_region2\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  providers = {\n    aws = aws.region2\n  }\n\n  name = local.name\n  cidr = \"10.100.0.0/18\"\n\n  azs              = [\"${local.region2}a\", \"${local.region2}b\", \"${local.region2}c\"]\n  public_subnets   = [\"10.100.0.0/24\", \"10.100.1.0/24\", \"10.100.2.0/24\"]\n  private_subnets  = [\"10.100.3.0/24\", \"10.100.4.0/24\", \"10.100.5.0/24\"]\n  database_subnets = [\"10.100.7.0/24\", \"10.100.8.0/24\", \"10.100.9.0/24\"]\n\n  create_database_subnet_group = true\n\n  tags = local.tags\n}\n\nmodule \"security_group_region2\" {\n  source  = \"terraform-aws-modules/security-group/aws\"\n  version = \"~> 5.0\"\n\n  providers = {\n    aws = aws.region2\n  }\n\n  name        = local.name\n  description = \"Replica PostgreSQL example security group\"\n  vpc_id      = module.vpc_region2.vpc_id\n\n  # ingress\n  ingress_with_cidr_blocks = [\n    {\n      from_port   = 5432\n      to_port     = 5432\n      protocol    = \"tcp\"\n      description = \"PostgreSQL access from within VPC\"\n      cidr_blocks = module.vpc_region2.vpc_cidr_block\n    },\n  ]\n\n  tags = local.tags\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/examples/cross-region-replica-postgres/main.tf", "category": "database", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure database", "completion": "```hcl\noutput \"db_instance_address\" {\n  description = \"The address of the RDS instance\"\n  value       = module.db.db_instance_address\n}\n\noutput \"db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = module.db.db_instance_arn\n}\n\noutput \"db_instance_availability_zone\" {\n  description = \"The availability zone of the RDS instance\"\n  value       = module.db.db_instance_availability_zone\n}\n\noutput \"db_instance_endpoint\" {\n  description = \"The connection endpoint\"\n  value       = module.db.db_instance_endpoint\n}\n\noutput \"db_instance_engine\" {\n  description = \"The database engine\"\n  value       = module.db.db_instance_engine\n}\n\noutput \"db_instance_engine_version_actual\" {\n  description = \"The running version of the database\"\n  value       = module.db.db_instance_engine_version_actual\n}\n\noutput \"db_instance_hosted_zone_id\" {\n  description = \"The canonical hosted zone ID of the DB instance (to be used in a Route 53 Alias record)\"\n  value       = module.db.db_instance_hosted_zone_id\n}\n\noutput \"db_instance_identifier\" {\n  description = \"The RDS instance identifier\"\n  value       = module.db.db_instance_identifier\n}\n\noutput \"db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = module.db.db_instance_resource_id\n}\n\noutput \"db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = module.db.db_instance_status\n}\n\noutput \"db_instance_name\" {\n  description = \"The database name\"\n  value       = module.db.db_instance_name\n}\n\noutput \"db_instance_username\" {\n  description = \"The master username for the database\"\n  value       = module.db.db_instance_username\n  sensitive   = true\n}\n\noutput \"db_instance_port\" {\n  description = \"The database port\"\n  value       = module.db.db_instance_port\n}\n\noutput \"db_subnet_group_id\" {\n  description = \"The db subnet group name\"\n  value       = module.db.db_subnet_group_id\n}\n\noutput \"db_subnet_group_arn\" {\n  description = \"The ARN of the db subnet group\"\n  value       = module.db.db_subnet_group_arn\n}\n\noutput \"db_parameter_group_id\" {\n  description = \"The db parameter group id\"\n  value       = module.db.db_parameter_group_id\n}\n\noutput \"db_parameter_group_arn\" {\n  description = \"The ARN of the db parameter group\"\n  value       = module.db.db_parameter_group_arn\n}\n\noutput \"db_enhanced_monitoring_iam_role_arn\" {\n  description = \"The Amazon Resource Name (ARN) specifying the monitoring role\"\n  value       = module.db.enhanced_monitoring_iam_role_arn\n}\n\noutput \"db_instance_cloudwatch_log_groups\" {\n  description = \"Map of CloudWatch log groups created and their attributes\"\n  value       = module.db.db_instance_cloudwatch_log_groups\n}\n\noutput \"db_instance_master_user_secret_arn\" {\n  description = \"The ARN of the master user secret (Only available when manage_master_user_password is set to true)\"\n  value       = module.db.db_instance_master_user_secret_arn\n}\n\noutput \"db_instance_role_associations\" {\n  description = \"The outputs for the role associations\"\n  value       = module.db.db_instance_role_associations\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/examples/role-association-postgres/outputs.tf", "category": "database", "authentic": true}}
{"prompt": "Write a Terraform configuration for AWS database", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_caller_identity\" \"current\" {}\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  name   = \"role-association-invoke-lambda\"\n  region = \"eu-west-1\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Name       = local.name\n    Example    = local.name\n    Repository = \"https://github.com/terraform-aws-modules/terraform-aws-rds\"\n  }\n}\n\n################################################################################\n# RDS Module\n################################################################################\n\nmodule \"db\" {\n  source = \"../../\"\n\n  identifier = local.name\n\n  # All available versions: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html#PostgreSQL.Concepts\n  engine               = \"postgres\"\n  engine_version       = \"14\"\n  family               = \"postgres14\" # DB parameter group\n  major_engine_version = \"14\"         # DB option group\n  instance_class       = \"db.t4g.large\"\n\n  allocated_storage = 20\n\n  # NOTE: Do NOT use 'user' as the value for 'username' as it throws:\n  # \"Error creating DB Instance: InvalidParameterValue: MasterUsername\n  # user cannot be used as it is a reserved word used by the engine\"\n  db_name  = \"RoleAssociationInvokeLambda\"\n  username = \"role_association_invoke_lambda\"\n  port     = 5432\n\n  multi_az               = true\n  db_subnet_group_name   = module.vpc.database_subnet_group\n  vpc_security_group_ids = [module.security_group.security_group_id]\n\n  maintenance_window      = \"Mon:00:00-Mon:03:00\"\n  backup_window           = \"03:00-06:00\"\n  backup_retention_period = 0\n\n  deletion_protection = false\n\n  # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/PostgreSQL-Lambda.html\n  db_instance_role_associations = {\n    Lambda = module.rds_invoke_lambda_role.iam_role_arn\n  }\n\n  parameters = [\n    {\n      name         = \"rds.custom_dns_resolution\"\n      value        = 1\n      apply_method = \"pending-reboot\"\n    },\n  ]\n\n  tags = local.tags\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs              = local.azs\n  public_subnets   = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k)]\n  private_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 3)]\n  database_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 6)]\n\n  create_database_subnet_group = true\n  enable_nat_gateway           = true\n\n  tags = local.tags\n}\n\nmodule \"security_group\" {\n  source  = \"terraform-aws-modules/security-group/aws\"\n  version = \"~> 4.0\"\n\n  name        = local.name\n  description = \"Complete PostgreSQL example security group\"\n  vpc_id      = module.vpc.vpc_id\n\n  # ingress\n  ingress_with_cidr_blocks = [\n    {\n      from_port   = 5432\n      to_port     = 5432\n      protocol    = \"tcp\"\n      description = \"PostgreSQL access from within VPC\"\n      cidr_blocks = module.vpc.vpc_cidr_block\n    },\n  ]\n\n  # egress\n  egress_with_cidr_blocks = [\n    {\n      from_port   = 443\n      to_port     = 443\n      protocol    = \"tcp\"\n      description = \"Egress to AWS Lambda VPC\"\n      cidr_blocks = \"0.0.0.0/0\"\n    }\n  ]\n\n  tags = local.tags\n}\n\nmodule \"rds_invoke_lambda_role\" {\n  source  = \"terraform-aws-modules/iam/aws//modules/iam-assumable-role\"\n  version = \"~> 5.28.0\"\n\n  create_role       = true\n  role_requires_mfa = false\n\n  role_name_prefix = local.name\n\n  custom_role_policy_arns = [\n    module.rds_invoke_lambda_policy.arn\n  ]\n  custom_role_trust_policy = data.aws_iam_policy_document.rds_invoke_lambda_assume_role.json\n}\n\nmodule \"rds_invoke_lambda_policy\" {\n  source  = \"terraform-aws-modules/iam/aws//modules/iam-policy\"\n  version = \"~> 5.28.0\"\n\n  name        = \"${local.name}-policy\"\n  path        = \"/\"\n  description = \"Invoke Lambda from RDS Postgresql policy\"\n\n  policy = data.aws_iam_policy_document.rds_invoke_lambda.json\n}\n\ndata \"aws_iam_policy_document\" \"rds_invoke_lambda\" {\n  statement {\n    sid = \"InvokeLambda\"\n    actions = [\n      \"lambda:InvokeFunction\"\n    ]\n    resources = [\n      module.lambda.lambda_function_arn\n    ]\n  }\n}\n\ndata \"aws_iam_policy_document\" \"rds_invoke_lambda_assume_role\" {\n  statement {\n    sid = \"AssumeRole\"\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"rds.amazonaws.com\"]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      values   = [data.aws_caller_identity.current.id]\n      variable = \"aws:SourceAccount\"\n    }\n\n    effect = \"Allow\"\n\n    actions = [\"sts:AssumeRole\"]\n  }\n}\n\nmodule \"lambda\" {\n  source  = \"terraform-aws-modules/lambda/aws\"\n  version = \"~> 6.0\"\n\n  function_name = local.name\n  handler       = \"lambda_function.lambda_handler\"\n  runtime       = \"python3.10\"\n  source_path   = \"${path.module}/fixtures/lambda_function.py\"\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-rds/examples/role-association-postgres/main.tf", "category": "database", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\noutput \"s3_bucket_id\" {\n  description = \"The name of the bucket.\"\n  value       = try(aws_s3_bucket.this[0].id, aws_s3_directory_bucket.this[0].bucket, \"\")\n}\n\noutput \"s3_bucket_arn\" {\n  description = \"The ARN of the bucket. Will be of format arn:aws:s3:::bucketname.\"\n  value       = try(aws_s3_bucket.this[0].arn, \"\")\n}\n\noutput \"s3_bucket_bucket_domain_name\" {\n  description = \"The bucket domain name. Will be of format bucketname.s3.amazonaws.com.\"\n  value       = try(aws_s3_bucket.this[0].bucket_domain_name, \"\")\n}\n\noutput \"s3_bucket_bucket_regional_domain_name\" {\n  description = \"The bucket region-specific domain name. The bucket domain name including the region name, please refer here for format. Note: The AWS CloudFront allows specifying S3 region-specific endpoint when creating S3 origin, it will prevent redirect issues from CloudFront to S3 Origin URL.\"\n  value       = try(aws_s3_bucket.this[0].bucket_regional_domain_name, \"\")\n}\n\noutput \"s3_bucket_hosted_zone_id\" {\n  description = \"The Route 53 Hosted Zone ID for this bucket's region.\"\n  value       = try(aws_s3_bucket.this[0].hosted_zone_id, \"\")\n}\n\noutput \"s3_bucket_lifecycle_configuration_rules\" {\n  description = \"The lifecycle rules of the bucket, if the bucket is configured with lifecycle rules. If not, this will be an empty string.\"\n  value       = try(aws_s3_bucket_lifecycle_configuration.this[0].rule, \"\")\n}\n\noutput \"s3_bucket_policy\" {\n  description = \"The policy of the bucket, if the bucket is configured with a policy. If not, this will be an empty string.\"\n  value       = try(aws_s3_bucket_policy.this[0].policy, \"\")\n}\n\noutput \"s3_bucket_region\" {\n  description = \"The AWS region this bucket resides in.\"\n  value       = try(aws_s3_bucket.this[0].bucket_region, \"\")\n}\n\noutput \"s3_bucket_website_endpoint\" {\n  description = \"The website endpoint, if the bucket is configured with a website. If not, this will be an empty string.\"\n  value       = try(aws_s3_bucket_website_configuration.this[0].website_endpoint, \"\")\n}\n\noutput \"s3_bucket_website_domain\" {\n  description = \"The domain of the website endpoint, if the bucket is configured with a website. If not, this will be an empty string. This is used to create Route 53 alias records.\"\n  value       = try(aws_s3_bucket_website_configuration.this[0].website_domain, \"\")\n}\n\noutput \"s3_directory_bucket_name\" {\n  description = \"Name of the directory bucket.\"\n  value       = try(aws_s3_directory_bucket.this[0].bucket, null)\n}\n\noutput \"s3_directory_bucket_arn\" {\n  description = \"ARN of the directory bucket.\"\n  value       = try(aws_s3_directory_bucket.this[0].arn, null)\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/outputs.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\nprovider \"aws\" {\n  region = \"eu-west-1\"\n\n  # Make it faster by skipping something\n  skip_metadata_api_check     = true\n  skip_region_validation      = true\n  skip_credentials_validation = true\n}\n\nlocals {\n  bucket_name = \"s3-table-bucket-${random_pet.this.id}\"\n}\n\ndata \"aws_caller_identity\" \"this\" {}\n\ndata \"aws_region\" \"this\" {}\n\nmodule \"table_bucket\" {\n  source = \"../../modules/table-bucket\"\n\n  table_bucket_name = local.bucket_name\n\n  encryption_configuration = {\n    kms_key_arn   = module.kms.key_arn\n    sse_algorithm = \"aws:kms\"\n  }\n\n  maintenance_configuration = {\n    iceberg_unreferenced_file_removal = {\n      status = \"enabled\"\n\n      settings = {\n        non_current_days  = 7\n        unreferenced_days = 3\n      }\n    }\n  }\n\n  create_table_bucket_policy = true\n  table_bucket_policy_statements = [\n    {\n      effect = \"Allow\"\n      principals = [{\n        type        = \"AWS\"\n        identifiers = [data.aws_caller_identity.this.account_id]\n      }]\n      actions = [\n        \"s3tables:GetTableData\",\n        \"s3tables:GetTableMetadataLocation\"\n      ]\n    }\n  ]\n\n  tables = {\n    table1 = {\n      format    = \"ICEBERG\"\n      namespace = aws_s3tables_namespace.namespace.namespace\n\n      encryption_configuration = {\n        kms_key_arn   = module.kms.key_arn\n        sse_algorithm = \"aws:kms\"\n      }\n\n      maintenance_configuration = {\n        iceberg_compaction = {\n          status = \"enabled\"\n          settings = {\n            target_file_size_mb = 64\n          }\n        }\n        iceberg_snapshot_management = {\n          status = \"enabled\"\n          settings = {\n            max_snapshot_age_hours = 40\n            min_snapshots_to_keep  = 3\n          }\n        }\n      }\n\n      create_table_policy = true\n      policy_statements = [\n        {\n          sid    = \"DeleteTable\"\n          effect = \"Allow\"\n          principals = [{\n            type        = \"AWS\"\n            identifiers = [data.aws_caller_identity.this.account_id]\n          }]\n          actions = [\n            \"s3tables:DeleteTable\",\n            \"s3tables:UpdateTableMetadataLocation\",\n            \"s3tables:PutTableData\",\n            \"s3tables:GetTableMetadataLocation\"\n          ]\n        }\n      ]\n    }\n    table2 = {\n      format    = \"ICEBERG\"\n      name      = \"table2\"\n      namespace = aws_s3tables_namespace.namespace.namespace\n    }\n    table3 = {\n      format    = \"ICEBERG\"\n      namespace = aws_s3tables_namespace.namespace.namespace\n\n      metadata = {\n        iceberg = {\n          schema = {\n            field = {\n              created_at = {\n                name     = \"created_at\"\n                type     = \"timestamp\"\n                required = false\n              }\n              price = {\n                type     = \"decimal(10,2)\"\n                required = false\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\nresource \"random_pet\" \"this\" {\n  length = 2\n}\n\nresource \"aws_s3tables_namespace\" \"namespace\" {\n  namespace        = \"example_namespace\"\n  table_bucket_arn = module.table_bucket.s3_table_bucket_arn\n}\n\nmodule \"kms\" {\n  source  = \"terraform-aws-modules/kms/aws\"\n  version = \"~> 3.0\"\n\n  description             = \"Key example for s3 table buckets\"\n  deletion_window_in_days = 7\n\n  # https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-kms-permissions.html\n  key_statements = [\n    {\n      sid = \"s3TablesMaintenancePolicy\"\n      actions = [\n        \"kms:GenerateDataKey\",\n        \"kms:Decrypt\"\n      ]\n      resources = [\"*\"]\n\n      principals = [\n        {\n          type        = \"Service\"\n          identifiers = [\"maintenance.s3tables.amazonaws.com\"]\n        }\n      ]\n\n      conditions = [\n        {\n          test     = \"StringEquals\"\n          variable = \"aws:SourceAccount\"\n          values = [\n            data.aws_caller_identity.this.id,\n          ]\n        },\n        {\n          test     = \"StringLike\"\n          variable = \"kms:EncryptionContext:aws:s3:arn\"\n          values = [\n            \"arn:aws:s3tables:${data.aws_region.this.region}:${data.aws_caller_identity.this.account_id}:bucket/${local.bucket_name}/table/*\"\n          ]\n        }\n      ]\n    }\n  ]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/examples/table-bucket/main.tf", "category": "storage", "authentic": true}}
{"prompt": "Write a Terraform configuration for AWS compute instances", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n\n  # Make it faster by skipping something\n  skip_metadata_api_check     = true\n  skip_region_validation      = true\n  skip_credentials_validation = true\n}\n\nlocals {\n  bucket_name = \"s3-bucket-${random_pet.this.id}\"\n  region      = \"eu-west-1\"\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_canonical_user_id\" \"current\" {}\n\ndata \"aws_cloudfront_log_delivery_canonical_user_id\" \"cloudfront\" {}\n\nresource \"random_pet\" \"this\" {\n  length = 2\n}\n\nresource \"aws_kms_key\" \"objects\" {\n  description             = \"KMS key is used to encrypt bucket objects\"\n  deletion_window_in_days = 7\n}\n\nresource \"aws_iam_role\" \"this\" {\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\ndata \"aws_iam_policy_document\" \"bucket_policy\" {\n  statement {\n    principals {\n      type        = \"AWS\"\n      identifiers = [aws_iam_role.this.arn]\n    }\n\n    actions = [\n      \"s3:ListBucket\",\n    ]\n\n    resources = [\n      \"arn:aws:s3:::${local.bucket_name}\",\n    ]\n  }\n}\n\nmodule \"log_bucket\" {\n  source = \"../../\"\n\n  bucket        = \"logs-${random_pet.this.id}\"\n  force_destroy = true\n\n  control_object_ownership = true\n\n  attach_elb_log_delivery_policy        = true\n  attach_lb_log_delivery_policy         = true\n  attach_access_log_delivery_policy     = true\n  attach_cloudtrail_log_delivery_policy = true\n  attach_deny_insecure_transport_policy = true\n  attach_require_latest_tls_policy      = true\n  attach_waf_log_delivery_policy        = true\n\n  access_log_delivery_policy_source_accounts      = [data.aws_caller_identity.current.account_id]\n  access_log_delivery_policy_source_buckets       = [\"arn:aws:s3:::${local.bucket_name}\"]\n  access_log_delivery_policy_source_organizations = [\"o-123456\"]\n  lb_log_delivery_policy_source_organizations     = [\"o-123456\"]\n}\n\nmodule \"cloudfront_log_bucket\" {\n  source = \"../../\"\n\n  bucket                   = \"cloudfront-logs-${random_pet.this.id}\"\n  control_object_ownership = true\n  object_ownership         = \"ObjectWriter\"\n\n  grant = [{\n    type       = \"CanonicalUser\"\n    permission = \"FULL_CONTROL\"\n    id         = data.aws_canonical_user_id.current.id\n    }, {\n    type       = \"CanonicalUser\"\n    permission = \"FULL_CONTROL\"\n    id         = data.aws_cloudfront_log_delivery_canonical_user_id.cloudfront.id # Ref. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html\n    }\n  ]\n\n  owner = {\n    id = data.aws_canonical_user_id.current.id\n  }\n\n  force_destroy = true\n}\n\nmodule \"simple_bucket\" {\n  source = \"../../\"\n\n  bucket = \"simple-${random_pet.this.id}\"\n\n  force_destroy = true\n}\n\nmodule \"s3_bucket\" {\n  source = \"../../\"\n\n  bucket = local.bucket_name\n\n  force_destroy       = true\n  acceleration_status = \"Suspended\"\n  request_payer       = \"BucketOwner\"\n\n  tags = {\n    Owner = \"Anton\"\n  }\n\n  # Note: Object Lock configuration can be enabled only on new buckets\n  # https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_object_lock_configuration\n  object_lock_enabled = true\n  object_lock_configuration = {\n    rule = {\n      default_retention = {\n        mode = \"GOVERNANCE\"\n        days = 1\n      }\n    }\n  }\n\n  # Bucket policies\n  attach_policy                             = true\n  policy                                    = data.aws_iam_policy_document.bucket_policy.json\n  attach_deny_insecure_transport_policy     = true\n  attach_require_latest_tls_policy          = true\n  attach_deny_incorrect_encryption_headers  = true\n  attach_deny_incorrect_kms_key_sse         = true\n  allowed_kms_key_arn                       = aws_kms_key.objects.arn\n  attach_deny_unencrypted_object_uploads    = true\n  attach_deny_ssec_encrypted_object_uploads = true\n\n  # S3 bucket-level Public Access Block configuration (by default now AWS has made this default as true for S3 bucket-level block public access)\n  # block_public_acls       = true\n  # block_public_policy     = true\n  # ignore_public_acls      = true\n  # restrict_public_buckets = true\n\n  # S3 Bucket Ownership Controls\n  # https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_ownership_controls\n  control_object_ownership = true\n  object_ownership         = \"BucketOwnerPreferred\"\n\n  expected_bucket_owner                  = data.aws_caller_identity.current.account_id\n  transition_default_minimum_object_size = \"varies_by_storage_class\"\n\n  acl = \"private\" # \"acl\" conflicts with \"grant\" and \"owner\"\n\n  logging = {\n    target_bucket = module.log_bucket.s3_bucket_id\n    target_prefix = \"log/\"\n    target_object_key_format = {\n      partitioned_prefix = {\n        partition_date_source = \"DeliveryTime\" # \"EventTime\"\n      }\n      # simple_prefix = {}\n    }\n  }\n\n  versioning = {\n    status     = true\n    mfa_delete = false\n  }\n\n  website = {\n    # conflicts with \"error_document\"\n    #        redirect_all_requests_to = {\n    #          host_name = \"https://modules.tf\"\n    #        }\n\n    index_document = \"index.html\"\n    error_document = \"error.html\"\n    routing_rules = [{\n      condition = {\n        key_prefix_equals = \"docs/\"\n      },\n      redirect = {\n        replace_key_prefix_with = \"documents/\"\n      }\n      }, {\n      condition = {\n        http_error_code_returned_equals = 404\n        key_prefix_equals               = \"archive/\"\n      },\n      redirect = {\n        host_name          = \"archive.myhost.com\"\n        http_redirect_code = 301\n        protocol           = \"https\"\n        replace_key_with   = \"not_found.html\"\n      }\n    }]\n  }\n\n  server_side_encryption_configuration = {\n    rule = {\n      apply_server_side_encryption_by_default = {\n        kms_master_key_id = aws_kms_key.objects.arn\n        sse_algorithm     = \"aws:kms\"\n      }\n    }\n  }\n\n  cors_rule = [\n    {\n      allowed_methods = [\"PUT\", \"POST\"]\n      allowed_origins = [\"https://modules.tf\", \"https://terraform-aws-modules.modules.tf\"]\n      allowed_headers = [\"*\"]\n      expose_headers  = [\"ETag\"]\n      max_age_seconds = 3000\n      }, {\n      allowed_methods = [\"PUT\"]\n      allowed_origins = [\"https://example.com\"]\n      allowed_headers = [\"*\"]\n      expose_headers  = [\"ETag\"]\n      max_age_seconds = 3000\n    }\n  ]\n\n  lifecycle_rule = [\n    {\n      id      = \"log\"\n      enabled = true\n\n      filter = {\n        tags = {\n          some    = \"value\"\n          another = \"value2\"\n        }\n      }\n\n      transition = [\n        {\n          days          = 30\n          storage_class = \"ONEZONE_IA\"\n          }, {\n          days          = 60\n          storage_class = \"GLACIER\"\n        }\n      ]\n\n      #        expiration = {\n      #          days = 90\n      #          expired_object_delete_marker = true\n      #        }\n\n      #        noncurrent_version_expiration = {\n      #          newer_noncurrent_versions = 5\n      #          days = 30\n      #        }\n    },\n    {\n      id                                     = \"log1\"\n      enabled                                = true\n      abort_incomplete_multipart_upload_days = 7\n\n      noncurrent_version_transition = [\n        {\n          days          = 30\n          storage_class = \"STANDARD_IA\"\n        },\n        {\n          days          = 60\n          storage_class = \"ONEZONE_IA\"\n        },\n        {\n          days          = 90\n          storage_class = \"GLACIER\"\n        },\n      ]\n\n      noncurrent_version_expiration = {\n        days = 300\n      }\n    },\n    {\n      id      = \"log2\"\n      enabled = true\n\n      filter = {\n        prefix                   = \"log1/\"\n        object_size_greater_than = 200000\n        object_size_less_than    = 500000\n        tags = {\n          some    = \"value\"\n          another = \"value2\"\n        }\n      }\n\n      noncurrent_version_transition = [\n        {\n          days          = 30\n          storage_class = \"STANDARD_IA\"\n        },\n      ]\n\n      noncurrent_version_expiration = {\n        days = 300\n      }\n    },\n  ]\n\n  intelligent_tiering = {\n    general = {\n      status = \"Enabled\"\n      filter = {\n        prefix = \"/\"\n        tags = {\n          Environment = \"dev\"\n        }\n      }\n      tiering = {\n        ARCHIVE_ACCESS = {\n          days = 180\n        }\n      }\n    },\n    documents = {\n      status = false\n      filter = {\n        prefix = \"documents/\"\n      }\n      tiering = {\n        ARCHIVE_ACCESS = {\n          days = 125\n        }\n        DEEP_ARCHIVE_ACCESS = {\n          days = 200\n        }\n      }\n    }\n  }\n\n  metric_configuration = [\n    {\n      name = \"documents\"\n      filter = {\n        prefix = \"documents/\"\n        tags = {\n          priority = \"high\"\n        }\n      }\n    },\n    {\n      name = \"other\"\n      filter = {\n        tags = {\n          production = \"true\"\n        }\n      }\n    },\n    {\n      name = \"all\"\n    }\n  ]\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/examples/complete/main.tf", "category": "compute", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\nprovider \"aws\" {\n  region = local.region\n\n  # Make it faster by skipping something\n  skip_metadata_api_check     = true\n  skip_region_validation      = true\n  skip_credentials_validation = true\n}\n\nlocals {\n  bucket_name = \"s3-bucket-${random_pet.this.id}\"\n  region      = \"eu-west-1\"\n}\n\nresource \"random_pet\" \"this\" {\n  length = 2\n}\n\nmodule \"s3_bucket\" {\n  source = \"../../\"\n\n  bucket        = local.bucket_name\n  force_destroy = true\n}\n\n#############################################\n# Using packaged function from Lambda module\n#############################################\n\nlocals {\n  package_url = \"https://raw.githubusercontent.com/terraform-aws-modules/terraform-aws-lambda/master/examples/fixtures/python3.8-zip/existing_package.zip\"\n  downloaded  = \"downloaded_package_${md5(local.package_url)}.zip\"\n}\n\nresource \"null_resource\" \"download_package\" {\n  triggers = {\n    downloaded = local.downloaded\n  }\n\n  provisioner \"local-exec\" {\n    command = \"curl -L -o ${local.downloaded} ${local.package_url}\"\n  }\n}\n\nmodule \"lambda_function1\" {\n  source  = \"terraform-aws-modules/lambda/aws\"\n  version = \"~> 3.0\"\n\n  function_name = \"${random_pet.this.id}-lambda1\"\n  handler       = \"index.lambda_handler\"\n  runtime       = \"python3.8\"\n\n  create_package         = false\n  local_existing_package = local.downloaded\n}\n\nmodule \"lambda_function2\" {\n  source  = \"terraform-aws-modules/lambda/aws\"\n  version = \"~> 3.0\"\n\n  function_name = \"${random_pet.this.id}-lambda2\"\n  handler       = \"index.lambda_handler\"\n  runtime       = \"python3.8\"\n\n  create_package         = false\n  local_existing_package = local.downloaded\n}\n\nmodule \"sns_topic1\" {\n  source  = \"terraform-aws-modules/sns/aws\"\n  version = \"~> 3.0\"\n\n  name_prefix = \"${random_pet.this.id}-2\"\n}\n\nmodule \"sns_topic2\" {\n  source  = \"terraform-aws-modules/sns/aws\"\n  version = \"~> 3.0\"\n\n  name_prefix = \"${random_pet.this.id}-2\"\n}\n\nresource \"aws_sqs_queue\" \"this\" {\n  count = 2\n  name  = \"${random_pet.this.id}-${count.index}\"\n}\n\n# SQS policy created outside of the module\ndata \"aws_iam_policy_document\" \"sqs_external\" {\n  statement {\n    effect  = \"Allow\"\n    actions = [\"sqs:SendMessage\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"s3.amazonaws.com\"]\n    }\n\n    resources = [aws_sqs_queue.this[0].arn]\n  }\n}\n\nresource \"aws_sqs_queue_policy\" \"allow_external\" {\n  queue_url = aws_sqs_queue.this[0].id\n  policy    = data.aws_iam_policy_document.sqs_external.json\n}\n\nmodule \"all_notifications\" {\n  source = \"../../modules/notification\"\n\n  bucket = module.s3_bucket.s3_bucket_id\n\n  eventbridge = true\n\n  # Common error - Error putting S3 notification configuration: InvalidArgument: Configuration is ambiguously defined. Cannot have overlapping suffixes in two rules if the prefixes are overlapping for the same event type.\n\n  lambda_notifications = {\n    lambda1 = {\n      function_arn  = module.lambda_function1.lambda_function_arn\n      function_name = module.lambda_function1.lambda_function_name\n      events        = [\"s3:ObjectCreated:Put\"]\n      filter_prefix = \"prefix/\"\n      filter_suffix = \".json\"\n    }\n\n    lambda2 = {\n      function_arn  = module.lambda_function2.lambda_function_arn\n      function_name = module.lambda_function2.lambda_function_name\n      events        = [\"s3:ObjectCreated:Post\"]\n    }\n  }\n\n  sqs_notifications = {\n    sqs1 = {\n      queue_arn     = aws_sqs_queue.this[0].arn\n      events        = [\"s3:ObjectCreated:Put\"]\n      filter_prefix = \"prefix2/\"\n      filter_suffix = \".txt\"\n\n      #      queue_id =  aws_sqs_queue.this[0].id // optional\n    }\n  }\n\n  sns_notifications = {\n    sns1 = {\n      topic_arn     = module.sns_topic1.sns_topic_arn\n      events        = [\"s3:ObjectRemoved:Delete\"]\n      filter_prefix = \"prefix3/\"\n      filter_suffix = \".csv\"\n    }\n\n    sns2 = {\n      topic_arn = module.sns_topic2.sns_topic_arn\n      events    = [\"s3:ObjectRemoved:DeleteMarkerCreated\"]\n    }\n  }\n\n  # Creation of policy is handled outside of the module\n  create_sqs_policy = false\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/examples/notification/main.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for AWS storage bucket", "completion": "```hcl\nlocals {\n  region = \"eu-west-1\"\n}\n\nprovider \"aws\" {\n  region = local.region\n\n  # Make it faster by skipping something\n  skip_metadata_api_check     = true\n  skip_region_validation      = true\n  skip_credentials_validation = true\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nmodule \"simple\" {\n  source = \"../../\"\n\n  is_directory_bucket = true\n  bucket              = random_pet.this.id\n  # https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-express-Endpoints.html\n  availability_zone_id = data.aws_availability_zones.available.zone_ids[1]\n}\n\nmodule \"complete\" {\n  source = \"../../\"\n\n  is_directory_bucket = true\n  bucket              = \"${random_pet.this.id}-complete\"\n  # https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-express-Endpoints.html\n  availability_zone_id = data.aws_availability_zones.available.zone_ids[1]\n  server_side_encryption_configuration = {\n    rule = {\n      bucket_key_enabled = true # required for directory buckets\n      apply_server_side_encryption_by_default = {\n        kms_master_key_id = aws_kms_key.objects.arn\n        sse_algorithm     = \"aws:kms\"\n      }\n    }\n  }\n  lifecycle_rule = [\n    {\n      id     = \"test\"\n      status = \"Enabled\"\n      expiration = {\n        days = 7\n      }\n    },\n    {\n      id     = \"logs\"\n      status = \"Enabled\"\n      expiration = {\n        days = 5\n      }\n      filter = {\n        prefix                = \"logs/\"\n        object_size_less_than = 10\n      }\n    },\n    {\n      id     = \"other\"\n      status = \"Enabled\"\n      expiration = {\n        days = 2\n      }\n      filter = {\n        prefix = \"other/\"\n      }\n    }\n  ]\n  attach_policy = true\n  policy        = data.aws_iam_policy_document.bucket_policy.json\n\n  tags = {\n    directory-bucket = true\n  }\n}\n\nresource \"random_pet\" \"this\" {\n  length = 2\n}\n\nresource \"aws_kms_key\" \"objects\" {\n  description             = \"KMS key is used to encrypt bucket objects\"\n  deletion_window_in_days = 7\n}\n\ndata \"aws_iam_policy_document\" \"bucket_policy\" {\n\n  statement {\n    sid    = \"ReadWriteAccess\"\n    effect = \"Allow\"\n\n    actions = [\n      \"s3express:CreateSession\",\n    ]\n\n    resources = [module.complete.s3_directory_bucket_arn]\n\n    principals {\n      identifiers = [data.aws_caller_identity.current.account_id]\n      type        = \"AWS\"\n    }\n  }\n\n  statement {\n    sid    = \"ReadOnlyAccess\"\n    effect = \"Allow\"\n\n    actions = [\n      \"s3express:CreateSession\",\n    ]\n\n    resources = [module.complete.s3_directory_bucket_arn]\n\n    principals {\n      identifiers = [data.aws_caller_identity.current.account_id]\n      type        = \"AWS\"\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      values   = [\"ReadOnly\"]\n      variable = \"s3express:SessionMode\"\n    }\n  }\n}\n```", "metadata": {"source": "real_local_repository", "file_path": "/tmp/tmpr5cy4nrj/terraform-aws-modules_terraform-aws-s3-bucket/examples/directory-bucket/main.tf", "category": "storage", "authentic": true}}
{"prompt": "Create a Terraform configuration for VPC networking", "completion": "```hcl\nresource \"aws_codebuild_project\" \"frontend\" {\n  name          = \"frontend\"\n  build_timeout = \"5\"\n  service_role  = \"${aws_iam_role.frontend_build.arn}\"\n\n  artifacts {\n    type = \"S3\"\n    location = \"frontend.myapp.com\"\n    namespace_type = \"NONE\"\n    packaging = \"NONE\"\n    path = \"public\"\n  }\n\n  environment {\n    compute_type                = \"BUILD_GENERAL1_SMALL\"\n    image                       = \"aws/codebuild/standard:1.0\"\n    type                        = \"LINUX_CONTAINER\"\n    image_pull_credentials_type = \"CODEBUILD\"\n\n    environment_variable {\n      name  = \"SOME_KEY1\"\n      value = \"SOME_VALUE1\"\n    }\n  }\n\n  logs_config {\n    cloudwatch_logs {\n      group_name = \"build\"\n      stream_name = \"frontend-build\"\n    }\n  }\n\n  source {\n    type            = \"GITHUB\"\n    location        = \"https://github.com/MyOrg/my-repo.git\"\n    git_clone_depth = 1\n    report_build_status = true\n    auth {\n      type = \"OAUTH\"\n    }\n  }\n\n  vpc_config {\n    vpc_id = module.vpc.vpc_id\n    subnets = module.vpc.private_subnets\n    security_group_ids = [aws_security_group.build.id]\n  }\n}\n```", "metadata": {"source": "stackoverflow", "question_id": 58321632, "title": "AWS CodeBuild VPC_CLIENT_ERROR: Unexpected EC2 error: UnauthorizedOperation", "score": 22, "category": "storage", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure deployment", "completion": "```hcl\nmodule \"nat\" {\n  source     = \"GoogleCloudPlatform/nat-gateway/google\"\n  region     = \"europe-west1\"\n  network    = \"default\"\n  subnetwork = \"default\"\n}\n\nresource \"google_container_node_pool\" \"cluster_1_np\" {\n  name               = \"cluster-1-np\"\n  region             = \"europe-west1\"\n  cluster            = \"${google_container_cluster.cluster_1.name}\"\n  initial_node_count = 1\n\n  lifecycle {\n    ignore_changes = [\"node_count\"]\n  }\n\n  autoscaling {\n    min_node_count = 1\n    max_node_count = 50\n  }\n\n  management {\n    auto_repair  = true\n    auto_upgrade = true\n  }\n\n  node_config {\n    oauth_scopes = [\n      \"https://www.googleapis.com/auth/compute\",\n      \"https://www.googleapis.com/auth/devstorage.read_only\",\n      \"https://www.googleapis.com/auth/logging.write\",\n      \"https://www.googleapis.com/auth/monitoring\",\n      \"https://www.googleapis.com/auth/pubsub\",\n    ]\n\n    tags = [\"${module.nat.routing_tag_regional}\"]\n  }\n}\n\nresource \"google_container_cluster\" \"cluster_1\" {\n  provider                 = \"google-beta\"\n  name                     = \"cluster-1\"\n  region                   = \"europe-west1\"\n  remove_default_node_pool = true\n\n  private_cluster_config {\n    enable_private_endpoint = false\n    enable_private_nodes    = true\n    master_ipv4_cidr_block  = \"172.16.0.0/28\"\n  }\n\n  ip_allocation_policy {\n    create_subnetwork = true\n  }\n\n  lifecycle {\n    ignore_changes = [\"initial_node_count\", \"network_policy\", \"node_config\", \"node_pool\"]\n  }\n\n  node_pool {\n    name = \"default-pool\"\n  }\n\n  addons_config {\n    http_load_balancing {\n      disabled = false\n    }\n\n    horizontal_pod_autoscaling {\n      disabled = false\n    }\n  }\n\n  master_authorized_networks_config {\n    cidr_blocks = [\n      {\n        cidr_block   = \"<MY_OFFICE_CIDR>\"\n        display_name = \"Office\"\n      },\n    ]\n  }\n}\n```", "metadata": {"source": "stackoverflow", "question_id": 53106222, "title": "Terraformed private GKE cluster automation access", "score": 8, "category": "module", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure deployment", "completion": "```hcl\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n-/+ destroy and then create replacement\n\nTerraform will perform the following actions:\n\n  # module.dev_environment.google_compute_instance.dev_machine must be replaced\n-/+ resource \"google_compute_instance\" \"dev_machine\" {\n      ~ cpu_platform         = \"Intel Broadwell\" -> (known after apply)\n      ~ current_status       = \"RUNNING\" -> (known after apply)\n      ~ deletion_protection  = false -> true\n      - enable_display       = false -> null\n      ~ guest_accelerator    = [] -> (known after apply)\n      ~ id                   = \"<id with project>\" -> (known after apply)\n      ~ instance_id          = \"<instance id>\" -> (known after apply)\n      ~ label_fingerprint    = \"<label fingerprint>\" -> (known after apply)\n      - labels               = {} -> null\n      - metadata             = {} -> null\n      ~ metadata_fingerprint = \"<metadata fingerprint>=\" -> (known after apply)\n      + min_cpu_platform     = (known after apply)\n        name                 = \"dev-machine-pweather\"\n      ~ project              = \"<project id>\" -> (known after apply)\n      - resource_policies    = [] -> null\n      ~ self_link            = \"<project id url>/instances/dev-machine-pweather\" -> (known after apply)\n        tags                 = [\n            \"dev-vm-pweather\",\n        ]\n      ~ tags_fingerprint     = \"<tag fingerprint>\" -> (known after apply)\n      ~ zone                 = \"us-east4-a\" -> (known after apply)\n        # (2 unchanged attributes hidden)\n\n      ~ boot_disk {\n          ~ device_name                = \"persistent-disk-0\" -> (known after apply)\n          + disk_encryption_key_sha256 = (known after apply)\n          + kms_key_self_link          = (known after apply)\n          ~ source                     = \"<project id url>/us-east4-a/disks/dev-machine-pweather\" -> (known after apply)\n            # (2 unchanged attributes hidden)\n\n          ~ initialize_params {\n              ~ image  = \"https://www.googleapis.com/compute/v1/projects/ubuntu-os-pro-cloud/global/images/ubuntu-pro-2004-focal-v20210720\" -> \"ubuntu-os-pro-cloud/ubuntu-pro-2004-lts\" # forces replacement\n              ~ labels = {} -> (known after apply)\n              ~ type   = \"pd-standard\" -> (known after apply)\n                # (1 unchanged attribute hidden)\n            }\n        }\n\n      + confidential_instance_config {\n          + enable_confidential_compute = (known after apply)\n        }\n\n      ~ network_interface {\n          ~ name               = \"nic0\" -> (known after apply)\n          ~ network            = \"<project id url>/global/networks/pweather-vpc\" -> \"pweather-vpc\"\n          ~ network_ip         = \"10.0.0.17\" -> (known after apply)\n          ~ subnetwork         = \"<project id url>/subnetworks/pweather-subnet\" -> \"pweather-subnet\"\n          ~ subnetwork_project = \"<project>\" -> (known after apply)\n\n          ~ access_config {\n              ~ nat_ip       = \"<NAT IP> -> (known after apply)\n              ~ network_tier = \"PREMIUM\" -> (known after apply)\n            }\n        }\n\n      + reservation_affinity {\n          + type = (known after apply)\n\n          + specific_reservation {\n              + key    = (known after apply)\n              + values = (known after apply)\n            }\n        }\n\n      ~ scheduling {\n          ~ automatic_restart   = true -> (known after apply)\n          ~ min_node_cpus       = 0 -> (known after apply)\n          ~ on_host_maintenance = \"MIGRATE\" -> (known after apply)\n          ~ preemptible         = false -> (known after apply)\n\n          + node_affinities {\n              + key      = (known after apply)\n              + operator = (known after apply)\n              + values   = (known after apply)\n            }\n        }\n\n      - shielded_instance_config {\n          - enable_integrity_monitoring = true -> null\n          - enable_secure_boot          = false -> null\n          - enable_vtpm                 = true -> null\n        }\n    }\n\n  # module.dev_environment.google_compute_instance.dev_machine-minor must be replaced\n-/+ resource \"google_compute_instance\" \"dev_machine-minor\" {\n      ~ cpu_platform         = \"Intel Broadwell\" -> (known after apply)\n      ~ current_status       = \"RUNNING\" -> (known after apply)\n      ~ deletion_protection  = false -> true\n      - enable_display       = false -> null\n      ~ guest_accelerator    = [] -> (known after apply)\n      ~ id                   = \"<project id url>/instances/dev-machine-minor-pweather\" -> (known after apply)\n      ~ instance_id          = \"<instance id>\" -> (known after apply)\n      ~ label_fingerprint    = \"<label fingerprint>\" -> (known after apply)\n      - labels               = {} -> null\n      - metadata             = {} -> null\n      ~ metadata_fingerprint = \"udK04sf2kcQ=\" -> (known after apply)\n      + min_cpu_platform     = (known after apply)\n        name                 = \"dev-machine-minor-pweather\"\n      ~ project              = \"<project name>\" -> (known after apply)\n      - resource_policies    = [] -> null\n      ~ self_link            = \"<project id url>/us-east4-a/instances/dev-machine-minor-pweather\" -> (known after apply)\n        tags                 = [\n            \"dev-vm-pweather\",\n        ]\n      ~ tags_fingerprint     = \"<tag fingerprint>\" -> (known after apply)\n      ~ zone                 = \"us-east4-a\" -> (known after apply)\n        # (2 unchanged attributes hidden)\n\n      ~ boot_disk {\n          ~ device_name                = \"persistent-disk-0\" -> (known after apply)\n          + disk_encryption_key_sha256 = (known after apply)\n          + kms_key_self_link          = (known after apply)\n          ~ source                     = \"<project id url>/us-east4-a/disks/dev-machine-minor-pweather\" -> (known after apply)\n            # (2 unchanged attributes hidden)\n\n          ~ initialize_params {\n              ~ image  = \"https://www.googleapis.com/compute/v1/projects/ubuntu-os-pro-cloud/global/images/ubuntu-pro-2004-focal-v20210720\" -> \"ubuntu-os-pro-cloud/ubuntu-pro-2004-lts\" # forces replacement\n              ~ labels = {} -> (known after apply)\n              ~ type   = \"pd-standard\" -> (known after apply)\n                # (1 unchanged attribute hidden)\n            }\n        }\n\n      + confidential_instance_config {\n          + enable_confidential_compute = (known after apply)\n        }\n\n      ~ network_interface {\n          ~ name               = \"nic0\" -> (known after apply)\n          ~ network            = \"<project id url>>/global/networks/pweather-vpc\" -> \"pweather-vpc\"\n          ~ network_ip         = \"10.0.0.16\" -> (known after apply)\n          ~ subnetwork         = \"<project id url>/us-east4/subnetworks/pweather-subnet\" -> \"pweather-subnet\"\n          ~ subnetwork_project = \"<project>\" -> (known after apply)\n\n          ~ access_config {\n              ~ nat_ip       = \"<NAT IP>\" -> (known after apply)\n              ~ network_tier = \"PREMIUM\" -> (known after apply)\n            }\n        }\n\n      + reservation_affinity {\n          + type = (known after apply)\n\n          + specific_reservation {\n              + key    = (known after apply)\n              + values = (known after apply)\n            }\n        }\n\n      ~ scheduling {\n          ~ automatic_restart   = true -> (known after apply)\n          ~ min_node_cpus       = 0 -> (known after apply)\n          ~ on_host_maintenance = \"MIGRATE\" -> (known after apply)\n          ~ preemptible         = false -> (known after apply)\n\n          + node_affinities {\n              + key      = (known after apply)\n              + operator = (known after apply)\n              + values   = (known after apply)\n            }\n        }\n\n      - shielded_instance_config {\n          - enable_integrity_monitoring = true -> null\n          - enable_secure_boot          = false -> null\n          - enable_vtpm                 = true -> null\n        }\n    }\n\nPlan: 2 to add, 0 to change, 2 to destroy.\n\nChanges to Outputs:\n  ~ vm_ip = \"<VM IP>\" -> (known after apply)\n\n------------------------------------------------------------------------\n\nNote: You didn't specify an \"-out\" parameter to save this plan, so Terraform\ncan't guarantee that exactly these actions will be performed if\n\"terraform apply\" is subsequently run.\n```", "metadata": {"source": "stackoverflow", "question_id": 68574608, "title": "Terraform always tries to replace gcp compute instance without changes", "score": 4, "category": "infrastructure", "authentic": true}}
{"prompt": "Write a Terraform configuration for infrastructure deployment", "completion": "```hcl\nprovider \"kubernetes\" {\n  config_path = \"~/.kube/config\"\n}\n\nresource \"kubernetes_namespace\" \"tfs\" {\n  metadata {\n    name = \"tfs\" # terraform-sandbox\n  }\n}\n\nresource \"kubernetes_deployment\" \"golang_webapp\" {\n  metadata {\n    name      = \"golang-webapp\"\n    namespace = \"tfs\"\n    labels = {\n      app = \"webapp\"\n    }\n  }\n  spec {\n    replicas = 3\n    selector {\n      match_labels = {\n        app = \"webapp\"\n      }\n    }\n    template {\n      metadata {\n        labels = {\n          app = \"webapp\"\n        }\n      }\n      spec {\n        container {\n          image             = \"golang-docker-example\"\n          name              = \"golang-webapp\"\n          image_pull_policy = \"Never\" # this is set so that kuberenetes wont try to download the image but use the localy built one\n          liveness_probe {\n            http_get {\n              path = \"/\"\n              port = 8080\n            }\n            initial_delay_seconds = 15\n            period_seconds        = 15\n          }\n\n          readiness_probe {\n            http_get {\n              path = \"/\"\n              port = 8080\n            }\n            initial_delay_seconds = 3\n            period_seconds        = 3\n          }\n        }\n      }\n    }\n  }\n}\n\n\nresource \"kubernetes_service\" \"golang_webapp\" {\n  metadata {\n    name      = \"golang-webapp\"\n    namespace = \"tfs\"\n    labels = {\n      app = \"webapp_ingress\"\n    }\n  }\n  spec {\n    selector = {\n      app = kubernetes_deployment.golang_webapp.metadata.0.labels.app\n    }\n    port {\n      port        = 8080\n      target_port = 8080\n      protocol    = \"TCP\"\n    }\n    # type = \"ClusterIP\"\n    type = \"NodePort\"\n  }\n}\n\nresource \"kubernetes_ingress\" \"main_ingress\" {\n  metadata {\n    name      = \"main-ingress\"\n    namespace = \"tfs\"\n  }\n\n  spec {\n    rule {\n      http {\n        path {\n          backend {\n            service_name = \"golang-webapp\"\n            service_port = 8080\n          }\n          path = \"/golang-webapp\"\n        }\n      }\n    }\n  }\n}\n```", "metadata": {"source": "stackoverflow", "question_id": 70497809, "title": "Terraform fails to create ingress (could not find the requested resource ingresses.extensions)", "score": 15, "category": "orchestration", "authentic": true}}
