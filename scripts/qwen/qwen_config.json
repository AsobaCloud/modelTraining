{
  "model_name": "Qwen3-14B",
  "model_path": "s3://asoba-llm-cache/models/Qwen/Qwen3-14B",
  "model_type": "qwen3",
  "system_prompt_file": "qwen_claude_md_system_prompt.txt",
  
  "model_config": {
    "architectures": ["Qwen3ForCausalLM"],
    "torch_dtype": "bfloat16",
    "max_position_embeddings": 40960,
    "vocab_size": 151936,
    "hidden_size": 5120,
    "num_hidden_layers": 40,
    "num_attention_heads": 40,
    "num_key_value_heads": 8
  },
  
  "generation_config": {
    "max_length": 4096,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 50,
    "repetition_penalty": 1.1,
    "do_sample": true,
    "pad_token_id": 151643,
    "eos_token_id": 151645
  },
  
  "quantization_config": {
    "load_in_8bit": true,
    "llm_int8_threshold": 6.0,
    "llm_int8_skip_modules": ["lm_head"],
    "llm_int8_enable_fp32_cpu_offload": false
  },
  
  "claude_md_integration": {
    "enabled": true,
    "complexity_threshold": {
      "simple": 3,
      "medium": 6,
      "complex": 8
    },
    "workflow_keywords": [
      "production", "enterprise", "scalable", "architecture", "design", 
      "system", "full-stack", "end-to-end", "pipeline", "platform", 
      "microservices", "distributed", "ci/cd", "deployment", "monitoring", "security"
    ]
  },
  
  "deployment_config": {
    "instance_types": ["g5.4xlarge", "g5.2xlarge", "g4dn.2xlarge"],
    "region": "us-east-1",
    "gpu_memory_requirement": "24GB",
    "system_memory_requirement": "64GB"
  }
}